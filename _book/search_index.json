[
["index.html", "数据科学中的 R 语言 前言 关于课程 课件中用到的宏包 RYouWithMe 致谢", " 数据科学中的 R 语言 王敏杰 2020-08-24 前言 你好，这里是四川师范大学研究生公选课《数据科学中的R语言》的课程内容。考虑到大家来自不同的学院，有着不同的学科背景，因此讲授的内容不会太深奥（要有信心喔）。 比如在课程中以下内容就不会出现 \\[ f(x)=\\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2} x^{2}} \\] 而出现更多的是 library(tidyverse) summary_monthly_temp &lt;- weather %&gt;% group_by(month) %&gt;% summarize(mean = mean(temp), std_dev = sd(temp)) 在跟进本课程的同时， 我强烈推荐大家阅读Hadley Wickham的 r4ds这本书 (Grolemund and Wickham 2017)。作者可是2019年8月刚刚获得考普斯总统奖（被誉为统计学的诺贝尔奖）的大神喔，点击这里可以看他照片。 关于课程 1、课程安排是这样的，每个章节研究的内容都是彼此独立的，大家可以单独阅读每章及运行代码。 基础篇 第 1 章介绍数据科学基础 第 2 章介绍R语言基本概念 第 3 章介绍R语言中的子集选取 tidyverse篇 第 4 章介绍可重复性研究 第 5 章介绍数据读入 第 6 章介绍数据规整与数据处理 第 7 章介绍数据框列方向和行方向 第 8 章介绍数据可视化 第 9 章介绍字符串处理 第 10 章介绍因子类型数据 第 11 章介绍函数式编程 第 12 章介绍探索性数据分析1 第 13 章介绍探索性数据分析2 第 14 章介绍探索性数据分析3 第 15 章介绍探索性数据分析4 第 16 章介绍探索性数据分析5 第 17 章介绍探索性数据分析6 第 18 章介绍探索性数据分析7 第 19 章再讲ggplot2 第 20 章ggplot2的主题 第 21 章ggplot2的标度 第 22 章ggplot2的图例 第 23 章让你的数据骚动起来 第 24 章介绍tidyverse中常用技巧 第 25 章介绍简单数据框 建模篇 第 26 章介绍模拟与抽样 第 27 章介绍方差分析 第 28 章介绍线性模型 第 29 章介绍多层线性模型 第 30 章介绍广义线性模型 第 31 章介绍有序logistic回归模型 第 32 章介绍机器学习 第 33 章介绍非标准性评估 应用篇 第 34 章介绍tidyverse进阶 第 35 章介绍tidyverse中行方向的操作 第 36 章介绍tidyverse中的dot 第 37 章介绍网页爬虫 第 38 章介绍社会网络分析 第 39 章介绍文本挖掘 第 40 章介绍时间序列分析 第 41 章介绍地理数据处理 第 42 章介绍我收集的一些有用和有趣的宏包 2、课件源代码和数据 我将持续改进课件，所以欢迎大家提出建议 https://github.com/perlatex/R_for_Data_Science 3、课程视频 部分课程视频放在bilibili网站 4、关于课程目标 课程目标: 熟悉数据科学流程，掌握统计编程技能，能运用探索性分析方法，解决基本的实际应用问题，做到学以致用，不是 learning R，而是 learning with R 授课方式: 边写代码边讲 通过案例式、问题式的方法，增强参与感和目标感 课堂要求 自带电脑，配好运行环境 光看李小龙的电影，是学不会功夫的 知识脚手架 知识脚手架，我个人比较喜欢这个比喻。在教育中，各种知识或技巧就好比建房子用的脚手架，它帮助我们加深理解，逐渐获得独立自主学习的能力。 5、关于如何提问 有的同学，这样一上来就问：老师，我的代码怎么运行不出来呢？或者图省事，干脆手机拍个照片一发。 我想说，要想获得快速的帮助，在问问题之前，请先告诉对方三个信息： 想解决的问题是什么？ 代码是什么？ 报错信息是什么？ 课件中用到的宏包 my_packages &lt;- c( &quot;brms&quot;, &quot;broom&quot;, &quot;broom.mixed&quot;, &quot;corrr&quot;, &quot;countrycode&quot;, &quot;cowplot&quot;, &quot;cranlogs&quot;, &quot;datapasta&quot;, &quot;devtools&quot;, &quot;dplyr&quot;, &quot;forcats&quot;, &quot;gapminder&quot;, &quot;gganimate&quot;, &quot;ggstatsplot&quot;, &quot;ggeffects&quot;, &quot;ggbeeswarm&quot;, &quot;ggforce&quot;, &quot;gghighlight&quot;, &quot;ggplot2&quot;, &quot;ggpubr&quot;, &quot;ggraph&quot;, &quot;ggrepel&quot;, &quot;ggridges&quot;, &quot;ggtext&quot;, &quot;gt&quot;, &quot;gtsummary&quot;, &quot;haven&quot;, &quot;here&quot;, &quot;janitor&quot;, &quot;knitr&quot;, &quot;latex2exp&quot;, &quot;lme4&quot;, &quot;lubridate&quot;, &quot;maps&quot;, &quot;margins&quot;, &quot;MASS&quot;, &quot;modelr&quot;, &quot;naniar&quot;, &quot;nycflights13&quot;, &quot;ordinal&quot;, &quot;pacman&quot;, &quot;paletteer&quot;, &quot;patchwork&quot;, &quot;performance&quot;, &quot;purrr&quot;, &quot;readr&quot;, &quot;readxl&quot;, &quot;remotes&quot;, &quot;reprex&quot;, &quot;rlang&quot;, &quot;rmarkdown&quot;, &quot;rstan&quot;, &quot;rvest&quot;, &quot;scales&quot;, &quot;sf&quot;, &quot;shadowtext&quot;, &quot;showtext&quot;, &quot;slider&quot;, &quot;stars&quot;, &quot;statsExpressions&quot;, &quot;stringr&quot;, &quot;styler&quot;, &quot;tibble&quot;, &quot;tibbletime&quot;, &quot;tidybayes&quot;, &quot;tidygraph&quot;, &quot;tidymodels&quot;, &quot;tidyr&quot;, &quot;tidytext&quot;, &quot;tidyverse&quot;, &quot;tinytex&quot;, &quot;viridis&quot;, &quot;visdat&quot;, &quot;geoshpere&quot;, &quot;ggstatsplot&quot;, &quot;datasauRus&quot;, &quot;ggimage&quot;, &quot;ggthemes&quot;, &quot;pacman&quot; ) install.packages(my_packages, repos = &quot;http://cran.rstudio.com&quot;, dependencies = T) 可能用到的开发版本的宏包 remotes::install_github(&quot;datalorax/equatiomatic&quot;) devtools::install_github(&quot;easystats/report&quot;) devtools::install_github(&quot;kassambara/navdata&quot;) devtools::install_github(&#39;cttobin/ggthemr&#39;) remotes::install_github(&quot;daranzolin/inferregex&quot;) devtools::install_github(&quot;EmilHvitfeldt/gganonymize&quot;) remotes::install_github(&quot;ThinkR-open/remedy&quot;) remotes::install_git(&quot;https://git.rud.is/hrbrmstr/hrbraddins.git&quot;) devtools::install_github(&quot;hadley/emo&quot;) remotes::install_github(&quot;romainfrancois/lay&quot;) remotes::install_github(&quot;kjhealy/covdata&quot;) RYouWithMe 致谢 非常感谢川师研究生院的信任， 有了您的支持，才会有更多的川师学子了解R的美！ 王敏杰 于 川师图书馆某角落 参考文献 "],
["author.html", "作者简介", " 作者简介 王敏杰，四川师范大学研究生公选课《数据科学中的R语言》和《社会科学中的统计学》授课老师，西南交通大学量子物理学博士，爱好数据科学，喜欢用R和Stan统计编程， 联系方式 38552109@qq.com "],
["intro-ds.html", "第 1 章 数据科学与R语言 1.1 什么是数据科学 1.2 什么是R 1.3 R能干什么 1.4 为什么选择 R 1.5 推荐阅读", " 第 1 章 数据科学与R语言 马克思曾说过：“一门科学只有当它达到能够成功运用数学时，才算真正得到发展。”数学为数据科学提供了坚实的理论基础，数据科学也为数学与实际应用之间建立起一个直接的桥梁。 1.1 什么是数据科学 数据科学是综合了统计学、计算机科学和领域知识的交叉学科，其基本内容就是用数据的方法研究科学，用科学的方法研究数据（鄂维南院士）。2010年，Drew Conway画了一张数据科学的韦恩图 从数据科学所涉及的学科领域来看，其知识结构不仅仅包括数学、统计学、计算机科学、信息科学等在内的基础性理论，还应该包括社会学、物理学、情报学、生物医学等在内的专业性领域理论。 （事实上，最重要的最下面那个部分，专业领域的知识） 1.2 什么是R 1.2.1 R那些事 1992年，新西兰奥克兰大学统计学教授 Ross Ihaka 和 Robert Gentleman，为了方便地给学生教授统计学课程，他们设计开发了R语言（他们名字的首字母都是R）。 2000年，R1.0.0 发布 2004年，第一届国际useR!会议（随后每年举办一次） 2005年，ggplot2宏包（2018.8 - 2019.8下载量超过 1.3 亿次） 2012年，R2.15.2 发布 2013年，R3.0.2 发布, CRAN上的宏包数量5026个 2016年，Rstudio公司推出 tidyverse 宏包（数据科学当前最流行的R宏包） 2017年，R3.4.1 发布，CRAN上的宏包数量10875个 2019年，R3.6.1 发布，CRAN上的宏包数量15102个 2020年，R4.0.0 发布，CRAN上的宏包数量16054个 The History of R 1.2.2 R是什么 官网定义：https://www.r-project.org/ R语言是用于统计分析，图形表示和报告的编程语言: R 是一个语言（statistical programming） R 可运行于多种平台之上，包括Windows、UNIX 和 Mac OS X R 拥有顶尖水准的功能 R 是免费的 R 应用广泛，拥有丰富的 活跃的 1.2.3 R语言发展趋势 TIOBE index 1.2.4 R路上的大神 2019 年 8 月，国际统计学年会将考普斯总统奖（The Committee of Presidents of Statistical Societies Awards，简称 COPSS 奖，被誉为统计学的诺贝尔奖）奖颁给 tidyverse的作者Hadley Wickham后，充分说明R语言得到了学术界的肯定和认可，我相信未来它在自然科学、社会科学和工业领域中的应用前景会非常光明。 Hadley Wickham R路上的大神 改变了R语言的人 1.3 R能干什么 1.3.1 数据科学流程 Hadley Wickham将数据科学流程分解成6个环节 即数据导入、数据规整、数据处理、可视化、建模以及形成可重复性报告，整个分析和探索过程都在一个程序代码中完成，这种方式对训练我们的数据思维非常有帮助。 1.3.2 tidyverse家族 https://www.tidyverse.org/ 1.3.3 R &amp; tidyverse 四大功能和代码演示 序号 | 内容 | 代码演示 1 统计 | 1_stats.R | 2 可视化 | 2 2_visual.R | 3 探索性分析 | 3_e 3_eda.R | 4 可重复性报告 | 4_re 4_reproducible.R | 可能看到这些代码，第一眼感觉是这样的 图 1.1: 图片来自电影《降临》 但我更希望这门课结束后，大家的感觉是这样的 图 1.2: 图片来自美剧《权利的游戏》 1.4 为什么选择 R 1.4.1 数据科学是为社会科学服务的 1.4.2 选择 R &amp; tidyverse 的理由 2016年权威机构KDnuggets做过调研，显示数据科学领域最受欢迎的工具，是python和R两种语言 事实上，python和R都是非常强大的工具，两者各有优劣，作为初学者，究竟选择谁? 可以参考《为什么R语言是当今最值得学习的数据科学语言》，这篇文章做了详细的对比。我个人的观点是，如果想做程序员或者打算今后在工业企业里工作，可以选择python; 如果你今后打算在科研机构做学术研究，我推荐R语言作为入门语言。 序号 | 内容 | 特性 | 评价 评价 | 1 统计分析 | 看 看家本领 好用 | 2 ggplot2画图 | 颜值担当 好看 | 3 tidyverse语法 | 简单易懂 好学 | 4 可重复性报告 | 方便快 方便快捷 好玩 | tidyverse 语法一致性（学习一个宏包，可以帮助理解其他宏包） 代码可读性，接近人类语言 ( %&gt;% 太酷了 ) 1.4.3 一见钟情，还是相见恨晚？ 为什么不能用excel做数据分析？画个图说明下 你心动了？ 1.5 推荐阅读 为什么R语言是当今最值得学习的数据科学语言 R for Data Science https://www.tidyverse.org/ "],
["intro-R.html", "第 2 章 R语言基础 2.1 安装 R 2.2 安装 RStudio 2.3 开始 2.4 一切都是对象 2.5 数据类型 2.6 数据结构 2.7 函数 2.8 脚本 2.9 宏包 2.10 如何获取帮助 2.11 R 语言社区 2.12 延伸阅读", " 第 2 章 R语言基础 R 软件是一个自由、开源软件平台，具有统计分析、可视化和编程的强大功能。 你可以从这里免费下载。 为了更好的使用 R 软件，我推荐大家使用 RStudio这个 IDE。这里有个在线教程帮助我们熟悉 R 和 RStudio。 2.1 安装 R 我们从官方网站http://cran.r-project.org下载, 网站界面感觉有点朴素: 2.2 安装 RStudio 安装完R， 还需要安装RStudio。有同学可能要问 R 与 RStudio 是什么关系呢？打个比方吧，R 就像汽车的发动机, RStudio 就是汽车的仪表盘。但我更觉得 R 是有趣的灵魂，而 Rstudio 是好看的皮囊。 同样，我们从官方网站下载并安装，如果你是苹果系统的用户，选择苹果系统对应的rstudio版本即可。 https://www.rstudio.com/download 选择RStudio Desktop 这里有个小小的提示： 电脑不要用中文用户名，否则Rstudio会杠上中文用户名 尽量安装在非系统盘，比如，可以选择安装在D盘 安装路径不要有中文和空格。比如，这样就比较好 D:/R D:/Rstudio 2.3 开始 安装完毕后，从windos开始菜单，点开rstudio图标，就打开了rstudio的窗口，界面效果如下 RStudio 的用户界面十分友好，想要运行一段R代码，只需要在 RStudio 控制台面板最下面 (Console)一行内键入R 代码，然后回车即可。比如我们键入1 + 1 并按回车后，RStudio 将显示如下结果 1 + 1 ## [1] 2 log(8) ## [1] 2.079 1:15 ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 2.4 一切都是对象 在R中存储的数据称为对象， R语言数据处理实际上就是不断的创建和操控这些对象。创建一个R对象，首先确定一个名称，然后使用 赋值操作符 &lt;-，将数据赋值给它。比如，如果想给变量 x 赋值为5，在命令行中可以这样写 x &lt;- 5 ，然后回车. x &lt;- 5 当键入x 然后回车，就打印出 x 的值。当然也可以使用命令print(x)，结果一样。 x ## [1] 5 x + 2 ## [1] 7 die &lt;- 1:6 die ## [1] 1 2 3 4 5 6 die / 2 ## [1] 0.5 1.0 1.5 2.0 2.5 3.0 die * die ## [1] 1 4 9 16 25 36 die %*% die ## [,1] ## [1,] 91 die %o% die ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 2 3 4 5 6 ## [2,] 2 4 6 8 10 12 ## [3,] 3 6 9 12 15 18 ## [4,] 4 8 12 16 20 24 ## [5,] 5 10 15 20 25 30 ## [6,] 6 12 18 24 30 36 2.5 数据类型 数值型 3 ## [1] 3 5000 ## [1] 5000 3e+06 ## [1] 3e+06 class(0.0001) ## [1] &quot;numeric&quot; 字符串型 &quot;hello&quot; ## [1] &quot;hello&quot; &quot;girl&quot; ## [1] &quot;girl&quot; &quot;1&quot; # 注意 1 和 &quot;1&quot; 的区别 ## [1] &quot;1&quot; class(&quot;1&quot;) ## [1] &quot;character&quot; 逻辑型 TRUE ## [1] TRUE FALSE ## [1] FALSE 3 &lt; 4 ## [1] TRUE class(T) ## [1] &quot;logical&quot; 3 &lt; 4 ## [1] TRUE 因子型 fac &lt;- factor(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) fac ## [1] a b c ## Levels: a b c class(fac) ## [1] &quot;factor&quot; 2.6 数据结构 大家前面看到x &lt;- 1 和 x &lt;- c(1, 2, 3)，这就是最简单的数据对象，叫原子型向量。 用c函数将一组数据构造成向量，要求每个元素用逗 号分隔，且每个元素的数据类型是一致的 die &lt;- c(2, 4, 3, 1, 5, 7) die ## [1] 2 4 3 1 5 7 长度为 1 的原子型向量 x &lt;- c(1) # or x &lt;- 1 强制转换 vec &lt;- c(&quot;R&quot;, 1, TRUE) class(vec) ## [1] &quot;character&quot; 大家看到前面die %o% die 是矩阵类型，矩阵就是二维数组 可以用matrix 函数创建 m &lt;- matrix(c(2, 4, 3, 1, 5, 7), nrow = 2, ncol = 3, byrow = TRUE ) m ## [,1] [,2] [,3] ## [1,] 2 4 3 ## [2,] 1 5 7 数据对象：数组 array 函数生成n维数组 ar &lt;- array(c(11:14, 21:24, 31:34), dim = c(2, 2, 3)) ar ## , , 1 ## ## [,1] [,2] ## [1,] 11 13 ## [2,] 12 14 ## ## , , 2 ## ## [,1] [,2] ## [1,] 21 23 ## [2,] 22 24 ## ## , , 3 ## ## [,1] [,2] ## [1,] 31 33 ## [2,] 32 34 数据对象：列表 与c函数创建向量的方式相似，不同的元素用逗号分开。不同的是，列表允许不同的数据类型（数值型，字符型，逻辑型等）， 而向量要求每个元素的数据类型必须相同。 list1 &lt;- list(100:110, &quot;R&quot;, c(2, 4, 3, 1, 5, 7)) list1 ## [[1]] ## [1] 100 101 102 103 104 105 106 107 108 109 110 ## ## [[2]] ## [1] &quot;R&quot; ## ## [[3]] ## [1] 2 4 3 1 5 7 数据对象：数据框 data.frame函数构建 df &lt;- data.frame( name = c(&quot;ace&quot;, &quot;bob&quot;, &quot;carl&quot;, &quot;kaite&quot;), age = c(21, 14, 13, 15), sex = c(&quot;girl&quot;, &quot;boy&quot;, &quot;boy&quot;, &quot;girl&quot;) ) df R 对象的数据结构(向量、矩阵、数组、列表和数据框)，总结如下 为了更好地理解相关概念，建议大家阅读Garrett Grolemund的 hopr这本书 (Grolemund 2014)。 2.7 函数 R 语言的强大在于使用函数操控各种对象，你可以把对象看作是名词，而函数看作是动词。 我们用一个简单的例子，sum()来演示函数如何工作的。这个函数的功能正如它的名字一样，对输入的各个对象求和，然后返回求和后的值，你可以在命令行中键入?sum()查看其官方文档。 sum()后的结果可以直接显示出来，也可以赋名。比如下面代码，首先计算x + 10并赋以名字y， 然后第二行中打印出来这个新创建的对象y y &lt;- sum(x, 10) y ## [1] 11 因为代码的灵活性，可以不断地重新定义对象。只要数据发生改变，原来的代码就会返回新的值。比如，对x重新赋值为 15， 同样运行sum()函数，这次我们不赋值给对象y，而是让它直接显示 x &lt;- 15 sum(x, 10) ## [1] 25 再比如 round(3.14159) ## [1] 3 mean(1:6) ## [1] 3.5 n &lt;- 100 x &lt;- seq(1, n) sum(x) ## [1] 5050 dt &lt;- mtcars[, 1:4] head(dt) cor(dt) ## mpg cyl disp hp ## mpg 1.0000 -0.8522 -0.8476 -0.7762 ## cyl -0.8522 1.0000 0.9020 0.8324 ## disp -0.8476 0.9020 1.0000 0.7909 ## hp -0.7762 0.8324 0.7909 1.0000 2.8 脚本 如果我们已经写好了一段R程序，我们可以保存为脚本文件，脚本文件通常以.R作为文件的后缀名。比如我们可以将刚才创建x和 y对象的命令，保存为脚本文件my_script.R。 这样我们可以在其它时间修改和重新运行它。 在RStudio中，你可以通过菜单栏依此点击File &gt; New File &gt; R Script 来创建一个新的脚本。 强烈建议大家在运行代码之前，使用脚本的形式编写和编辑自己的程序，养成这样的习惯后，你今后所有的工作都有案可查，并且具有可重复性。 点击 Run 或者 Source 运行脚本 2.9 宏包 R 语言的强大还在于各种宏包，一般在The Comprehensive R Archive Network (CRAN)下载安装。宏包扩展了R语言本身的各种功能，也为解决问题提供了各种方案。截至撰写本书时止，CRAN上大约有1.4万个宏包可以使用。但由于各种包接口不统一，语法不一致，也带来一些困扰。为了解决这个问题，RStudio 公司的Hadley Wickham 与其带领的团队推出了tidyverse宏包， tidyverse将常用的宏包整合在一起，并保持了语法的一致性。可以说，tidyverse宏包是R语言入门 学习的首选。 本书正是基于tidyverse宏包而成的，本书也将通过一些例子不断地展示tidyverse在数据分析和可视化的应用。 可以用如下命令安装 ggplot2 宏包: # 安装单个包 install.packages(&quot;tidyverse&quot;) # 安装多个包 install.packages(c(&quot;ggplot2&quot;, &quot;devtools&quot;, &quot;dplyr&quot;)) 如果下载速度太慢，可以选择国内镜像 如果安装宏包过程中出错，可以试试这样 install.packages(&quot;tidyverse&quot;, repos = &quot;http://cran.rstudio.com&quot;) # 或者 install.packages(&quot;tidyverse&quot;, repos = &quot;https://CRAN.R-project.org&quot;) 如果遇到如下报错信息 Warning in install.packages : unable to access index for repository http://cran.rstudio.com/src/contrib: cannot open URL &#39;http://cran.rstudio.com/src/contrib/PACKAGES&#39; 输入下面命令后，再试试 options(download.file.method=&quot;libcurl&quot;) 或者打开D:\\R\\etc\\Rprofile.site，添加以下内容： local({r &lt;- getOption(&quot;repos&quot;) r[&quot;CRAN&quot;] &lt;- &quot;http://mirrors.tuna.tsinghua.edu.cn/CRAN&quot; options(repos=r)}) options(download.file.method=&quot;libcurl&quot;) 如果打开代码是乱码，可以试试修改如下设置 如果加载太慢，可以在Rstudio里将这几个选项取消 2.10 如何获取帮助 记住和学习所有的函数几乎是不可能的 打开函数的帮助页面(Rstudio右下面板的Help选项卡) ?sqrt ?gather ?spread ?ggplot2 ?scale ?map_dfr 比如： 2.11 R 语言社区 R 语言社区非常友好，可以在这里找到你问题的答案 twitter: https://twitter.com/ R-Bloggers: https://www.r-bloggers.com/ kaggle: https://www.kaggle.com/ stackoverflow: https://stackoverflow.com/questions/tagged/r rstudio: https://community.rstudio.com/ 2.12 延伸阅读 如何获取向量a &lt;- c(\"a\", \"c\", \"e\")的第二个元素？矩阵和列表的时候，又该如何? 试试 c(1, FALSE) 与 c(\"a\", TRUE) 会是什么？ 1 == \"1\" 和 -1 &lt; FALSE 为什么为真？ \"one\" &lt; 2 为什么为假？ R语言里可以构造哪些数据对象？ 数据框可以装载哪些数据类型的数据？ 数据框和列表区别在哪里？ ()与[]区别？ 参考文献 "],
["subsetting.html", "第 3 章 子集选取 3.1 向量 3.2 列表 3.3 矩阵 3.4 数据框 3.5 增强型数据框 3.6 延伸阅读", " 第 3 章 子集选取 子集选取单独作一章，说明它确实很重要。 上一章讲对象、数据类型和数据结构等概念。为了方便理解，我这里打个比方， 对象就是我们在计算机里新建了存储空间，好比一个盒子， 我们可以往盒子里面装东西，比如鞋子、袜子、糖果东西。数据类型就是指我们装的东西的类型，比如是吃的还是用的呢， 只不过计算机用的是机器语言，称之为，数值型、字符串型、因子型等等。 数据结构就是盒子里东西的摆放次序，是相同的（同质）放一起，还是不同的（异质）放一起， 相同的放一起就是向量、矩阵；不同的放一起可能是列表和数据框。 子集选取，就是从盒子里取东西出来1。 3.1 向量 对于原子型向量，我们有至少四种选取子集的方法 x &lt;- c(1.1, 2.2, 3.3, 4.4, 5.5) 正整数： 指定向量元素中的位置 x[1] ## [1] 1.1 x[c(1,3)] ## [1] 1.1 3.3 x[c(3,1)] ## [1] 3.3 1.1 负整数：删除指定位置的元素 x[-2] ## [1] 1.1 3.3 4.4 5.5 x[c(-3, -4)] ## [1] 1.1 2.2 5.5 逻辑向量：将TRUE对应位置的元素提取出来 x[c(TRUE, FALSE, TRUE, FALSE, TRUE)] ## [1] 1.1 3.3 5.5 常用的一种情形；筛选出大于某个值的所有元素 x &gt; 3 ## [1] FALSE FALSE TRUE TRUE TRUE x[x &gt; 3] ## [1] 3.3 4.4 5.5 如果是命名向量 y &lt;- c(&quot;a&quot; = 11, &quot;b&quot; = 12, &quot;c&quot; = 13, &quot;d&quot; = 14) y ## a b c d ## 11 12 13 14 我们可以用命名向量，返回其对应位置的向量 y[c(&quot;d&quot;, &quot;c&quot;, &quot;a&quot;)] ## d c a ## 14 13 11 3.2 列表 对列表取子集，和向量的方法一样。使用 [ 总是返回列表， l &lt;- list(&quot;one&quot; = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), &quot;two&quot; = c(1:5), &quot;three&quot; = c(TRUE, FALSE) ) l ## $one ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; ## ## $two ## [1] 1 2 3 4 5 ## ## $three ## [1] TRUE FALSE l[1] ## $one ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 如果想列表中的元素，需要使用 [[ l[[1]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 也可以使用其中的元素名，比如[[\"one\"]]， l[[&quot;one&quot;]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 程序员觉得以上太麻烦了，要写太多的字符了，所以用$来简写 l$one ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 所以请记住 [ 和[[的区别 x$y 是 x[[\"y\"]]的简写 3.3 矩阵 a &lt;- matrix(1:9, nrow = 3) a ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 我们取第1行到第2行的2-3列，[1:2, 2:3]，中间以逗号分隔，于是得到一个新的矩阵 a[1:2, 2:3] ## [,1] [,2] ## [1,] 4 7 ## [2,] 5 8 默认情况下, [ 会将获取的数据，以尽可能低的维度形式呈现。比如 a[1, 1:2] ## [1] 1 4 表示第1行的第1、2列，此时不是\\(1 \\times 2\\)矩阵，而是包含了两个元素的向量。 以尽可能低的维度形式呈现，换句话说，这个1, 4长的像个矩阵，又有点像向量，向量的维度比矩阵低，那就是向量吧。 有些时候，我们想保留所有的行或者列，比如 行方向，只选取第 1 行到第 2 行 列方向，选取所有列 可以这样简写 a[1:2, ] ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 对于下面这种情况，想想，会输出什么 a[ , ] ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 可以再简化点？ a[] ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 是不是可以再简化点？ a ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 3.4 数据框 数据框具有list和matrix的双重属性，因此 当选取数据框的某几列的时候，可以和list一样，指定元素位置，比如df[1:2]选取前两列 也可以像矩阵一样，使用行和列的标识选取，比如df[1:3, ]选取前三行的所有列 df &lt;- data.frame(x = 1:4, y = 4:1, z = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) ) df # Like a list df[c(&quot;x&quot;, &quot;z&quot;)] # Like a matrix df[, c(&quot;x&quot;, &quot;z&quot;)] 也可以通过行和列的位置 df[1:2] df[1:3, ] 当遇到单行或单列的时候，也和矩阵一样，数据会降维 df[, &quot;x&quot;] ## [1] 1 2 3 4 如果想避免降维，需要多写一句话 df[, &quot;x&quot;, drop = FALSE] 这样输出的还是矩阵形式, 但程序员总是偷懒的，有时候我们也容易忘记写drop = FALSE， 所以我比较喜欢下面的tibble. 3.5 增强型数据框 tibble是增强型的data.frame，选取tibble的行或者列，即使遇到单行或者单列的时候，数据也不会降维，总是返回tibble，即仍然是数据框的形式。 tb &lt;- tibble::tibble( x = 1:4, y = 4:1, z = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) ) tb tb[&quot;x&quot;] tb[, &quot;x&quot;] 除此以外，tibble还有很多优良的特性，我们会在第 25 章专门讲 3.6 延伸阅读 如何获取matrix(1:9, nrow = 3)上对角元? 对角元？ 对数据框，思考df[\"x\"]， df[[\"x\"]]， df$x三者的区别? 如果x是一个矩阵，请问 x[] &lt;- 0 和x &lt;- 0 有什么区别？ m &lt;- matrix(1:9, nrow = 3) m diag(m) upper.tri(m, diag = FALSE) m[upper.tri(m, diag = FALSE)] 操控盒子里的东西，比如把糖果变大，这个过程叫函数.↩︎ "],
["rmarkdown.html", "第 4 章 可重复性研究 4.1 什么是Rmarkdown 4.2 markdown 基本语法 4.3 Hello R Markdown 4.4 生成html文档 4.5 生成word文档 4.6 生成pdf文档 4.7 使用方法 4.8 延伸阅读", " 第 4 章 可重复性研究 有时候，我们需要展示和分享我们的数据分析结果给同行、老板或者老师。 那么，为了让老板能快速地的理解我们的分析思路和方法， 最好的方法，就是将分析背景、分析过程、分析结果以及图表等形成报告，让读者能重复和验证我们的结果，确保结论的真实可信。 因此，本章就将介绍如何生成分析报告（可重复性报告）。 4.1 什么是Rmarkdown 4.2 markdown 基本语法 # This is a title # 第一章 （注意 &quot;#&quot; 与 &quot;第一章&quot;之间有空格） ## 第一节 （同上，&quot;##&quot; 与 &quot;第一节&quot;之间有空格） This is a sentence. Now a list begins: - no importance - again - repeat A numbered list: 1. first 2. second __bold__, _italic_, ~~strike through~~ 4.3 Hello R Markdown Rstudio create Rmd file ： File -&gt; New File -&gt; R Markdown. 基本构成（图中绿色括号地方） metadata text code 点击knit（图中红色地方），选择想要输出的文档格式即可。 4.4 生成html文档 希望html文档有章节号、目录或者更好显示表格，可以修改头文件（用下面的内容替换Rmarkdown的头文件） --- title: Habits author: John Doe date: &quot;2020-08-24&quot; output: html_document: df_print: paged toc: yes number_sections: yes --- 4.5 生成word文档 rmarkdown 生成的word功能不是很多，推荐使用officedown宏包 4.6 生成pdf文档 pdf文档可以插入漂亮的矢量图和优雅的数学公式，所以备受同学们的喜欢。但往往我们写中文的时候，编译不成功。这里就来讲讲如何解决这些问题，推荐阅读这里，或者看这个视频。 Instructions 安装最新版本 R (&gt;3.5) 和 RStudio Desktop (&gt;1.2). 安装pdf查看器，sumatrapdf网站 安装 LaTeX. 然而这个软件会比较大 (e.g. MacTeX is approximate 3.9G). 如果你之前没有安装过 LaTeX，我推荐你安装轻量级的 tinytex. 安装方法如下，打开R，然后再命令行输入: install.packages(&quot;tinytex&quot;) tinytex::install_tinytex(dir = &quot;D:\\\\Tinytex&quot;, force = T) 中途会有两次警告，按 “ 确定 ” 就可以了。 修改头文件，用下面的内容替换Rmarkdown的头文件, 不要修改缩进 --- title: &#39;Going deeper with dplyr&#39; author: &quot;王小二&quot; date: &quot;`r Sys.Date()`&quot; output: pdf_document: latex_engine: xelatex extra_dependencies: ctex: UTF8 number_sections: yes df_print: kable toc: yes classoptions: &quot;hyperref, 12pt, a4paper&quot; --- 4.7 使用方法 4.7.1 插入公式 我相信你已经熟悉了latex语法，那么我们在Rmarkdwon里输入 $$\\frac{\\sum (\\bar{x} - x_i)^2}{n-1}$$，那么实际输出: \\[\\frac{\\sum (\\bar{x} - x_i)^2}{n-1}\\] 也可以使用latex的等式环境， 比如 $$\\Theta = \\begin{pmatrix}\\alpha &amp; \\beta\\\\ \\gamma &amp; \\delta \\end{pmatrix}$$ 输出 \\[ \\Theta = \\begin{pmatrix}\\alpha &amp; \\beta\\\\ \\gamma &amp; \\delta \\end{pmatrix} \\] 4.7.2 插入图片 ```{r, out.width=&#39;35%&#39;, fig.align=&#39;left&#39;, fig.cap=&#39;this is caption&#39;} knitr::include_graphics(&quot;images/R_logo.png&quot;) ``` 图 4.1: this is caption 4.7.3 运行代码 summary(cars) ## speed dist ## Min. : 4.0 Min. : 2 ## 1st Qu.:12.0 1st Qu.: 26 ## Median :15.0 Median : 36 ## Mean :15.4 Mean : 43 ## 3rd Qu.:19.0 3rd Qu.: 56 ## Max. :25.0 Max. :120 4.7.4 表格 ```{r tables-mtcars} knitr::kable(iris[1:5, ], caption = &quot;A caption&quot;) ``` 表 4.1: A caption Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 需要更优美的表格，可参考这里 4.7.5 生成图片 ```{r} plot(pressure) ``` 或者 ```{r, out.width = &#39;85%&#39;, fig.showtext = TRUE} library(tidyverse) library(nycflights13) library(showtext) showtext_auto() flights %&gt;% group_by(dest) %&gt;% summarize( count = n(), dist = mean(distance, na.rm = TRUE), delay = mean(arr_delay, na.rm = TRUE) ) %&gt;% dplyr::filter(delay &gt; 0, count &gt; 20, dest != &quot;HNL&quot;) %&gt;% ggplot(mapping = aes(x = dist, y = delay)) + geom_point(aes(size = count), alpha = 1 / 3) + geom_smooth(se = FALSE) + ggtitle(&quot;这是我的标题&quot;) ``` Download my_pdf_document.Rmd 4.8 延伸阅读 Markdown tutorial https://www.markdowntutorial.com (10分钟学完) LaTeX tutorial https://www.latex-tutorial.com/quick-start/ Rmarkdown 介绍 https://bookdown.org/yihui/rmarkdown/ Rmarkdown 手册 https://bookdown.org/yihui/rmarkdown-cookbook/ "],
["readr.html", "第 5 章 读取数据 5.1 常见格式 5.2 范例 5.3 乱码情形", " 第 5 章 读取数据 本章介绍如何读取数据到 R。事实上，R语言提供了很多读取数据的函数。 5.1 常见格式 下表列出了常见文件格式的读取方法 文件格式 R 函数 .txt read.table() .csv read.csv() and readr::read_csv() .xls and .xlsx readxl::read_excel() and openxlsx::read.xlsx() .sav foreign::read.spss() .Rdata or rda load() .rds readRDS() and readr::read_rds() .dta haven::read_dta() and haven::read_stata() Internet download.file() 5.2 范例 d &lt;- read.table(file= &quot;./data/txt_file.txt&quot;, header = TRUE) load(file = &quot;./data/rda_file.rda&quot;) d &lt;- readRDS(file = &quot;./data/rds_file.rds&quot;) library(readr) d &lt;- read_csv(file = &quot;./data/csv_file.csv&quot;) url &lt;- &quot;https://raw.githubusercontent.com/perlatex/R_for_Data_Science/master/demo_data/wages.csv&quot; d &lt;- read_csv(url) library(readxl) d &lt;- read_excel(&quot;./data/vowel_data.xlsx&quot;) library(haven) d &lt;- read_excel(&quot;./data/cfps2010.dta&quot;) 5.3 乱码情形 遇到乱码的情况，这里有个小小的提示： 可以先用记事本转换成“UTF-8”编码， 或者指定编码格式，比如read.table(…, fileEncoding = “UTF-8”)，再试试。 "],
["dplyr.html", "第 6 章 数据处理 6.1 mutate() 6.2 管道 %&gt;% 6.3 select() 6.4 filter() 6.5 summarise()统计 6.6 group_by()分组 6.7 arrange()排序 6.8 left_join() 6.9 right_join() 6.10 延伸阅读", " 第 6 章 数据处理 Hadley Wickhamt提出了数据科学tidy原则，我结合自己的理解，tidy思想体现在: 一切都是数据框，任何数据都可以规整 数据框的一列代表一个变量，数据框的一行代表一次观察 函数处理数据时，数据框进数据框出（函数的第一个参数始终为数据框） 本章我们介绍tidyverse里数据处理的神器dplyr宏包。首先，我们加载该宏包 library(dplyr) dplyr 定义了数据处理的规范语法，其中主要包含以下九个主要的函数。 mutate(), select(), filter() summarise(), group_by(), arrange() left_join(), right_join()， full_join() 我们依次介绍 6.1 mutate() 假定我们有一数据框，包含三位学生的英语和数学 df &lt;- data.frame( name = c(&quot;Alice&quot;, &quot;Alice&quot;, &quot;Bob&quot;, &quot;Bob&quot;, &quot;Carol&quot;, &quot;Carol&quot;), type = c(&quot;english&quot;, &quot;math&quot;, &quot;english&quot;, &quot;math&quot;, &quot;english&quot;, &quot;math&quot;) ) df 这里有他们的最近的考试成绩，我们想增加到数据框里去 score2020 &lt;- c(80.2, 90.5, 92.2, 90.8, 82.5, 84.6) score2020 ## [1] 80.2 90.5 92.2 90.8 82.5 84.6 使用传统的方法 df$newscore &lt;- score2020 df dplyr语法这样写 mutate(df, newscore = score2020) mutate() 函数 mutate(.data = df, newscore = score2020) 第一参数是我们要处理的数据框，比如这里的df， 第二个参数是newscore = score2020，等号左边的newscore是我们打算创建一个新列，而取的列名； 等号右边是装着学生成绩的向量（注意，向量 的长度要与数据框的行数相等，比如这里长度都是6） 6.2 管道 %&gt;% 这里有必要介绍下管道操作符%&gt;%. c(1:10) ## [1] 1 2 3 4 5 6 7 8 9 10 sum(c(1:10)) ## [1] 55 与下面的写法是等价的, c(1:10) %&gt;% sum() ## [1] 55 这条语句的意思，向量c(1:10) 通过管道操作符 %&gt;% ，传递到函数sum()的第一个参数位置，即sum(c(1:10))， 这个%&gt;%管道操作符还是很形象的， 当对执行多个函数操作的时候，就显得格外方便，代码可读性更强。 sqrt(sum(abs(c(-10:10)))) ## [1] 10.49 # sqrt(sum(abs(c(-10:10)))) c(-10:10) %&gt;% abs() %&gt;% sum() %&gt;% sqrt() ## [1] 10.49 那么，上面增加学生成绩的语句mutate(df, newscore = score2020)就可以使用管道 # 等价于 df %&gt;% mutate(newscore = score2020) 是不是很赞？ df &lt;- df %&gt;% mutate(newscore = score2020) df 6.3 select() select()顾名思义选择，就是选择数据框的某一列， 我们还是以学生成绩的数据框为例 我们可以选择name列, 结果是只有一列的数据框（仍然数据框喔） 使用传统的方法 df[&quot;name&quot;] dplyr 的方法 df %&gt;% select(name) 如果选取多列，用dplyr 就只是再写一个就行了 df %&gt;% select(name, newscore) 如果不想要某列， 可以在变量前面加-， 结果与上面的一样 df %&gt;% select(-type) 6.4 filter() select是列方向的选择， 我们还可以对数据行方向的选择和筛选， 比如这里把成绩高于90分的同学筛选出来 df %&gt;% filter(newscore &gt;= 90) 也可以限定多个条件进行筛选, 英语成绩高于90分的筛选出来 df %&gt;% filter(type == &quot;english&quot;, newscore &gt;= 90) 6.5 summarise()统计 summarise()主要用于统计，往往与其他函数配合使用，比如计算所有同学考试成绩的均值 df %&gt;% summarise( mean_score = mean(newscore)) 比如，计算所有同学的考试成绩的标准差 df %&gt;% summarise( mean_score = sd(newscore)) 还同时完成多个统计 df %&gt;% summarise( mean_score = mean(newscore), median_score = median(newscore), n = n(), sum = sum(newscore) ) 6.6 group_by()分组 事实上，summarise()往往配合group_by()一起使用，即，先分组再统计。比如，我们想统计每个学生的平均成绩，那么就需要先按学生name分组，然后求平均 df %&gt;% group_by(name) %&gt;% summarise( mean_score = mean(newscore), sd_score = sd(newscore) ) 6.7 arrange()排序 这个很好理解的。比如我们按照考试成绩从低到高排序，然后输出 df %&gt;% arrange(newscore) 如果从高到低排序呢，有两种方法: df %&gt;% arrange(-newscore) 写成下面这种形式也是降序排列，但可读性更强些 df %&gt;% arrange(desc(newscore)) 也可对多个变量先后排序。先按学科排，然后按照成绩从高到底排序 df %&gt;% arrange(type, desc(newscore)) 6.8 left_join() 数据框合并，假定我们已经统计了每个同学的平均成绩，存放在df1 df1 &lt;- df %&gt;% group_by(name) %&gt;% summarise( mean_score = mean(newscore) ) df1 我们有新一个数据框df2，包含同学们的年龄信息 df2 &lt;- tibble( name = c(&quot;Alice&quot;, &quot;Bob&quot;), age = c(12, 13) ) df2 可以用 left_join把两个数据框df1和df2，合并连接再一起, 两个数据框是通过姓名name连接的，因此需要指定by = \"name\" left_join(df1, df2, by = &quot;name&quot;) # df1 %&gt;% left_join(df2, by = &quot;name&quot;) 大家注意到最后一行Carol的年龄是NA， 大家想想为什么呢？ 6.9 right_join() 我们再试试right_join() df1 %&gt;% right_join(df2, by = &quot;name&quot;) Carol同学的信息没有了？ 大家想想又为什么呢？ 事实上，答案就在函数的名字上，left_join()是左合并，即以左边数据框df1中的学生姓名name为准，在右边数据框df2里，有Alice和Bob的年龄，那么就对应合并过来，没有Carol，就为缺失值NA left_join()是右合并，即以右边数据框df2中的学生姓名name为准，只有Alice和Bob，因此而df1只需要把Alice和Bob的信息粘过来。 6.10 延伸阅读 推荐https://dplyr.tidyverse.org/. cheatsheet 作业：读懂并运行下面的代码 Download nycflights.Rmd "],
["colwise.html", "第 7 章 列方向和行方向 7.1 体验新版本 7.2 简单回顾 7.3 summarise()更强大了 7.4 summarise()后的分组信息是去是留？ 7.5 选择某列 7.6 重命名某列 7.7 调整列的位置 7.8 强大的across函数 7.9 “current” group or “current” variable 7.10 行方向操作 7.11 参考资料", " 第 7 章 列方向和行方向 dplyr宏包是数据科学tidyverse集合的核心部件之一，Hadley Wickham大神说将会在5月15日发布dplyr 1.0版本，欢呼。 为迎接新时代的到来，我在线上同大家一起分享dplyr 1.0版本新的特点和功能，看看都为我们带来哪些惊喜？ 7.1 体验新版本 New dplyr - 8 things to know: Built in tidyselect relocate() Superpowered summarise() colwise using across() cur_data() cur_group() and cur_column() new rowwise() grammar easy modeling inside dataframes nest_by() devtools::install_github(&quot;tidyverse/dplyr&quot;) library(dplyr, warn.conflicts = FALSE) library(tidyr) 7.2 简单回顾 mutate() select() filter() group_by() summarise() arrange() rename() left_join() 7.3 summarise()更强大了 在dplyr 1.0之前，summarise()会把统计结果整理成一行一列的数据框，现在可以根据函数返回的结果，可以有多种形式： 长度为 1 的向量，比如，min(x), n(), or sum(is.na(y)) 长度为 n 的向量，比如，quantile() 数据框 df &lt;- tibble( grp = rep(c(&quot;a&quot;, &quot;b&quot;), each = 5), x = c(rnorm(5, -0.25, 1), rnorm(5, 0, 1.5)), y = c(rnorm(5, 0.25, 1), rnorm(5, 0, 0.5)) ) df df %&gt;% group_by(grp) %&gt;% summarise(rng = mean(x)) 当统计函数返回多个值的时候，比如range()返回是最小值和最大值，summarise()很贴心地将结果整理成多行，这样符合tidy的格式。 df %&gt;% group_by(grp) %&gt;% summarise(rng = range(x)) 类似的还有quantile()函数，也是返回多个值 df %&gt;% group_by(grp) %&gt;% summarise( rng = quantile(x, probs = c(0.05, 0.5, 0.95)) ) df %&gt;% group_by(grp) %&gt;% summarise( x = quantile(x, c(0.25, 0.5, 0.75)), q = c(0.25, 0.5, 0.75) ) summarise()可以输出数据框，比如 my_quantile &lt;- function(x, probs) { tibble(x = quantile(x, probs), probs = probs) } mtcars %&gt;% group_by(cyl) %&gt;% summarise(my_quantile(disp, c(0.25, 0.75))) 再比如： dplyr 1.0 之前是需要group_modify()来实现数据框进，数据框出 mtcars %&gt;% group_by(cyl) %&gt;% group_modify( ~broom::tidy(lm(mpg ~ wt, data = .)) ) dplyr 1.0 之后，有了新的方案 mtcars %&gt;% group_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt)) ) 7.4 summarise()后的分组信息是去是留？ 当 group_by()与summarise()配合使用的时候，summarise()默认会抵消掉最近一次的分组信息，比如下面按照cyl和vs分组，但summarise()后，就只剩下cyl的分组信息了。 mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n()) mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n()) %&gt;% group_vars() ## [1] &quot;cyl&quot; 如果想保留vs的分组信息，就需要设置.groups = keep参数 mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n(), .groups = &quot;keep&quot;) %&gt;% group_vars() ## [1] &quot;cyl&quot; &quot;vs&quot; 当然summarise()可以控制输出的更多形式 丢弃所有的分组信息 mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n(), .groups = &quot;drop&quot;) %&gt;% group_vars() ## character(0) 变成行方向分组，即，每行是一个分组 mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n(), .groups = &quot;rowwise&quot;) %&gt;% group_vars() ## [1] &quot;cyl&quot; &quot;vs&quot; 7.5 选择某列 通过位置索引进行选取 df %&gt;% select(1, 3) df %&gt;% select(2:3) 通过列名 df %&gt;% select(grp, x, y) df %&gt;% select(x:y) 通过函数选取 df %&gt;% select(starts_with(&quot;x&quot;)) df %&gt;% select(ends_with(&quot;p&quot;)) df %&gt;% select(contains(&quot;x&quot;)) df %&gt;% select(matches(&quot;x&quot;)) 通过类型 df %&gt;% select(is.character) df %&gt;% select(is.numeric) 通过各种组合 df %&gt;% select(!is.character) df %&gt;% select(is.numeric &amp; starts_with(&quot;x&quot;)) df %&gt;% select(starts_with(&quot;g&quot;) | ends_with(&quot;y&quot;)) # 注意any_of和all_of的区别 vars &lt;- c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;) df %&gt;% select(all_of(vars)) df %&gt;% select(any_of(vars)) 7.6 重命名某列 df %&gt;% rename(group = grp) df %&gt;% rename_with(toupper) df %&gt;% rename_with(toupper, is.numeric) df %&gt;% rename_with(toupper, starts_with(&quot;x&quot;)) 7.7 调整列的位置 我们前面一章讲过arrange()排序，这是行方向的排序， 比如按照x变量绝对值的大小从高到低排序。 df %&gt;% arrange(desc(abs(x))) 我们现在想调整列的位置，比如，这里调整数据框三列的位置，让grp列放在x列的后面 df %&gt;% select(x, grp, y) 如果列变量很多的时候，上面的方法就不太好用，因此推荐大家使用relocate() df %&gt;% relocate(grp, .after = y) df %&gt;% relocate(x, .before = grp) 还有 df %&gt;% relocate(grp, .after = last_col()) 7.8 强大的across函数 我们必须为这个函数点赞。大爱Hadley Wickham !!! 我们经常需要对数据框的多列执行相同的操作。比如 iris iris %&gt;% group_by(Species) %&gt;% summarise( mean_Sepal_Length = mean(Sepal.Length), mean_Sepal_Width = mean(Sepal.Width), mean_Petal_Length = mean(Petal.Length), mean_Petal_Width = mean(Petal.Width) ) dplyr 1.0之后，使用across()函数异常简练 iris %&gt;% group_by(Species) %&gt;% summarise( across(everything(), mean) ) 或者更科学的 iris %&gt;% group_by(Species) %&gt;% summarise( across(is.numeric, mean) ) 可以看到，以往是一列一列的处理，现在对多列同时操作，这主要得益于across()函数，它有两个主要的参数： across(.cols = , .fns = ) 第一个参数.cols，选取我们要需要的若干列，选取多列的语法与select()的语法一致 第二个参数.fns，我们要执行的函数（或者多个函数），函数的语法有三种形式可选： A function, e.g. mean. A purrr-style lambda, e.g. ~ mean(.x, na.rm = TRUE) A list of functions/lambdas, e.g. list(mean = mean, n_miss = ~ sum(is.na(.x)) 再看看这个案例 std &lt;- function(x) { (x - mean(x)) / sd(x) } iris %&gt;% group_by(Species) %&gt;% summarise( across(starts_with(&quot;Sepal&quot;), std) ) # purrr style iris %&gt;% group_by(Species) %&gt;% summarise( across(starts_with(&quot;Sepal&quot;), ~ (.x - mean(.x)) / sd(.x)) ) iris %&gt;% group_by(Species) %&gt;% summarise( across(starts_with(&quot;Petal&quot;), list(min = min, max = max)) # across(starts_with(&quot;Petal&quot;), list(min = min, max = max), .names = &quot;{fn}_{col}&quot;) ) iris %&gt;% group_by(Species) %&gt;% summarise( across(starts_with(&quot;Sepal&quot;), mean), Area = mean(Petal.Length * Petal.Width), across(c(Petal.Width), min), n = n() ) 除了在summarise()里可以使用外，在其它函数也是可以使用的 iris %&gt;% mutate(across(is.numeric, mean)) iris %&gt;% mutate(across(starts_with(&quot;Sepal&quot;), mean)) iris %&gt;% mutate(across(is.numeric, std)) # std function has defined before iris %&gt;% mutate( across(is.numeric, ~ .x / 2), across(is.factor, stringr::str_to_upper) ) 7.9 “current” group or “current” variable n(), 返回当前分组的多少行 cur_data(), 返回当前分组的数据内容（不包含分组变量） cur_group(), 返回当前分组的分组变量（一行一列的数据框） across(cur_column()), 返回当前列的列名 这些函数返回当前分组的信息，因此只能在特定函数内部使用，比如summarise() and mutate() df &lt;- tibble( g = sample(rep(letters[1:3], 1:3)), x = runif(6), y = runif(6) ) df df %&gt;% group_by(g) %&gt;% summarise( n = n() ) df %&gt;% group_by(g) %&gt;% summarise( data = list(cur_group()) ) df %&gt;% group_by(g) %&gt;% summarise( data = list(cur_data()) ) mtcars %&gt;% group_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt, data = cur_data())) ) df %&gt;% group_by(g) %&gt;% mutate(across(everything(), ~ paste(cur_column(), round(.x, 2)))) wt &lt;- c(x = 0.2, y = 0.8) df %&gt;% mutate( across(c(x, y), ~ .x * wt[cur_column()]) ) 7.10 行方向操作 数据框中向量de方向，事实上可以看做有两个方向，横着看是row-vector，竖着看是col-vector。 tidyverse遵循的tidy原则，一列表示一个变量，一行表示一次观察。 这种数据的存储格式，对ggplot2很方便，但对行方向的操作或者运算不同友好。比如 7.10.1 行方向上的统计 df &lt;- tibble(id = letters[1:6], w = 10:15, x = 20:25, y = 30:35, z = 40:45) df 计算每行的均值， df %&gt;% mutate(avg = mean(c(w, x, y, z))) 好像不对？为什么呢？ 按照tidy的方法 df %&gt;% pivot_longer( cols = -id, names_to = &quot;variable&quot;, values_to = &quot;value&quot; ) %&gt;% group_by(id) %&gt;% summarize( r_mean = mean(value) ) 如果保留原始数据，就还需要再left_join()一次，虽然思路清晰，但还是挺周转的。 按照Jenny Bryan的方案，使用purrr宏包的pmap_dbl函数 library(purrr) df %&gt;% mutate(r_mean = pmap_dbl(select_if(., is.numeric), lift_vd(mean))) 但需要学习新的语法，代价也很高。 rowwise() df %&gt;% rowwise() %&gt;% mutate(avg = mean(c(w, x, y, z))) 变量名要是很多的话，又变了体力活了，怎么才能变的轻巧一点呢？ rowwise() + c_across()，现在dplyr 1.0终于给出了一个很好的解决方案 df %&gt;% rowwise() %&gt;% mutate( avg = mean(c_across(w:z)) ) 这个很好的解决方案中，rowwise()工作原理类似与group_by()，是按每一行进行分组，然后按行（行方向）统计 df %&gt;% rowwise(id) %&gt;% mutate(total = mean(c_across(w:z))) df %&gt;% rowwise(id) %&gt;% mutate(mean = mean(c_across(is.numeric))) df %&gt;% rowwise(id) %&gt;% summarise( m = mean(c_across(is.numeric)) ) 因此，我们可以总结成下面这张图 7.10.2 行方向处理与列表列是天然一对 rowwise()不仅仅用于计算行方向均值这样的简单统计，而是当处理列表列时，方才显示出rowwise()与purrr::map一样的强大。那么，什么是列表列？ 列表列指的是数据框的一列是一个列表， 比如 tb &lt;- tibble( x = list(1, 2:3, 4:6) ) 如果想显示列表中每个元素的长度，用purrr包，可以这样写 tb %&gt;% mutate(l = purrr::map_int(x, length)) 如果从行方向的角度理解，其实很简练 tb %&gt;% rowwise() %&gt;% mutate(l = length(x)) 7.10.3 行方向上的建模 mtcars 以cyl分组，计算每组中mpg ~ wt的线性模型的系数. mtcars %&gt;% group_by(cyl) %&gt;% nest() 7.10.3.1 列方向的做法 分组建模后，形成列表列，此时列表中的每个元素对应一个模型，我们需要依次提取每次模型的系数，列方向的做法是，借用purrr::map完成列表中每个模型的迭代， mtcars %&gt;% group_by(cyl) %&gt;% nest() %&gt;% mutate(model = purrr::map(data, ~ lm(mpg ~ wt, data = .))) %&gt;% mutate(result = purrr::map(model, ~ broom::tidy(.))) %&gt;% unnest(result) 用purrr::map实现列表元素一个一个的依次迭代，从数据框的角度来看（数据框是列表的一种特殊形式），因此实质上就是一行一行的处理。所以，尽管purrr很强大，但需要一定学习成本，从解决问题的路径上也比较周折。 7.10.3.2 行方向的做法 事实上，分组建模后，形成列表列，这种存储格式，天然地符合行处理的范式，因此一开始就使用行方向分组（这里nest_by() 类似于 group_by()） mtcars %&gt;% nest_by(cyl) %&gt;% mutate(model = list(lm(mpg ~ wt, data = data))) %&gt;% summarise(broom::tidy(model)) # or mtcars %&gt;% nest_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt, data = data)) ) 至此，tidyverse框架下，实现分组统计中的数据框进，数据框输出， 现在有四种方法了 mtcars %&gt;% group_nest(cyl) %&gt;% mutate(model = purrr::map(data, ~ lm(mpg ~ wt, data = .))) %&gt;% mutate(result = purrr::map(model, ~ broom::tidy(.))) %&gt;% tidyr::unnest(result) mtcars %&gt;% group_by(cyl) %&gt;% group_modify( ~ broom::tidy(lm(mpg ~ wt, data = .)) ) mtcars %&gt;% nest_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt, data = data)) ) mtcars %&gt;% group_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt, data = cur_data())) ) # or mtcars %&gt;% group_by(cyl) %&gt;% summarise(broom::tidy(lm(mpg ~ wt))) 7.11 参考资料 https://dplyr.tidyverse.org/dev/articles/rowwise.html https://dplyr.tidyverse.org/dev/articles/colwise.html "],
["ggplot2-aes.html", "第 8 章 数据可视化 8.1 为什么要可视化 8.2 宏包ggplot2 8.3 ggplot2 的图形语法 8.4 映射 8.5 映射 vs.设置 8.6 几何对象 8.7 图层叠加 8.8 Global vs. Local 8.9 保存图片 8.10 延伸阅读", " 第 8 章 数据可视化 上节课介绍了R语言的基本数据结构，可能大家有种看美剧的感觉，有些懵。这很正常，我在开始学习R的时候，感觉和大家一样，所以不要惊慌，我们后面会慢慢填补这些知识点。 这节课，我们介绍R语言最强大的可视化，看看都有哪些炫酷的操作。 library(tidyverse) # install.packages(&quot;tidyverse&quot;) library(patchwork) # install.packages(&quot;patchwork&quot;) 8.1 为什么要可视化 我们先从一个故事开始，1854年伦敦爆发严重霍乱，当时流行的观点是霍乱是通过空气传播的，而John Snow医生（不是《权力的游戏》里的 Jon Snow）研究发现，霍乱是通过饮用水传播的。研究过程中，John Snow医生统计每户病亡人数，每死亡一人标注一条横线，分析发现，大多数病例的住所都围绕在Broad Street水泵附近，结合其他证据得出饮用水传播的结论，于是移掉了Broad Street水泵的把手，霍乱最终得到控制。 另一个有趣的例子就是辛普森悖论（Simpson’s Paradox）。比如我们想研究下，学习时间和考试成绩的关联。结果发现两者呈负相关性，即补课时间越长，考试成绩反而越差（下图横坐标是学习时间，纵坐标是考试成绩），很明显这个结果有违生活常识。 事实上，当我们把学生按照不同年级分成五组，再来观察学习时间和考试成绩之间的关联，发现相关性完全逆转了! 我们可以看到学习时间和考试成绩强烈正相关。 辛普森悖论在日常生活中层出不穷。 那么如何避免辛普森悖论呢？我们能做的，就是仔细地研究分析各种影响因素，不要笼统概括地、浅尝辄止地看问题。其中，可视化分析为我们提供了一个好的方法。 8.2 宏包ggplot2 ggplot2是RStudio首席科学家Hadley Wickham在2005年读博士期间的作品。很多人学习R语言，就是因为ggplot2宏包。目前， ggplot2已经发展成为最受欢迎的R宏包，没有之一。 我们可以看看它2019年cran的下载量 library(cranlogs) d &lt;- cran_downloads(package = &quot;ggplot2&quot;, from = &quot;2019-01-01&quot;, to = &quot;2019-12-31&quot;) sum(d$count) ## [1] 9889742 8.3 ggplot2 的图形语法 ggplot2有一套优雅的绘图语法，包名中“gg”是grammar of graphics的简称。 ggplot()函数包括9个部件： 数据 (data) （ 数据框） 映射 (mapping) 几何对象 (geom) 统计变换 (stats) 标度 (scale) 坐标系 (coord) 分面 (facet) 主题 (theme) 存储和输出 (output) 其中前三个是必需的。 Hadley Wickham将这套语法诠释为: 一张统计图形就是从数据到几何对象(geometric object，缩写geom)的图形属性(aesthetic attribute，缩写aes)的一个映射。 此外，图形中还可能包含数据的统计变换(statistical transformation，缩写stats)，最后绘制在某个特定的坐标系(coordinate system，缩写coord)中，而分面(facet)则可以用来生成数据不同子集的图形。 8.3.1 语法模板 先看一个简单的案例（1880-2014年温度变化和二氧化碳排放量） library(tidyverse) d &lt;- read_csv(&quot;./demo_data/temp_carbon.csv&quot;) d library(ggplot2) ggplot(data = d, mapping = aes(x = year, y = carbon_emissions)) + geom_line() + xlab(&quot;Year&quot;) + ylab(&quot;Carbon emissions (metric tons)&quot;) + ggtitle(&quot;Annual global carbon emissions, 1880-2014&quot;) 是不是很简单? 8.4 映射 我们用ggplot2宏包内置数据集mpg来演示. 1999年和2008年期间，市面上38种流行车型，燃油经济性数据 mpg包含234行和11个变量的数据框 str(mpg) ## tibble [234 x 11] (S3: tbl_df/tbl/data.frame) ## $ manufacturer: chr [1:234] &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ... ## $ model : chr [1:234] &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; ... ## $ displ : num [1:234] 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ... ## $ year : int [1:234] 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ... ## $ cyl : int [1:234] 4 4 4 4 6 6 6 4 4 4 ... ## $ trans : chr [1:234] &quot;auto(l5)&quot; &quot;manual(m5)&quot; &quot;manual(m6)&quot; &quot;auto(av)&quot; ... ## $ drv : chr [1:234] &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ... ## $ cty : int [1:234] 18 21 20 21 16 18 18 18 16 20 ... ## $ hwy : int [1:234] 29 29 31 30 26 26 27 26 25 28 ... ## $ fl : chr [1:234] &quot;p&quot; &quot;p&quot; &quot;p&quot; &quot;p&quot; ... ## $ class : chr [1:234] &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; ... 序号 变量 含义 1 manufacturer 生产厂家 2 model 类型 3 displ 发动机排量，升 4 year 生产年份 5 cyl 气缸数量 6 trans 传输类型 7 drv 驱动类型(f =前轮驱动，r =后轮驱动，4 = 4wd) 8 cty 每加仑城市里程 9 hwy 每加仑高速公路英里 10 fl 汽油种类 11 class 类型 8.4.1 排量越大，越耗油吗？ 这里提出一个问题，是不是汽车的排量越大越耗油吗？ 回答这个问题，我们用到mpg数据集其中的三个变量 序号 变量 含义 3 displ 发动机排量, 排量 9 hwy 每加仑英里数，油耗 11 class 汽车类型 mpg[c(&quot;displ&quot;, &quot;hwy&quot;, &quot;class&quot;)] mpg %&gt;% select(displ, hwy, class) %&gt;% head(4) 为考察发动机排量(displ)与每加仑英里数(hwy)之间的关联，先绘制这两个变量的散点图， ggplot()表示调用该函数画图，data = mpg 表示使用mpg这个数据框来画图。 aes()表示数据和视觉属性之间的映射， aes(x = displ, y = hwy)，意思是变量displ作为（映射为）x轴方向的位置，变量hwy作为（映射为）y轴方向的位置。 aes()除了位置上映射，还可以实现色彩、形状或透明度等视觉属性的映射。 geom_point()表示绘制散点图。 +表示添加图层。 运行脚本后生成图片： 刚才看到的是位置上的映射，ggplot还包含了颜色、形状以及透明度等图形属性的映射， 比如我们在aes()里增加一个颜色映射color = class, 这样做就是希望，不同的汽车类型, 用不同的颜色来表现。这里，汽车类型有七组，那么就用七种不同的颜色来表示 ggplot(data = mpg, aes(x = displ, y = hwy, color = class) ) + geom_point() 此图绘制不同类型的车，displ和hwy的散点图， 并用颜色来实现了分组。 大家试试下面代码呢， ggplot(data = mpg, aes(x = displ, y = hwy, size = class)) + geom_point() ggplot(data = mpg, aes(x = displ, y = hwy, shape = class)) + geom_point() ggplot(data = mpg, aes(x = displ, y = hwy, alpha = class)) + geom_point() 为什么图中是这样的颜色呢？那是因为ggplot内部有一套默认的设置 不喜欢默认的颜色，可以自己定义喔。请往下看 8.5 映射 vs.设置 想把图中的点指定为某一种颜色，可以使用设置语句，比如 ggplot(mpg, aes(displ, hwy)) + geom_point(color = &quot;blue&quot;) 大家也可以试试下面 ggplot(mpg, aes(displ, hwy)) + geom_point(size = 5) ggplot(mpg, aes(displ, hwy)) + geom_point(shape = 2) ggplot(mpg, aes(displ, hwy)) + geom_point(alpha = 0.5) 8.5.1 提问 思考下aes(color = \"blue\")为什么会红色的点？ ggplot(mpg, aes(x = displ, y = hwy, color = &quot;ffee&quot;)) + geom_point() mpg[c(&quot;displ&quot;, &quot;hwy&quot;, &quot;class&quot;)] mpg$col &lt;- &quot;blue&quot; mpg[c(&quot;displ&quot;, &quot;hwy&quot;, &quot;class&quot;, &quot;col&quot;)] ggplot(mpg, aes(x = displ, y = hwy, color = col)) + geom_point() 8.6 几何对象 geom_point() 可以画散点图，也可以使用geom_smooth()绘制平滑曲线， p1 &lt;- ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() p1 p2 &lt;- ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_smooth() p2 8.7 图层叠加 p3 &lt;- ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() + geom_smooth() p3 library(patchwork) (p1 / p2) | p3 8.8 Global vs. Local ggplot(mpg, aes(x = displ, y = hwy, color = class)) + geom_point(aes(x = displ, y = hwy, color = class)) ggplot(mpg) + geom_point( aes(x = displ, y = hwy, color = class) ) 大家可以看到，以上两段代码出来的图是一样。但背后的含义却不同。 事实上，如果映射关系aes() 写在ggplot()里, ggplot(mpg, aes(x = displ, y = hwy, color = class)) + geom_point() 那么映射关系x = displ, y = hwy, color = class 为全局变量。因此，当geom_point()画图时，发现缺少所绘图所需要的映射关系，就会从ggplot()中继承全局变量的映射关系。 如果映射关系aes() 写在几何对象geom_point()里, 那么映射关系就为局部变量, 比如。 ggplot(mpg) + geom_point(aes(x = displ, y = hwy, color = class)) 此时geom_point()绘图所需要的映射关系aes(x = displ, y = hwy, color = class) 已经存在，就不会继承全局变量的映射关系。 再看下面这个例子， ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(color = class)) + geom_smooth() 这里的 geom_point() 和 geom_smooth() 都会从全局变量中继承映射关系。 再看下面这个例子， ggplot(mpg, aes(x = displ, y = hwy, color = class)) + geom_point(aes(color = factor(cyl))) 局部变量中的映射关系 aes(color = )已经存在，因此不会从全局变量中继承，沿用当前的映射关系。 大家细细体会下，下面两段代码的区别 ggplot(mpg, aes(x = displ, y = hwy, color = class)) + geom_smooth(method = lm) + geom_point() ggplot(mpg, aes(x = displ, y = hwy)) + geom_smooth(method = lm) + geom_point(aes(color = class)) 8.9 保存图片 可以使用ggsave()函数，将图片保存为所需要的格式，如“.pdf”, “.png”等 p &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_smooth(method = lm) + geom_point(aes(color = class)) + ggtitle(&quot;This is my first plot&quot;) ggsave(filename = &quot;myfirst_plot.pdf&quot;, plot = p, width = 8, height = 6, dpi = 300 ) 8.10 延伸阅读 在第 19 章到第 22 章会再讲ggplot2 "],
["stringr.html", "第 9 章 正则表达式 9.1 问题 9.2 什么是正则表达式 9.3 字符串基础 9.4 使用正则表达式进行模式匹配 9.5 解决实际问题 9.6 进阶部分 9.7 案例分析 9.8 回答提问 9.9 一些有趣的正则表达式的宏包", " 第 9 章 正则表达式 library(tidyverse) library(stringr) 9.1 问题 这是一份关于地址信息的数据 问题：如何提取Sichuan Univ后面的学院？这需要用到正则表达式的知识。 9.2 什么是正则表达式 我们在word文档或者excel中，经常使用查找和替换, 然而有些情况，word是解决不了的，比如 条件搜索 统计文中，前面有 “data”, “computer” or “statistical” 的 “analysis”，这个单词的个数 找出文中重复的单词，比如“we love love you” 拼写检查 电话号码（邮件，密码等）是否正确格式 日期书写的规范与统一 提取信息 提取文本特定位置的数据 文本挖掘 非结构化的提取成结构化 这个时候就需要用到正则表达式（Regular Expression），这一强大、便捷、高效的文本处理工具。那么，什么是正则表达式呢？简单点说，正则表达式是处理字符串的。复杂点说，正则表达式描述了一种字符串匹配的模式（pattern），通常被用来检索、替换那些符合某个模式(规则)的文本。这种固定的格式的文本，生活中常见的有电话号码、网络地址、邮件地址和日期格式等等。 正则表达式并不是R语言特有的，事实上，几乎所有程序语言都支持正则表达式 (e.g. Perl, Python, Java, Ruby, etc). R 语言中很多函数都需要使用正则表达式，然而正则表达式不太好学。幸运的是，大神Hadley Wickham开发的stringr包让正则表达式简单易懂，因此今天我们就介绍这个包。本章的内容与《R for data science》第10章基本一致。本章目的教大家写简单的正则表示式就行了。 9.3 字符串基础 9.3.1 字符串长度 想获取字符串的长度，可以使用str_length()函数 str_length(&quot;R for data science&quot;) ## [1] 18 字符串向量，也适用 str_length(c(&quot;a&quot;, &quot;R for data science&quot;, NA)) ## [1] 1 18 NA 数据框里配合dplyr函数，同样很方便 data.frame( x = c(&quot;a&quot;, &quot;R for data science&quot;, NA) ) %&gt;% mutate(y = str_length(x)) 9.3.2 字符串组合 把字符串拼接在一起，使用 str_c() 函数 str_c(&quot;x&quot;, &quot;y&quot;) ## [1] &quot;xy&quot; 把字符串拼接在一起，可以设置中间的间隔 str_c(&quot;x&quot;, &quot;y&quot;, sep = &quot;, &quot;) ## [1] &quot;x, y&quot; str_c(c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), sep = &quot;, &quot;) ## [1] &quot;x&quot; &quot;y&quot; &quot;z&quot; 是不是和你想象的不一样，那就?str_c，或者试试这个 str_c(c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), sep = &quot;, &quot;) ## [1] &quot;x, x&quot; &quot;y, y&quot; &quot;z, z&quot; 用在数据框里 data.frame( x = c(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;), y = c(&quot;you&quot;, &quot;like&quot;, &quot;me&quot;) ) %&gt;% mutate(z = str_c(x, y, sep = &quot;|&quot;)) 使用collapse选项，是先组合，然后再转换成单个字符串，大家对比下 str_c(c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), sep = &quot;|&quot;) ## [1] &quot;x|a&quot; &quot;y|b&quot; &quot;z|c&quot; str_c(c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), collapse = &quot;|&quot;) ## [1] &quot;xa|yb|zc&quot; 9.3.3 字符串取子集 截取字符串的一部分，需要指定截取的开始位置和结束位置 x &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;) str_sub(x, 1, 3) ## [1] &quot;App&quot; &quot;Ban&quot; &quot;Pea&quot; 开始位置和结束位置如果是负整数，就表示位置是从后往前数，比如下面这段代码，截取倒数第3个至倒数第1个位置上的字符串 x &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;) str_sub(x, -3, -1) ## [1] &quot;ple&quot; &quot;ana&quot; &quot;ear&quot; 也可以进行赋值，如果该位置上有字符，就用新的字符替换旧的字符 x &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;) x ## [1] &quot;Apple&quot; &quot;Banana&quot; &quot;Pear&quot; str_sub(x, 1, 1) ## [1] &quot;A&quot; &quot;B&quot; &quot;P&quot; str_sub(x, 1, 1) &lt;- &quot;Q&quot; x ## [1] &quot;Qpple&quot; &quot;Qanana&quot; &quot;Qear&quot; 9.4 使用正则表达式进行模式匹配 正则表示式慢慢会呈现了 9.4.1 基础匹配 str_view() 是查看string是否匹配pattern，如果匹配，就高亮显示 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(string = x, pattern = &quot;an&quot;) 有时候，我们希望在字符a前后都有字符（即，a处在两字符中间，如rap, bad, sad, wave，spear等等） x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;.a.&quot;) 这里的. 代表任意字符。如果向表达.本身呢？ c(&quot;s.d&quot;) %&gt;% str_view(&quot;.&quot;) c(&quot;s.d&quot;) %&gt;% str_view(&quot;\\\\.&quot;) 9.4.2 锚点 希望a是字符串的开始 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;^a&quot;) 希望a是一字符串的末尾 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;a$&quot;) x &lt;- c(&quot;apple pie&quot;, &quot;apple&quot;, &quot;apple cake&quot;) str_view(x, &quot;^apple$&quot;) 9.4.3 字符类与字符选项 前面提到，.匹配任意字符，事实上还有很多这种特殊含义的字符： \\d: matches any digit. \\s: matches any whitespace (e.g. space, tab, newline). [abc]: matches a, b, or c. [^abc]: matches anything except a, b, or c. str_view(c(&quot;grey&quot;, &quot;gray&quot;), &quot;gr[ea]y&quot;) 9.4.4 重复 控制匹配次数: ?: 0 or 1 +: 1 or more *: 0 or more x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;CC?&quot;) str_view(x, &quot;X+&quot;) 控制匹配次数: {n}: exactly n {n,}: n or more {,m}: at most m {n,m}: between n and m x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;C{2}&quot;) str_view(x, &quot;C{2,}&quot;) str_view(x, &quot;C{2,3}&quot;) 默认的情况，*, + 匹配都是贪婪的，也就是它会尽可能的匹配更多 如果想让它不贪婪，而是变得懒惰起来，可以在*, + 加个? x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;CLX+&quot;) str_view(x, &quot;CLX+?&quot;) 小结一下呢 9.4.5 分组与回溯引用 ft &lt;- fruit %&gt;% head(10) ft ## [1] &quot;apple&quot; &quot;apricot&quot; &quot;avocado&quot; ## [4] &quot;banana&quot; &quot;bell pepper&quot; &quot;bilberry&quot; ## [7] &quot;blackberry&quot; &quot;blackcurrant&quot; &quot;blood orange&quot; ## [10] &quot;blueberry&quot; 我们想看看这些单词里，有哪些字母是重复两次的，比如aa, pp. 如果用上面学的方法 str_view(ft, &quot;.{2}&quot;, match = TRUE) 发现不是和我们的预想不一样呢。 所以需要用到新技术 分组与回溯引用， str_view(ft, &quot;(.)\\\\1&quot;, match = TRUE) . 是匹配任何字符 (.) 将匹配项括起来，它就用了一个名字，叫\\\\1； 如果有两个括号，就叫\\\\1和\\\\2 \\\\1 表示回溯引用，表示引用\\\\1对于的(.) 所以(.)\\\\1的意思就是，匹配到了字符，后面还希望有个同样的字符 如果是匹配abab, wcwc str_view(ft, &quot;(..)\\\\1&quot;, match = TRUE) 如果是匹配abba, wccw呢？ str_view(ft, &quot;(.)(.)\\\\2\\\\1&quot;, match = TRUE) 是不是很神奇？ 9.5 解决实际问题 9.5.1 确定一个字符向量是否匹配一种模式 实际问题中，想判断是否匹配？可以用到str_detect()函数 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_detect(x, &quot;e&quot;) ## [1] TRUE FALSE TRUE 数据框中也是一样 d %&gt;% mutate(has_e = str_detect(x, &quot;e&quot;)) 用于筛选也很方便 d %&gt;% dplyr::filter(str_detect(x, &quot;e&quot;)) stringr::words包含了牛津字典里常用单词 stringr::words %&gt;% head() ## [1] &quot;a&quot; &quot;able&quot; &quot;about&quot; &quot;absolute&quot; ## [5] &quot;accept&quot; &quot;account&quot; 我们统计下以t开头的单词，有多少个？ # How many common words start with t? sum(str_detect(words, &quot;^t&quot;)) ## [1] 65 我们又一次看到了强制转换. 以元音结尾的单词，占比多少？ # proportion of common words end with a vowel? mean(str_detect(words, &quot;[aeiou]$&quot;)) ## [1] 0.2765 放在数据框里看看, 看看以x结尾的单词是哪些？ tibble( word = words ) %&gt;% dplyr::filter(str_detect(word, &quot;x$&quot;)) str_detect() 有一个功能类似的函数str_count()，区别在于，后者不是简单地返回是或否，而是返回字符串中匹配的数量 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_count(x, &quot;a&quot;) ## [1] 1 3 1 tibble( word = words ) %&gt;% mutate( vowels = str_count(word, &quot;[aeiou]&quot;), consonants = str_count(word, &quot;[^aeiou]&quot;) ) 9.5.2 确定匹配的位置 大家放心，正则表达式不会重叠匹配。比如用\"aba\"去匹配\"abababa\"，肉眼感觉是三次，但正则表达式告诉我们是两次，因为不会重叠匹配 str_count(&quot;abababa&quot;, &quot;aba&quot;) ## [1] 2 str_view_all(&quot;abababa&quot;, &quot;aba&quot;) 9.5.3 提取匹配的内容 colours &lt;- c( &quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;purple&quot; ) colour_match &lt;- str_c(colours, collapse = &quot;|&quot;) colour_match ## [1] &quot;red|orange|yellow|green|blue|purple&quot; colour_match 这里是一个字符串，放在pattern参数位置上也是正则表达式了, 这里注意以下两者的区别 str_view(&quot;abcd&quot;, &quot;ab|cd&quot;) str_view(&quot;abc&quot;, &quot;a[bc]d&quot;) more &lt;- &quot;It is hard to erase blue or red ink.&quot; str_extract(more, pattern = colour_match) ## [1] &quot;blue&quot; str_extract_all(more, pattern = colour_match) ## [[1]] ## [1] &quot;blue&quot; &quot;red&quot; more &lt;- sentences[str_count(sentences, colour_match) &gt; 1] more ## [1] &quot;It is hard to erase blue or red ink.&quot; ## [2] &quot;The green light in the brown box flickered.&quot; ## [3] &quot;The sky in the west is tinged with orange red.&quot; 取出sentences中，含有有两种和两种颜色以上的句子。不过，不喜欢这种写法，看着费劲，还是用tidyverse的方法 tibble(sentence = sentences) %&gt;% filter(str_count(sentences, colour_match) &gt; 1) str_extract()提取匹配, 谁先匹配就提取谁 tibble(x = more) %&gt;% mutate(color = str_extract(x, colour_match)) str_extract_all()提取全部匹配项 tibble(x = more) %&gt;% mutate(color = str_extract_all(x, colour_match)) tibble(x = more) %&gt;% mutate(color = str_extract_all(x, colour_match)) %&gt;% unnest(color) 9.5.4 替换匹配内容 只替换匹配的第一项 x &lt;- c(&quot;apple&quot;, &quot;pear&quot;, &quot;banana&quot;) str_replace(x, &quot;[aeiou]&quot;, &quot;-&quot;) ## [1] &quot;-pple&quot; &quot;p-ar&quot; &quot;b-nana&quot; 替换全部匹配项 str_replace_all(x, &quot;[aeiou]&quot;, &quot;-&quot;) ## [1] &quot;-ppl-&quot; &quot;p--r&quot; &quot;b-n-n-&quot; 9.5.5 拆分字符串 这个和str_c()是相反的操作 lines &lt;- &quot;I love my country&quot; lines ## [1] &quot;I love my country&quot; str_split(lines, &quot; &quot;) ## [[1]] ## [1] &quot;I&quot; &quot;love&quot; &quot;my&quot; &quot;country&quot; fields &lt;- c(&quot;Name: Hadley&quot;, &quot;Country: NZ&quot;, &quot;Age: 35&quot;) fields %&gt;% str_split(&quot;: &quot;, n = 2, simplify = TRUE) ## [,1] [,2] ## [1,] &quot;Name&quot; &quot;Hadley&quot; ## [2,] &quot;Country&quot; &quot;NZ&quot; ## [3,] &quot;Age&quot; &quot;35&quot; 9.6 进阶部分 带有条件的匹配 9.6.1 look ahead 想匹配Windows，同时希望Windows右侧是\"95\", \"98\", \"NT\", \"2000\"中的一个 win &lt;- c(&quot;Windows2000&quot;, &quot;Windows&quot;, &quot;Windows3.1&quot;) str_view(win, &quot;Windows(?=95|98|NT|2000)&quot;) win &lt;- c(&quot;Windows2000&quot;, &quot;Windows&quot;, &quot;Windows3.1&quot;) str_view(win, &quot;Windows(?!95|98|NT|2000)&quot;) Windows后面的 () 是匹配条件，事实上，有四种情形： (?=pattern) 要求此位置的后面必须匹配表达式pattern (?!pattern) 要求此位置的后面不能匹配表达式pattern (?&lt;=pattern) 要求此位置的前面必须匹配表达式pattern (?&lt;!pattern) 要求此位置的前面不能匹配表达式pattern 注意：对于正则表达式引擎来说，它是从文本头部向尾部（从左到右）开始解析的，因此对于文本尾部方向，称为“前”，因为这个时候，正则引擎还没走到那块；而对文本头部方向，则称为“后”，因为正则引擎已经走过了那一块地方。 9.6.2 look behind win &lt;- c(&quot;2000Windows&quot;, &quot;Windows&quot;, &quot;3.1Windows&quot;) str_view(win, &quot;(?&lt;=95|98|NT|2000)Windows&quot;) win &lt;- c(&quot;2000Windows&quot;, &quot;Windows&quot;, &quot;3.1Windows&quot;) str_view(win, &quot;(?&lt;!95|98|NT|2000)Windows&quot;) 9.7 案例分析 9.7.1 案例1 我们希望能提取第二列中的数值，构成新的一列 dt &lt;- tibble( x = 1:4, y = c(&quot;wk 3&quot;, &quot;week-1&quot;, &quot;7&quot;, &quot;w#9&quot;) ) dt dt %&gt;% mutate( z = str_extract(y, &quot;[0-9]&quot;) ) 9.7.2 案例2 提取第二列中的大写字母 df &lt;- data.frame( x = seq_along(1:7), y = c(&quot;2016123456&quot;, &quot;20150513&quot;, &quot;AB2016123456&quot;, &quot;J2017000987&quot;, &quot;B2017000987C&quot;, &quot;aksdf&quot;, &quot;2014&quot;) ) df df %&gt;% mutate( item = str_extract_all(y, &quot;[A-Z]&quot;) ) %&gt;% tidyr::unnest(item) 9.7.3 案例3 要求：中英文分开 tb &lt;- tibble(x = c(&quot;I我&quot;, &quot;love爱&quot;, &quot;you你&quot;)) tb tb %&gt;% tidyr::extract( #x, c(&quot;en&quot;, &quot;cn&quot;), &quot;([:alpha:]+)([^:alpha:]+)&quot;, x, c(&quot;en&quot;, &quot;cn&quot;), &quot;([a-zA-Z]+)([^a-zA-Z]+)&quot;, remove = FALSE ) 9.7.4 案例4 要求：提取起始数字 df &lt;- tibble(x = c(&quot;1-12周&quot;, &quot;1-10周&quot;, &quot;5-12周&quot;)) df df %&gt;% extract( x, #c(&quot;start&quot;, &quot;end&quot;, &quot;cn&quot;), &quot;([:digit:]+)-([:digit:]+)([^:alpha:]+)&quot;, c(&quot;start&quot;, &quot;end&quot;, &quot;cn&quot;), &quot;(\\\\d+)-(\\\\d+)(\\\\D+)&quot;, remove = FALSE ) 9.7.5 案例5 要求：提取大写字母后的数字 df &lt;- tibble( x = c(&quot;12W34&quot;, &quot;AB2C46&quot;, &quot;B217C&quot;, &quot;akTs6df&quot;, &quot;21WD4&quot;) ) df %&gt;% mutate( item = str_extract_all(x, &quot;(?&lt;=[A-Z])[0-9]&quot;) ) %&gt;% tidyr::unnest(item) 思考题， 如何提取大写字母后的连续数字，比如B217C后面的217 如何提取提取数字前的大写字母？ 为什么第一个正则表达式返回结果为\"\" x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_match_all(x, &quot;C?&quot;) # &quot;?&quot;的意思是匹配0次或者1次 ## [[1]] ## [,1] ## [1,] &quot;&quot; ## [2,] &quot;&quot; ## [3,] &quot;&quot; ## [4,] &quot;&quot; ## [5,] &quot;&quot; ## [6,] &quot;&quot; ## [7,] &quot;&quot; ## [8,] &quot;&quot; ## [9,] &quot;&quot; ## [10,] &quot;&quot; ## [11,] &quot;&quot; ## [12,] &quot;&quot; ## [13,] &quot;&quot; ## [14,] &quot;&quot; ## [15,] &quot;&quot; ## [16,] &quot;&quot; ## [17,] &quot;&quot; ## [18,] &quot;&quot; ## [19,] &quot;C&quot; ## [20,] &quot;C&quot; ## [21,] &quot;C&quot; ## [22,] &quot;&quot; ## [23,] &quot;&quot; ## [24,] &quot;&quot; ## [25,] &quot;&quot; ## [26,] &quot;&quot; ## [27,] &quot;&quot; ## [28,] &quot;&quot; ## [29,] &quot;&quot; ## [30,] &quot;&quot; str_match_all(x, &quot;CC?&quot;) ## [[1]] ## [,1] ## [1,] &quot;CC&quot; ## [2,] &quot;C&quot; 9.7.6 案例6 提取数字并求和 df &lt;- tibble( x = c(&quot;1234&quot;, &quot;B246&quot;, &quot;217C&quot;, &quot;2357f&quot;, &quot;21WD4&quot;) ) df df %&gt;% mutate(num = str_match_all(x, &quot;\\\\d&quot;)) %&gt;% unnest(num) %&gt;% mutate_at(vars(num), as.numeric) %&gt;% group_by(x) %&gt;% summarise(sum = sum(num)) 9.7.7 案例7 text &lt;- &quot;Quantum entanglement is a physical phenomenon that occurs when pairs or groups of particles are generated, interact, or share spatial proximity in ways such that the quantum state of each particle cannot be described independently of the state of the others, even when the particles are separated by a large distance.&quot; pairs &lt;- tibble::tribble( ~item, ~code, &quot;Quantum entanglement&quot;, &quot;A01&quot;, &quot;physical phenomenon&quot;, &quot;A02&quot;, &quot;quantum state&quot;, &quot;A03&quot;, &quot;quantum mechanics&quot;, &quot;A04&quot; ) %&gt;% tibble::deframe() text %&gt;% str_replace_all(pairs) ## [1] &quot;A01 is a A02 that occurs when pairs or groups of particles are generated, interact, or share spatial proximity in ways such that the A03 of each particle cannot be described independently of the state of the others, even when the particles are separated by a large distance.&quot; 9.8 回答提问 回到上课前的提问：如何提取Sichuan Univ后面的学院？ d %&gt;% dplyr::mutate( coll = str_extract(address, &quot;(?&lt;=Sichuan Univ,).*&quot;) ) %&gt;% tidyr::unnest(coll, keep_empty = TRUE) 当然还有其他的解决办法 d %&gt;% mutate( coll = str_remove_all(address, &quot;.*,&quot;) ) d %&gt;% tidyr::separate( address, into = c(&quot;univ&quot;, &quot;coll&quot;), sep = &quot;,&quot;, remove = FALSE ) d %&gt;% tidyr::extract( address, c(&quot;univ&quot;, &quot;coll&quot;), &quot;(Sichuan Univ), (.+)&quot;, remove = FALSE ) 9.9 一些有趣的正则表达式的宏包 https://github.com/gadenbuie/regexplain https://github.com/daranzolin/inferregex https://github.com/VerbalExpressions/RVerbalExpressions library(inferregex) # remotes::install_github(&quot;daranzolin/inferregex&quot;) s &lt;- &quot;abcd-9999-ab9&quot; infer_regex(s)$regex ## [1] &quot;^[a-z]{4}-\\\\d{4}-[a-z]{2}\\\\d$&quot; "],
["forcats.html", "第 10 章 因子型变量 10.1 什么是因子 10.2 创建因子 10.3 调整因子顺序 10.4 应用", " 第 10 章 因子型变量 本章介绍R语言中的因子类型数据。因子型变量常用于数据处理和可视化中，尤其在希望不以字母顺序排序的时候，因子就格外有用。 10.1 什么是因子 因子是把数据进行分类并标记为不同层级(level，有时候也翻译成因子水平， 我个人觉得翻译为层级，更接近它的特性，因此，我都会用层级来描述)的数据对象，他们可以存储字符串和整数。因子类型有三个属性： 存储类别的数据类型 离散变量 因子的层级是有限的，只能取因子层级中的值或缺失(NA) 10.2 创建因子 income &lt;- c(&quot;low&quot;, &quot;high&quot;, &quot;medium&quot;, &quot;medium&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;) factor(income) ## [1] low high medium medium low high high ## Levels: high low medium 因子层级会自动按照字符串的字母顺序排序，比如high low medium。也可以指定顺序， factor(income, levels = c(&quot;low&quot;, &quot;high&quot;, &quot;medium&quot;) ) ## [1] low high medium medium low high high ## Levels: low high medium 不属于因子层级中的值, 比如这里因子层只有c(\"low\", \"high\")，那么income中的“medium”会被当作缺省值NA factor(income, levels = c(&quot;low&quot;, &quot;high&quot;) ) ## [1] low high &lt;NA&gt; &lt;NA&gt; low high high ## Levels: low high 相比较字符串而言，因子类型更容易处理，因子很多函数会自动的将字符串转换为因子来处理，但事实上，这也会造成，不想当做因子的却又当做了因子的情形，最典型的是在R 4.0之前，data.frame()中stringsAsFactors选项，默认将字符串类型转换为因子类型，但这个默认也带来一些不方便，因此在R 4.0之后取消了这个默认。在tidyverse集合里，有专门处理因子的宏包forcats，因此，本章将围绕forcats宏包讲解如何处理因子类型变量，更多内容可以参考这里。 library(forcats) 10.3 调整因子顺序 前面看到因子层级是按照字母顺序排序 x &lt;- factor(income) x ## [1] low high medium medium low high high ## Levels: high low medium 也可以指定顺序 x %&gt;% fct_relevel(levels = c(&quot;high&quot;, &quot;medium&quot;, &quot;low&quot;)) ## [1] low high medium medium low high high ## Levels: high medium low 或者让“medium” 移动到最前面 x %&gt;% fct_relevel(levels = c(&quot;medium&quot;)) ## [1] low high medium medium low high high ## Levels: medium high low 或者让“medium” 移动到最后面 x %&gt;% fct_relevel(&quot;medium&quot;, after = Inf) ## [1] low high medium medium low high high ## Levels: high low medium 可以按照字符串第一次出现的次序 x %&gt;% fct_inorder() ## [1] low high medium medium low high high ## Levels: low high medium 按照其他变量的中位数的升序排序 x %&gt;% fct_reorder(c(1:7), .fun = median) ## [1] low high medium medium low high high ## Levels: low medium high 10.4 应用 调整因子层级有什么用呢？ 这个功能在ggplot可视化中调整分类变量的顺序非常方便。这里为了方便演示，我们假定有数据框 d &lt;- tibble( x = c(&quot;a&quot;,&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;), y = c(2, 2, 1, 5, 0, 3) ) d 先画个散点图看看吧 d %&gt;% ggplot(aes(x = x, y = y)) + geom_point() 我们看到，横坐标上是a-b-c的顺序。 10.4.1 fct_reorder() fct_reorder()可以让x的顺序按照x中每个分类变量对应y值的中位数升序排序，具体为 a对应的y值c(2, 2) 中位数是median(c(2, 2)) = 2 b对应的y值c(1, 5) 中位数是median(c(1, 5)) = 3 c对应的y值c(0, 3) 中位数是median(c(0, 3)) = 1.5 因此，x的因子层级的顺序调整为c-a-b d %&gt;% ggplot(aes(x = fct_reorder(x, y, .fun = median), y = y)) + geom_point() 当然，我们可以加一个参数.desc = TRUE让因子层级变为降序排列b-a-c d %&gt;% ggplot(aes(x = fct_reorder(x, y, .fun = median, .desc = TRUE), y = y)) + geom_point() 但这样会造成x坐标标签一大串，因此建议可以写mutate()函数里 d %&gt;% mutate(x = fct_reorder(x, y, .fun = median, .desc = TRUE)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() 我们还可以按照y值中最小值的大小降序排列 d %&gt;% mutate(x = fct_reorder(x, y, .fun = min, .desc = TRUE)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() 10.4.2 fct_rev() 按照因子层级的逆序排序 d %&gt;% mutate(x = fct_rev(x)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() 10.4.3 fct_relevel() d %&gt;% mutate( x = fct_relevel(x, c(&quot;c&quot;, &quot;a&quot;, &quot;b&quot;)) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() "],
["purrr.html", "第 11 章 函数式编程 11.1 简单回顾 11.2 向量化运算 11.3 多说说列表 11.4 列表 vs 向量 11.5 purrr 11.6 自定义函数 11.7 在dplyr函数中的运用map 11.8 延伸阅读", " 第 11 章 函数式编程 很多教材都是讲函数和循环，都是从for, while, ifelse讲起 ，如果我也这样讲，又回到了Base R的老路上去了。考虑到大家都没有编程背景，也不会立志当程序员，所以我直接讲purrr包，留坑以后填吧。 11.1 简单回顾 大家知道R常用的数据结构是向量、矩阵、列表和数据框，如下图 他们构造起来，很多相似性。 list(a = 1, b = &quot;a&quot;) # 列表 c(a = 1, b = 2) # 命名向量 data.frame(a = 1, b = 2) # 数据框 tibble(a = 1, b = 2) # 增强型数据框 11.2 向量化运算 a &lt;- c(2, 4, 3, 1, 5, 7) 用for()循环，让向量的每个元素乘以2 for (i in 1:length(a)) { print(a[i] * 2) } ## [1] 4 ## [1] 8 ## [1] 6 ## [1] 2 ## [1] 10 ## [1] 14 事实上，R语言是支持向量化（将运算符或者函数作用在向量的每一个元素上），可以用向量化代替循环 a * 2 ## [1] 4 8 6 2 10 14 达到同样的效果。 再比如，找出向量a中元素大于2的所有值 for (i in 1:length(a)) { if (a[i] &gt; 2) print(a[i]) } ## [1] 4 ## [1] 3 ## [1] 5 ## [1] 7 用向量化的运算，可以轻松实现 a[a &gt; 2] ## [1] 4 3 5 7 向量是R中最基础的一种数据结构，有种说法是“一切都是向量”，R中的矩阵、数组甚至是列表都可以看成是某种意义上的向量。因此，使用向量化操作可以大大提高代码的运行效率。 11.3 多说说列表 我们构造一个列表 a_list &lt;- list( num = c(8, 9), log = TRUE, cha = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) ) a_list ## $num ## [1] 8 9 ## ## $log ## [1] TRUE ## ## $cha ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 要想访问某个元素，可以这样 a_list[&quot;num&quot;] ## $num ## [1] 8 9 注意返回结果，第一行是$num，说明返回的结果仍然是列表, 相比a_list来说，a_list[\"num\"]是只包含一个元素的列表。 想将num元素里面的向量提取出来，就得用两个[[ a_list[[&quot;num&quot;]] ## [1] 8 9 大家知道程序员都是偷懒的，为了节省体力，用一个美元符号$代替[[\" \"]]六个字符 a_list$num ## [1] 8 9 在tidyverse里，还可以用 a_list %&gt;% pluck(1) ## [1] 8 9 或者 a_list %&gt;% pluck(&quot;num&quot;) ## [1] 8 9 11.4 列表 vs 向量 假定一向量 v &lt;- c(-2, -1, 0, 1, 2) v ## [1] -2 -1 0 1 2 我们对元素分别取绝对值 abs(v) ## [1] 2 1 0 1 2 如果是列表形式，abs函数应用到列表中就会报错 lst &lt;- list(-2, -1, 0, 1, 2) abs(lst) ## Error in abs(lst): 数学函数中用了非数值参数 报错了。用在向量的函数用在list上，往往行不通。 再来一个例子：我们模拟了5个学生的10次考试的成绩 exams &lt;- list( student1 = round(runif(10, 50, 100)), student2 = round(runif(10, 50, 100)), student3 = round(runif(10, 50, 100)), student4 = round(runif(10, 50, 100)), student5 = round(runif(10, 50, 100)) ) exams ## $student1 ## [1] 76 84 75 68 68 81 61 79 52 51 ## ## $student2 ## [1] 87 53 93 88 95 98 60 53 54 60 ## ## $student3 ## [1] 64 62 100 60 87 81 81 55 99 76 ## ## $student4 ## [1] 86 81 88 69 51 69 50 71 52 55 ## ## $student5 ## [1] 77 61 51 66 79 52 80 75 92 69 很显然，exams是一个列表。那么，每个学生的平均成绩是多呢？ 我们可能会想到用mean函数，但是 mean(exams) ## [1] NA 发现报错了，可以看看帮助文档看看问题出在什么地方 ?mean() 帮助文档告诉我们，mean()要求第一个参数是数值型或者逻辑型的向量。 而我们这里的exams是列表，因此无法运行。 那好，我们就用笨办法吧 list( student1 = mean(exams$student1), student2 = mean(exams$student2), student3 = mean(exams$student3), student4 = mean(exams$student4), student5 = mean(exams$student5) ) ## $student1 ## [1] 69.5 ## ## $student2 ## [1] 74.1 ## ## $student3 ## [1] 76.5 ## ## $student4 ## [1] 67.2 ## ## $student5 ## [1] 70.2 成功了。但发现我们写了好多代码，如果有100个学生，那就得写更多的代码，如果是这样，程序员就不高兴了，这太累了啊。于是purrr包的map函数来解救我们，下面主角出场了。 11.5 purrr 介绍之前，先试试 exams %&gt;% map(mean) ## $student1 ## [1] 69.5 ## ## $student2 ## [1] 74.1 ## ## $student3 ## [1] 76.5 ## ## $student4 ## [1] 67.2 ## ## $student5 ## [1] 70.2 哇，短短几句话，得出了相同的结果。如果希望返回的是数值型的向量，可以这样写 exams %&gt;% map_dbl(mean) ## student1 student2 student3 student4 student5 ## 69.5 74.1 76.5 67.2 70.2 如果希望返回的结果是数据框 exams %&gt;% map_df(mean) 是不是很酷？ 事实上，map函数 第一个参数是向量或列表（数据框是列表的一种特殊形式，因此数据框也是可以的） 第二个参数是函数，这个函数会应用到列表的每一个元素，比如这里map函数执行过程如下 ： 具体为，exams有5个元素，一个元素装着一个学生的10次考试成绩， 运行map(exams, mean)函数后， 首先取出exams第一个元素exams$student1(它是向量)，然后执行 mean(exams$student1), 然后将计算结果存放在列表result中的第一个位置result1上； 做完第一个学生的，紧接着取出exams第二个元素exams$student2，执行 mean(exams$student2), 然后将计算结果存放在列表result中的第一个位置result2上； 如此这般，直到所有学生都处理完毕。我们得到了最终结果—一个新的列表result。 当然，我们也可以根据需要，让map返回我们需要的数据格式, purrr也提供了方便的函数，具体如下 我们将mean函数换成求方差var函数试试， exams %&gt;% map_df(var) 11.6 自定义函数 刚才我们是让学生成绩执行求平均mean，求方差var等函数。我们也可以自定义函数。 比如我们这里定义了将向量中心化的函数（先求出10次考试的平均值，然后每次考试成绩去减这个平均值） my_fun &lt;- function(x){ x - mean(x) } exams %&gt;% map_df(my_fun) 当然可以偷懒将函数直接写在map()里，用~代替my_fun， 但代价是参数必须是规定的写法，比如.x exams %&gt;% map_df(~ .x - mean(.x)) 有时候，程序员觉得x还是有点多余，于是更够懒一点，只用.， 也是可以的 exams %&gt;% map_df(~ . - mean(.)) 总之，有三种方法将函数传递给map() 直接传递 map(.x, mean, na.rm = TRUE ) 匿名函数 map(.x, funciton(.x) { mean(.x, na.rm = TRUE) } ) 使用 ~ function(.x) { .x *2 } # 程序员偷懒了 ~ .x * 2 map(.x, ~ mean(.x, na.rm = TRUE) ) 11.7 在dplyr函数中的运用map 如果想显示列表中每个元素的长度，可以这样写 tibble( x = list(1, 2:3, 4:6) ) %&gt;% mutate(l = purrr::map_int(x, length)) 用于各种函数，比如产生随机数 tibble( x = c(3, 5, 6) ) %&gt;% mutate(r = purrr::map(x, ~rnorm(.x, mean = 0, sd = 1))) 用于建模 mtcars %&gt;% group_by(cyl) %&gt;% nest() %&gt;% mutate(model = purrr::map(data, ~ lm(mpg ~ wt, data = .))) %&gt;% mutate(result = purrr::map(model, ~ broom::tidy(.))) %&gt;% unnest(result) 更多内容和方法可参考第 7 章数据框列方向和行方向。 11.8 延伸阅读 1、阅读Hadley Wickham的r4ds这本书第16章。 2、看手册?purrr::modify()， 思考下它与map()的区别 exams %&gt;% map(~ . - mean(.)) exams %&gt;% modify(~ . - mean(.)) exams %&gt;% as_tibble() %&gt;% map(~ . - mean(.)) exams %&gt;% as_tibble() %&gt;% modify(~ . - mean(.)) 3、他们的区别哪里？函数能否互换？ mtcars %&gt;% map_chr(typeof) mtcars %&gt;% map_lgl(is.double) mtcars %&gt;% map_int(n_unique) mtcars %&gt;% map_dbl(mean) "],
["eda01.html", "第 12 章 探索性数据分析 12.1 探索性 12.2 数据集 12.3 导入数据 12.4 数据结构 12.5 我们想探索哪些问题？ 12.6 每个学科颁过多少次奖 12.7 看看我们伟大的祖国 12.8 哪些大神多次获得诺贝尔奖 12.9 大神在得奖的时候是多大年龄？ 12.10 性别比例 12.11 这些大神都是哪个年代出生的人？ 12.12 最年轻的诺奖获得者？ 12.13 平均年龄和获奖数量 12.14 出生地与工作地分布 12.15 迁移模式 12.16 地图 12.17 出生地和工作地不一样的占比 12.18 诺奖分享者 12.19 其它 12.20 延伸阅读", " 第 12 章 探索性数据分析 探索性数据分析（exporatory data analysis）是各种知识的综合运用。本章通过一个案例，讲解探索性数据分析的基本思路，也算是对前面几章内容的一次总结复习。 12.1 探索性 数据准备（对数据要做到心中有数） 描述变量 数据结构 缺失值及其处理 数据探索（围绕探索的目标） 数据规整 可视化 建模 12.2 数据集 这是一个诺贝尔奖获得者的数据集， 12.3 导入数据 library(tidyverse) library(lubridate) df &lt;- read_csv(&quot;./demo_data/nobel_winners.csv&quot;) df # 如果是xlsx格式 readxl::read_excel(&quot;myfile.xlsx&quot;) # 如果是csv格式 readr::read_csv(&quot;myfile.csv&quot;) 这里有个小小的提示： 路径（包括文件名）， 不要用中文和空格 数据框中变量，也不要有中文和空格（可用下划线代替空格） 12.4 数据结构 一行就是一个诺奖获得者的记录? 确定？ 缺失值及其处理 df %&gt;% map_df(~sum(is.na(.))) 性别缺失怎么造成的？ df %&gt;% count(laureate_type) 12.5 我们想探索哪些问题？ 你想关心哪些问题，可能是 每个学科颁过多少次奖？ 这些大神都是哪个年代的人？ 性别比例 平均年龄和获奖数量 最年轻的诺奖获得者是谁？ 中国诺奖获得者有哪些？ 得奖的时候多大年龄？ 获奖者所在国家的经济情况？ 有大神多次获得诺贝尔奖，而且在不同科学领域获奖？ 出生地分布？工作地分布？迁移模式？ GDP经济与诺奖模型？ 诺奖分享情况？ 12.6 每个学科颁过多少次奖 df %&gt;% count(category) df %&gt;% count(category) %&gt;% ggplot(aes(x = category, y = n, fill = category)) + geom_col() + geom_text(aes(label = n), vjust = -0.25) + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) df %&gt;% count(category) %&gt;% ggplot(aes(x = fct_reorder(category, n), y = n, fill = category)) + geom_col() + geom_text(aes(label = n), vjust = -0.25) + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) 也可以使用别人定义好的配色方案 library(ggthemr) # install.packages(&quot;devtools&quot;) # devtools::install_github(&#39;cttobin/ggthemr&#39;) ggthemr(&#39;dust&#39;) df %&gt;% count(category) %&gt;% ggplot(aes(x = fct_reorder(category, n), y = n, fill = category)) + geom_col() + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) 这个配色方案感觉挺好看的呢，比较适合我这种又挑剔又懒惰的人。 当然，也可以自己DIY，或者使用配色网站的主题方案(https://learnui.design/tools/data-color-picker.html#palette) df %&gt;% count(category) %&gt;% ggplot(aes(x = fct_reorder(category, n), y = n)) + geom_col(fill = c(&quot;#003f5c&quot;, &quot;#444e86&quot;, &quot;#955196&quot;, &quot;#dd5182&quot;, &quot;#ff6e54&quot;, &quot;#ffa600&quot;) ) + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) 让图骚动起来吧 library(gganimate) #install.packages(&quot;gganimate&quot;, dependencies = T) df %&gt;% count(category) %&gt;% mutate(category = fct_reorder(category, n)) %&gt;% ggplot(aes(x = category, y = n)) + geom_text(aes(label = n), vjust = -0.25) + geom_col(fill = c(&quot;#003f5c&quot;, &quot;#444e86&quot;, &quot;#955196&quot;, &quot;#dd5182&quot;, &quot;#ff6e54&quot;, &quot;#ffa600&quot;) ) + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) + transition_states(category) + shadow_mark(past = TRUE) 和ggplot2的分面一样，动态图可以增加数据展示的维度。 12.7 看看我们伟大的祖国 df %&gt;% filter(birth_country == &quot;China&quot;) %&gt;% select(full_name, prize_year, category) 我们发现获奖者有多个地址，就会有重复的情况，比如 Charles Kuen Kao在2009年Physics有两次，为什么重复计数了呢？ 下面我们去重吧， 去重可以用distinct()函数 dt &lt;- tibble::tribble( ~x, ~y, ~z, 1, 1, &quot;a&quot;, 1, 1, &quot;b&quot;, 1, 2, &quot;c&quot;, 1, 2, &quot;d&quot; ) dt dt %&gt;% distinct_at(vars(x), .keep_all = T) dt %&gt;% distinct_at(vars(x, y), .keep_all = T) nobel_winners &lt;- df %&gt;% mutate_if(is.character, tolower) %&gt;% distinct_at(vars(full_name, prize_year, category), .keep_all = TRUE) %&gt;% mutate(decade = 10 * (prize_year %/% 10), prize_age = prize_year - year(birth_date)) nobel_winners 这是时候，我们才对数据有了一个初步的了解 再来看看我的祖国 nobel_winners %&gt;% filter(birth_country == &quot;china&quot;) %&gt;% select(full_name, prize_year, category) 12.8 哪些大神多次获得诺贝尔奖 nobel_winners %&gt;% count(full_name, sort =T) nobel_winners %&gt;% group_by(full_name) %&gt;% mutate( number_prize = n(), number_cateory = n_distinct(category) ) %&gt;% arrange(desc(number_prize), full_name) %&gt;% filter(number_cateory == 2) 12.9 大神在得奖的时候是多大年龄？ nobel_winners %&gt;% count(prize_age) %&gt;% ggplot(aes(x = prize_age, y = n)) + geom_col() nobel_winners %&gt;% group_by(category) %&gt;% summarise(mean_prize_age = mean(prize_age, na.rm = T) ) nobel_winners %&gt;% mutate(category = fct_reorder(category, prize_age, median, na.rm = TRUE)) %&gt;% ggplot(aes(category, prize_age)) + geom_point() + geom_boxplot() + coord_flip() nobel_winners %&gt;% filter(!is.na(prize_age)) %&gt;% group_by(decade, category) %&gt;% summarize(average_age = mean(prize_age), median_age = median(prize_age)) %&gt;% ggplot(aes(decade, average_age, color = category)) + geom_line() library(ggridges) nobel_winners %&gt;% ggplot(aes(x = prize_age, y = category, fill = category)) + geom_density_ridges() 他们60多少岁才得诺奖，大家才23或24岁，还年轻，不用焦虑喔。 nobel_winners %&gt;% ggplot(aes(x = prize_age, fill = category, color = category)) + geom_density() + facet_wrap(vars(category)) + theme(legend.position = &quot;none&quot;) 有同学说要一个个的画，至于group_split()函数，下次课在讲 nobel_winners %&gt;% group_split(category) %&gt;% map( ~ ggplot(data = .x, aes(x = prize_age)) + geom_density() + ggtitle(.x$category) ) ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] ## ## [[5]] ## ## [[6]] 也可以用强大的group_by() + group_map()组合，我们会在第 34 章讲到 nobel_winners %&gt;% group_by(category) %&gt;% group_map( ~ ggplot(data = .x, aes(x = prize_age)) + geom_density() + ggtitle(.y) ) 12.10 性别比例 nobel_winners %&gt;% filter(laureate_type == &quot;individual&quot;) %&gt;% count(category, gender) %&gt;% group_by(category) %&gt;% mutate(prop = n / sum(n) ) 各年代性别比例 nobel_winners %&gt;% filter(laureate_type == &quot;individual&quot;) %&gt;% # mutate(decade = glue::glue(&quot;{round(prize_year - 1, -1)}s&quot;)) %&gt;% count(decade, category, gender) %&gt;% group_by(decade, category) %&gt;% mutate(prop = n / sum(n)) %&gt;% ggplot(aes(decade, category, fill = prop)) + geom_tile(size = 0.7) + #geom_text(aes(label = scales::percent(prop, accuracy = .01))) + geom_text(aes(label = scales::number(prop, accuracy = .01))) + facet_grid(vars(gender)) + scale_fill_gradient(low = &quot;#FDF4E9&quot;, high = &quot;#834C0D&quot;) library(ggbeeswarm)#install.packages(&quot;ggbeeswarm&quot;) nobel_winners %&gt;% ggplot(aes(x = category, y = prize_age, colour = gender, alpha = gender)) + ggbeeswarm::geom_beeswarm() + coord_flip() + scale_color_manual(values = c(&quot;#BB1288&quot;, &quot;#5867A6&quot;)) + scale_alpha_manual(values = c(1, .4)) + theme_minimal() + theme(legend.position = &quot;top&quot;) + labs(title = &quot;诺奖获得者性别不平衡&quot;, subtitle = &quot;1901年-2016年数据&quot;, colour = &quot;Gender&quot;, alpha = &quot;Gender&quot;, x = &quot;学科&quot;, y = &quot;获奖年龄&quot;) nobel_winners %&gt;% count(decade, category, gender = coalesce(gender, laureate_type)) %&gt;% group_by(decade, category) %&gt;% mutate(percent = n / sum(n)) %&gt;% ggplot(aes(decade, n, fill = gender)) + geom_col() + facet_wrap(~ category) + labs(x = &quot;Decade&quot;, y = &quot;# of nobel prize winners&quot;, fill = &quot;Gender&quot;, title = &quot;Nobel Prize gender distribution over time&quot;) 12.11 这些大神都是哪个年代出生的人？ nobel_winners %&gt;% select(category, birth_date) %&gt;% mutate(year = floor(year(birth_date)/10) * 10 ) %&gt;% count(category, year) %&gt;% filter(!is.na(year)) %&gt;% ggplot(aes(x = year, y = n)) + geom_col() + scale_x_continuous(breaks = seq(1810, 1990, 20)) + geom_text(aes(label = n), vjust = -0.25) + facet_wrap(vars(category)) 课堂练习，哪位同学能把图弄得好看些？ 12.12 最年轻的诺奖获得者？ nobel_winners %&gt;% filter(prize_age == min(prize_age, na.rm = T)) nobel_winners %&gt;% filter( rank(prize_year - year(birth_date) ) == 1 ) nobel_winners %&gt;% arrange( prize_year - year(birth_date) ) nobel_winners %&gt;% top_n(1, year(birth_date) - prize_year ) 12.13 平均年龄和获奖数量 df1 &lt;- nobel_winners %&gt;% group_by(category) %&gt;% summarise( mean_prise_age = mean(prize_age, na.rm = T), total_num = n() ) df1 df1 %&gt;% ggplot(aes(mean_prise_age, total_num)) + geom_point(aes(color = category)) + geom_smooth(method = lm, se = FALSE) 12.14 出生地与工作地分布 nobel_winners_clean &lt;- nobel_winners %&gt;% mutate_at( vars(birth_country, death_country), ~ ifelse(str_detect(., &quot;\\\\(&quot; ), str_extract(., &quot;(?&lt;=\\\\().*?(?=\\\\))&quot; ), .) ) %&gt;% mutate_at( vars(birth_country, death_country), ~ case_when( . == &quot;scotland&quot; ~ &quot;united kingdom&quot;, . == &quot;northern ireland&quot; ~ &quot;united kingdom&quot;, str_detect(., &quot;czech&quot;) ~ &quot;czechia&quot;, str_detect(., &quot;germany&quot;) ~ &quot;germany&quot;, TRUE ~ . ) ) %&gt;% select(full_name, prize_year, category, birth_date, birth_country, gender, organization_name, organization_country, death_country) nobel_winners_clean %&gt;% count(death_country, sort = TRUE) 12.15 迁移模式 nobel_winners_clean %&gt;% mutate( colour = case_when( death_country == &quot;united states of america&quot; ~ &quot;#FF2B4F&quot;, death_country == &quot;germany&quot; ~ &quot;#fcab27&quot;, death_country == &quot;united kingdom&quot; ~ &quot;#3686d3&quot;, death_country == &quot;france&quot; ~ &quot;#88398a&quot;, death_country == &quot;switzerland&quot; ~ &quot;#20d4bc&quot;, TRUE ~ &quot;gray60&quot; ) ) %&gt;% ggplot(aes( x = 0, y = fct_rev(factor(birth_country)), xend = death_country, yend = 1, colour = colour, alpha = (colour != &quot;gray60&quot;) )) + geom_curve(curvature = -0.5, arrow = arrow(length = unit(0.01, &quot;npc&quot;))) + scale_x_discrete() + scale_y_discrete() + scale_color_identity() + scale_alpha_manual(values = c(0.1, 0.2), guide = F) + scale_size_manual(values = c(0.1, 0.4), guide = F) + theme_minimal() + theme( panel.grid = element_blank(), plot.background = element_rect(fill = &quot;#F0EFF1&quot;, colour = &quot;#F0EFF1&quot;), legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 40, hjust = 1) ) 12.16 地图 library(here) library(sf) library(countrycode) #countrycode(&#39;Albania&#39;, &#39;country.name&#39;, &#39;iso3c&#39;) nobel_winners_birth_country &lt;- nobel_winners_clean %&gt;% count(birth_country) %&gt;% filter(!is.na(birth_country)) %&gt;% mutate(ISO3 = countrycode(birth_country, origin = &quot;country.name&quot;, destination = &quot;iso3c&quot;)) global &lt;- sf::st_read(&quot;./demo_data/worldmap/TM_WORLD_BORDERS_SIMPL-0.3.shp&quot;) %&gt;% st_transform(4326) ## Reading layer `TM_WORLD_BORDERS_SIMPL-0.3&#39; from data source `G:\\R_for_Data_Science\\demo_data\\worldmap\\TM_WORLD_BORDERS_SIMPL-0.3.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 246 features and 11 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -180 ymin: -90 xmax: 180 ymax: 83.57 ## geographic CRS: WGS 84 global %&gt;% full_join(nobel_winners_birth_country, by = &quot;ISO3&quot;) %&gt;% ggplot() + geom_sf(aes(fill = n), color = &quot;white&quot;, size = 0.1 ) + labs( x = NULL, y = NULL, title = &quot;Nobel Winners by country&quot;, subtitle = &quot;color of map indicates number of Nobel lauretes&quot;, fill = &quot;num of Nobel lauretes&quot;, caption = &quot;Made: wang_minjie&quot; ) + scale_fill_gradientn(colors = c(&quot;royalblue1&quot;,&quot;magenta&quot;,&quot;orange&quot;,&quot;gold&quot;), na.value = &quot;white&quot;) + #scale_fill_gradient(low = &quot;wheat1&quot;, high = &quot;red&quot;) + theme_void() + theme( legend.position = c(0.1, 0.3), plot.background = element_rect(fill = &quot;gray&quot;) ) # Determine to 10 Countries topCountries &lt;- nobel_winners_clean %&gt;% count(birth_country, sort = TRUE) %&gt;% na.omit() %&gt;% top_n(8) topCountries df4 &lt;- nobel_winners_clean %&gt;% filter(birth_country %in% topCountries$birth_country) %&gt;% group_by(birth_country, category, prize_year) %&gt;% summarise(prizes = n()) %&gt;% mutate(cumPrizes = cumsum(prizes)) df4 library(gganimate) df4 %&gt;% mutate(prize_year = as.integer(prize_year)) %&gt;% ggplot(aes(x = birth_country, y = category, color = birth_country)) + geom_point(aes(size = cumPrizes), alpha = 0.6) + #geom_text(aes(label = cumPrizes)) + scale_size_continuous(range = c(2, 30)) + transition_reveal(prize_year) + labs(title = &#39;诺奖获得者最多的10个国家&#39;, subtitle = &quot;Year: {frame_along}&quot;, y = &#39;Category&#39;) + theme_minimal() + theme( plot.title = element_text(size = 22), axis.title = element_blank()) + scale_color_brewer(palette = &quot;RdYlBu&quot;) + theme(legend.position = &quot;none&quot;) + theme(plot.margin = margin(5.5, 5.5, 5.5, 5.5)) 12.17 出生地和工作地不一样的占比 nobel_winners_clean %&gt;% select(category, birth_country, death_country) %&gt;% mutate(immigration = if_else(birth_country == death_country, 0, 1)) 12.18 诺奖分享者 nobel_winners %&gt;% separate(prize_share, into = c(&quot;num&quot;, &quot;deno&quot;), sep = &quot;/&quot;, remove = FALSE) nobel_winners %&gt;% filter(category == &quot;medicine&quot;) %&gt;% mutate(num_a = as.numeric(str_sub(prize_share, 1, 1)), num_b = as.numeric(str_sub(prize_share, -1)), share = num_a/num_b, year = prize_year %% 10, decade = 10 * (prize_year %/% 10) ) %&gt;% group_by(prize_year) %&gt;% mutate(n = row_number()) %&gt;% ggplot() + geom_col(aes(x = &quot;&quot;, y = share, fill = as.factor(n)), show.legend = FALSE ) + coord_polar(&quot;y&quot;) + facet_grid(decade ~ year, switch = &quot;both&quot;) + labs(title = &quot;每年诺贝尔奖分享情况&quot;) + theme_void() + theme( plot.title = element_text(face = &quot;bold&quot;, vjust = 8), strip.text.x = element_text(size = 7, margin = margin(t = 5)), strip.text.y = element_text(size = 7, angle = 180, hjust = 1, margin = margin(r = 10)) ) 12.19 其它 没有回答的问题，大家自己花时间探索下。 12.20 延伸阅读 有些图可以再美化下 "],
["eda02.html", "第 13 章 探索性数据分析2 13.1 导入数据 13.2 可视化 13.3 回归分析 13.4 预测 13.5 再次可视化 13.6 list_column 13.7 课后作业", " 第 13 章 探索性数据分析2 这是Nature期刊上的一篇文章Nature. 2004 September 30; 431(7008)， 虽然觉得这个结论不太严谨，但我却无力反驳。 于是在文章补充材料里，我找到了文章使用的数据，现在的任务是，重复这张图和文章的分析过程。 13.1 导入数据 library(tidyverse) library(readxl) d &lt;- read_excel(&quot;./demo_data/olympics.xlsx&quot;) d 13.2 可视化 我们先画图看看 d %&gt;% ggplot() + geom_point(aes(x = Olympic_year, y = Men_score), color = &quot;blue&quot;) + geom_point(aes(x = Olympic_year, y = Women_score), color = &quot;red&quot;) 这样写也是可以的，只不过最好先tidy数据 d1 &lt;- d %&gt;% pivot_longer( cols = -Olympic_year, names_to = &quot;sex&quot;, values_to = &quot;winning_time&quot; ) d1 然后在画图 d1 %&gt;% ggplot(aes(x = Olympic_year, y = winning_time, color = sex)) + geom_point() + #geom_smooth(method = &quot;lm&quot;) + scale_color_manual( values = c(&quot;Men_score&quot; = &quot;blue&quot;, &quot;Women_score&quot; = &quot;red&quot;) ) + scale_x_continuous( breaks = seq(1900, 2004, by = 4), labels = seq(1900, 2004, by = 4) ) + theme(axis.text.x = element_text( size = 10, angle = 45, colour = &quot;black&quot;, vjust = 1, hjust = 1 )) 13.3 回归分析 建立年份与成绩的线性关系 \\[ \\text{score}_i = \\alpha + \\beta \\times \\text{year}_i + \\epsilon_i; \\qquad \\epsilon_i\\in \\text{Normal}(\\mu, \\sigma) \\] 我们需要求出其中系数\\(\\alpha\\)和\\(\\beta\\)，写R语言代码如下 (lm(y ~ 1 + x,data = d), 要求得 \\(\\alpha\\)和\\(\\beta\\)，就是对应 1 和 x 前的系数) fit_1 &lt;- lm(Men_score ~ 1 + Olympic_year, data = d) summary(fit_1) ## ## Call: ## lm(formula = Men_score ~ 1 + Olympic_year, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.26371 -0.05270 0.00738 0.08005 0.21456 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 31.826453 1.679643 18.9 4.1e-15 *** ## Olympic_year -0.011006 0.000859 -12.8 1.1e-11 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.135 on 22 degrees of freedom ## (3 observations deleted due to missingness) ## Multiple R-squared: 0.882, Adjusted R-squared: 0.876 ## F-statistic: 164 on 1 and 22 DF, p-value: 1.13e-11 fit_2 &lt;- lm(Women_score ~ 1 + Olympic_year, data = d) summary(fit_2) ## ## Call: ## lm(formula = Women_score ~ 1 + Olympic_year, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.3758 -0.0846 0.0093 0.0829 0.3223 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 44.34705 4.28425 10.35 1.7e-08 *** ## Olympic_year -0.01682 0.00218 -7.73 8.6e-07 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.21 on 16 degrees of freedom ## (9 observations deleted due to missingness) ## Multiple R-squared: 0.789, Adjusted R-squared: 0.776 ## F-statistic: 59.8 on 1 and 16 DF, p-value: 8.63e-07 13.4 预测 使用predict()完成预测 df &lt;- data.frame(Olympic_year = 2020) predict(fit_1, newdata = df) ## 1 ## 9.595 为了图片中的一致，我们使用1900年到2252年(seq(1900, 2252, by = 4))建立预测项，并整理到数据框里 grid &lt;- tibble( Olympic_year = as.numeric(seq(1900, 2252, by = 4)) ) grid tb &lt;- grid %&gt;% mutate( Predict_Men = predict(fit_1, newdata = grid), Predict_Women = predict(fit_2, newdata = grid) ) tb 有时候我喜欢用modelr::add_predictions()函数实现相同的功能 library(modelr) grid %&gt;% add_predictions(fit_1, var = &quot;Predict_Men&quot;) %&gt;% add_predictions(fit_2, var = &quot;Predict_Women&quot;) 13.5 再次可视化 tb1 &lt;- tb %&gt;% pivot_longer( cols = -Olympic_year, names_to = &quot;sex&quot;, values_to = &quot;winning_time&quot; ) tb1 tb1 %&gt;% ggplot(aes(x = Olympic_year, y = winning_time, color = sex) ) + geom_line(size = 2) + geom_point(data = d1) + scale_color_manual( name = &quot;标记&quot;, values = c(&quot;Men_score&quot; = &quot;blue&quot;, &quot;Women_score&quot; = &quot;red&quot;, &quot;Predict_Men&quot; = &quot;#588B8B&quot;, &quot;Predict_Women&quot; = &quot;#C8553D&quot;), labels = c(&quot;Men_score&quot; = &quot;男性历史成绩&quot;, &quot;Women_score&quot; = &quot;女性历史成绩&quot;, &quot;Predict_Men&quot; = &quot;男性预测成绩&quot;, &quot;Predict_Women&quot; = &quot;女性预测成绩&quot;) ) + scale_x_continuous( breaks = seq(1900, 2252, by = 16), labels = as.character(seq(1900, 2252, by = 16)) ) + theme(axis.text.x = element_text( size = 10, angle = 45, colour = &quot;black&quot;, vjust = 1, hjust = 1 )) 早知道nature文章这么简单，10年前我也可以写啊！ 13.6 list_column 这里是另外的一种方法 library(modelr) d1 &lt;- d %&gt;% pivot_longer( cols = -Olympic_year, names_to = &quot;sex&quot;, values_to = &quot;winning_time&quot; ) fit_model &lt;- function(df) lm(winning_time ~ Olympic_year, data = df) d2 &lt;- d1 %&gt;% group_nest(sex) %&gt;% mutate( mod = map(data, fit_model) ) d2 # d2 %&gt;% mutate(p = list(grid, grid)) # d3 &lt;- d2 %&gt;% mutate(p = list(grid, grid)) # d3 # d3 %&gt;% # mutate( # predictions = map2(p, mod, add_predictions), # ) # or tb4 &lt;- d2 %&gt;% mutate( predictions = map(mod, ~ add_predictions(grid, .)) ) %&gt;% select(sex, predictions) %&gt;% unnest(predictions) tb4 %&gt;% ggplot(aes(x = Olympic_year, y = pred, group = sex, color = sex) ) + geom_point() + geom_line(size = 2) + geom_point(data = d1, aes(x = Olympic_year, y = winning_time, group = sex, color = sex) ) + scale_x_continuous( breaks = seq(1900, 2252, by = 16), labels = as.character(seq(1900, 2252, by = 16)) ) + theme(axis.text.x = element_text( size = 10, angle = 45, colour = &quot;black&quot;, vjust = 1, hjust = 1 )) 13.7 课后作业 探索数据，建立身高体重的线性模型 "],
["eda03.html", "第 14 章 探索性数据分析3 14.1 数据来源 14.2 读取数据 14.3 数据集结构 14.4 数据清洗规整 14.5 可视化探索 14.6 每个国家的情况 14.7 地图 14.8 更多", " 第 14 章 探索性数据分析3 library(tidyverse) library(lubridate) library(maps) library(viridis) library(ggrepel) library(paletteer) library(shadowtext) library(showtext) showtext_auto() 新型冠状病毒（俗称武汉肺炎）疫情在多国蔓延，本章通过分析疫情数据，了解疫情发展，祝愿人类早日会战胜病毒！ 图 14.1: 电影《传染病》,《流感》海报 图 14.2: 电影《传染病》,《流感》海报 14.1 数据来源 我们打开链接https://github.com/CSSEGISandData/COVID-19， 找到疫情时间序列数据，你可以通过点击该网页Clone or download直接下载的方式获取数据。 14.2 读取数据 假定你已经下载了数据，比如time_series_covid19_confirmed_global.csv， 那么我们可以用readr::read_csv()函数直接读取, 关于在R语言里文件读取的方法可以参考第 5 章。 d &lt;- read_csv(&quot;./demo_data/time_series_covid19_confirmed_global.csv&quot;) d 14.3 数据集结构 探索数据之前，我们一定要对数据存储结构、数据变量名及其含义要非常清楚，重要的事情说三遍。 glimpse(d) ## Rows: 256 ## Columns: 74 ## $ `Province/State` &lt;chr&gt; NA, NA, NA, NA, NA, NA, N... ## $ `Country/Region` &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;,... ## $ Lat &lt;dbl&gt; 33.00, 41.15, 28.03, 42.5... ## $ Long &lt;dbl&gt; 65.000, 20.168, 1.660, 1.... ## $ `1/22/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/23/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/24/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/25/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/26/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/27/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/28/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/29/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/30/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/31/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/1/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/2/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/3/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/4/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/5/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/6/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/7/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/8/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/9/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/10/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/11/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/12/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/13/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/14/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/15/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/16/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/17/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/18/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/19/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/20/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/21/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/22/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/23/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/24/20` &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/25/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `2/26/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `2/27/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `2/28/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `2/29/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `3/1/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0... ## $ `3/2/20` &lt;dbl&gt; 1, 0, 3, 1, 0, 0, 0, 1, 0... ## $ `3/3/20` &lt;dbl&gt; 1, 0, 5, 1, 0, 0, 1, 1, 0... ## $ `3/4/20` &lt;dbl&gt; 1, 0, 12, 1, 0, 0, 1, 1, ... ## $ `3/5/20` &lt;dbl&gt; 1, 0, 12, 1, 0, 0, 1, 1, ... ## $ `3/6/20` &lt;dbl&gt; 1, 0, 17, 1, 0, 0, 2, 1, ... ## $ `3/7/20` &lt;dbl&gt; 1, 0, 17, 1, 0, 0, 8, 1, ... ## $ `3/8/20` &lt;dbl&gt; 4, 0, 19, 1, 0, 0, 12, 1,... ## $ `3/9/20` &lt;dbl&gt; 4, 2, 20, 1, 0, 0, 12, 1,... ## $ `3/10/20` &lt;dbl&gt; 5, 10, 20, 1, 0, 0, 17, 1... ## $ `3/11/20` &lt;dbl&gt; 7, 12, 20, 1, 0, 0, 19, 1... ## $ `3/12/20` &lt;dbl&gt; 7, 23, 24, 1, 0, 0, 19, 4... ## $ `3/13/20` &lt;dbl&gt; 7, 33, 26, 1, 0, 1, 31, 8... ## $ `3/14/20` &lt;dbl&gt; 11, 38, 37, 1, 0, 1, 34, ... ## $ `3/15/20` &lt;dbl&gt; 16, 42, 48, 1, 0, 1, 45, ... ## $ `3/16/20` &lt;dbl&gt; 21, 51, 54, 2, 0, 1, 56, ... ## $ `3/17/20` &lt;dbl&gt; 22, 55, 60, 39, 0, 1, 68,... ## $ `3/18/20` &lt;dbl&gt; 22, 59, 74, 39, 0, 1, 79,... ## $ `3/19/20` &lt;dbl&gt; 22, 64, 87, 53, 0, 1, 97,... ## $ `3/20/20` &lt;dbl&gt; 24, 70, 90, 75, 1, 1, 128... ## $ `3/21/20` &lt;dbl&gt; 24, 76, 139, 88, 2, 1, 15... ## $ `3/22/20` &lt;dbl&gt; 40, 89, 201, 113, 2, 1, 2... ## $ `3/23/20` &lt;dbl&gt; 40, 104, 230, 133, 3, 3, ... ## $ `3/24/20` &lt;dbl&gt; 74, 123, 264, 164, 3, 3, ... ## $ `3/25/20` &lt;dbl&gt; 84, 146, 302, 188, 3, 3, ... ## $ `3/26/20` &lt;dbl&gt; 94, 174, 367, 224, 4, 7, ... ## $ `3/27/20` &lt;dbl&gt; 110, 186, 409, 267, 4, 7,... ## $ `3/28/20` &lt;dbl&gt; 110, 197, 454, 308, 5, 7,... ## $ `3/29/20` &lt;dbl&gt; 120, 212, 511, 334, 7, 7,... ## $ `3/30/20` &lt;dbl&gt; 170, 223, 584, 370, 7, 7,... ## $ `3/31/20` &lt;dbl&gt; 174, 243, 716, 376, 7, 7,... 14.4 数据清洗规整 14.4.1 必要的预备知识之select() d %&gt;% select(-c(1:4)) d %&gt;% select(5:ncol(.)) d %&gt;% select(matches(&quot;/20&quot;)) d %&gt;% select(ends_with(&quot;/20&quot;)) # 应该还有其他的方法 14.4.2 必要的预备知识之pivot_longer() 宽表格变长表格，需要用到pivot_longer() 和 pivot_wider()， 比如 table4a longer &lt;- table4a %&gt;% pivot_longer( cols = `1999`:`2000`, names_to = &quot;year&quot;, values_to = &quot;cases&quot; ) longer 14.4.3 必要的预备知识之pivot_wider() 有时候我们想折腾下，比如把长表格再变回宽表格 longer %&gt;% pivot_wider( names_from = year, values_from = cases ) 14.4.4 必要的预备知识之日期格式 有时候，我会遇到日期date这种数据类型，我推荐使用lubridate包来处理，比如 c(&quot;2020-3-25&quot;, &quot;20200325&quot;, &quot;20-03-25&quot;, &quot;2020 03 25&quot;) %&gt;% lubridate::ymd() ## [1] &quot;2020-03-25&quot; &quot;2020-03-25&quot; &quot;2020-03-25&quot; &quot;2020-03-25&quot; c(&quot;3/25/20&quot;, &quot;03-25-20&quot;, &quot;3-25/2020&quot;) %&gt;% lubridate::mdy() ## [1] &quot;2020-03-25&quot; &quot;2020-03-25&quot; &quot;2020-03-25&quot; 遇到这种010210日期的，请把输入数据的人扁一顿，他会告诉你的 lubridate::dmy(010210) lubridate::dym(010210) lubridate::mdy(010210) lubridate::myd(010210) lubridate::ymd(010210) lubridate::ydm(010210) 14.4.5 必要的预备知识之时间差 difftime(ymd(&quot;2020-03-24&quot;), ymd(&quot;2020-03-23&quot;), units = &quot;days&quot; ) ## Time difference of 1 days 或者更直观的表述 ymd(&quot;2020-03-24&quot;) - ymd(&quot;2020-03-23&quot;) ## Time difference of 1 days 转换为天数 (ymd(&quot;2020-03-24&quot;) - ymd(&quot;2020-03-23&quot;)) %&gt;% as.numeric() ## [1] 1 14.4.6 有时候需要log10_scale tb &lt;- tibble( days_since_100 = 0:18, cases = 100 * 1.33^days_since_100 ) p1 &lt;- tb %&gt;% ggplot(aes(days_since_100, cases)) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) p2 &lt;- tb %&gt;% ggplot(aes(days_since_100, log10(cases))) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) p3 &lt;- tb %&gt;% ggplot(aes(days_since_100, cases)) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) + scale_y_log10() library(patchwork) p1 + p2 + p3 14.4.7 数据清洗规整 d1 &lt;- d %&gt;% pivot_longer( cols = 5:ncol(.), names_to = &quot;date&quot;, values_to = &quot;cases&quot; ) %&gt;% mutate(date = lubridate::mdy(date)) %&gt;% janitor::clean_names() %&gt;% group_by(country_region, date) %&gt;% summarise(cases = sum(cases)) %&gt;% ungroup() d1 d1 %&gt;% group_by(date) %&gt;% summarise(confirmed = sum(cases)) 【WHO：2019冠状病毒全球大流行正在“加速”】世界卫生组织（WHO）昨日发出警告，指2019冠状病毒全球感染者已超过30万人，全球大流行正在“加速”。世卫组织指，从首例病例报告到感染者达到10万人用了67天；感染人数增至20万用了11天；从20万到突破30万则只用了4天。 d1 %&gt;% group_by(date) %&gt;% summarise(confirmed = sum(cases)) %&gt;% ggplot(aes(x = date, y = confirmed)) + geom_point() + scale_x_date( date_labels = &quot;%m-%d&quot;, date_breaks = &quot;1 week&quot; ) + scale_y_continuous( breaks = c(0, 50000, 100000, 200000, 300000, 500000, 900000), labels = scales::comma ) # d1 %&gt;% distinct(country_region) %&gt;% pull(country_region) d1 %&gt;% distinct(country_region) d1 %&gt;% filter(country_region == &quot;China&quot;) d1 %&gt;% filter(country_region == &quot;China&quot;) %&gt;% ggplot(aes(x = date, y = cases)) + geom_point() + scale_x_date(date_breaks = &quot;1 week&quot;, date_labels = &quot;%m-%d&quot;) + scale_y_log10(labels = scales::comma) d1 %&gt;% group_by(country_region) %&gt;% filter(max(cases) &gt;= 20000) %&gt;% ungroup() %&gt;% ggplot(aes(x = date, y = cases, color = country_region)) + geom_point() + scale_x_date(date_breaks = &quot;1 week&quot;, date_labels = &quot;%m-%d&quot;) + scale_y_log10() + facet_wrap(vars(country_region), ncol = 2) + theme( axis.text.x = element_text(angle = 45, hjust = 1) ) + theme(legend.position = &quot;none&quot;) 14.5 可视化探索 网站https://www.ft.com/coronavirus-latest 这张图很受关注，于是打算重复 图 14.3: 图片来源www.ft.com 这张图想表达的是，出现100个案例后，各国确诊人数的爆发趋势 横坐标是天数，即在出现100个案例后的第几天 纵坐标是累积确诊人数 那么，我们需要对数据的时间轴做相应的变形 首先按照国家分组 筛选，累积确诊人数超过100的国家 找到所有case &gt;= 100的日期，date[cases &gt;= 100] 最早的日期，就说我们要找的第 0 day， min(date[cases &gt;= 100]) 构建新的一列mutate( days_since_100 = date - min(date[cases &gt;= 100]) 将days_since_100转换成数值型as.numeric() d2 &lt;- d1 %&gt;% group_by(country_region) %&gt;% filter(max(cases) &gt;= 100) %&gt;% mutate( days_since_100 = date - min(date[cases &gt;= 100]) ) %&gt;% mutate(days_since_100 = as.numeric(days_since_100)) %&gt;% filter(days_since_100 &gt;= 0) %&gt;% ungroup() d2 大家都谈过恋爱，也有可能失恋。大家失恋时间是不同的，若把失恋的当天作为第 0 day, 就可以比较失恋若干天后每个人精神波动情况。参照《失恋33天》 d2_most &lt;- d2 %&gt;% group_by(country_region) %&gt;% top_n(1, days_since_100) %&gt;% filter(cases &gt;= 10000) %&gt;% ungroup() %&gt;% arrange(desc(cases)) d2_most d2 %&gt;% bind_rows( tibble(country = &quot;33% daily rise&quot;, days_since_100 = 0:30) %&gt;% mutate(cases = 100 * 1.33^days_since_100) ) %&gt;% ggplot(aes(days_since_100, cases, color = country_region)) + geom_hline(yintercept = 100) + geom_vline(xintercept = 0) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) + # scale_colour_manual( # values = c( # &quot;US&quot; = &quot;#EB5E8D&quot;, # &quot;Italy&quot; = &quot;black&quot;, # &quot;Spain&quot; = &quot;#c2b7af&quot;, # &quot;China&quot; = &quot;red&quot;, # &quot;Germany&quot; = &quot;#c2b7af&quot;, # &quot;France&quot; = &quot;#c2b7af&quot;, # &quot;Iran&quot; = &quot;#9dbf57&quot;, # &quot;United Kingdom&quot; = &quot;#ce3140&quot;, # &quot;Korea, South&quot; = &quot;#208fce&quot;, # &quot;Japan&quot; = &quot;#208fce&quot;, # &quot;Singapore&quot; = &quot;#1E8FCC&quot;, # &quot;33% daily rise&quot; = &quot;#D9CCC3&quot;, # &quot;Switzerland&quot; = &quot;#c2b7af&quot;, # &quot;Turkey&quot; = &quot;#208fce&quot;, # &quot;Belgium&quot; = &quot;#c2b7af&quot;, # &quot;Netherlands&quot; = &quot;#c2b7af&quot;, # &quot;Austria&quot; = &quot;#c2b7af&quot;, # &quot;Hong Kong&quot; = &quot;#1E8FCC&quot;, # # gray # &quot;India&quot; = &quot;#c2b7af&quot;, # &quot;Switzerland&quot; = &quot;#c2b7af&quot;, # &quot;Belgium&quot; = &quot;#c2b7af&quot;, # &quot;Norway&quot; = &quot;#c2b7af&quot;, # &quot;Sweden&quot; = &quot;#c2b7af&quot;, # &quot;Austria&quot; = &quot;#c2b7af&quot;, # &quot;Australia&quot; = &quot;#c2b7af&quot;, # &quot;Denmark&quot; = &quot;#c2b7af&quot;, # &quot;Canada&quot; = &quot;#c2b7af&quot;, # &quot;Brazil&quot; = &quot;#c2b7af&quot;, # &quot;Portugal&quot; = &quot;#c2b7af&quot; # ) # ) + geom_shadowtext( data = d2_most, aes(label = paste0(&quot; &quot;, country_region)), bg.color = &quot;white&quot; ) + scale_y_log10( expand = expansion(mult = c(0, .1)), breaks = c(100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000), labels = scales::comma ) + scale_x_continuous( expand = expansion(mult = c(0, .1)), breaks = c(0, 5, 10, 15, 20, 25, 30) ) + theme_minimal() + theme( panel.grid.minor = element_blank(), plot.background = element_rect(fill = &quot;#FFF1E6&quot;), legend.position = &quot;none&quot;, panel.spacing = margin(3, 15, 3, 15, &quot;mm&quot;) ) + labs( x = &quot;Number of days since 100th case&quot;, y = &quot;&quot;, title = &quot;Country by country: how coronavirus case trajectories compare&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot; ) 有点乱，还有很多细节没有实现，后面再弄弄了 14.5.1 简便的方法 d2a &lt;- d1 %&gt;% group_by(country_region) %&gt;% filter(cases &gt;= 100) %&gt;% mutate(days_since_100 = 0:(n() - 1)) %&gt;% # same as # mutate(edate = as.numeric(date - min(date))) ungroup() d2a 这里的d2a 和d2是一样的了，但方法简单很多。 14.5.2 疫情持续时间最久的国家 d3 &lt;- d2a %&gt;% group_by(country_region) %&gt;% filter(days_since_100 == max(days_since_100)) %&gt;% # same as # top_n(1, days_since_100) %&gt;% ungroup() %&gt;% arrange(desc(days_since_100)) d3 highlight &lt;- d3 %&gt;% top_n(10, days_since_100) %&gt;% pull(country_region) highlight ## [1] &quot;China&quot; &quot;Diamond Princess&quot; ## [3] &quot;Korea, South&quot; &quot;Japan&quot; ## [5] &quot;Italy&quot; &quot;Iran&quot; ## [7] &quot;France&quot; &quot;Singapore&quot; ## [9] &quot;Germany&quot; &quot;Spain&quot; d2a %&gt;% bind_rows( tibble(country = &quot;33% daily rise&quot;, days_since_100 = 0:30) %&gt;% mutate(cases = 100 * 1.33^days_since_100) ) %&gt;% ggplot(aes(days_since_100, cases, color = country_region)) + geom_hline(yintercept = 100) + geom_vline(xintercept = 0) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) + scale_y_log10( expand = expansion(mult = c(0, .1)), breaks = c(100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000), labels = scales::comma ) + scale_x_continuous( expand = expansion(mult = c(0, .1)), breaks = c(0, 5, 10, 15, 20, 25, 30, 40, 50, 60) ) + theme_minimal() + theme( panel.grid.minor = element_blank(), plot.background = element_rect(fill = &quot;#FFF1E6&quot;), legend.position = &quot;none&quot;, panel.spacing = margin(3, 15, 3, 15, &quot;mm&quot;) ) + labs( x = &quot;Number of days since 100th case&quot;, y = &quot;&quot;, title = &quot;Country by country: how coronavirus case trajectories compare&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot; ) + gghighlight::gghighlight(country_region %in% highlight, label_key = country_region, use_direct_label = TRUE, label_params = list(segment.color = NA, nudge_x = 1), use_group_by = FALSE ) 灰色线条的国家名，有点不好弄，在想办法 14.5.3 笨办法吧 笨办法，实际上是4张表共同完成 highlight &lt;- c( &quot;China&quot;, &quot;Spain&quot;, &quot;US&quot;, &quot;United Kingdom&quot;, &quot;Korea, South&quot;, &quot;Italy&quot;, &quot;Japan&quot;, &quot;Singapore&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Iran&quot; ) gray &lt;- c( &quot;India&quot;, &quot;Switzerland&quot;, &quot;Belgium&quot;, &quot;Netherlands&quot;, &quot;Sweden&quot;, &quot;Austria&quot;, &quot;Australia&quot;, &quot;Denmark&quot;, &quot;Canada&quot;, &quot;Brazil&quot;, &quot;Portugal&quot; ) d3_highlight &lt;- d2a %&gt;% filter(country_region %in% highlight) d3_gray &lt;- d2a %&gt;% filter(country_region %in% gray) d2a %&gt;% ggplot(aes(days_since_100, cases, group = country_region)) + geom_hline(yintercept = 100) + geom_vline(xintercept = 0) + geom_line(size = 0.8, color = &quot;gray70&quot;) + geom_point(pch = 21, size = 1, color = &quot;gray70&quot;) + # highlight country geom_line(data = d3_highlight, aes(color = country_region)) + geom_point(data = d3_highlight, aes(color = country_region)) + geom_text( data = d3_highlight %&gt;% group_by(country_region) %&gt;% top_n(1, days_since_100) %&gt;% ungroup(), aes(color = country_region, label = country_region), hjust = 0, vjust = 0, nudge_x = 0.5 ) + # gray country geom_text( data = d3_gray %&gt;% group_by(country_region) %&gt;% top_n(1, days_since_100) %&gt;% ungroup(), aes(label = country_region), color = &quot;gray50&quot;, hjust = 0, vjust = 0, nudge_x = 0.5 ) + geom_point( data = d3_gray %&gt;% group_by(country_region) %&gt;% top_n(1, days_since_100) %&gt;% ungroup(), size = 2, color = &quot;gray50&quot; ) + scale_y_log10( expand = expansion(mult = c(0, .1)), breaks = c(100, 200, 500, 2000, 5000, 10000, 20000, 50000, 100000, 150000), labels = scales::comma ) + scale_x_continuous( expand = expansion(mult = c(0, .1)), breaks = c(0, 5, 10, 15, 20, 25, 30, 40, 50, 60) ) + theme_minimal() + theme( panel.grid.minor = element_blank(), plot.background = element_rect(fill = &quot;#FFF1E6&quot;), legend.position = &quot;none&quot;, panel.spacing = margin(3, 15, 3, 15, &quot;mm&quot;) ) + labs( x = &quot;Number of days since 100th case&quot;, y = &quot;&quot;, title = &quot;Country by country: how coronavirus case trajectories compare&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot; ) 差强人意，再想想有没有好的办法 14.5.4 比较tidy的方法 对数据框d2a增加两列属性(有无标签，有无颜色)，然后手动改颜色 highlight_country &lt;- d2a %&gt;% group_by(country_region) %&gt;% filter(days_since_100 == max(days_since_100)) %&gt;% ungroup() %&gt;% arrange(desc(days_since_100)) %&gt;% top_n(10, days_since_100) %&gt;% pull(country_region) highlight_country ## [1] &quot;China&quot; &quot;Diamond Princess&quot; ## [3] &quot;Korea, South&quot; &quot;Japan&quot; ## [5] &quot;Italy&quot; &quot;Iran&quot; ## [7] &quot;France&quot; &quot;Singapore&quot; ## [9] &quot;Germany&quot; &quot;Spain&quot; 吸取了Kieran Healy大神的配色方案 ## Colors cgroup_cols &lt;- c(prismatic::clr_darken(paletteer_d(&quot;ggsci::category20_d3&quot;), 0.2)[1:length(highlight_country)], &quot;gray70&quot;) scales::show_col(cgroup_cols) d2a %&gt;% group_by(country_region) %&gt;% filter(max(days_since_100) &gt; 9) %&gt;% mutate( end_label = ifelse(days_since_100 == max(days_since_100), country_region, NA_character_) ) %&gt;% mutate(end_label = case_when(country_region %in% highlight_country ~ end_label, TRUE ~ NA_character_), cgroup = case_when(country_region %in% highlight_country ~ country_region, TRUE ~ &quot;ZZOTHER&quot;)) %&gt;% # length(highlight_country) + gray ggplot(aes(x = days_since_100, y = cases, color = cgroup, label = end_label, group = country_region)) + geom_line(size = 0.8) + geom_text_repel(nudge_x = 1.1, nudge_y = 0.1, segment.color = NA) + guides(color = FALSE) + scale_color_manual(values = cgroup_cols) + scale_y_continuous(labels = scales::comma_format(accuracy = 1), breaks = 10^seq(2, 8), trans = &quot;log10&quot; ) + labs(x = &quot;Days Since 100 Confirmed Death&quot;, y = &quot;Cumulative Number of Deaths (log10 scale)&quot;, title = &quot;Cumulative Number of Reported Deaths from COVID-19, Selected Countries&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot;) 感觉这样是最好的方案。 14.6 每个国家的情况 d2 %&gt;% group_by(country_region) %&gt;% filter(max(cases) &gt;= 1000) %&gt;% ungroup() d2 %&gt;% group_by(country_region) %&gt;% filter(max(cases) &gt;= 1000) %&gt;% ungroup() %&gt;% ggplot(aes(days_since_100, cases)) + geom_line(size = 0.8) + geom_line( data = d2 %&gt;% rename(country = country_region), aes(days_since_100, cases, group = country), color = &quot;grey&quot; ) + geom_point(pch = 21, size = 1, color = &quot;red&quot;) + scale_y_log10( expand = expansion(mult = c(0, .1)), breaks = c(100, 1000, 10000, 50000) ) + scale_x_continuous( expand = expansion(mult = c(0, 0)), breaks = c(0, 5, 10, 20, 30, 50) ) + facet_wrap(vars(country_region), scales = &quot;free_x&quot;) + theme( panel.background = element_rect(fill = &quot;#FFF1E6&quot;), plot.background = element_rect(fill = &quot;#FFF1E6&quot;) ) + labs( x = &quot;Number of days since 100th case&quot;, y = &quot;&quot;, title = &quot;Outbreak are now underway in dozens of other countries, with some on the same trajectory as Italy&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot; ) 14.7 地图 library(countrycode) # countrycode(&#39;Albania&#39;, &#39;country.name&#39;, &#39;iso3c&#39;) d2_newest %&gt;% mutate(ISO3 = countrycode(country_region, origin = &quot;country.name&quot;, destination = &quot;iso3c&quot; )) 我们选取最新的日期 d_newest &lt;- d %&gt;% select(Long, Lat, last_col()) %&gt;% set_names(&quot;Long&quot;, &quot;Lat&quot;, &quot;newest_date&quot;) d_newest world &lt;- map_data(&quot;world&quot;) ggplot() + geom_polygon( data = world, aes(x = long, y = lat, group = group), fill = &quot;grey&quot;, alpha = 0.3 ) + geom_point( data = d_newest, aes(x = Long, y = Lat, size = newest_date, color = newest_date), stroke = F, alpha = 0.7 ) + scale_size_continuous( name = &quot;Cases&quot;, trans = &quot;log&quot;, range = c(1, 7), breaks = c(1, 20, 100, 1000, 50000), labels = c(&quot;1-19&quot;, &quot;20-99&quot;, &quot;100-999&quot;, &quot;1,000-49,999&quot;, &quot;50,000+&quot;) ) + scale_color_viridis_c( option = &quot;inferno&quot;, name = &quot;Cases&quot;, trans = &quot;log&quot;, breaks = c(1, 20, 100, 1000, 50000), labels = c(&quot;1-19&quot;, &quot;20-99&quot;, &quot;100-999&quot;, &quot;1,000-49,999&quot;, &quot;50,000+&quot;) ) + theme_void() + guides(colour = guide_legend()) + labs( title = &quot;Mapping the coronavirus outbreak&quot;, subtitle = &quot;&quot;, caption = &quot;Source: JHU Unviersity, CSSE; FT research @www.FT.com&quot; ) + theme( legend.position = &quot;bottom&quot;, text = element_text(color = &quot;#22211d&quot;), plot.background = element_rect(fill = &quot;#ffffff&quot;, color = NA), panel.background = element_rect(fill = &quot;#ffffff&quot;, color = NA), legend.background = element_rect(fill = &quot;#ffffff&quot;, color = NA) ) 14.8 更多 参考 (https://www.ft.com/coronavirus-latest) (https://covid19datahub.io/) "],
["eda04.html", "第 15 章 探索性数据分析4 15.1 探索anscombe 15.2 规整数据 15.3 统计 15.4 建模 15.5 可视化看看", " 第 15 章 探索性数据分析4 在可视化章节，我们提到 Anscombe’s quartet这个数据集， ?datasets::anscombe 在其官方文档，我们可看到它是这样描述的： Four x-y datasets which have the same traditional statistical properties (mean, variance, correlation, regression line, etc.), yet are quite different. d &lt;- datasets::anscombe head(d) 15.1 探索anscombe library(tidyverse) 本节课的内容，就是用tidyverse的方法去探索下这个数据集： 规整数据 分组统计 建模 可视化 15.2 规整数据 我们再看看数据 head(d) 实际上，这是四组(x1, y1), (x2, y2), (x3, y3), (x4, y4)。那要怎么样规整数据， 或者说怎么样把数据弄成tidy呢。这里有个技巧，你可以想象，数据能ggplot()可视化的基本上就是tidy的。 d %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + facet_wrap(~set) 那么，我们希望我们的数据是这样的格式 | set | x | y | |—–|—-|——| | 1 | 10 | 8.04 | | 1 | 8 | 6.95 | | … | | | | 2 | 10 | 9.14 | | 2 | 8 | 8.14 | | … | | | 15.2.1 小小的回顾 我们之前讲过，数据变形中，宽表格变成长表格， 需要用到tidyr::pivot_longer()函数 比如 dt &lt;- tibble(id = c(&quot;a&quot;, &quot;b&quot;), x_1 = 1:2, x_2 = 3:4, y_1 = 5:6, y_2 = 8:9) dt dt %&gt;% pivot_longer(-id, names_to = &quot;name&quot;, values_to = &quot;vaules&quot;) 有时候，我们不想要下划线后面的编号，只想保留前面的第一个字母 dt %&gt;% pivot_longer( cols = -id, names_to = &quot;name&quot;, names_pattern = &quot;(.)_.&quot;, values_to = &quot;vaules&quot; ) 有时候人的需求是多样的，比如不想要前面的第一个字母，只要下划线后面的编号 dt %&gt;% pivot_longer( cols = -id, names_to = &quot;name&quot;, names_pattern = &quot;._(.)&quot;, values_to = &quot;vaules&quot; ) 有时候我们都想要呢？ dt %&gt;% pivot_longer( cols = -id, names_to = c(&quot;name&quot;, &quot;group&quot;), names_pattern = &quot;(.)_(.)&quot;, values_to = &quot;vaules&quot; ) 有时候，我们希望\"x\", \"y\"保留在列名，那么匹配出来的第一个字母，就不能给\"name\"，而是传给特殊的符号\".value\"，它会收集匹配出来的字符，然后放在列名中 dt %&gt;% pivot_longer( cols = -id, names_to = c(&quot;.value&quot;, &quot;group&quot;), names_pattern = &quot;(.)_(.)&quot;, values_to = &quot;vaules&quot; ) 是不是觉得很强大？ 15.2.2 回到案例 具体来说，我们希望 x1 按照指定的正则表达式分成了两个部分 x和 1，那么1放在set下，而 x 传给了.value 当作变型后的列名. knitr::include_graphics(&quot;images/pivot_longer_values.jpg&quot;) 那么和上面的情况一样，使用tidyr::pivot_longer()函数 tidy_d &lt;- d %&gt;% pivot_longer( cols = everything(), names_to = c(&quot;.value&quot;, &quot;set&quot;), names_pattern = &quot;(.)(.)&quot; ) tidy_d 再啰嗦下参数的含义： cols = everything() 表示选择所有列 names_to = c(\".value\", \"set\") 希望变型后的列名是c(\".value\", \"set\"), 这里 \".value\" 是个特殊的符号，代表着names_pattern匹配过来的值，一般情况下，是多个值，如果传给\".value\"的\"x, y, z\"，那么列名就会变成c(\"x\", \"y\", \"z\", \"set\") names_pattern = \"(.)(.)\" 将变换前的列名按照指定的正则表达式匹配，并且传递给names_to的对应的参数，比如这里第一个(.)传递给.value；第二个(.)传递给set. 15.3 统计 数据规整了，统计就很简单了 tidy_d_summary &lt;- tidy_d %&gt;% group_by(set) %&gt;% summarise(across(.cols = everything(), .fns = lst(mean, sd, var), .names = &quot;{col}_{fn}&quot;) ) tidy_d_summary 15.4 建模 具体参考第 7 章整理的四种方法 tidy_d %&gt;% group_nest(set) %&gt;% mutate(fit = map(data, ~lm(y ~ x, data = .x)), tidy = map(fit, broom::tidy), glance = map(fit, broom::glance) ) %&gt;% unnest(tidy) 感觉大家更喜欢这种 tidy_d %&gt;% group_by(set) %&gt;% group_modify( ~ broom::tidy(lm(y ~ x, data = .)) ) tidy_d %&gt;% group_by(set) %&gt;% summarise( broom::tidy(lm(y ~ x, data = cur_data())) ) 15.5 可视化看看 tidy_d %&gt;% ggplot(aes(x = x, y = y, colour = set)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + theme(legend.position = &quot;none&quot;) + facet_wrap(~set) "],
["eda05.html", "第 16 章 探索性数据分析5 16.1 案例分析 16.2 可视化 16.3 来点高级的 16.4 建模", " 第 16 章 探索性数据分析5 library(tidyverse) 16.1 案例分析 这是一份身高和体重的数据集 d &lt;- read_csv(&quot;./demo_data/weight-height.csv&quot;) d d %&gt;% summarise( across(everything(), ~ sum(is.na(.))) ) 16.2 可视化 16.2.1 画出不同性别的身高分布 常规答案 d %&gt;% ggplot(aes(x = Height, fill = Gender)) + geom_density(alpha = 0.5) d %&gt;% ggplot(aes(x = Height, fill = Gender)) + geom_density(alpha = 0.5) + facet_wrap(vars(Gender)) 16.3 来点高级的 刚才我们看到了分面的操作，全局数据按照某个变量分组后，形成的若干个子集在不同的面板中分别展示出来。 这种方法很适合子集之间对比。事实上，我们看到每个子集的情况后，还很想知道全局的情况，以及子集在全局中的分布、状态或者位置。也就说，想对比子集和全局的情况。 所以我们期望（子集之间对比，子集与全局对比）。 具体方法：用分面的方法高亮展示子集，同时在每个分面上添加全局（灰色背景） 第一步，先把子集用分面的方法，分别画出来 d %&gt;% ggplot(aes(x = Height)) + geom_density() + facet_wrap(vars(Gender)) 第二步，添加整体的情况作为背景图层。因为第一步用到了分面，也就说会分组，但我们希望整体的背景图层不受分面信息影响，或者叫背景图层不需要分组，而是显示全部。也就说，要保证每个分面面板中的背景图都是一样的，因此，在这个geom_denstiy()图层中，构建不受facet_wrap()影响的数据，即删掉data的分组列。 d %&gt;% ggplot(aes(x = Height)) + geom_density( data = d %&gt;% select(-Gender) ) + geom_density() + facet_wrap(vars(Gender)) 第三步，y轴的调整，我们希望保持密度的形状，同时希望y轴不用比例值而是用具体的count个数，这样整体和局部能放在一个标度下， d %&gt;% ggplot(aes(x = Height, y = after_stat(count))) + geom_density( data = d %&gt;% select(-Gender) ) + geom_density() + facet_wrap(vars(Gender)) 第四步， 配色。 配色网站选颜色 “Male”, “Female” 是Gender已经存在的分组。另外，我们在背景图层，新增了一个组“all people”，这样，整个图就有三个分组（三个color组），那么，我们可以在scale_fill_manual中统一设置和指定。 density_colors &lt;- c( &quot;Male&quot; = &quot;#247BA0&quot;, &quot;Female&quot; = &quot;#F25F5C&quot;, &quot;all people&quot; = &quot;grey85&quot; ) d %&gt;% ggplot(aes(x = Height, y = after_stat(count))) + geom_density( data = df %&gt;% select(-Gender), aes(fill = &quot;all people&quot;, color = &quot;all people&quot;) ) + geom_density(aes(color = Gender, fill = Gender)) + facet_wrap(vars(Gender)) + scale_fill_manual(name = NULL, values = density_colors) + scale_color_manual(name = NULL, values = density_colors) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) 16.3.1 完整代码 density_colors &lt;- c( &quot;Male&quot; = &quot;#247BA0&quot;, &quot;Female&quot; = &quot;#F25F5C&quot;, &quot;all people&quot; = &quot;grey80&quot; ) scales::show_col(density_colors) d %&gt;% ggplot(aes(x = Height, y = after_stat(count))) + geom_density( data = d %&gt;% dplyr::select(-Gender), aes(fill = &quot;all people&quot;, color = &quot;all people&quot;) ) + geom_density(aes(color = Gender, fill = Gender)) + facet_wrap(vars(Gender)) + scale_fill_manual(name = NULL, values = density_colors) + scale_color_manual(name = NULL, values = density_colors) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) 或者，用不同的主题风格 density_colors &lt;- c( &quot;Male&quot; = &quot;#56B4E9&quot;, &quot;Female&quot; = &quot;#EF8A17&quot;, &quot;all participants&quot; = &quot;grey85&quot; ) d %&gt;% ggplot(aes(x = Height, y = after_stat(count))) + geom_density( data = function(x) dplyr::select(x, -Gender), aes(fill = &quot;all participants&quot;, color = &quot;all participants&quot;) ) + geom_density(aes(fill = Gender, color = Gender)) + facet_wrap(vars(Gender)) + scale_color_manual(name = NULL, values = density_colors) + scale_fill_manual(name = NULL, values = density_colors) + cowplot::theme_minimal_hgrid(16) + theme(legend.position = &quot;bottom&quot;, legend.justification = &quot;center&quot;) 16.3.2 画出不同性别的体重分布 d %&gt;% ggplot(aes(x = Weight, fill = Gender)) + geom_density(alpha = 0.5) 16.4 建模 16.4.1 身高与体重的散点图 d %&gt;% ggplot(aes(x = Height, y = Weight, color = Gender)) + geom_point() 16.4.2 建立身高与体重的线性模型 fit &lt;- lm(Weight ~ 1 + Height, data = d) summary(fit) ## ## Call: ## lm(formula = Weight ~ 1 + Height, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -51.93 -8.24 -0.12 8.26 46.84 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -350.7372 2.1115 -166 &lt;2e-16 *** ## Height 7.7173 0.0318 243 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 12.2 on 9998 degrees of freedom ## Multiple R-squared: 0.855, Adjusted R-squared: 0.855 ## F-statistic: 5.9e+04 on 1 and 9998 DF, p-value: &lt;2e-16 broom::tidy(fit) 16.4.3 建立不同性别下的身高与体重的线性模型 d %&gt;% group_by(Gender) %&gt;% group_modify( ~ broom::tidy(lm(Weight ~ 1 + Height, data = .)) ) d %&gt;% ggplot(aes(x = Height, y = Weight, group = Gender)) + geom_point(aes(color = Gender)) + geom_smooth(method = lm) "],
["eda06.html", "第 17 章 探索性数据分析6 17.1 驯鹿位置跟踪 17.2 驯鹿的身份信息 17.3 性别比例 17.4 每个站点运动最频繁的前10的驯鹿 17.5 驯鹿的活动信息 17.6 被追踪最多次的驯鹿的轨迹 17.7 某一只驯鹿的轨迹 17.8 选择某个驯鹿，查看他的活动轨迹 17.9 季节模式 17.10 迁移速度 17.11 动态展示 17.12 更多", " 第 17 章 探索性数据分析6 本章我们分析加拿大哥伦比亚林地驯鹿追踪数据，数据包含了从1988年到2016年期间260只驯鹿，近250000个位置标签。 17.1 驯鹿位置跟踪 knitr::include_graphics(&quot;images/caribou_location.png&quot;) 大家可以在这里了解数据集的信息，它包含了两个数据集 # devtools::install_github(&quot;thebioengineer/tidytuesdayR&quot;) library(tidytuesdayR) tuesdata &lt;- tidytuesdayR::tt_load(&#39;2020-06-23&#39;) # or # tuesdata &lt;- tidytuesdayR::tt_load(2020, week = 26) library(tidyverse) library(lubridate) library(gganimate) individuals &lt;- readr::read_csv(&#39;./demo_data/caribou/individuals.csv&#39;) locations &lt;- readr::read_csv(&#39;./demo_data/caribou/locations.csv&#39;) 17.2 驯鹿的身份信息 individuals %&gt;% glimpse() ## Rows: 286 ## Columns: 14 ## $ animal_id &lt;chr&gt; &quot;HR_151.510&quot;, &quot;GR_C04... ## $ sex &lt;chr&gt; &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;... ## $ life_stage &lt;chr&gt; NA, NA, NA, NA, NA, N... ## $ pregnant &lt;lgl&gt; NA, NA, NA, NA, NA, N... ## $ with_calf &lt;lgl&gt; NA, NA, NA, NA, NA, N... ## $ death_cause &lt;chr&gt; NA, NA, NA, NA, NA, N... ## $ study_site &lt;chr&gt; &quot;Hart Ranges&quot;, &quot;Graha... ## $ deploy_on_longitude &lt;dbl&gt; NA, NA, NA, NA, NA, N... ## $ deploy_on_latitude &lt;dbl&gt; NA, NA, NA, NA, NA, N... ## $ deploy_on_comments &lt;chr&gt; NA, NA, NA, NA, NA, N... ## $ deploy_off_longitude &lt;dbl&gt; NA, NA, NA, NA, NA, N... ## $ deploy_off_latitude &lt;dbl&gt; NA, NA, NA, NA, NA, N... ## $ deploy_off_type &lt;chr&gt; &quot;unknown&quot;, &quot;unknown&quot;,... ## $ deploy_off_comments &lt;chr&gt; NA, NA, NA, NA, NA, N... individuals %&gt;% count(animal_id) 我们发现有重复id的，怎么办？ individuals %&gt;% janitor::get_dupes(animal_id) individuals %&gt;% filter(deploy_on_latitude &gt;50) %&gt;% ggplot(aes(x = deploy_on_longitude, y = deploy_on_latitude)) + geom_point(aes(color = study_site)) #+ #borders(&quot;world&quot;, regions = &quot;china&quot;) 17.3 性别比例 17.4 每个站点运动最频繁的前10的驯鹿 17.5 驯鹿的活动信息 简单点说，就是哪个驯鹿在什么时间出现在什么地方 locations locations %&gt;% ggplot(aes(x = longitude, y = latitude)) + geom_point(aes(color = study_site)) 17.6 被追踪最多次的驯鹿的轨迹 top_animal_ids &lt;- count(locations, animal_id, sort = TRUE) %&gt;% slice(1:10) %&gt;% pull(animal_id) locations %&gt;% filter(animal_id %in% top_animal_ids) %&gt;% arrange(animal_id, timestamp) %&gt;% group_by(animal_id) %&gt;% mutate(measurement_n = row_number()) %&gt;% ggplot(aes(x = longitude, y = latitude, color = animal_id, alpha = measurement_n))+ geom_point(show.legend = FALSE, size = 1) + geom_path( show.legend = FALSE, size = 1) + #scale_color_manual(values = ) + theme_minimal() + theme( plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 10), text = element_text(color = &quot;White&quot;), panel.grid.minor = element_blank(), panel.grid.major = element_line(color = &quot;gray60&quot;, size = 0.05), plot.background = element_rect(fill = &quot;gray10&quot;), axis.text = element_text(color = &quot;white&quot;) ) + labs( x = &quot;\\nLongitude&quot;, y = &quot;Latitude\\n&quot;, title = &quot;Caribou movement tracking&quot;, subtitle = &quot;Latitude and longitude locations of the animals with the highest number of measurements\\n&quot;, caption = &quot;Tidy Tuesday: Caribou Location Tracking&quot; ) 17.7 某一只驯鹿的轨迹 locations %&gt;% filter(animal_id %in% c(&quot;QU_car143&quot;)) %&gt;% arrange(animal_id, timestamp) %&gt;% group_by(animal_id) %&gt;% mutate(measurement_n = row_number()) %&gt;% ggplot(aes(x = longitude, y = latitude, color = measurement_n, alpha = measurement_n))+ geom_point(show.legend = FALSE, size = 1) + geom_path( show.legend = FALSE, size = 1) + scale_color_gradient(low = &quot;white&quot;, high = &quot;firebrick3&quot;) + theme_minimal() + theme( plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 10), text = element_text(color = &quot;White&quot;), panel.grid.minor = element_blank(), panel.grid.major = element_line(color = &quot;gray60&quot;, size = 0.05), plot.background = element_rect(fill = &quot;gray10&quot;), axis.text = element_text(color = &quot;white&quot;) ) + labs( x = &quot;\\nLongitude&quot;, y = &quot;Latitude\\n&quot;, title = &quot;QU_car143 movement tracking&quot;, subtitle = &quot;Latitude and longitude locations of the animals with the highest number of measurements\\n Ligher colors indicate earlier measurements&quot;, caption = &quot;Tidy Tuesday: Caribou Location Tracking&quot; ) 17.8 选择某个驯鹿，查看他的活动轨迹 example_animal &lt;- locations %&gt;% dplyr::filter(animal_id == sample(animal_id, 1)) %&gt;% dplyr::arrange(timestamp) example_animal &quot;2010-03-28 21:00:44&quot; %&gt;% lubridate::as_date() &quot;2010-03-28 21:00:44&quot; %&gt;% lubridate::as_datetime() &quot;2010-03-28 21:00:44&quot; %&gt;% lubridate::quarter() example_animal %&gt;% dplyr::mutate(date = lubridate::as_date(timestamp)) %&gt;% ggplot(aes(x = longitude, y = latitude, color = date)) + geom_path() example_animal %&gt;% dplyr::mutate(quarter = lubridate::quarter(timestamp) %&gt;% as.factor()) %&gt;% ggplot(aes(x = longitude, y = latitude, color = quarter)) + geom_path() + facet_wrap(vars(quarter)) + labs(title = &quot;一只小驯鹿到处啊跑&quot;) 17.9 季节模式 看看驯鹿夏季和冬季运动模式，这段代码来自gkaramanis movement &lt;- locations %&gt;% filter(study_site != &quot;Hart Ranges&quot;) %&gt;% mutate( season = fct_rev(season), longitude = round(longitude, 2), latitude = round(latitude, 2) ) %&gt;% distinct(season, study_site, longitude, latitude) ggplot(movement) + geom_point(aes(longitude, latitude, group = study_site, colour = study_site), size = 0.1) + gghighlight::gghighlight( unhighlighted_params = list(colour = &quot;grey70&quot;), use_direct_label = FALSE ) + scale_colour_manual( values = c(&#39;#ffe119&#39;, &#39;#4363d8&#39;, &#39;#f58231&#39;, &#39;#e6194B&#39;, &#39;#800000&#39;, &#39;#000075&#39;, &#39;#f032e6&#39;, &#39;#3cb44b&#39;), breaks = c(&quot;Graham&quot;, &quot;Scott&quot;, &quot;Moberly&quot;, &quot;Burnt Pine&quot;, &quot;Kennedy&quot;, &quot;Quintette&quot;, &quot;Narraway&quot;) ) + guides(colour = guide_legend(title = &quot;Herd&quot;, override.aes = list(size = 3))) + coord_fixed(ratio = 1.5) + facet_wrap(vars(season), ncol = 2) + # labs( # title = &quot;Migration patterns of Northern Caribou\\nin the South Peace of British Columbia&quot;, # subtitle = str_wrap(&quot;In summer, most caribou migrate towards the central core of the Rocky Mountains where they use alpine and subalpine habitat. The result of this movement to the central core of the Rocky Mountains is that some of the east side herds can overlap with west side herds during the summer.&quot;, 100), # caption = str_wrap(&quot;Source: Seip DR, Price E (2019) Data from: Science update for the South Peace Northern Caribou (Rangifer tarandus caribou pop. 15) in British Columbia. Movebank Data Repository. https://doi.org/10.5441/001/1.p5bn656k | Graphic: Georgios Karamanis&quot;, 70) # ) + theme_void() + theme( legend.position = c(0.5, 0.6), legend.text = element_text(size = 11, colour = &quot;#F9EED9&quot;), legend.title = element_text(size = 16, hjust = 0.5, colour = &quot;#F9EED9&quot;), panel.spacing.x = unit(3, &quot;lines&quot;), plot.margin = margin(20, 20, 20, 20), plot.background = element_rect(fill = &quot;#7A6A4F&quot;, colour = NA), strip.text = element_text(colour = &quot;#F9EED9&quot;, size = 18), plot.title = element_text(colour = &quot;white&quot;, size = 20, hjust = 0, lineheight = 1), plot.subtitle = element_text(colour = &quot;white&quot;, size = 12, hjust = 0, lineheight = 1, margin = margin(10, 0, 50, 0)), plot.caption = element_text(colour = &quot;grey80&quot;, size = 7, hjust = 1, margin = margin(30, 0, 10, 0)) ) 17.10 迁移速度 location_with_speed &lt;- locations %&gt;% dplyr::group_by(animal_id) %&gt;% dplyr::mutate( last_longitude = lag(longitude), last_latitude = lag(latitude), hours = as.numeric(difftime(timestamp, lag(timestamp), units = &quot;hours&quot;)), km = geosphere::distHaversine( cbind(longitude, latitude), cbind(last_longitude, last_latitude)) /1000, speed = km/hours ) %&gt;% dplyr::ungroup() location_with_speed location_with_speed %&gt;% ggplot(aes(x = speed)) + geom_histogram() + scale_x_log10() 17.11 动态展示 library(gganimate) example_animal %&gt;% ggplot(aes(x = longitude, y = latitude)) + geom_point() + transition_time(time = timestamp) + shadow_mark(past = TRUE) + labs(title = &quot;date is {frame_time}&quot;) 17.12 更多 df &lt;- locations %&gt;% filter(study_site == &quot;Graham&quot;, year(timestamp) == 2002) %&gt;% group_by(animal_id) %&gt;% filter(as_date(min(timestamp)) == &quot;2002-01-01&quot;, as_date(max(timestamp)) == &quot;2002-12-31&quot;) %&gt;% ungroup() %&gt;% mutate(date = as_date(timestamp)) %&gt;% group_by(animal_id, date) %&gt;% summarise(longitude_centroid = mean(longitude), latitude_centroid = mean(latitude)) %&gt;% ungroup() %&gt;% complete(animal_id, date) %&gt;% arrange(animal_id, date) %&gt;% fill(longitude_centroid, latitude_centroid, .direction = &quot;down&quot;) p &lt;- df %&gt;% ggplot(aes(longitude_centroid, latitude_centroid, colour = animal_id)) + geom_point(size = 2) + coord_map() + theme_void() + theme(legend.position = &quot;none&quot;) + transition_time(time = date) + shadow_mark(alpha = 0.2, size = 0.8) + ggtitle(&quot;Caribou location on {frame_time}&quot;) p "],
["eda07.html", "第 18 章 探索性数据分析7 18.1 数据 18.2 探索性分析", " 第 18 章 探索性数据分析7 今天讲一个关于企鹅的数据故事。数据来源这里，图片来源这里. 18.1 数据 18.1.1 导入数据 可通过宏包palmerpenguins::penguins获取数据，也可以读取本地penguins.csv文件， 我们采取后面一种方法： library(tidyverse) penguins &lt;- read_csv(&quot;./demo_data/penguins.csv&quot;) %&gt;% janitor::clean_names() penguins %&gt;% head() 18.1.2 变量含义 variable class description species integer 企鹅种类 (Adelie, Gentoo, Chinstrap) island integer 所在岛屿 (Biscoe, Dream, Torgersen) bill_length_mm double 嘴峰长度 (单位毫米) bill_depth_mm double 嘴峰深度 (单位毫米) flipper_length_mm integer 鰭肢长度 (单位毫米) body_mass_g integer 体重 (单位克) sex integer 性别 year integer 记录年份 18.1.3 数据清洗 penguins %&gt;% filter_all( any_vars(is.na(.)) ) 发现有11行至少有一处有缺失值，于是我们就删除这些行 penguins &lt;- penguins %&gt;% drop_na() penguins 18.2 探索性分析 大家可以提出自己想探索的内容 18.2.1 每种类型企鹅有多少只 penguins %&gt;% count(species, sort = T) penguins %&gt;% count(island, sort = T) 18.2.2 每种类型企鹅各种属性的均值和分布 penguins %&gt;% group_by(species) %&gt;% summarize(across(where(is.numeric), mean, na.rm = TRUE)) penguins %&gt;% ggplot(aes(x = bill_length_mm)) + geom_histogram(aes(fill = sex)) + facet_wrap(vars(species), scales = &quot;free&quot;) 来张更好看点的 penguins %&gt;% ggplot(aes(x = bill_length_mm, fill = sex)) + geom_histogram( position = &quot;identity&quot;, alpha = 0.7, bins = 25 ) + scale_fill_manual(values = c(&quot;#66b3ff&quot;, &quot;#8c8c8c&quot;)) + ylab(&quot;number of penguins&quot;) + xlab(&quot;length (mm)&quot;) + theme_minimal() + theme( legend.position = &quot;bottom&quot;, legend.text = element_text(size = 11), legend.title = element_blank(), panel.grid.minor = element_blank(), axis.title = element_text(color = &quot;white&quot;, size = 10), plot.title = element_text(size = 20), plot.subtitle = element_text(size = 12, hjust = 1) ) + facet_wrap(vars(species), scales = &quot;free&quot;) 同理可以画出其他属性的分布 penguins %&gt;% ggplot(aes(x = bill_length_mm)) + geom_density() + facet_wrap(vars(species)) 我更喜欢这样，方便比较均值 library(ggridges) penguins %&gt;% ggplot(aes(x = bill_length_mm, y = species, fill = species)) + ggridges::geom_density_ridges() 同理，我们可以画出嘴峰深度的分布 penguins %&gt;% ggplot(aes(x = bill_depth_mm, fill = species)) + ggridges::geom_density_ridges(aes(y = species)) penguins %&gt;% ggplot(aes(x = bill_depth_mm, fill = sex)) + ggridges::geom_density_ridges(aes(y = species)) penguins %&gt;% ggplot(aes(x = body_mass_g, y = species, fill = sex)) + ggridges::geom_density_ridges(alpha = 0.5) 但，这样一个变量一个变量的画，可能会比较麻烦。于是我们可以这样 penguins %&gt;% select(species, bill_length_mm:body_mass_g) %&gt;% pivot_longer(-species, names_to = &quot;measurement&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = value)) + geom_density(aes(color = species, fill = species), size = 1.2, alpha = 0.2) + facet_wrap(vars(measurement), ncol = 2, scales = &quot;free&quot;) penguins %&gt;% select(species, bill_length_mm:body_mass_g) %&gt;% pivot_longer(-species, names_to = &quot;measurement&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = species, y = value)) + geom_boxplot(aes(color = species, fill = species), size = 1.2, alpha = 0.2) + facet_wrap(vars(measurement), ncol = 2, scales = &quot;free&quot;) penguins %&gt;% select(species, bill_length_mm:body_mass_g) %&gt;% pivot_longer(-species, names_to = &quot;measurement&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = value, y = species, fill = species) ) + ggridges::geom_density_ridges() + facet_wrap(vars(measurement), scales = &quot;free&quot;) 18.2.3 嘴峰长度和深度的关联 penguins %&gt;% ggplot(aes( x = bill_length_mm, y = bill_depth_mm, shape = species, color = species )) + geom_point() penguins %&gt;% ggplot(aes( x = bill_length_mm, y = bill_depth_mm, shape = species, color = species )) + geom_point(aes(size = body_mass_g)) 感觉这是一个辛普森佯谬， 我们画图看看 penguins %&gt;% ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(aes(color = species, shape = species)) + geom_smooth(method = lm) + geom_smooth(method = lm, aes(color = species)) 18.2.4 体重与翅膀长度的关联 penguins %&gt;% group_by(species, island, sex) %&gt;% ggplot(aes( x = body_mass_g, y = reorder(species, -body_mass_g), color = species )) + geom_jitter(position = position_jitter(seed = 2020, width = 0.2), alpha = 0.4, size = 2) + stat_summary(fun = mean, geom = &quot;point&quot;, size = 5, alpha = 1) library(ggtext) penguins %&gt;% ggplot(aes(flipper_length_mm, body_mass_g, group = species)) + geom_point(aes(colour = species, shape = species), alpha = 0.7) + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + labs( title = &quot;Penguin Size, Palmer Station LTER&quot;, subtitle = &quot;Flipper length and body mass for &lt;span style = &#39;color:darkorange;&#39;&gt;Adelie&lt;/span&gt;, &lt;span style = &#39;color:purple;&#39;&gt;Chinstrap&lt;/span&gt; and &lt;span style = &#39;color:cyan4;&#39;&gt;Gentoo&lt;/span&gt; Penguins&quot;, x = &quot;flipper length (mm)&quot;, y = &quot;body mass (g)&quot; ) + theme_minimal() + theme( legend.position = &quot;none&quot;, # text = element_text(family = &quot;Futura&quot;), # (I only have &#39;Light&#39; ) plot.title = element_text(size = 16), plot.subtitle = element_markdown(), # element_markdown from `ggtext` to parse the css in the subtitle plot.title.position = &quot;plot&quot;, plot.caption = element_text(size = 8, colour = &quot;grey50&quot;), plot.caption.position = &quot;plot&quot; ) 18.2.5 不同种类的宝宝，体重具有显著性差异？ penguins %&gt;% ggplot(aes(x = species, y = body_mass_g)) + geom_boxplot() + geom_jitter() 这里推荐可视化学统计的宏包ggstatsplot宏包将统计分析的结果写在图片里，统计结果和图形融合在一起，让统计结果更容易懂了。（使用这个宏包辅助我们学习统计） penguins %&gt;% group_by(species) %&gt;% summarise( count = n(), mean_body_mass = mean(body_mass_g), sd_body_mass = sd(body_mass_g) ) 18.2.5.1 参数检验 one-way ANOVA(要求等方差) stats::aov(formula = body_mass_g ~ species, data = penguins) %&gt;% summary() ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## species 2 1.45e+08 72595110 342 &lt;2e-16 *** ## Residuals 330 7.01e+07 212332 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 one-way ANOVA(不要求等方差)，相关介绍看here oneway.test(body_mass_g ~ species, data = penguins) ## ## One-way analysis of means (not assuming equal ## variances) ## ## data: body_mass_g and species ## F = 317, num df = 2, denom df = 188, p-value ## &lt;2e-16 stats::aov(formula = body_mass_g ~ species, data = penguins) %&gt;% TukeyHSD(which = &quot;species&quot;) %&gt;% broom::tidy() library(ggstatsplot) penguins %&gt;% ggbetweenstats( x = species, # &gt; 2 groups y = body_mass_g, type = &quot;parametric&quot;, messages = FALSE, var.equal = FALSE ) 18.2.5.2 非参数检验 相关介绍看here kruskal.test(body_mass_g ~ species, data = penguins) ## ## Kruskal-Wallis rank sum test ## ## data: body_mass_g by species ## Kruskal-Wallis chi-squared = 212, df = 2, ## p-value &lt;2e-16 penguins %&gt;% ggbetweenstats( x = species, y = body_mass_g, type = &quot;nonparametric&quot;, mean.ci = TRUE, pairwise.comparisons = TRUE, # &lt;&lt; pairwise.display = &quot;all&quot;, # ns = only non-significant p.adjust.method = &quot;fdr&quot;, # &lt;&lt; messages = FALSE ) 18.2.6 嘴峰长度与嘴峰深度的比例 penguins %&gt;% mutate(ratio = bill_length_mm / bill_depth_mm) %&gt;% group_by(species) %&gt;% summarise(mean = mean(ratio)) penguins %&gt;% mutate(ratio = bill_length_mm / bill_depth_mm) %&gt;% ggplot(aes(x = ratio, fill = species)) + ggridges::geom_density_ridges(aes(y = species)) 18.2.7 建立模型 scale_fun &lt;- function(x) { (x - mean(x)) / sd(x) } d &lt;- penguins %&gt;% select(sex, species, bill_length_mm:body_mass_g) %&gt;% mutate( across(where(is.numeric), scale_fun) ) %&gt;% mutate(male = if_else(sex == &quot;male&quot;, 1, 0)) d 按照species分组后，对flipper_length_mm标准化？这样数据会聚拢到一起了喔, 还是不要了 penguins %&gt;% select(sex, species, bill_length_mm:body_mass_g) %&gt;% group_by(species) %&gt;% mutate( across(where(is.numeric), scale_fun) ) %&gt;% ungroup() 18.2.7.1 model_01 logit_mod1 &lt;- glm( male ~ 1 + species + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, data = d, family = binomial(link = &quot;logit&quot;) ) summary(logit_mod1) library(ggeffects) ggpredict(logit_mod1, &quot;bill_depth_mm [all]&quot;) %&gt;% plot() 18.2.7.2 model_02 library(brms) brms_mod2 &lt;- brm( male ~ 1 + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g + (1 | species), data = d, family = binomial(link = &quot;logit&quot;) ) summary(brms_mod2) library(ggeffects) ggpredict(brms_mod2, &quot;bill_depth_mm [all]&quot;) %&gt;% plot() 18.2.7.3 model_03 penguins %&gt;% ggplot(aes(x = flipper_length_mm, y = bill_length_mm, color = species)) + geom_point() brms_mod3 &lt;- brm(bill_length_mm ~ flipper_length_mm + (1 + species), data = penguins ) penguins %&gt;% group_by(species) %&gt;% modelr::data_grid(flipper_length_mm) %&gt;% tidybayes::add_fitted_draws(brms_mod3, n = 100) %&gt;% ggplot() + geom_point( data = penguins, aes(flipper_length_mm, bill_length_mm, color = species, shape = species) ) + geom_line(aes(flipper_length_mm, .value, group = interaction(.draw, species), color = species), alpha = 0.1) "],
["ggplot2-geom.html", "第 19 章 ggplot2 19.1 一个有趣的案例 19.2 学习目标 19.3 开始 19.4 基本绘图 19.5 主题风格 19.6 定制 19.7 组合图片 19.8 中文字体 19.9 高亮某一组 19.10 函数图 19.11 地图 19.12 你喜欢哪个图 19.13 参考资料", " 第 19 章 ggplot2 采菊东篱下，悠然见南山。 根据大家投票，觉得ggplot2是最想掌握的技能，我想这就是R语言中最有质感的部分吧。所以，这里专门拿出一节课讲ggplot2，也算是补上之前第 ?? 章数据可视化没讲的内容。 有几个新的宏包需要提前安装（不是必须的） install.packages(c(&quot;sf&quot;, &quot;cowplot&quot;, &quot;patchwork&quot;, &quot;gghighlight&quot;, &quot;ggforce&quot;)) 如果安装不成功，请先update宏包，再执行上面安装命令 library(tidyverse) library(gghighlight) library(cowplot) library(patchwork) library(ggforce) 19.1 一个有趣的案例 先看一组数据 df &lt;- read_csv(&quot;./demo_data/datasaurus.csv&quot;) df 先用dataset分组后，然后计算每组下x的均值和方差，y的均值和方差，以及x，y两者的相关系数，我们发现每组数据下它们几乎都是相等的 df %&gt;% group_by(dataset) %&gt;% summarise( across(everything(), list(mean = mean, sd = sd), .names = &quot;{fn}_{col}&quot;) ) %&gt;% mutate( across(is.numeric, round, 3) ) 如果上面代码不熟悉，可以用第 6 章的代码重新表达，也是一样的 df %&gt;% group_by(dataset) %&gt;% summarize( mean_x = mean(x), mean_y = mean(y), std_dev_x = sd(x), std_dev_y = sd(y), corr_x_y = cor(x, y) ) 那么，我们是否能得出结论，每组的数据长的差不多呢？然而，我们画图发现 ggplot(df, aes(x = x, y = y, colour = dataset)) + geom_point() + # geom_smooth(method = lm) + theme(legend.position = &quot;none&quot;) + facet_wrap(~dataset, ncol = 3) 事实上，每张图都相差很大。所以，这里想说明的是，眼见为实。换句话说，可视化是数据探索中非常重要的部分。本章的目的就是带领大家学习ggplot2基本的绘图技能。 19.2 学习目标 Grammer of Graphics data: 数据框data.frame (注意，不支持向量vector和列表list类型） aes: 数据框中的数据变量映射到图形属性。什么叫图形属性？就是图中点的位置、形状，大小，颜色等眼睛能看到的东西。什么叫映射？就是一种对应关系，比如数学中的函数b = f(a)就是a和b之间的一种映射关系, a的值决定或者控制了b的值，在ggplot2语法里，a就是我们输入的数据变量，b就是图形属性， 这些图形属性包括： x（x轴方向的位置） y（y轴方向的位置） color（点或者线等元素的颜色） size（点或者线等元素的大小） shape（点或者线等元素的形状） alpha（点或者线等元素的透明度） geoms: 几何对象，确定我们想画什么样的图，一个geom_***确定一种图形。更多几何对象推荐阅读这里 geom_bar() geom_density() geom_freqpoly() geom_histogram() geom_violin() geom_boxplot() geom_col() geom_point() geom_smooth() geom_tile() geom_density2d() geom_bin2d() geom_hex() geom_count() geom_text() geom_sf() stats: 统计变换 scales: 标度 coord: 坐标系统 facet: 分面 layer： 增加图层 theme: 主题风格 save: 保存图片 ggplot2图层语法框架 19.3 开始 前面讲到R语言数据类型有字符串型、数值型、因子型、逻辑型、日期型等，ggplot2会将字符串型、因子型、逻辑型、日期型默认为离散变量，而数值型默认为连续变量。我们在而呈现数据的时候，可能会同时用到多种类型的数据，比如 一个离散 一个连续 两个离散 两个连续 一个离散, 一个连续 三个连续 19.3.1 导入数据 gapdata &lt;- read_csv(&quot;./demo_data/gapminder.csv&quot;) gapdata 19.3.2 检查数据 # 是否有缺失值 gapdata %&gt;% summarise( across(everything(), ~ sum(is.na(.))) ) country 代表国家 countinet 表示所在的洲 year 时间 lifeExp 平均寿命 pop 人口数量 gdpPercap 人均GDP 接下来，我们需要思考我们应该选择什么样的图，呈现这些不同类型的数据，探索数据背后的故事 19.4 基本绘图 19.4.1 柱状图 常用于一个离散变量 gapdata %&gt;% ggplot(aes(x = continent)) + geom_bar() gapdata %&gt;% ggplot(aes(x = reorder(continent, continent, length))) + geom_bar() gapdata %&gt;% ggplot(aes(x = reorder(continent, continent, length))) + geom_bar() + coord_flip() # geom_bar vs stat_count gapdata %&gt;% ggplot(aes(x = continent)) + stat_count() gapdata %&gt;% count(continent) 可见，geom_bar() 自动完成了这个统计，更多geom与stat对应关系见这里 gapdata %&gt;% distinct(continent, country) %&gt;% ggplot(aes(x = continent)) + geom_bar() 我个人比较喜欢先统计，然后画图 gapdata %&gt;% distinct(continent, country) %&gt;% group_by(continent) %&gt;% summarise(num = n()) %&gt;% ggplot(aes(x = continent, y = num)) + geom_col() 19.4.2 直方图 常用于一个连续变量 gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_histogram() # 对应的stat_bin() gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_histogram(binwidth = 1) #&#39; histograms, 默认使用 `position = &quot;stack&quot;` gapdata %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_histogram() #&#39; 使用`position = &quot;identity&quot;` gapdata %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_histogram(position = &quot;identity&quot;) gapdata %&gt;% ggplot(aes(x = lifeExp, color = continent)) + geom_freqpoly() #&#39; smooth histogram = densityplot gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_density() 如果不喜欢下面那条线，可以这样 gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_line(stat = &quot;density&quot;) # adjust 调节bandwidth, # adjust = 1/2 means use half of the default bandwidth. gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_density(adjust = 1) gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_density(adjust = 0.2) gapdata %&gt;% ggplot(aes(x = lifeExp, color = continent)) + geom_density() gapdata %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_density(alpha = 0.2) gapdata %&gt;% filter(continent != &quot;Oceania&quot;) %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_density(alpha = 0.2) gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_density() + # facet_wrap(vars(continent)) facet_grid(. ~ continent) gapdata %&gt;% filter(continent != &quot;Oceania&quot;) %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_histogram() + facet_grid(continent ~ .) 直方图和密度图画在一起。注意y = stat(density)表示y是由x新生成的变量，这是一种固定写法，类似的还有stat(count), stat(level) gapdata %&gt;% filter(continent != &quot;Oceania&quot;) %&gt;% ggplot(aes(x = lifeExp, y = stat(density))) + geom_histogram(aes(fill = continent)) + geom_density() + facet_grid(continent ~ .) 19.4.3 箱线图 一个离散变量 + 一个连续变量 #&#39; 思考下结果为什么是这样？ gapdata %&gt;% ggplot(aes(x = year, y = lifeExp)) + geom_boxplot() # 数据框中的year变量是数值型，需要先转换成因子型，弄成离散型变量 gapdata %&gt;% ggplot(aes(x = as.factor(year), y = lifeExp)) + geom_boxplot() # 明确指定分组变量 gapdata %&gt;% ggplot(aes(x = year, y = lifeExp)) + geom_boxplot(aes(group = year)) gapdata %&gt;% ggplot(aes(x = year, y = lifeExp)) + geom_violin(aes(group = year)) + geom_jitter(alpha = 1 / 4) + geom_smooth(se = FALSE) 19.4.4 抖散图 点重叠的处理方案 gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_point() gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_jitter() gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_boxplot() gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_boxplot() + geom_jitter() gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_jitter() + stat_summary(fun.y = median, colour = &quot;red&quot;, geom = &quot;point&quot;, size = 5) gapdata %&gt;% ggplot(aes(reorder(x = continent, lifeExp), y = lifeExp)) + geom_jitter() + stat_summary(fun.y = median, colour = &quot;red&quot;, geom = &quot;point&quot;, size = 5) 注意到我们已经提到过 stat_count / stat_bin / stat_summary gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_violin( trim = FALSE, alpha = 0.5 ) + stat_summary( fun.y = mean, fun.ymax = function(x) { mean(x) + sd(x) }, fun.ymin = function(x) { mean(x) - sd(x) }, geom = &quot;pointrange&quot; ) 19.4.5 山峦图 常用于一个离散变量 + 一个连续变量 gapdata %&gt;% ggplot(aes(x = lifeExp, y = continent, fill = continent)) + ggridges::geom_density_ridges() # https://learnui.design/tools/data-color-picker.html#palette gapdata %&gt;% ggplot(aes(x = lifeExp, y = continent, fill = continent)) + ggridges::geom_density_ridges() + scale_fill_manual( values = c(&quot;#003f5c&quot;,&quot;#58508d&quot;,&quot;#bc5090&quot;,&quot;#ff6361&quot;,&quot;#ffa600&quot;) ) gapdata %&gt;% ggplot(aes(x = lifeExp, y = continent, fill = continent)) + ggridges::geom_density_ridges() + scale_fill_manual( values = colorspace::sequential_hcl(5, palette = &quot;Peach&quot;) ) 19.4.6 散点图 常用于两个连续变量 gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() gapdata %&gt;% ggplot(aes(x = log(gdpPercap), y = lifeExp)) + geom_point() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + scale_x_log10() # A better way to log transform gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent)) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(alpha = (1 / 3), size = 2) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + geom_smooth() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + geom_smooth(lwd = 3, se = FALSE) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point(show.legend = FALSE) + facet_wrap(~continent) jCountries &lt;- c(&quot;Canada&quot;, &quot;Rwanda&quot;, &quot;Cambodia&quot;, &quot;Mexico&quot;) gapdata %&gt;% filter(country %in% jCountries) %&gt;% ggplot(aes(x = year, y = lifeExp, color = country)) + geom_line() + geom_point() gapdata %&gt;% filter(country %in% jCountries) %&gt;% ggplot(aes( x = year, y = lifeExp, color = reorder(country, -1 * lifeExp, max) )) + geom_line() + geom_point() 这是一种技巧，但我更推荐以下方法 d1 &lt;- gapdata %&gt;% filter(country %in% jCountries) %&gt;% group_by(country) %&gt;% mutate(end_label = if_else(year == max(year), country, NA_character_)) d1 d1 %&gt;% ggplot(aes( x = year, y = lifeExp, color = country )) + geom_line() + geom_point() + geom_label(aes(label = end_label)) + theme(legend.position = &quot;none&quot;) 如果觉得麻烦，就用gghighlight宏包吧 gapdata %&gt;% filter(country %in% jCountries) %&gt;% ggplot(aes( x = year, y = lifeExp, color = country )) + geom_line() + geom_point() + gghighlight::gghighlight() 19.4.7 点线图 gapdata %&gt;% filter(continent == &quot;Asia&quot; &amp; year == 2007) %&gt;% ggplot(aes(x = lifeExp, y = country)) + geom_point() gapdata %&gt;% filter(continent == &quot;Asia&quot; &amp; year == 2007) %&gt;% ggplot(aes( x = lifeExp, y = reorder(country, lifeExp) )) + geom_point(color = &quot;blue&quot;, size = 2) + geom_segment(aes( x = 40, xend = lifeExp, y = reorder(country, lifeExp), yend = reorder(country, lifeExp) ), color = &quot;lightgrey&quot; ) + labs( x = &quot;Life Expectancy (years)&quot;, y = &quot;&quot;, title = &quot;Life Expectancy by Country&quot;, subtitle = &quot;GapMinder data for Asia - 2007&quot; ) + theme_minimal() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank() ) 19.4.8 文本标注 gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + ggforce::geom_mark_ellipse(aes(filter = gdpPercap &gt; 70000, label = &quot;有钱的国家&quot;, description = &quot;他们是什么国家?&quot;)) ten_countries &lt;- gapdata %&gt;% distinct(country) %&gt;% pull() %&gt;% sample(10) library(ggrepel) gapdata %&gt;% filter(year == 2007) %&gt;% mutate( label = ifelse(country %in% ten_countries, as.character(country), &quot;&quot;) ) %&gt;% ggplot(aes(log(gdpPercap), lifeExp)) + geom_point( size = 3.5, alpha = .9, shape = 21, col = &quot;white&quot;, fill = &quot;#0162B2&quot; ) + geom_text_repel( aes(label = label), size = 4.5, point.padding = .2, box.padding = .3, force = 1, min.segment.length = 0 ) + theme_minimal(14) + theme( legend.position = &quot;none&quot;, panel.grid.minor = element_blank() ) + labs( x = &quot;log(GDP per capita)&quot;, y = &quot;life expectancy&quot; ) 19.4.9 errorbar图 avg_gapdata &lt;- gapdata %&gt;% group_by(continent) %&gt;% summarise( mean = mean(lifeExp), sd = sd(lifeExp) ) avg_gapdata avg_gapdata %&gt;% ggplot(aes(continent, mean, fill = continent)) + # geom_col(alpha = 0.5) + geom_point() + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.25) 19.4.10 椭圆图 gapdata %&gt;% ggplot(aes(x = log(gdpPercap), y = lifeExp)) + geom_point() + stat_ellipse(type = &quot;norm&quot;, level = 0.95) 19.4.11 2D 密度图 与一维的情形geom_density()类似， geom_density_2d(), geom_bin2d(), geom_hex()常用于刻画两个变量构成的二维区间的密度 gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_bin2d() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_hex() 19.4.12 马赛克图 geom_tile()， geom_contour()， geom_raster()常用于3个变量 gapdata %&gt;% group_by(continent, year) %&gt;% summarise(mean_lifeExp = mean(lifeExp)) %&gt;% ggplot(aes(x = year, y = continent, fill = mean_lifeExp)) + geom_tile() + scale_fill_viridis_c() 事实上可以有更好的呈现方式 gapdata %&gt;% group_by(continent, year) %&gt;% summarise(mean_lifeExp = mean(lifeExp)) %&gt;% ggplot(aes(x = year, y = continent, size = mean_lifeExp)) + geom_point() gapdata %&gt;% group_by(continent, year) %&gt;% summarise(mean_lifeExp = mean(lifeExp)) %&gt;% ggplot(aes(x = year, y = continent, size = mean_lifeExp)) + geom_point(shape = 21, color = &quot;red&quot;, fill = &quot;white&quot;) + scale_size_continuous(range = c(7, 15)) + geom_text(aes(label = round(mean_lifeExp, 2)), size = 3, color = &quot;black&quot;) + theme(legend.position = &quot;none&quot;) 19.5 主题风格 gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggtitle(&quot;Life expectancy over time by continent&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + theme_grey() # the default gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + theme_bw() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_calc() + ggtitle(&quot;ggthemes::theme_calc()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_economist() + ggtitle(&quot;ggthemes::theme_economist()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_economist_white() + ggtitle(&quot;ggthemes::theme_economist_white()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_few() + ggtitle(&quot;ggthemes::theme_few()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_gdocs() + ggtitle(&quot;ggthemes::theme_gdocs()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_tufte() + ggtitle(&quot;ggthemes::theme_tufte()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_wsj() + ggtitle(&quot;ggthemes::theme_wsj()&quot;) 19.6 定制 19.6.1 Labels gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + ggtitle(&quot;My Plot Title&quot;) + xlab(&quot;The X Variable&quot;) + ylab(&quot;The Y Variable&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + labs( title = &quot;My Plot Title&quot;, subtitle = &quot;My Plot subtitle&quot;, x = &quot;The X Variable&quot;, y = &quot;The Y Variable&quot; ) 19.6.2 定制颜色 我喜欢用这两个函数定制喜欢的绘图色彩，scale_colour_manual() 和 scale_fill_manual(). 更多方法可以参考 Colours chapter in Cookbook for R gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + scale_color_manual( values = c(&quot;#195744&quot;, &quot;#008148&quot;, &quot;#C6C013&quot;, &quot;#EF8A17&quot;, &quot;#EF2917&quot;) ) 19.7 组合图片 我们有时候想把多张图组合到一起 19.7.1 cowplot 可以使用 cowplot 宏包的plot_grid()函数完成多张图片的组合，使用方法很简单。 p1 &lt;- gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = lifeExp &gt; mean(lifeExp))) + scale_x_log10() + theme(legend.position = &quot;none&quot;) + scale_color_manual(values = c(&quot;orange&quot;, &quot;pink&quot;)) + labs( title = &quot;My Plot Title&quot;, x = &quot;The X Variable&quot;, y = &quot;The Y Variable&quot; ) p2 &lt;- gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + scale_color_manual( values = c(&quot;#195744&quot;, &quot;#008148&quot;, &quot;#C6C013&quot;, &quot;#EF8A17&quot;, &quot;#EF2917&quot;) ) + theme(legend.position = &quot;none&quot;) + labs( title = &quot;My Plot Title&quot;, x = &quot;The X Variable&quot;, y = &quot;The Y Variable&quot; ) cowplot::plot_grid( p1, p2, labels = c(&quot;A&quot;, &quot;B&quot;) ) 也可以使用patchwork宏包，更简单的方法 library(patchwork) p1 + p2 p1 / p2 p1 + p2 + plot_annotation( tag_levels = &#39;A&#39;, title = &#39;The surprising truth about mtcars&#39;, subtitle = &#39;These 3 plots will reveal yet-untold secrets about our beloved data-set&#39;, caption = &#39;Disclaimer: None of these plots are insightful&#39; ) patchwork 使用方法很简单，根本不需要记 19.7.2 保存图片 使用ggsave()函数，将图片保存为所需要的格式，如“.pdf”, “.png”等， 还可以指定图片的高度和宽度，默认units是英寸，也可以使用“cm”, or “mm”. pp &lt;- gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + scale_color_manual( values = c(&quot;#195744&quot;, &quot;#008148&quot;, &quot;#C6C013&quot;, &quot;#EF8A17&quot;, &quot;#EF2917&quot;) ) + theme(legend.position = &quot;none&quot;) + labs( title = &quot;My Plot Title&quot;, x = &quot;The X Variable&quot;, y = &quot;The Y Variable&quot; ) # ggsave(&quot;demo_plot.pdf&quot;, plot = pp, width = 8, height = 6) 19.8 中文字体 library(showtext) showtext_auto() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + scale_color_manual( values = c(&quot;#195744&quot;, &quot;#008148&quot;, &quot;#C6C013&quot;, &quot;#EF8A17&quot;, &quot;#EF2917&quot;) ) + theme(legend.position = &quot;none&quot;) + labs( title = &quot;这是我的标题美美哒&quot;, x = &quot;这是我的x坐标&quot;, y = &quot;这是我的y坐标&quot; ) # ggsave(&quot;myfirst.pdf&quot;, width = 8, height = 6) 19.9 高亮某一组 画图很容易，然而画一张好图，不容易。图片质量好不好，其原则就是不增加看图者的心智负担，有些图片的色彩很丰富，然而需要看图人配合文字和图注等信息才能看懂作者想表达的意思，这样就失去了图片“一图胜千言”的价值。 分析数据过程中，我们可以使用高亮我们某组数据，突出我们想表达的信息，是非常好的一种可视化探索手段。 19.9.1 ggplot2方法 这种方法是将背景部分和高亮部分分两步来画 drop_facet &lt;- function(x) select(x, -continent) gapdata %&gt;% ggplot() + geom_line( data = drop_facet, aes(x = year, y = lifeExp, group = country), color = &quot;grey&quot;, ) + geom_line(aes(x = year, y = lifeExp, color = country, group = country)) + facet_wrap(vars(continent)) + theme(legend.position = &quot;none&quot;) 再来一个 gapdata %&gt;% mutate(group = country) %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% ggplot() + geom_line( data = function(d) select(d, -country), aes(x = year, y = lifeExp, group = group), color = &quot;grey&quot;, ) + geom_line(aes(x = year, y = lifeExp, group = country), color = &quot;red&quot;) + facet_wrap(vars(country)) + theme(legend.position = &quot;none&quot;) 19.9.2 gghighlight方法 这里推荐gghighlight宏包 dplyr has filter() ggplot has Highlighting gapdata %&gt;% filter(country == &quot;China&quot;) gapdata %&gt;% ggplot( aes(x = year, y = lifeExp, color = continent, group = country) ) + geom_line() + gghighlight( country == &quot;China&quot;, # which is passed to dplyr::filter(). label_key = country ) gapdata %&gt;% filter(continent == &quot;Asia&quot;) gapdata %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% ggplot(aes(year, lifeExp, color = country, group = country)) + geom_line(size = 1.2, alpha = .9, color = &quot;#E58C23&quot;) + theme_minimal(base_size = 14) + theme( legend.position = &quot;none&quot;, panel.grid.major.x = element_blank(), panel.grid.minor = element_blank() ) + gghighlight( country %in% c(&quot;China&quot;, &quot;India&quot;, &quot;Japan&quot;, &quot;Korea, Rep.&quot;), use_group_by = FALSE, use_direct_label = FALSE, unhighlighted_params = list(color = &quot;grey90&quot;) ) + facet_wrap(vars(country)) 19.10 函数图 有时候我们想画一个函数图，比如正态分布的函数，可能会想到先产生数据，然后画图，比如下面的代码 tibble(x = seq(from = -3, to = 3, by = .01)) %&gt;% mutate(y = dnorm(x, mean = 0, sd = 1)) %&gt;% ggplot(aes(x = x, y = y)) + geom_line(color = &quot;grey33&quot;) 事实上，stat_function()可以简化这个过程 ggplot(data = data.frame(x = c(-3, 3)), aes(x = x)) + stat_function(fun = dnorm) 当然我们也可以绘制自定义函数 myfun &lt;- function(x) { (x - 1)**2 } ggplot(data = data.frame(x = c(-1, 3)), aes(x = x)) + stat_function(fun = myfun, geom = &quot;line&quot;, colour = &quot;red&quot;) 下面这是一个很不错的例子，细细体会下 d &lt;- tibble(x = rnorm(2000, mean = 2, sd = 4)) ggplot(data = d, aes(x = x)) + geom_histogram(aes(y = stat(density))) + geom_density() + stat_function(fun = dnorm, args = list(mean = 2, sd = 4), colour = &quot;red&quot;) 19.11 地图 小时候画地图很容易，长大了画地图却不容易了。 这是一个公园🏞地图和公园里松鼠🐿数量的数据集 nyc_squirrels &lt;- read_csv(&quot;./demo_data/nyc_squirrels.csv&quot;) central_park &lt;- sf::read_sf(&quot;./demo_data/central_park&quot;) 先来一个地图， ggplot() + geom_sf(data = central_park) 一个geom_sf就搞定了🥂，貌似没那么难呢？ 好吧，换个姿势，在地图上标注松鼠出现的位置 nyc_squirrels %&gt;% drop_na(primary_fur_color) %&gt;% ggplot() + geom_sf(data = central_park, color = &quot;grey85&quot;) + geom_point( aes(x = long, y = lat, color = primary_fur_color), size = .8 ) 分开画呢 nyc_squirrels %&gt;% drop_na(primary_fur_color) %&gt;% ggplot() + geom_sf(data = central_park, color = &quot;grey85&quot;) + geom_point( aes(x = long, y = lat, color = primary_fur_color), size = .8 ) + facet_wrap(vars(primary_fur_color)) + theme(legend.position = &quot;none&quot;) label_colors &lt;- c(&quot;all squirrels&quot; = &quot;grey75&quot;, &quot;highlighted group&quot; = &quot;#0072B2&quot;) nyc_squirrels %&gt;% drop_na(primary_fur_color) %&gt;% ggplot() + geom_sf(data = central_park, color = &quot;grey85&quot;) + geom_point( data = function(x) select(x, -primary_fur_color), aes(x = long, y = lat, color = &quot;all squirrels&quot;), size = .8 ) + geom_point( aes(x = long, y = lat, color = &quot;highlighted group&quot;), size = .8 ) + cowplot::theme_map(16) + theme( legend.position = &quot;bottom&quot;, legend.justification = &quot;center&quot; ) + facet_wrap(vars(primary_fur_color)) + scale_color_manual(name = NULL, values = label_colors) + guides(color = guide_legend(override.aes = list(size = 2))) # ggsave(&quot;Squirrels.pdf&quot;, width = 9, height = 6) 当然，也可以用gghighlight的方法 nyc_squirrels %&gt;% drop_na(primary_fur_color) %&gt;% ggplot() + geom_sf(data = central_park, color = &quot;grey85&quot;) + geom_point( aes(x = long, y = lat, color = primary_fur_color), size = .8 ) + gghighlight( label_key = primary_fur_color, use_direct_label = FALSE ) + facet_wrap(vars(primary_fur_color)) + cowplot::theme_map(16) + theme(legend.position = &quot;none&quot;) library(ggplot2) library(showtext) showtext_auto() font_families() ## [1] &quot;sans&quot; &quot;serif&quot; &quot;mono&quot; ## [4] &quot;wqy-microhei&quot; font_paths() ## [1] &quot;C:\\\\Windows\\\\Fonts&quot; font_files() ## Add fonts that are available on Windows(默认路径&quot;C:\\\\Windows\\\\Fonts&quot;) font_add(&quot;heiti&quot;, &quot;simhei.ttf&quot;) font_add(&quot;constan&quot;, &quot;constan.ttf&quot;, italic = &quot;constani.ttf&quot;) font_add(&quot;kaishu&quot;, &quot;simkai.ttf&quot;) #font_add(&quot;Noto&quot;, &quot;NotoSansCJKsc-Regular.otf&quot;) font_add(&quot;Yahei&quot;, &quot;Yahei.ttf&quot;) # 也可放在指定的目录(尽量英文) # https://github.com/yixuan/showtext/issues/18 font_add(&quot;fzfsj&quot;, here::here(&quot;myfont&quot;, &quot;fzfsj.ttf&quot;)) font_add(&quot;fzxbsj&quot;, here::here(&quot;myfont&quot;, &quot;FZXBSJW.ttf&quot;)) font_add(&quot;maoti&quot;, here::here(&quot;myfont&quot;, &quot;maoti.ttf&quot;)) font_add(&quot;fzshuliu&quot;, here::here(&quot;myfont&quot;, &quot;fzshuliu.ttf&quot;)) font_families() ## [1] &quot;sans&quot; &quot;serif&quot; &quot;mono&quot; ## [4] &quot;wqy-microhei&quot; &quot;heiti&quot; &quot;constan&quot; ## [7] &quot;kaishu&quot; &quot;Yahei&quot; &quot;fzfsj&quot; ## [10] &quot;fzxbsj&quot; &quot;maoti&quot; &quot;fzshuliu&quot; ## maybe, 保存为pdf图，才能看到有效字体 ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + ggtitle(&quot;这是我的小标宋简体&quot;) + theme( plot.title = element_text(family = &quot;fzxbsj&quot;) ) + geom_text(aes(x = 5, y = 40), label = &quot;方正仿宋简体&quot;, family = &quot;fzfsj&quot;) + geom_text(aes(x = 5, y = 38), label = &quot;这是我的雅黑&quot;, family = &quot;Yahei&quot;) + geom_text(aes(x = 5, y = 35), label = &quot;方正楷书简体&quot;, family = &quot;kaishu&quot;) + geom_text(aes(x = 5, y = 30), label = &quot;草檀斋毛泽东字体&quot;, family = &quot;maoti&quot;) + geom_text(aes(x = 5, y = 28), label = &quot;方正苏新诗柳楷简体&quot;, family = &quot;fzshuliu&quot;) #ggsave(&quot;showtext-example-9.pdf&quot;, width = 7, height = 4, dpi = 200) 根据往年大家提交的作业，有同学用rmarkdown生成pdf，图片标题使用了中文字体，但中文字体无法显示 。解决方案是R code chunks加上fig.showtext=TRUE ```{r, fig.showtext=TRUE} 详细资料可参考这里 19.11.1 latex公式 library(ggplot2) library(latex2exp) ggplot(mpg, aes(x = displ, y = hwy)) + geom_point() + annotate(&quot;text&quot;, x = 4, y = 40, label = TeX(&quot;$\\\\alpha^2 + \\\\theta^2 = \\\\omega^2 $&quot;), size = 9) + labs(title = TeX(&quot;The ratio of 1 and 2 is $\\\\,\\\\, \\\\frac{1}{2}$&quot;), x = TeX(&quot;$\\\\alpha$&quot;), y = TeX(&quot;$\\\\alpha^2$&quot;) ) 19.12 你喜欢哪个图 library(tidyverse) library(ggridges) library(patchwork) p1 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + geom_point() + geom_smooth() + labs(title = &quot;1: geom_point() + geom_smooth()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p2 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + geom_hex() + labs(title = &quot;2: geom_hex()&quot;) + guides(fill = FALSE) + theme(plot.title = element_text(face = &quot;bold&quot;)) p3 &lt;- ggplot(mpg, aes(x = drv, fill = drv)) + geom_bar() + labs(title = &quot;3: geom_bar()&quot;) + guides(fill = FALSE) + theme(plot.title = element_text(face = &quot;bold&quot;)) p4 &lt;- ggplot(mpg, aes(x = cty)) + geom_histogram(binwidth = 2, color = &quot;white&quot;) + labs(title = &quot;4: geom_histogram()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p5 &lt;- ggplot(mpg, aes(x = cty, y = drv, fill = drv)) + geom_violin() + guides(fill = FALSE) + labs(title = &quot;5: geom_violin()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p6 &lt;- ggplot(mpg, aes(x = cty, y = drv, fill = drv)) + geom_boxplot() + guides(fill = FALSE) + labs(title = &quot;6: geom_boxplot()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p7 &lt;- ggplot(mpg, aes(x = cty, fill = drv)) + geom_density(alpha = 0.7) + guides(fill = FALSE) + labs(title = &quot;7: geom_density()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p8 &lt;- ggplot(mpg, aes(x = cty, y = drv, fill = drv)) + geom_density_ridges() + guides(fill = FALSE) + labs(title = &quot;8: ggridges::geom_density_ridges()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p9 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + geom_density_2d() + labs(title = &quot;9: geom_density_2d()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 + plot_layout(nrow = 3) 19.13 参考资料 Look at Data from Data Vizualization for Social Science Chapter 3: Data Visualisation of R for Data Science Chapter 28: Graphics for communication of R for Data Science Graphs in R Graphics Cookbook ggplot2 cheat sheet ggplot2 documentation The R Graph Gallery (this is really useful) Top 50 ggplot2 Visualizations R Graphics Cookbook by Winston Chang ggplot extensions plotly for creating interactive graphs "],
["ggplot2-theme.html", "第 20 章 ggplot2之主题设置 20.1 图表整体元素 20.2 坐标轴元素 20.3 面板元素 20.4 图例元素 20.5 分面元素 20.6 小结 20.7 提问", " 第 20 章 ggplot2之主题设置 这一章我们一起学习ggplot2中的theme elements 语法，感谢Henry Wang提供了很好的思路。如果需要详细了解，可以参考Hadley Wickham最新版的《ggplot2: Elegant Graphics for Data Analysis》，最推荐的是ggplot2官方文档 theme(element_name = element_function()) 这里element_function()有四个 element_text() element_line() element_rect() element_blank() 望文生义吧，内置元素函数有四个基础类型： element_text(), 文本，一般用于控制标签和标题的字体风格 element_line(), 线条，一般用于控制线条或线段的颜色或线条类型 element_rect(), 矩形区域，一般用于控制背景矩形的颜色或者边界线条类型 element_blank() , 空白，就是不分配相应的绘图空间，即删去这个地方的绘图元素。 每个元素函数都有一系列控制外观的参数，下面我们通过具体的案例来一一介绍吧。 library(tidyverse) 还是用让人生厌的ggplot2::mpg数据包吧，具体介绍请见?? 章。 glimpse(mpg) ## Rows: 234 ## Columns: 12 ## $ manufacturer &lt;chr&gt; &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;audi... ## $ model &lt;chr&gt; &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;,... ## $ displ &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8,... ## $ year &lt;int&gt; 1999, 1999, 2008, 2008, 1999,... ## $ cyl &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4,... ## $ trans &lt;chr&gt; &quot;auto(l5)&quot;, &quot;manual(m5)&quot;, &quot;ma... ## $ drv &lt;chr&gt; &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;,... ## $ cty &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 1... ## $ hwy &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 2... ## $ fl &lt;chr&gt; &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;,... ## $ class &lt;chr&gt; &quot;compact&quot;, &quot;compact&quot;, &quot;compac... ## $ col &lt;chr&gt; &quot;blue&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;blue... 稍微做点数据整理 df &lt;- mpg %&gt;% filter(class != &quot;2seater&quot;, manufacturer %in% c(&quot;toyota&quot;, &quot;volkswagen&quot;)) df 我相信这种图你们已经会画了吧 df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) 想让这张图，符合你的想法？如何控制呢？come on 20.1 图表整体元素 图表整体元素包括: 描述 主题元素 类型 整个图形背景 plot.background element_rect() 图形标题 plot.title element_text() 图形边距 plot.margin margin() df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( plot.background = element_rect(fill = &quot;orange&quot;, color =&quot;black&quot;, size = 10), plot.title = element_text(hjust = 1, color = &quot;red&quot;, face = &quot;italic&quot;), plot.margin = margin(t = 20, r = 20, b = 20, l = 20, unit =&quot;pt&quot;) ) 20.2 坐标轴元素 坐标轴元素包括: 描述 主题元素 类型 坐标轴刻度 axis.ticks element_line() 坐标轴标题 axis.title element_text() 坐标轴标签 axis.text element_text() 直线和坐标轴 axis.line element_line() df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( axis.line = element_line(color = &quot;orange&quot;, size = 2), axis.title = element_text(color = &quot;red&quot;, face = &quot;italic&quot;), axis.ticks = element_line(color = &quot;purple&quot;, size = 3), axis.text = element_text(color = &quot;blue&quot;), axis.text.x = element_text(angle = 45, hjust = 1) ) 20.3 面板元素 面板元素包括: 描述 主题元素 类型 面板背景 panel.background element_rect() 面板网格线 panel.grid element_line() 面板边界 panel.border element_rect() df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( panel.background = element_rect(fill = &quot;orange&quot;, color = &quot;red&quot;), panel.grid = element_line(color = &quot;grey80&quot;, size = 0.5) ) 或者 df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( panel.background = element_rect(fill = &quot;orange&quot;), panel.grid = element_line(color = &quot;grey80&quot;, size = 0.5), panel.border = element_rect(color = &quot;red&quot;, fill = NA) ) 20.4 图例元素 图例元素包括: 描述 主题元素 类型 图例背景 legend.background element_rect() 图例符号 legend.key element_rect() 图例标签 legend.text element_text() 图例标题 legend.title element_text() 图例边距 legend.margin margin 图例位置 legend.postion “top”, “bottom”, “left”, “right” df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( legend.background = element_rect(fill = &quot;orange&quot;), legend.title = element_text(color = &quot;blue&quot;, size = 10), legend.key = element_rect(fill = &quot;grey80&quot;), legend.text = element_text(color = &quot;red&quot;), legend.margin = margin(t = 20, r = 20, b = 20, l = 20, unit =&quot;pt&quot;), legend.position = &quot;bottom&quot; ) 20.5 分面元素 分面元素包括: 描述 主题元素 类型 分面标签背景 strip.background element_rect() 条状文本 strip.text element_text() 分面间隔 panel.spacing unit df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( strip.background = element_rect(fill = &quot;orange&quot;), strip.text = element_text(color = &quot;red&quot;), panel.spacing = unit(0.3, &quot;inch&quot;)#, #strip.switch.pad.grid = ) 20.6 小结 20.7 提问 ggplot2中 plot 与 panel 有区别？ "],
["ggplot2-scales.html", "第 21 章 ggplot2之标度 21.1 标度 21.2 图形属性和变量类型 21.3 坐标轴和图例是同样的东西 21.4 丰富的标度体系 21.5 案例详解 21.6 用标度还是主题？", " 第 21 章 ggplot2之标度 这一章我们一起学习ggplot2中的scales语法，推荐大家阅读Hadley Wickham最新版的《ggplot2: Elegant Graphics for Data Analysis》，但如果需要详细了解标度参数体系，还是要看ggplot2官方文档 21.1 标度 在 ??章，我们了解到ggplot2中，映射是数据转化到图形属性，这里的图形属性是指视觉可以感知的东西，比如大小，形状，颜色和位置等。我们今天讨论的标度（scale）是控制着数据到图形属性映射的函数，每一种标度都是从数据空间的某个区域（标度的定义域）到图形属性空间的某个区域（标度的值域）的一个函数。 简单点来说，标度是用于调整数据映射的图形属性。 在ggplot2中，每一种图形属性都拥有一个默认的标度，也许你对这个默认的标度不满意，可以就需要学习如何修改默认的标度。比如， 系统默认\"a\"对应红色，\"b\"对应蓝色，我们想让\"a\"对应紫色，\"b\"对应橙色。 21.2 图形属性和变量类型 还是用我们熟悉的ggplot2::mpg，可能有同学说，我画图没接触到scale啊，比如 library(tidyverse) mpg %&gt;% ggplot(aes(x = displ, y = hwy)) + geom_point(aes(colour = class)) 能画个很漂亮的图，那是因为ggplot2默认缺省条件下，已经很美观了。（据说Hadley Wickham很后悔使用了这么漂亮的缺省值，因为很漂亮了大家都不认真学画图了。马云好像也说后悔创立了阿里巴巴？） 事实上，根据映射关系和变量名，我们将标度写完整，应该是这样的 ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = class)) + scale_x_continuous() + scale_y_continuous() + scale_colour_discrete() 如果每次都要手动设置一次标度函数，那将是比较繁琐的事情。因此ggplot2使用了默认了设置，如果不满意ggplot2的默认值，可以手动调整或者改写标度，比如 ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = class)) + scale_x_continuous(name = &quot;这是我的x坐标&quot;) + scale_y_continuous(name = &quot;这是我的y坐标&quot;) + scale_colour_brewer() 21.3 坐标轴和图例是同样的东西 21.4 丰富的标度体系 注意到，标度函数是由\"_\"分割的三个部分构成的 - scale - 视觉属性名 (e.g., colour, shape or x) - 标度名 (e.g., continuous, discrete, brewer). 每个标度函数内部都有丰富的参数系统 scale_colour_manual( palette = function(), limits = NULL, name = waiver(), labels = waiver(), breaks = waiver(), minor_breaks = waiver(), values = waiver(), ... ) 参数name，坐标和图例的名字，如果不想要图例的名字，就可以 name = NULL 参数limits, 坐标或图例的范围区间。连续性c(n, m)，离散型c(\"a\", \"b\", \"c\") 参数breaks, 控制显示在坐标轴或者图例上的值（元素） 参数labels, 坐标和图例的间隔标签 一般情况下，内置函数会自动完成 也可人工指定一个字符型向量，与breaks提供的字符型向量一一对应 也可以是函数，把breaks提供的字符型向量当做函数的输入 NULL，就是去掉标签 参数values 指的是（颜色、形状等）视觉属性值, 要么，与数值的顺序一致； 要么，与breaks提供的字符型向量长度一致 要么，用命名向量c(\"数据标签\" = \"视觉属性\")提供 参数expand, 控制参数溢出量 参数range, 设置尺寸大小范围，比如针对点的相对大小 下面，我们通过具体的案例讲解如何使用参数，把图形变成我们想要的模样。 21.5 案例详解 先导入一个数据 gapdata &lt;- read_csv(&quot;./demo_data/gapminder.csv&quot;) newgapdata &lt;- gapdata %&gt;% group_by(continent, country) %&gt;% summarise( across(c(lifeExp, gdpPercap, pop), mean) ) newgapdata newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_continuous() newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10() newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10(breaks = c(500, 1000, 3000, 10000, 30000), labels = scales::dollar) newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10( name = &quot;人均GDP&quot;, breaks = c(500, 1000, 3000, 10000, 30000), labels = scales::unit_format(unit = &quot;美元&quot;)) newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10() + scale_color_viridis_d() 离散变量映射到色彩的情形，可以使用ColorBrewer色彩。 newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10() + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10() + scale_color_manual( name = &quot;五大洲&quot;, values = c(&quot;Africa&quot; = &quot;red&quot;, &quot;Americas&quot; = &quot;blue&quot;, &quot;Asia&quot; = &quot;orange&quot;, &quot;Europe&quot; = &quot;black&quot;, &quot;Oceania&quot; = &quot;gray&quot;), breaks = c(&quot;Africa&quot;, &quot;Americas&quot;, &quot;Asia&quot;, &quot;Europe&quot;, &quot;Oceania&quot;), labels = c(&quot;非洲&quot;, &quot;美洲&quot;, &quot;亚洲&quot;, &quot;欧洲&quot;, &quot;大洋洲&quot;) ) + scale_size( name = &quot;人口数量&quot;, breaks = c(2e8, 5e8, 7e8), labels = c(&quot;2亿&quot;, &quot;5亿&quot;, &quot;7亿&quot;) ) 21.6 用标度还是主题？ 那什么时候用标度，什么时候用主题？这里有个原则：主题风格不会增加标签，也不会改变变量的范围，主题只会改变字体、大小、颜色等等。 假定数据是这样 library(tidyverse) set.seed(12) d1 &lt;- data.frame(x = rnorm(50, 10, 2), type = &quot;Island #1&quot;) d2 &lt;- data.frame(x = rnorm(50, 18, 1.2), type = &quot;Island #2&quot;) dd &lt;- bind_rows(d1, d2) %&gt;% set_names(c(&quot;Height&quot;, &quot;Location&quot;)) head(dd) 你画图后，交给老板看 dd %&gt;% ggplot(aes(x = Height, fill = Location)) + geom_histogram(binwidth = 1, color = &quot;white&quot;) + scale_fill_manual(values = c(&quot;green3&quot;, &quot;turquoise3&quot;)) 然而，老板有点不满意，希望你要这样改 请用前后两章学到的内容让老板满意吧 "],
["ggplot2-guides.html", "第 22 章 ggplot2之图例系统 22.1 图例系统 22.2 案例详解", " 第 22 章 ggplot2之图例系统 这一章，我们一起学习ggplot2中的图例系统，内容相对简单，但还是推荐大家阅读ggplot2官方文档 22.1 图例系统 为了方便演示，我们还是用熟悉的配方ggplot2::mpg library(tidyverse) mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() 如果想调整图例的样式，可以使用guides()函数，用法类似上节课中的theme函数, 具体参数为： 要么是字符串 (i.e. \"color = colorbar\" or \"color = legend\"), 要么是特定的函数 (i.e. color = guide_colourbar() or color = guide_legend()) 22.2 案例详解 mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + guides(color = &quot;legend&quot;) mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + guides(color = guide_bins( title = &quot;my title&quot;, label.hjust = 1 ) ) mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + guides(color = guide_legend( ncol = 4 ) ) mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + guides(color = guide_legend( title = &quot;标题好像有点高&quot;, title.position = &quot;top&quot;, title.vjust = 5, label.position = &quot;left&quot;, label.hjust = 1, label.theme = element_text(size = 15, face = &quot;italic&quot;, colour = &quot;red&quot;, angle = 0), keywidth = 5, reverse = TRUE ) ) "],
["ggplot2-gganimate.html", "第 23 章 ggplot2之让你的数据骚动起来 23.1 为什么要使用动图 23.2 gganimate宏包 23.3 The grammar of animation 23.4 希望动画随哪个变量动起来 23.5 希望坐标轴随数据动起来 23.6 希望动画有个记忆 23.7 定义新数据出现和旧数据退去的方式 23.8 控制变化的节奏 23.9 标签 23.10 保存 23.11 案例演示一 23.12 案例演示二 23.13 案例演示三 23.14 课后作业", " 第 23 章 ggplot2之让你的数据骚动起来 这节课，我们讲如何让我们的图动起来。 23.1 为什么要使用动图 改进了图形在时间上和空间上的重新定位 传递更多信息 引人注意 23.2 gganimate宏包 动图可以将其理解为多张静态图堆在一起，当然不是随意的堆放，而是按照一定的规则，比如按照时间的顺序，或者类别的顺序。一般而言，动图制作包括两个步骤: 静态图制作及图形组装。静态图制作，前面几章我们讲过主要用ggplot2宏包实现；对于图形组装，需要用到今天我们要讲Thomas Lin Pedersen的gganimate宏包，来自同一工厂的产品，用起来自然是无缝衔接啦。 install.packages(&quot;gganimate&quot;) 23.2.1 先来一张静态图 library(tidyverse) library(covdata) # remotes::install_github(&quot;kjhealy/covdata&quot;) library(gganimate) covdata::covnat %&gt;% dplyr::filter(iso3 == &quot;USA&quot;) %&gt;% dplyr::filter(cu_cases &gt; 0) %&gt;% ggplot(aes(x = date, y = cases)) + geom_path() + labs(title = &quot;美国新冠肺炎累积确诊病例&quot;, subtitle = &quot;数据来源https://kjhealy.github.io/covdata/&quot;) 让它动起来，我们只需要增加一行代码！ covdata::covnat %&gt;% dplyr::filter(iso3 == &quot;USA&quot;) %&gt;% dplyr::filter(cu_cases &gt; 0) %&gt;% ggplot(aes(x = date, y = cases)) + geom_path() + labs(title = &quot;美国新冠肺炎累积确诊病例 {frame_along}&quot;, subtitle = &quot;数据来源https://kjhealy.github.io/covdata/&quot;) + transition_reveal(along = date) 23.2.2 相对复杂点的例子 library(datasauRus) ggplot(datasaurus_dozen) + aes(x, y, color = dataset) + geom_point() 用分面展示 ggplot(datasaurus_dozen) + aes(x, y, color = dataset) + geom_point() + facet_wrap(~dataset) 可以用动图展示 ggplot(datasaurus_dozen) + aes(x, y, color = dataset) + geom_point() + transition_states(dataset, 3, 1) + #&lt;&lt; labs(title = &quot;Dataset: {closest_state}&quot;) 是不是很炫酷，下面我们就一个个讲解其中的函数。 23.3 The grammar of animation 使用gganimate做动画，只需要掌握以下五类函数： transition_*(): 定义动画是根据哪个变量进行”动”，以及如何”动” view_*(): 定义坐标轴随数据变化. shadow_*(): 影子（旧数据的历史记忆）?定义点相继出现的方式. enter_*()/exit_*(): 定义新数据出现和旧数据退去的方式. ease_aes(): 美观定义，控制变化的节奏(如何让整个动画看起来更舒适). 下面通过案例依次讲解这些函数功能。 23.4 希望动画随哪个变量动起来 变量如何选择，这需要从变量类型和变量代表的信息来确定。 23.4.1 transition_states transition_states(states = ), 这里的参数states往往带有分组信息，可以等价于静态图中的分面。 diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + facet_wrap(vars(color)) diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_states(states = color, transition_length = 3, state_length = 1) 23.4.2 transition_time transition_time(time = ), 这里的time一般认为是连续的值，相比于transition_states，没有了transtion_length这个选项，是因为transtion_length默认为time. 事实上，transition_time是transition_states的一种特例，但其实也有分组的要求 p &lt;- gapminder::gapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, size = pop, colour = country)) + geom_point(alpha = 0.7, show.legend = FALSE) + scale_size(range = c(2, 12)) + scale_x_log10() + labs(x = &quot;GDP per capita&quot;, y = &quot;life expectancy&quot; ) p anim &lt;- p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) anim 23.4.3 transition_reveal transition_reveal(along = ), along 这个词可以看出，它是按照某个变量依次显示的意思，比如顺着x轴显示 ggplot(data = economics) + aes(x= date, y = unemploy) + geom_line() ggplot(economics) + aes(x= date, y = unemploy) + geom_line() + transition_reveal(along = date) + labs(title = &quot;now is {frame_along}&quot;) 23.4.4 transition_filter transition_filter( 至少2个筛选条件，transition_length = , filter_length =), 动图将会在这些筛选条件对应的子图之间转换 diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_filter( transition_length = 3, filter_length = 1, cut == &quot;Ideal&quot;, Deep = depth &gt;= 60 ) 23.4.5 transition_layers transition_layers(): 依次显示每个图层 mtcars %&gt;% ggplot(aes(mpg, disp)) + geom_point() + geom_smooth(colour = &#39;grey&#39;, se = FALSE) + geom_smooth(aes(colour = factor(gear))) + transition_layers(layer_length = 1, transition_length = 2, from_blank = FALSE, keep_layers = c(Inf, 0, 0)) + enter_fade() + exit_fade() 23.4.6 其他 transition_manual() transition_components() transition_events() 23.5 希望坐标轴随数据动起来 动画过程中，绘图窗口怎么变化呢？ 23.5.1 view_follow ggplot(iris, aes(Sepal.Length, Sepal.Width)) + geom_point() + labs(title = &quot;{closest_state}&quot;) + transition_states(Species, transition_length = 4, state_length = 1) + view_follow() 23.5.2 其它 view_step() view_step_manual() view_zoom() view_zoom_manual() 23.6 希望动画有个记忆 shadow_wake(wake_length =, ) 旧数据消退时，制造点小小的尾迹的效果（wake除了叫醒，还有尾迹的意思，合起来就是记忆_尾迹） shadow_trail(distance = 0.05) 旧数据消退时，制造面包屑一样的残留痕迹（记忆_零星残留） shadow_mark(past = TRUE, future = FALSE) 将旧数据和新数据当作背景（记忆_标记） 23.6.1 shadow_wake() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + shadow_wake(wake_length = 0.1, alpha = FALSE) ggplot(iris, aes(Petal.Length, Sepal.Length)) + geom_point(size = 2) + labs(title = &quot;{closest_state}&quot;) + transition_states(Species, transition_length = 4, state_length = 1) + shadow_wake(wake_length = 0.1) 23.6.2 shadow_trail() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + shadow_trail(distance = 0.1) ggplot(iris, aes(Petal.Length, Sepal.Length)) + geom_point(size = 2) + labs(title = &quot;{closest_state}&quot;) + transition_states(Species, transition_length = 4, state_length = 1) + shadow_trail(distance = 0.1) 23.6.3 shadow_mark() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + shadow_mark(alpha = 0.3, size = 0.5) ggplot(airquality, aes(Day, Temp)) + geom_line(color = &#39;red&#39;, size = 1) + transition_time(Month) + shadow_mark(colour = &#39;black&#39;, size = 0.75) 23.7 定义新数据出现和旧数据退去的方式 出现和退去的函数是成对的 23.7.1 enter/exit_fade() 透明度上的变化，我这里用柱状图展示，效果要明显一点。 tibble(x = month.name, y = sample.int(12) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_col() + theme(axis.text.x = element_text(angle =45, hjust = 1, vjust = 1)) + transition_states(states = month.name) tibble(x = month.name, y = sample.int(12) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_col() + theme(axis.text.x = element_text(angle =45, hjust = 1, vjust = 1)) + transition_states(states = month.name) + shadow_mark(past = TRUE) + enter_fade() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + enter_fade() 23.7.2 enter_grow()/exit_shrink() 大小上的变化 tibble(x = month.name, y = sample.int(12) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_col() + theme(axis.text.x = element_text(angle =45, hjust = 1, vjust = 1)) + transition_states(states = month.name) + shadow_mark(past = TRUE) + enter_grow() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + enter_grow() + enter_fade() 23.8 控制变化的节奏 控制数据点变化的快慢 p + ease_aes({aesthetic} = {ease}) p + ease_aes(x = &quot;cubic&quot;) knitr::include_graphics(&quot;images/ease.png&quot;) Source: https://easings.net/ 看下面的案例： diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_states(color, transition_length = 3, state_length = 1) + ease_aes(&quot;cubic-in&quot;) # Change easing of all aesthetics diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_states(color, transition_length = 3, state_length = 1) + ease_aes(x = &quot;elastic-in&quot;) # Only change `x` (others remain “linear”) 23.9 标签 我们可能需要在标题中加入每张动画的信息，常用罗列如下 transition_states(states = ) + labs(title = &quot;previous is {previous_state}, current is {closest_state}, next is {next_state}&quot;) transition_layers() + labs(title = &quot;previous is {previous_layers}, current is {closest_layers}, next is {next_layers}&quot;) transition_time(time = ) + labs(title = &quot;now is {frame_time}&quot;) transition_reveal(along = ) + labs(title = &quot;now is {frame_along}&quot;) 23.10 保存 23.10.1 Renderer options 23.10.2 常用方法 一般用anim_save()保存为 gif 格式，方法类似ggsave() animation_to_save &lt;- diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_states(color, transition_length = 3, state_length = 1) + ease_aes(&quot;cubic-in&quot;) anim_save(&quot;first_saved_animation.gif&quot;, animation = animation_to_save) 23.11 案例演示一 这是网上有段时间比较火的racing_bar图 ranked_by_date &lt;- covdata::covnat %&gt;% group_by(date) %&gt;% arrange(date, desc(cu_cases)) %&gt;% mutate(rank = 1:n()) %&gt;% filter(rank &lt;= 10) %&gt;% ungroup() ranked_by_date %&gt;% filter(date &gt;= &quot;2020-05-01&quot;) %&gt;% ggplot( aes(x = rank, y = cname, group = cname, fill = cname) ) + geom_tile( aes( y = cu_cases / 2, height = cu_cases, width = 0.9 ), alpha = 0.8, show.legend = F ) + geom_text(aes( y = cu_cases, label = cname ), show.legend = FALSE ) + scale_x_reverse( breaks = c(1:10), label = c(1:10) ) + theme_minimal() + coord_flip(clip = &quot;off&quot;, expand = FALSE) + labs( title = &quot;日期: {closest_state}&quot;, x = &quot;&quot;, caption = &quot;Source: github/kjhealy/covdata&quot; ) + transition_states(date, transition_length = 4, state_length = 1, wrap = TRUE ) + ease_aes(&quot;cubic-in-out&quot;) 23.12 案例演示二 bats &lt;- readr::read_csv(&quot;./demo_data/bats-subset.csv&quot;) %&gt;% dplyr::mutate(id = factor(id)) bats %&gt;% ggplot(aes(x = longitude, y = latitude, group = id, color = id) ) + geom_point() 23.12.1 常规的方法 bats %&gt;% ggplot(aes(x = longitude, y = latitude, group = id, color = id) ) + geom_point() + transition_time(time) + shadow_mark(past = TRUE) geom_path()是按照数据点出现的先后顺序 geom_line()是按照数据点在x轴的顺序 bats %&gt;% ggplot(aes(x = longitude, y = latitude, group = id, color = id) ) + geom_path() + transition_time(time) + shadow_mark(past = TRUE) 23.12.2 炫酷点的 bats %&gt;% dplyr::mutate( image = &quot;images/bat-cartoon.png&quot; ) %&gt;% ggplot(aes(x = longitude, y = latitude, group = id, color = id) ) + geom_path() + ggimage::geom_image(aes(image = image), size = 0.1) + transition_reveal(time) 23.13 案例演示三 全球R-Ladies组织，会议活动的情况，我们在地图上用动图展示 rladies &lt;- read_csv(&quot;./demo_data/rladies.csv&quot;) rladies #library(maps) #library(ggthemes) world &lt;- ggplot() + borders(&quot;world&quot;, colour = &quot;gray85&quot;, fill = &quot;gray80&quot;) + ggthemes::theme_map() world world + geom_point( data = rladies, aes(x = lon, y = lat, size = followers), colour = &#39;purple&#39;, alpha = .5) + scale_size_continuous(range = c(1, 8), breaks = c(250, 500, 750, 1000)) + labs(size = &#39;Followers&#39;) 用动图展示（这种方法可以用在流行病传播的展示上） world + geom_point(aes(x = lon, y = lat, size = followers), data = rladies, colour = &#39;purple&#39;, alpha = .5 ) + scale_size_continuous(range = c(1, 8), breaks = c(250, 500, 750, 1000)) + transition_states(created_at) + shadow_mark(past = TRUE) + labs(title = &#39;Day: {closest_state}&#39;) 23.14 课后作业 23.14.1 作业1 把下图弄成你喜欢的样子 library(gapminder) theme_set(theme_bw()) ggplot(gapminder) + aes(x = gdpPercap, y=lifeExp, size = pop, colour = country) + geom_point(show.legend = FALSE) + scale_x_log10() + scale_color_viridis_d() + scale_size(range = c(2, 12)) + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy&quot;) + transition_time(year) + labs(title = &quot;Year: {frame_time}&quot;) 23.14.2 作业2 那请说说这以下三个的区别？ bats %&gt;% dplyr::filter(id == 1) %&gt;% ggplot( aes(x = longitude, y = latitude)) + geom_point() + transition_reveal(time) #&lt;&lt; bats %&gt;% dplyr::filter(id == 1) %&gt;% ggplot( aes(x = longitude, y = latitude)) + geom_point() + transition_states(time) #&lt;&lt; bats %&gt;% dplyr::filter(id == 1) %&gt;% ggplot( aes(x = longitude, y = latitude)) + geom_point() + transition_time(time) #&lt;&lt; "],
["tips.html", "第 24 章 tidyverse中的若干技巧 24.1 From gather() to pivot() 24.2 count() 24.3 在 count() 中创建新变量 24.4 add_count() 24.5 nth(), first(), last() 24.6 列变量重新排序 24.7 if_else 24.8 case_when 24.9 找出前几名 24.10 去除多余的空白 24.11 取反操作 24.12 drop_na() 24.13 replace_na() 24.14 coalesce 24.15 summarise() 生成 list-column 24.16 count() + fct_reorder() + geom_col() + coord_flip() 24.17 scale_x/y_log10 24.18 fct_lump 24.19 fct_reoder2 24.20 unite 24.21 separate() 24.22 extract() 24.23 crossing()", " 第 24 章 tidyverse中的若干技巧 聊聊tidyverse中常用的一些小技巧 “most of data science is counting, and sometimes dividing” — Hadley Wickham library(tidyverse) library(patchwork) # install.packages(&quot;patchwork&quot;) 24.1 From gather() to pivot() make data tidy VARIABLE, OBSERVATION, VALUE Each variable is a column Each observation is a row Each type of observational unit is a table plant_heigt &lt;- data.frame( Day = 1:5, A = c(0.7, 1.0, 1.5, 1.8, 2.2), B = c(0.5, 0.7, 0.9, 1.3, 1.8) ) plant_heigt 大家想想， 把植物高度大于或等于0.8cm的筛选出来，怎么写语句? 用不同的颜色画出两种植物生长曲线，怎么写语句? plant_heigt %&gt;% filter( ___ &gt;= 0.8) plant_heigt %&gt;% ggplot(aes(x = Day, y = ___, color = ___)) + geom_line() 想用上面的语句，数据就得变形。那么怎么变形呢？ 从2019年9月份，tidyr 1.0.0新增了一组函数pivot_longer()/pivot_wider()，用来补充和完善原来的gather()/spread() gather()/pivot_longer it makes “wide” data longer. spread()/pivot_wider it makes “long” data wider. 所以现在使用pivot_longer()函数 long &lt;- pivot_longer(plant_heigt, 2:3, names_to = &quot;plant&quot;, values_to = &quot;height&quot; ) long plant_heigt %&gt;% pivot_longer( cols = -Day, # A:B 或者 c(A, B) 或者 c(&quot;A&quot;, &quot;B&quot;) names_to = &quot;plant&quot;, values_to = &quot;height&quot; ) long %&gt;% ggplot(aes(x = Day, y = height, color = plant)) + geom_line() wide &lt;- long %&gt;% pivot_wider( names_from = &quot;plant&quot;, values_from = &quot;height&quot; ) wide 24.2 count() 我之前多次用到count()函数，其功能就是统计某个变量中各组出现的次数 df &lt;- tibble( name = c(&quot;Alice&quot;, &quot;Alice&quot;, &quot;Bob&quot;, &quot;Bob&quot;, &quot;Carol&quot;, &quot;Carol&quot;), type = c(&quot;english&quot;, &quot;math&quot;, &quot;english&quot;, &quot;math&quot;, &quot;english&quot;, &quot;math&quot;), score = c(60.2, 90.5, 92.2, 98.8, 82.5, 74.6) ) df df %&gt;% count(name) 如果用之前讲的group_by() + summarise()来写， df %&gt;% group_by(name) %&gt;% summarise( n = n()) count() 还有更多强大的参数， 比如 df %&gt;% count(name, sort = TRUE, wt = score, name = &quot;total_score&quot; ) 如果不用count()，用group_by() + summarise()写， df %&gt;% group_by(name) %&gt;% summarise( n = n(), total_score = sum(score, na.rm = TRUE) ) %&gt;% arrange(desc(total_score)) 当然，count()在特定场合下的简便写法，遇到复杂的分组统计，还是得用用group_by() + summarise()组合。 24.3 在 count() 中创建新变量 可以在count()里构建新变量，并利用这个新变量完成统计 df %&gt;% count(range = 10 * (score %/% 10)) 24.4 add_count() 想增加一列，代表每人参加的考试次数 df %&gt;% group_by(name) %&gt;% mutate(n = n()) %&gt;% ungroup() 可以有更简单的方法 df %&gt;% add_count(name) 24.5 nth(), first(), last() v &lt;- c(&quot;a&quot;, &quot;c&quot;, &quot;d&quot;, &quot;k&quot;) v[1] ## [1] &quot;a&quot; v[length(v)] ## [1] &quot;k&quot; c(&quot;a&quot;, &quot;c&quot;, &quot;d&quot;, &quot;k&quot;) %&gt;% nth(3) ## [1] &quot;d&quot; c(&quot;a&quot;, &quot;c&quot;, &quot;d&quot;, &quot;k&quot;) %&gt;% first() ## [1] &quot;a&quot; c(&quot;a&quot;, &quot;c&quot;, &quot;d&quot;, &quot;k&quot;) %&gt;% last() ## [1] &quot;k&quot; 用在数据框中，同样可以使用 df %&gt;% filter(score == first(score)) df %&gt;% group_by(name) %&gt;% filter(score == last(score)) 24.6 列变量重新排序 比如想把score放在第一列 df %&gt;% select(score, everything()) 这个方法，对列变量较多的情形非常适用。 24.7 if_else df %&gt;% mutate( assess = if_else(score &gt; 85, &quot;very_good&quot;, &quot;good&quot;) ) 24.8 case_when df %&gt;% mutate( assess = case_when( score &lt; 70 ~ &quot;general&quot;, score &gt;= 70 &amp; score &lt; 80 ~ &quot;good&quot;, score &gt;= 80 &amp; score &lt; 90 ~ &quot;very_good&quot;, score &gt;= 90 ~ &quot;best&quot;, TRUE ~ &quot;other&quot; ) ) 24.9 找出前几名 df %&gt;% top_n(2, score) 24.10 去除多余的空白 library(stringr) str_trim(&quot; excess whitespace in a string be gone!&quot;) ## [1] &quot;excess whitespace in a string be gone!&quot; # Use str_squish() to remove any leading, trailing, or excess whitespace str_squish(&quot; excess whitespace in a string be gone!&quot;) ## [1] &quot;excess whitespace in a string be gone!&quot; 24.11 取反操作 3:10 %in% c(1:5) ## [1] TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE 有时候需要一个不属于的操作符 # 自定义一个不属于操作符 `%nin%` &lt;- Negate(`%in%`) 3:10 %nin% c(1:5) ## [1] FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE # 使用purrr::negate()自定义反向操作符 `%nin%` &lt;- purrr::negate(`%in%`) 3:10 %nin% c(1:5) ## [1] FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE 24.12 drop_na() dt &lt;- tribble( ~x, ~y, 1, NA, 2, NA, NA, -3, NA, -4, 5, -5 ) dt dt %&gt;% drop_na() # dt %&gt;% drop_na(x) 24.13 replace_na() dt &lt;- tribble( ~x, ~y, 1, NA, 2, NA, NA, -3, NA, -4, 5, -5 ) dt %&gt;% mutate(x = replace_na(x, 0)) dt %&gt;% mutate( x = replace_na(x, mean(x, na.rm = TRUE)) ) 之前讲正则表达式也有类似的函数stringr::str_replace_na()， 24.14 coalesce dt &lt;- tribble( ~x, ~y, 1, NA, 2, NA, NA, -3, NA, -4, 5, -5 ) dt %&gt;% mutate( z = coalesce(x, 0) # z = coalesce(x, y) ) 有时候，我们可能为了减少信息丢失，想填充NA dt &lt;- tribble( ~name, ~age, &quot;a&quot;, 1, &quot;b&quot;, 2, &quot;c&quot;, NA, &quot;d&quot;, 2 ) dt %&gt;% mutate( age_adj = ifelse(is.na(age), mean(age, na.rm = TRUE), age) ) 24.15 summarise() 生成 list-column summarize()会生成一个value， library(gapminder) gapminder %&gt;% group_by(continent) %&gt;% summarise( avg_gdpPercap = mean(gdpPercap) ) summarize()也可以生成一个list， library(gapminder) gapminder %&gt;% group_by(continent) %&gt;% summarise(test = list(t.test(gdpPercap))) %&gt;% # 单样本的t检验 mutate(tidied = purrr::map(test, broom::tidy)) %&gt;% unnest(tidied) %&gt;% ggplot(aes(estimate, continent)) + geom_point() + geom_errorbarh(aes( xmin = conf.low, xmax = conf.high )) gapminder %&gt;% group_by(continent) %&gt;% summarise(test = list(lm(lifeExp ~ gdpPercap))) %&gt;% # 线性回归 mutate(tidied = purrr::map(test, broom::tidy, conf.int = TRUE)) %&gt;% unnest(tidied) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% ggplot(aes(estimate, continent)) + geom_point() + geom_errorbarh(aes( xmin = conf.low, xmax = conf.high, height = .3 )) 以下两种方法，同样完成上面的工作，具体方法会在第 34 章介绍 gapminder %&gt;% group_nest(continent) %&gt;% mutate(test = map(data, ~ t.test(.x$gdpPercap))) %&gt;% mutate(tidied = map(test, broom::tidy)) %&gt;% unnest(tidied) gapminder %&gt;% group_by(continent) %&gt;% group_modify( ~ broom::tidy(t.test(.x$gdpPercap)) ) 24.16 count() + fct_reorder() + geom_col() + coord_flip() 最好用的四件套 gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) %&gt;% ggplot(aes(x = continent, y = n)) + geom_col() gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) %&gt;% ggplot(aes(x = fct_reorder(continent, n), y = n)) + geom_col() + coord_flip() 画图容易，但画出一张好图并不容易 gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) %&gt;% mutate(coll = if_else(continent == &quot;Asia&quot;, &quot;red&quot;, &quot;gray&quot;)) %&gt;% ggplot(aes(x = fct_reorder(continent, n), y = n)) + geom_text(aes(label = n), hjust = -0.25) + geom_col(width = 0.8, aes(fill = coll) ) + coord_flip() + theme_classic() + scale_fill_manual(values = c(&quot;#b3b3b3a0&quot;, &quot;#D55E00&quot;)) + theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 11) ) + labs(title = &quot;我的标题&quot;, x = &quot;&quot;) 或者偷懒，将continent == \"Asia\"的结果直接赋值给aes(fill = ___ )， 效果与上面是一样的。 gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) %&gt;% ggplot(aes(x = fct_reorder(continent, n), y = n)) + geom_text(aes(label = n), hjust = -0.25) + geom_col(width = 0.8, aes(fill = continent == &quot;Asia&quot;) ) + coord_flip() + theme_classic() + scale_fill_manual(values = c(&quot;#b3b3b3a0&quot;, &quot;#D55E00&quot;)) + annotate(&quot;text&quot;, x = 3.8, y = 48, label = &quot;this is important\\ncase&quot;, color = &quot;#D55E00&quot;, size = 5) + annotate( geom = &quot;curve&quot;, x = 4.1, y = 48, xend = 4.1, yend = 35, curvature = .3, arrow = arrow(length = unit(2, &quot;mm&quot;)) ) + theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 11) ) + labs(title = &quot;我的标题&quot;, x = &quot;&quot;) 24.17 scale_x/y_log10 现实世界很多满足对数规则 各国人均GDP 各国人口 不同人士的收入 公司的营业额 gapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() gapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + scale_x_log10() # A better way to log transform 24.18 fct_lump 门诊病症的流水记录 tb &lt;- tibble::tribble( ~disease, ~n, &quot;鼻塞&quot;, 112, &quot;流涕&quot;, 130, &quot;发热&quot;, 89, &quot;腹泻&quot;, 5, &quot;呕吐&quot;, 12, &quot;咳嗽&quot;, 102, &quot;咽痛&quot;, 98, &quot;乏力&quot;, 15, &quot;腹痛&quot;, 2, &quot;妄想&quot;, 3, &quot;幻听&quot;, 6, &quot;失眠&quot;, 1, &quot;贫血&quot;, 8, &quot;多动&quot;, 2, &quot;胸痛&quot;, 4, &quot;胸闷&quot;, 5 ) p1 &lt;- tb %&gt;% uncount(n) %&gt;% ggplot(aes(x = disease, fill = disease)) + geom_bar() + coord_flip() + theme(legend.position = &quot;none&quot;) p2 &lt;- tb %&gt;% uncount(n) %&gt;% mutate( disease = forcats::fct_lump(disease, 5), disease = forcats::fct_reorder(disease, .x = disease, .fun = length) ) %&gt;% ggplot(aes(x = disease, fill = disease)) + geom_bar() + coord_flip() + theme(legend.position = &quot;none&quot;) p1 + p2 24.19 fct_reoder2 让图例的顺序与图的曲线顺序一致 dat_wide &lt;- tibble( x = 1:3, top = c(4.5, 4, 5.5), middle = c(4, 4.75, 5), bottom = c(3.5, 3.75, 4.5) ) dat_wide %&gt;% pivot_longer( cols = c(top, middle, bottom), names_to = &quot;region&quot;, values_to = &quot;awfulness&quot;) dat &lt;- dat_wide %&gt;% pivot_longer( cols = c(top, middle, bottom), names_to = &quot;region&quot;, values_to = &quot;awfulness&quot;) %&gt;% mutate( region_ABCD = factor(region), region_sane = fct_reorder2(region, x, awfulness) ) p_ABCD &lt;- ggplot(dat, aes(x, awfulness, colour = region_ABCD)) + geom_line() + theme(legend.justification = c(1, 0.85)) p_sane &lt;- ggplot(dat, aes(x, awfulness, colour = region_sane)) + geom_line() + theme(legend.justification = c(1, 0.85)) p_ABCD + p_sane + plot_annotation( title = &#39;Make the legend order = data order, with forcats::fct_reorder2()&#39;) 24.20 unite df &lt;- tribble( ~school, ~class, &quot;chuansi&quot;, &quot;01&quot;, &quot;chuansi&quot;, &quot;02&quot;, &quot;shude&quot;, &quot;07&quot;, &quot;shude&quot;, &quot;08&quot;, &quot;huapulu&quot;, &quot;101&quot;, &quot;huapulu&quot;, &quot;103&quot; ) df df_united &lt;- df %&gt;% unite(school, class, col = &quot;school_plus_class&quot;, sep = &quot;_&quot;, remove = FALSE) df_united 当然，简单的情况也可以用mutate()实现 df %&gt;% mutate(newcol = str_c(school, &quot;_&quot;, class)) 24.21 separate() df_united %&gt;% separate(school_plus_class, into = c(&quot;sch&quot;, &quot;cls&quot;), sep = &quot;_&quot;, remove = F) 如果用mutate()来实现，语句就会比较复杂些 df_united %&gt;% mutate(sch = str_split(school_plus_class, &quot;_&quot;) %&gt;% map_chr(1)) %&gt;% mutate(cls = str_split(school_plus_class, &quot;_&quot;) %&gt;% map_chr(2)) 如果每行不是都恰好分隔成两部分呢？就需要tidyr::extract(), 使用方法和tidyr::separate()类似 df &lt;- tribble( ~school_class, &quot;chuansi_01&quot;, &quot;chuansi_02_03&quot;, &quot;shude_07_0&quot;, &quot;shude_08_0&quot;, &quot;huapulu_101_u&quot;, &quot;huapulu_103__p&quot; ) df df %&gt;% separate(school_class, into = c(&quot;sch&quot;, &quot;cls&quot;), sep = &quot;_&quot;, extra = &quot;drop&quot;, remove = F) 24.22 extract() 有时候分隔符搞不定的，可以用正则表达式，讲捕获的每组弄成一列 df &lt;- tibble(x = c(&quot;1-12week&quot;, &quot;1-10wk&quot;, &quot;5-12w&quot;, &quot;01-05weeks&quot;)) df df %&gt;% extract( x, c(&quot;start&quot;, &quot;end&quot;, &quot;letter&quot;), &quot;(\\\\d+)-(\\\\d+)([a-z]+)&quot;, remove = FALSE ) 24.23 crossing() 先看看效果 crossing(x = c(&quot;F&quot;, &quot;M&quot;), y = c(&quot;a&quot;, &quot;b&quot;), z = c(1:2)) 这个函数在数据模拟的时候很方便， crossing(trials = 1:10, m = 1:5) %&gt;% group_by(trials) %&gt;% mutate( guess = sample.int(5, n()), result = m == guess ) %&gt;% summarise(score = sum(result) / n()) 再来一个例子 sim &lt;- tribble( ~f, ~params, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 10) ) sim %&gt;% mutate(sim = invoke_map(f, params)) rep_sim &lt;- sim %&gt;% crossing(rep = 1:1e5) %&gt;% mutate(sim = invoke_map(f, params)) %&gt;% unnest(sim) %&gt;% group_by(rep) %&gt;% summarise(mean_sim = mean(sim)) head(rep_sim) rep_sim %&gt;% ggplot(aes(x = mean_sim)) + geom_histogram(binwidth = 0.05, fill = &quot;skyblue&quot;) + theme_classic() 也可用在较复杂的模拟，比如下面介绍的大数极限定理， sim &lt;- tribble( ~n_tosses, ~f, ~params, 10, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 15), 30, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 30), 100, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 100), 1000, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 1000), 10000, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 1e4) ) sim_rep &lt;- sim %&gt;% crossing(replication = 1:50) %&gt;% mutate(sims = invoke_map(f, params)) %&gt;% unnest(sims) %&gt;% group_by(replication, n_tosses) %&gt;% summarise(avg = mean(sims)) sim_rep %&gt;% ggplot(aes(x = factor(n_tosses), y = avg)) + ggbeeswarm::geom_quasirandom(color = &quot;lightgrey&quot;) + scale_y_continuous(limits = c(0, 1)) + geom_hline( yintercept = 0.5, color = &quot;skyblue&quot;, lty = 1, size = 1, alpha = 3 / 4 ) + ggthemes::theme_pander() + labs( title = &quot;50 Replicates Of Mean &#39;Heads&#39; As Number Of Tosses Increase&quot;, y = &quot;mean&quot;, x = &quot;Number Of Tosses&quot; ) 数值模拟我们会在第 26 章专门介绍。 "],
["tibble.html", "第 25 章 简单数据框 25.1 tidyverse 家族 25.2 人性化的tibble 25.3 tibble 与 data.frame 25.4 tibble数据操作 25.5 关于行名 25.6 修复列名 25.7 nested tibble 25.8 延伸阅读", " 第 25 章 简单数据框 library(tidyverse) library(tibble) #事实上，library(tidyverse)已经加装了library(tibble) 25.1 tidyverse 家族 前面陆续介绍了tidyverse家族，家庭主要成员包括 功能 宏包 有颜值担当 ggplot2 数据处理王者 dplyr 数据转换专家 tidyr 数据载入利器 readr 循环加速器 purrr 强化数据框 tibble 25.2 人性化的tibble tibble是用来替换data.frame类型的扩展的数据框 tibble继承了data.frame，是弱类型的。换句话说，tibble是data.frame的子类型 tibble与data.frame有相同的语法，使用起来更方便 tibble更早的检查数据，方便写出更干净、更多富有表现力的代码 tibble对data.frame做了重新的设定： tibble，不关心输入类型，可存储任意类型，包括list类型 tibble，没有行名设置 row.names tibble，支持任意的列名 tibble，会自动添加列名 tibble，类型只能回收长度为1的输入 tibble，会懒加载参数，并按顺序运行 tibble，是tbl_df类型 25.3 tibble 与 data.frame 传统创建数据框 data.frame(a = 1:5, b = letters[1:5]) 发现，data.frame()会自动将字符串型的变量转换成因子型，如果想保持原来的字符串型，就得 data.frame(a = 1:5, b = letters[1:5], stringsAsFactors = FALSE) Note： 在R 4.0 后，data.frame() 不会将字符串型变量自动转换成因子型 用tibble创建数据框，不会这么麻烦，输出的就是原来的字符串类型 tibble(a = 1:5, b = letters[1:5]) 我们有时候喜欢这样，构建两个有关联的变量， 比如 tb &lt;- tibble( x = 1:3, y = x + 2 ) tb 但是，如果用传统的data.frame()来构建，会报错 df &lt;- data.frame( x = 1:3, y = x + 2 ) ## Error in data.frame(x = 1:3, y = x + 2): arguments imply differing number of rows: 3, 7 df 因此，在这一点上tibble()做的比较人性化。 大家还可以发现tibble另一个优势：tibble输出时，会显示多一行，用来指定每一列的类型。 tibble用缩写定义了7种类型： 类型 含义 int 代表integer dbl 代表double chr 代表character向量或字符串 dttm 代表日期+时间(date+time) lgl 代表逻辑判断TRUE或者FALSE fctr 代表因子类型factor date 代表日期dates 25.4 tibble数据操作 25.4.1 创建tibble tibble()创建一个tibble类型的data.frame: tibble(a = 1:5, b = letters[1:5]) 刚才提到了，可以这样， tibble( a = 1:5, b = 10:14, c = a + b ) 为了让每列更加直观，也可以tribble()创建，数据量不大的时候，挺方便的 tribble( ~x, ~y, ~z, &quot;a&quot;, 2, 3.6, &quot;b&quot;, 1, 8.5 ) 25.4.2 转换成tibble类型 转换成tibble类型意思就是说，刚开始不是tibble, 现在转换成tibble， 包括 data.frame转换成tibble vector转换成tibble list转换成tibble matrix转换成tibble 25.4.2.1 data.frame转换成tibble t1 &lt;- iris[1:6, 1:4] # data.frame类型: class(t1) ## [1] &quot;data.frame&quot; as_tibble(t1) 25.4.2.2 vector转型到tibble x &lt;- as_tibble(1:5) # Use `tibble::enframe() x 25.4.2.3 把list转型为tibble df &lt;- as_tibble(list(x = 1:6, y = runif(6), z = 6:1)) df 把tibble再转为list? as.list(df) 25.4.2.4 把matrix转型为tibble。 m &lt;- matrix(rnorm(15), ncol = 5) as_tibble(m) tibble转回matrix? as.matrix(df) 25.4.3 tibble简单操作 构建一个简单的数据框 df &lt;- tibble(x = 1:2, y = 2:1) df 增加一列 add_column(df, z = 0:1, w = 0) 增加一行 add_row(df, x = 99, y = 9) 在第二行，增加一行 add_row(df, x = 99, y = 9, .before = 2) 25.4.4 有用的函数lst lst，创建一个list，具有tibble特性的list。 lst(n = 5, x = runif(n), y = TRUE) ## $n ## [1] 5 ## ## $x ## [1] 0.2415 0.8672 0.5930 0.2385 0.9099 ## ## $y ## [1] TRUE 25.4.5 有用的函数enframe enframe()将矢量快速创建tibble，，创建的tibble只有2列: name和value enframe(1:3) enframe(c(a = 5, b = 7, c = 9)) 25.4.6 有用的函数deframe deframe()可以看做是enframe() 的反操作，把tibble反向转成向量 df &lt;- enframe(c(a = 5, b = 7)) df # 转为vector deframe(df) ## a b ## 5 7 25.4.7 读取文件 read_csv()读取文件时，生成的直接就是tibble read_csv(&quot;./demo_data/wages.csv&quot;) 25.5 关于行名 data.frame是支持行名的，但tibble不支持行名，这也是两者不同的地方 # 创建data.frame df &lt;- data.frame(x = 1:3, y = 3:1) # 给df增加行名 row.names(df) &lt;- LETTERS[1:3] df # 判断是否有行名 has_rownames(df) ## [1] TRUE 但是对于tibble tb &lt;- tibble(x = 1:3, y = 3:1) row.names(tb) &lt;- LETTERS[1:3] 需要注意的： 有时候遇到含有行名的data.frame，转换成tibble后，行名会被丢弃 如果想保留行名，就需要把行名转换成单独的一列 举个例子 df &lt;- mtcars[1:3, 1:3] df # 把行名转换为单独的一列 rownames_to_column(df, var = &quot;rowname&quot;) # 把行索引转换为单独的一列 rowid_to_column(df, var = &quot;rowid&quot;) 25.6 修复列名 规范的来说，数据框的列名应该是唯一。但现实中代码是人写的，因此可能会稀奇古怪的，所幸的是tibble也提供了人性化的解决方案 tibble(x = 1, x = 2) ## Error: Column name `x` must not be duplicated. .name_repair = \"check_unique\" 检查列名唯一性，但不做修复（默认） .name_repair = \"minimal\"， 不检查也不修复，维持现状 .name_repair = \"unique\" 修复列名，使得列名唯一且不为空 .name_repair = \"universal\" 修复列名，使得列名唯一且语法可读 具体使用方法： tibble(x = 1, x = 2, .name_repair = &quot;minimal&quot;) tibble(x = 1, x = 2, .name_repair = &quot;unique&quot;) tibble(x = 1, x = 2, .name_repair = &quot;universal&quot;) tibble(`a 1` = 1, `a 2` = 2, .name_repair = &quot;universal&quot;) 如果认为x...1, x...2 不符合自己的审美，可以指定修复函数 tibble(x = 1, x = 2, .name_repair = make.unique) tibble(x = 1, x = 2, .name_repair = ~make.unique(.x, sep = &quot;_&quot;)) tibble(x = 1, x = 2, .name_repair = ~ make.names(., unique = TRUE)) 注意make.unique(names, sep = \".\")和make.names(names, unique = FALSE, allow_ = TRUE) 是基础包的函数，可通过?make.unique()或者make.names()获取说明文档。 当然也可以自定义函数 fix_names &lt;- function(x) gsub(&quot;\\\\s+&quot;, &quot;_&quot;, x) tibble(`year 1` = 1, `year 2` = 2, .name_repair = fix_names) 感觉越说越复杂了，事实上，我们写数据框的时候，完全可以避免上述问题，只要做到规范列名。 如果真正遇到比较乱的列名，推荐使用janitor::clean_names()一步到位。 library(janitor) tibble(`year 1` = 1, `year 2` = 2) %&gt;% clean_names() 25.7 nested tibble nested tibble 和 List-columns (列表列) 会在后面的章节详细介绍。 iris %&gt;% group_by(Species) %&gt;% nest() 25.8 延伸阅读 1、阅读Hadley Wickham的r4ds这本书第10章。 2、 tibble的官方主页：https://tibble.tidyverse.org/ 3、创建列表列的方法，可以参考nested tibble和 list-columns "],
["sampling.html", "第 26 章 模拟与抽样 26.1 模拟 26.2 MASS::mvrnorm 26.3 蒙特卡洛 26.4 抽样与样本 26.5 扩展阅读", " 第 26 章 模拟与抽样 library(tidyverse) 本章目的是在tidyverse的架构下，介绍一些模拟和抽样的知识。先回顾下Hadley Wickham提出的数据科学tidy原则，tidy思想体现在: 任何数据都可以规整为数据框 数据框的一列代表一个变量，数据框的一行代表一次观察 函数处理数据时，数据框进、数据框出 26.1 模拟 26.1.1 生成随机数 比如生成5个高斯分布的随机数，高斯分布就是正态分布，R语言里我们用rnorm()函数产生正态分布的随机数 rnorm(n = 5, mean = 0, sd = 1) ## [1] 0.3070 -0.1948 -1.0236 0.1429 0.6283 事实上，R内置了很多随机数产生的函数 Distrution | Notation | R | R Uniform \\(\\text{U}(a, b)\\) runif Normal \\(\\text{N}(\\mu, \\sigma)\\) rnorm Binormal \\(\\text{Bin}(n, p)\\) rbinorm Piosson \\(\\text{pois}(\\lambda)\\) rpois Beta \\(\\text{Beta}(\\alpha, \\beta)\\) rbeta 如果大家查看帮助文档?runif，会发现每种分布都有对应的四个函数 d:density p:cumulative probability q:quantile r:random dnorm(seq(0.1, 0.5, length.out = 10), mean = 0, sd = 1) ## [1] 0.3970 0.3948 0.3919 0.3882 0.3838 0.3788 0.3730 ## [8] 0.3666 0.3596 0.3521 在tidyverse的框架下，我们喜欢在数据框(data.frame)下运用这些函数，因为这样我们可以方便使用ggplot2来可视化， 例子1，我们生成100个正态分布的点，然后看看其分布 tibble( x = rnorm(n = 100, mean = 0, sd = 1) ) %&gt;% ggplot(aes(x = x)) + geom_density() 我们将模拟的正态分布和理论上正态分布画在一起 tibble( x = rnorm(n = 100, mean = 0, sd = 1) ) %&gt;% ggplot(aes(x = x)) + geom_density() + stat_function( fun = dnorm, args = list(mean = 0, sd = 1), color = &quot;red&quot; ) 如果我们模拟点再增加点，会越来越逼近理论上的分布。 例子2，在数据框(data.frame)下，建立模拟\\(x\\)和\\(y\\)的线性关系 \\[ y_i = 4 + 3.2\\, x_i\\] 现实中，观察值往往会带入误差，假定误差服从正态分布，那么\\(x\\)和\\(y\\)的线性关系重新表述为 \\[ y_i = \\beta_0 + \\beta_1\\, x_i + \\epsilon_i, \\quad \\epsilon \\in \\text{Normal}(\\mu =0, \\sigma =1) \\] beta_0 &lt;- 4 beta_1 &lt;- 3.2 epsilon &lt;- rnorm(n = 1000, mean = 0, sd = 1) sim_normal &lt;- tibble( # x_vals = runif(1000, 0, 10) x_vals = seq(from = 0, to = 5, length.out = 1000), y_vals = beta_0 + beta_1 * x_vals + epsilon, ) sim_normal %&gt;% head() sim_normal %&gt;% ggplot(aes(x = x_vals, y = y_vals)) + geom_point() 有时候为了方便，可以写简练点 tibble( a = runif(1000, 0, 5), b = 4 + rnorm(1000, mean = 3.2 * a, sd = 1) ) %&gt;% ggplot(aes(x = a, y = b)) + geom_point() 26.2 MASS::mvrnorm MASS::mvrnorm(n = 1, mu, Sigma)产生多元高斯分布的随机数，每组随机变量高度相关。 比如人的身高服从正态分布，人的体重也服从正态分布，同时身高和体重又存在强烈的关联。 n: 随机样本的大小 mu: 多元高斯分布的均值向量 Sigma: 协方差矩阵，主要这里是大写的S (Sigma)，提醒我们它是一个矩阵，不是一个数值 a &lt;- 3.5 b &lt;- -1 sigma_a &lt;- 1 sigma_b &lt;- 0.5 rho &lt;- -0.7 mu &lt;- c(a, b) cov_ab &lt;- sigma_a * sigma_b * rho # 协方差 # 构建协方差矩阵 sigma &lt;- matrix(c(sigma_a^2, cov_ab, cov_ab, sigma_b^2), ncol = 2) d &lt;- MASS::mvrnorm(1000, mu = mu, Sigma = sigma) %&gt;% data.frame() %&gt;% set_names(&quot;group_a&quot;, &quot;group_b&quot;) head(d) d %&gt;% ggplot(aes(x = group_a)) + geom_density(color = &quot;transparent&quot;, fill = &quot;dodgerblue3&quot;, alpha = 1/2) + stat_function(fun = dnorm, args = list(mean = 3.5, sd = 1), linetype = 2 ) d %&gt;% ggplot(aes(x = group_b)) + geom_density(color = &quot;transparent&quot;, fill = &quot;dodgerblue3&quot;, alpha = 1/2) + stat_function(fun = dnorm, args = list(mean = -1, sd = 0.5), linetype = 2 ) d %&gt;% ggplot(aes(x = group_a, y = group_b)) + geom_point() + stat_ellipse(type = &quot;norm&quot;, level = 0.95) 我们回头验算一下 d %&gt;% summarise( a_mean = mean(group_a), b_mean = mean(group_b), a_sd = sd(group_a), b_sd = sd(group_b), cor = cor(group_a,group_b), cov = cov(group_a,group_b) ) 26.3 蒙特卡洛 这是我研究生时候老师布置的一个的题目，当时我用的是C语言代码，现在我们有强大的tidyverse set.seed(2019) n &lt;- 50000 points &lt;- tibble(&quot;x&quot; = runif(n), &quot;y&quot; = runif(n)) points &lt;- points %&gt;% mutate(inside = map2_dbl(.x = x, .y = y, ~if_else(.x**2 + .y**2 &lt; 1, 1, 0))) %&gt;% rowid_to_column(&quot;N&quot;) 正方形的面积是1，圆的面积是\\(\\pi r^2 = \\frac{1}{4} \\pi\\)，如果知道两者的比例，就可以估算\\(\\pi\\) points &lt;- points %&gt;% mutate(estimate = 4*cumsum(inside)/N) points %&gt;% tail() points %&gt;% ggplot() + geom_line(aes(y = estimate, x = N), colour = &quot;#82518c&quot;) + geom_hline(yintercept = pi) 26.4 抽样与样本 26.4.1 总体分布 假定一个事实，川师男生总体的平均身高和身高的标准差分别为 true.mean &lt;- 175.7 true.sd &lt;- 15.19 那么我们可以模拟分布情况如下 pop.distn &lt;- tibble( height = seq(100, 250, 0.5), density = dnorm(height, mean = true.mean, sd = true.sd) ) ggplot(pop.distn) + geom_line(aes(height, density)) + geom_vline( xintercept = true.mean, color = &quot;red&quot;, linetype = &quot;dashed&quot; ) + geom_vline( xintercept = true.mean + true.sd, color = &quot;blue&quot;, linetype = &quot;dashed&quot; ) + geom_vline( xintercept = true.mean - true.sd, color = &quot;blue&quot;, linetype = &quot;dashed&quot; ) + labs( x = &quot;Height (cm)&quot;, y = &quot;Density&quot;, title = &quot;川师男生身高分布&quot; ) 26.4.2 样本 假定我们从中抽取30个男生身高样本 sample.a &lt;- tibble(height = rnorm(n = 30, mean = true.mean, sd = true.sd)) 然后看看样本的直方图 sample.a %&gt;% ggplot(aes(x = height)) + geom_histogram(aes(y = stat(density)), fill = &quot;steelblue&quot;, alpha = 0.75, bins = 10 ) + geom_line( data = pop.distn, aes(x = height, y = density), alpha = 0.25, size = 1.5 ) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_vline(xintercept = mean(sample.a$height), linetype = &quot;solid&quot;) 红色的虚线代表分布的总体的均值，黑色实线代表30个样本的均值， sample.a %&gt;% summarize( sample.mean = mean(height), sample.sd = sd(height) ) 也就是说，基于这30个观察值的样本，我们认为川师男生的身高均值为175.743cm，方差为17.3027 可能有同学说，这个样本太少了，计算的均值还不够科学，会以偏概全。于是又重新找了30个男生，和上次类似，用rnorm函数模拟，我们记为样本b sample.b &lt;- tibble(height = rnorm(30, mean = true.mean, sd = true.sd)) 再来看看这次样本的分布 sample.b %&gt;% ggplot(aes(x = height)) + geom_histogram(aes(y = stat(density)), fill = &quot;steelblue&quot;, alpha = 0.75, bins = 10 ) + geom_line( data = pop.distn, aes(x = height, y = density), alpha = 0.25, size = 1.5 ) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_vline(xintercept = mean(sample.a$height), linetype = &quot;solid&quot;) 同样，我们计算样本b的均值和方差 sample.b %&gt;% summarize( sample.mean = mean(height), sample.sd = sd(height) ) 这次抽样的结果，均值为173.711cm，方差为14.8641 和样本a比，有一点点变化。不经想问，我能否继续抽样呢？结果会有变化吗？为了避免重复写代码 ，我把上面的过程整合到一起，写一个子函数，专门模拟抽样过程 rnorm.stats &lt;- function(n, mu, sigma) { the.sample &lt;- rnorm(n, mu, sigma) tibble( sample.size = n, sample.mean = mean(the.sample), sample.sd = sd(the.sample) ) } 于是，我们又可以继续模拟了。注意我们之前设定的总体分布的均值和方差 true.mean &lt;- 175.7 true.sd &lt;- 15.19 rnorm.stats(30, true.mean, true.sd) yes，代码工作的很好，但不过只是代码减少了一点点，仍然只是一次抽样（这里30个样本为一次抽样），我们的目的是反复抽样， 抽很多次的那种喔。 那我们用purrr包的rerun函数偷个懒， df.samples.of.30 &lt;- purrr::rerun(2500, rnorm.stats(30, true.mean, true.sd)) %&gt;% dplyr::bind_rows() 哇，一下子抽了2500个样本,全部装进了df.sample.of.30这个数据框， 偷偷看一眼呢 df.samples.of.30 %&gt;% head() 回过头看看df.samples.of.30是什么： 从川师的男生中随机抽取30个，计算这30个人身高的均值和方差，这叫一次抽样 把上面的工作，重复2500次，得到2500个均值和方差 2500个均值和方差，组成了一个数据框 我们发现每次抽样的均值都不一样，感觉又像一个分布(抽样的均值分布)，我们画出来看看吧 df.samples.of.30 %&gt;% ggplot(aes(x = sample.mean, y = stat(density))) + geom_histogram(bins = 25, fill = &quot;firebrick&quot;, alpha = 0.5) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs( title = &quot;抽样2500次（每次30个男生）身高均值的分布&quot;, subtitle = &quot;Distribution of mean heights for 2500 samples of size 30&quot; ) 注意到，这不是男生身高的分布，而是每次抽样计算的均值构成的分布. 为了更清楚的说明，我们把整体的分布(灰色曲线)、样本a（蓝色直方图）、抽样的均值分布（红色直方图）三者画在一起。 df.samples.of.30 %&gt;% ggplot(aes(x = sample.mean, y = stat(density))) + geom_histogram(bins = 50, fill = &quot;firebrick&quot;, alpha = 0.5) + geom_histogram( data = sample.a, aes(x = height, y = stat(density)), bins = 11, fill = &quot;steelblue&quot;, alpha = 0.25 ) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_line(data = pop.distn, aes(x = height, y = density), alpha = 0.25, size = 1.5) + xlim(125, 225) 样本的均值分布，是个很有意思的结果，比如，我们再选30个男生再抽样一次，我们可以断定，这次抽样的均值会落在了红色的区间之内。 然而，注意到，必须限定再次抽样的大小仍然是30个男生，以上这句话才成立。 df.samples.of.30 %&gt;% summarize( mean.of.means = mean(sample.mean), sd.of.means = sd(sample.mean) ) 这里计算的是抽样(样本大小为30)均值分布，而不是整体的均值分布。言外之意，样本大小可以是其它的呗， 那就把样本调整为50、100、250、500分别试试看 df.samples.of.50 &lt;- rerun(2500, rnorm.stats(50, true.mean, true.sd)) %&gt;% bind_rows() df.samples.of.100 &lt;- rerun(2500, rnorm.stats(100, true.mean, true.sd)) %&gt;% bind_rows() df.samples.of.250 &lt;- rerun(2500, rnorm.stats(250, true.mean, true.sd)) %&gt;% bind_rows() df.samples.of.500 &lt;- rerun(2500, rnorm.stats(500, true.mean, true.sd)) %&gt;% bind_rows() 忍不住想画图看看，每次抽取的男生数量不同，均值的分布会有不同？ df.combined &lt;- bind_rows( df.samples.of.30, df.samples.of.50, df.samples.of.100, df.samples.of.250, df.samples.of.500 ) %&gt;% mutate(sample.sz = as.factor(sample.size)) df.combined %&gt;% ggplot(aes(x = sample.mean, y = stat(density), fill = sample.sz)) + geom_histogram(bins = 25, alpha = 0.5) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;) + facet_wrap(vars(sample.sz), nrow = 1) + scale_fill_brewer(palette = &quot;Set1&quot;) + labs( x = &quot;Sample means&quot;, y = &quot;Density&quot;, title = &quot;Distribution of mean heights for samples of varying size&quot; ) 随着样本大小由30增加到500，抽样的均值分布围绕着越来越聚合到实际的均值，或者说随着样本大小的增多，对均值估计的不确定性越小。 sampling.distn.mean.table &lt;- df.combined %&gt;% group_by(sample.size) %&gt;% summarize( mean.of.means = mean(sample.mean), sd.of.means = sd(sample.mean) ) sampling.distn.mean.table 有个统计学上的概念需要明确。 输出结果的第三列sd.of.means 是不同样本大小(30,50,100,250,500)下，反复抽样后平均数分布的标准差。 数学上，如果已知总体的标准差(\\(\\sigma\\))，那么抽取无限多份大小为 \\(n\\) 的样本，每个样本各有一个平均值，所有这个大小的样本之平均值的标准差可证明为 \\[ \\frac{\\sigma}{\\sqrt{n}} \\] 即，平均值的标准误差。 下面我们画图看看，模拟出来的\\(sd.of.means\\)和理论值\\(\\frac{\\sigma}{\\sqrt{n}}\\)是否一致。 注意到这里的\\(\\sigma\\)是总体的标准差，即最开始我们设定的川师男生身高的标准差true.sd. 也就说，理论上 df.se.mean.theory &lt;- tibble( sample.size = seq(10,500,10) ) %&gt;% mutate(std.error = true.sd/sqrt(sample.size)) df.se.mean.theory sampling.distn.mean.table %&gt;% ggplot(aes(x = sample.size, y = sd.of.means)) + geom_point() + geom_line(aes(x = sample.size, y = std.error), data = df.se.mean.theory, color = &quot;red&quot;) + labs( x = &quot;Sample size&quot;, y = &quot;Std Error of Mean&quot;, title = &quot;平均值标准误差随样本大小变化（理论值和模拟值对比）&quot; ) 两者吻合的很好。 刚刚我们看到的，抽样均值分布随着样本大小变化而变化。可以试想下，抽样的其他统计量分布（方差，中位数），是不是也随着样本大小变化而变化呢？ sampling.distn.sd.table &lt;- df.combined %&gt;% group_by(sample.size) %&gt;% summarize( mean.of.sds = mean(sample.sd), sd.of.sds = sd(sample.sd) ) sampling.distn.sd.table 答案是肯定的，样本量的增多，抽样方差的不确定性减少。 26.5 扩展阅读 https://learningstatisticswithr.com/book/ "],
["tidystats.html", "第 27 章 Tidy Statistics 27.1 从一个案例开始 27.2 单因素方差分析 27.3 双因素方差分析", " 第 27 章 Tidy Statistics 本章介绍基本的方差分析内容 library(tidyverse) 27.1 从一个案例开始 从这是一份1994年收集1379个对象关于收入、身高、教育水平等信息的数据集，数据在课件首页下载。 首先，我们下载后导入数据 wages &lt;- read_csv(&quot;./demo_data/wages.csv&quot;) wages %&gt;% head() %&gt;% knitr::kable() earn height sex race ed age 79571 73.89 male white 16 49 96397 66.23 female white 16 62 48711 63.77 female white 16 33 80478 63.22 female other 16 95 82089 63.08 female white 17 43 15313 64.53 female white 15 30 我们的问题：男性是否就比女性挣的多？ 27.2 单因素方差分析 t.test(earn ~ sex, data = wages) ## ## Welch Two Sample t-test ## ## data: earn by sex ## t = -12, df = 768, p-value &lt;2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -25324 -18171 ## sample estimates: ## mean in group female mean in group male ## 24246 45993 lm(earn ~ sex, data = wages) %&gt;% summary() ## ## Call: ## lm(formula = earn ~ sex, data = wages) ## ## Residuals: ## Min 1Q Median 3Q Max ## -46092 -20516 -4639 11722 271956 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 24246 1004 24.1 &lt;2e-16 *** ## sexmale 21748 1636 13.3 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29400 on 1377 degrees of freedom ## Multiple R-squared: 0.114, Adjusted R-squared: 0.113 ## F-statistic: 177 on 1 and 1377 DF, p-value: &lt;2e-16 aov(earn ~ sex, data = wages) %&gt;% summary() ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## sex 1 1.53e+11 1.53e+11 177 &lt;2e-16 *** ## Residuals 1377 1.19e+12 8.66e+08 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 27.3 双因素方差分析 我们采用ggpubr宏包下的ToothGrowth来说明，这个数据集包含60个样本，记录着每10只豚鼠在不同的喂食方法和不同的药物剂量下，牙齿的生长情况. len : 牙齿长度 supp : 两种喂食方法 (橙汁和维生素C) dose : 抗坏血酸剂量 (0.5, 1, and 2 mg) library(&quot;ggpubr&quot;) my_data &lt;- ToothGrowth %&gt;% mutate_at(vars(supp, dose), ~ as_factor(.)) my_data %&gt;% head() my_data %&gt;% ggplot(aes(x = supp, y = len, fill = supp)) + geom_boxplot(position = position_dodge()) + facet_wrap(vars(dose)) + labs(title = &quot;VC剂量和摄入方式对豚鼠牙齿的影响&quot;) 问题：豚鼠牙齿的长度是否与药物的食用方法和剂量有关？ 线性回归时，我们是通过独立变量来预测响应变量，但现在我们关注的重点会从预测转向不同组别差异之间的分析，这即为方差分析（ANOVA）。 这里是两个解释变量，所以问题需要双因素方差分析 (ANOVA) aov(len ~ supp + dose, data = my_data) %&gt;% broom::tidy() 检验表明不同类型之间存在显著差异，但是并没有告诉我们具体谁与谁之间的不同。需要多重比较帮助我们解决这个问题。使用TurkeyHSD函数 aov(len ~ supp + dose, data = my_data) %&gt;% TukeyHSD(which = &quot;dose&quot;) %&gt;% broom::tidy() aov(len ~ supp + dose, data = my_data) %&gt;% TukeyHSD(which = &quot;supp&quot;) %&gt;% broom::tidy() 思考：交互效应是否显著？ aov(len ~ supp * dose, data = my_data) %&gt;% broom::tidy() "],
["lm.html", "第 28 章 线性回归 28.1 从一个案例开始 28.2 线性回归模型 28.3 使用lm() 函数 28.4 模型的解释 28.5 多元线性回归 28.6 更多模型 28.7 变量重要性 28.8 可能遇到的情形 28.9 延伸阅读", " 第 28 章 线性回归 线性模型是数据分析中最常用的一种分析方法。最基础的往往最深刻。 library(tidyverse) 28.1 从一个案例开始 这是一份1994年收集1379个对象关于收入、身高、教育水平等信息的数据集。数据在课件首页提供了下载链接。 首先，我们下载后导入数据 wages &lt;- read_csv(&quot;./demo_data/wages.csv&quot;) wages %&gt;% head() 28.1.1 缺失值检查 一般情况下，拿到一份数据，首先要了解数据，知道每个变量的含义， wages %&gt;% colnames() ## [1] &quot;earn&quot; &quot;height&quot; &quot;sex&quot; &quot;race&quot; &quot;ed&quot; ## [6] &quot;age&quot; 同时检查数据是否有缺失值，这点很重要。在R中 NA（not available，不可用）表示缺失值, 比如可以这样检查是否有缺失值。 # 如何检查数据是否有缺失值？ wages %&gt;% summarise( earn_na = sum(is.na(earn)), height_na = sum(is.na(height)), sex_na = sum(is.na(sex)), race_na = sum(is.na(race)), ed_na = sum(is.na(ed)), age_na = sum(is.na(age)) ) 程序员都是偷懒的，所以也可以写的简便一点。大家在学习的过程中，也会慢慢的发现tidyverse的函数很贴心，很周到。 wages %&gt;% summarise_all( ~ sum(is.na(.)) ) 当然，也可以用purrr::map()的方法。这部分我会在后面的章节中逐步介绍。 wages %&gt;% map_df(~ sum(is.na(.))) 28.1.2 变量简单统计 然后探索下每个变量的分布。比如调研数据中男女的数量分别是多少？ wages %&gt;% count(sex) 男女这两组的身高均值分别是多少？收入的均值分别是多少？ wages %&gt;% group_by(sex) %&gt;% summarise( n = n(), mean_height = mean(height), mean_earn = mean(earn) ) 也有可以用可视化的方法，呈现男女收入的分布情况 wages %&gt;% ggplot(aes(x = earn, color = sex)) + geom_density() 大家可以自行探索其他变量的情况。现在提出几个问题，希望大家带着这些问题去探索： 长的越高的人挣钱越多？ 是否男性就比女性挣的多？ 影响收入最大的变量是哪个？ 怎么判定我们建立的模型是不是很好？ 28.2 线性回归模型 长的越高的人挣钱越多？ 要回答这个问题，我们先介绍线性模型。顾名思义，就是认为\\(x\\)和\\(y\\)之间有线性关系，数学上可以写为 \\[ \\begin{aligned} y &amp;= \\alpha + \\beta x + \\epsilon \\\\ \\epsilon &amp;\\in \\text{Normal}(\\mu, \\sigma) \\end{aligned} \\] \\(\\epsilon\\) 代表误差项，它与\\(x\\) 无关，且服从正态分布。 建立线性模型，就是要估计这里的系数\\(\\hat\\alpha\\)和\\(\\hat\\beta\\)，即截距项和斜率项。常用的方法是最小二乘法（ordinary least squares (OLS) regression）： 就是我们估算的\\(\\hat\\alpha\\)和\\(\\hat\\beta\\), 要使得残差的平方和最小，即\\(\\sum_i(y_i - \\hat y_i)^2\\)或者叫\\(\\sum_i \\epsilon_i^2\\)最小。 当然，数据量很大，手算是不现实的，我们借助R语言代码吧 28.3 使用lm() 函数 用R语言代码(建议大家先?lm看看帮助文档)， lm参数很多, 但很多我们都用不上，所以我们只关注其中重要的两个参数 lm(formula = y ~ x, data) lm(y ~ x, data) 是最常用的线性模型函数(lm是linear model的缩写)。参数解释说明 formula：指定回归模型的公式，对于简单的线性回归模型y ~ x. ~ 符号：代表“预测”，可以读做“y由x预测”。有些学科不同的表述，比如下面都是可以的 response ~ explanatory dependent ~ independent outcome ~ predictors data：代表数据框，数据框包含了响应变量和独立变量 在运行lm()之前，先画出身高和收入的散点图(记在我们想干什么，寻找身高和收入的关系) wages %&gt;% ggplot(aes(x = height, y = earn)) + geom_point() 等不及了，就运行代码吧 mod1 &lt;- lm(formula = earn ~ height, data = wages) 这里我们将earn作为响应变量，height为预测变量。lm()返回赋值给mod1. mod1现在是个什么东东呢？ mod1是一个叫lm object或者叫类的东西， names(mod1) ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; ## [4] &quot;rank&quot; &quot;fitted.values&quot; &quot;assign&quot; ## [7] &quot;qr&quot; &quot;df.residual&quot; &quot;xlevels&quot; ## [10] &quot;call&quot; &quot;terms&quot; &quot;model&quot; 我们打印看看，会发生什么 print(mod1) ## ## Call: ## lm(formula = earn ~ height, data = wages) ## ## Coefficients: ## (Intercept) height ## -126523 2387 这里有两部分信息。首先第一部分是我们建立的模型；第二部分是R给出了截距（\\(\\alpha = -126532\\)）和斜率（\\(\\beta = 2387\\)）. 也就是说我们建立的线性回归模型是 \\[ \\hat y = -126532 + 2387 \\; x \\] 查看详细信息 summary(mod1) ## ## Call: ## lm(formula = earn ~ height, data = wages) ## ## Residuals: ## Min 1Q Median 3Q Max ## -47903 -19744 -5184 11642 276796 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -126523 14076 -8.99 &lt;2e-16 *** ## height 2387 211 11.31 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29900 on 1377 degrees of freedom ## Multiple R-squared: 0.085, Adjusted R-squared: 0.0844 ## F-statistic: 128 on 1 and 1377 DF, p-value: &lt;2e-16 查看拟合值 # predict(mod1) # predictions at original x values wages %&gt;% modelr::add_predictions(mod1) 查看残差值 # resid(mod1) wages %&gt;% modelr::add_predictions(mod1) %&gt;% modelr::add_residuals(mod1) 28.4 模型的解释 建立一个lm模型是简单的，然而最重要的是，我们能解释这个模型。 mod1的解释： 对于斜率\\(\\beta = 2387\\)意味着，当一个人的身高是68英寸时，他的预期收入\\(earn = -126532 + 2387 \\times 68= 35806\\) 美元， 换个方式说，身高\\(height\\)每增加一个1英寸, 收入\\(earn\\)会增加2387美元。 对于截距\\(\\alpha = -126532\\)，即当身高为0时，期望的收入值-126532。呵呵，人的身高不可能为0，所以这是一种极端的理论情况，现实不可能发生。 wages %&gt;% ggplot(aes(x = height, y = earn)) + geom_point(alpha = 0.25) + geom_smooth(method = &quot;lm&quot;, se = FALSE) 28.5 多元线性回归 刚才讨论的单个预测变量height，现在我们增加一个预测变量ed，稍微扩展一下我们的一元线性模型，就是多元回归模型 \\[ \\begin{aligned} earn &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 \\text{ed} +\\epsilon \\\\ \\end{aligned} \\] R语言代码实现也很简单，只需要把变量ed增加在公式的右边 mod2 &lt;- lm(earn ~ height + ed, data = wages) 同样，我们打印mod2看看 mod2 ## ## Call: ## lm(formula = earn ~ height + ed, data = wages) ## ## Coefficients: ## (Intercept) height ed ## -161541 2087 4118 大家试着解释下mod2. 😄 28.6 更多模型 lm(earn ~ sex, data = wages) lm(earn ~ ed, data = wages) lm(earn ~ age, data = wages) lm(earn ~ height + sex, data = wages) lm(earn ~ height + ed, data = wages) lm(earn ~ height + age, data = wages) lm(earn ~ height + race, data = wages) lm(earn ~ height + sex + ed, data = wages) lm(earn ~ height + sex + age, data = wages) lm(earn ~ height + sex + race, data = wages) lm(earn ~ height + ed + age, data = wages) lm(earn ~ height + ed + race, data = wages) lm(earn ~ height + age + race, data = wages) lm(earn ~ height + sex + ed + age, data = wages) lm(earn ~ height + sex + ed + race, data = wages) lm(earn ~ height + sex + age + race, data = wages) lm(earn ~ height + ed + age + race, data = wages) lm(earn ~ sex + ed + age + race, data = wages) lm(earn ~ height + sex + ed + age + race, data = wages) 28.7 变量重要性 哪个变量对收入的影响最大？ lm(earn ~ height + ed + age, data = wages) 方法一，变量都做标准化处理后，再放到模型中计算，然后对比系数的绝对值 fit &lt;- wages %&gt;% mutate_at(vars(earn, height, ed, age), scale) %&gt;% lm(earn ~ 1 + height + ed + age, data = .) summary(fit) ## ## Call: ## lm(formula = earn ~ 1 + height + ed + age, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.921 -0.536 -0.121 0.353 8.298 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.77e-16 2.40e-02 0.00 1 ## height 2.74e-01 2.43e-02 11.26 &lt; 2e-16 *** ## ed 3.39e-01 2.43e-02 13.97 &lt; 2e-16 *** ## age 1.55e-01 2.44e-02 6.35 2.9e-10 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.89 on 1375 degrees of freedom ## Multiple R-squared: 0.21, Adjusted R-squared: 0.208 ## F-statistic: 122 on 3 and 1375 DF, p-value: &lt;2e-16 方法二，通过比较模型参数的t-statistic的绝对值，可以考察参数的重要程度 caret::varImp(fit) 28.8 可能遇到的情形 根据同学们的建议，模型中涉及统计知识，留给统计老师讲，我们这里是R语言课，应该讲代码。 因此，这里再介绍几种线性回归中遇到的几种特殊情况 28.8.1 截距项 # 包含截距，以下两者是等价的 lm(earn ~ 1 + height, data = wages) lm(earn ~ height, data = wages) # 去掉截距，以下两者是等价的 lm(earn ~ height - 1, data = wages) lm(earn ~ 0 + height, data = wages) 不包含截距项，实际上就是强制通过原点(0,0)，这样做很大程度上影响了斜率。 28.8.2 只有截距项 lm(earn ~ 1, data = wages) ## ## Call: ## lm(formula = earn ~ 1, data = wages) ## ## Coefficients: ## (Intercept) ## 32446 只有截距项，实质上就是计算y变量的均值 wages %&gt;% summarise( mean_wages = mean(earn) ) 28.8.3 分类变量 race变量就是数据框wages的一个分类变量，代表四个不同的种族。用分类变量做回归，本质上是各组之间的进行比较。 wages %&gt;% distinct(race) wages %&gt;% ggplot(aes(x = race, y = earn, fill = race)) + geom_boxplot(position = position_dodge()) + scale_y_continuous(limits = c(0, 20000)) 以分类变量作为解释变量，做线性回归 mod3 &lt;- lm(earn ~ race, data = wages) mod3 ## ## Call: ## lm(formula = earn ~ race, data = wages) ## ## Coefficients: ## (Intercept) racehispanic raceother ## 28372 -2887 3905 ## racewhite ## 4993 tidyverse框架下，喜欢数据框的统计结果，因此，可用broom的tidy()函数将模型输出转换为数据框的形式 broom::tidy(mod3) 我们看到输出结果，只有race_hispanic、 race_other和race_white三个系数和Intercept截距，race_black去哪里了呢？ 事实上，race变量里有4组，回归时，选择black为基线，hispanic的系数，可以理解为由black切换到hispanic，引起earn收入的变化（效应） 对 black 组的估计，earn = 28372.09 = 28372.09 对 hispanic组的估计，earn = 28372.09 + -2886.79 = 25485.30 对 other 组的估计，earn = 28372.09 + 3905.32 = 32277.41 对 white 组的估计，earn = 28372.09 + 4993.33 = 33365.42 分类变量的线性回归本质上就是方差分析 第 27 章专题讨论方差分析 28.8.4 因子变量 hispanic组的估计最低，适合做基线，因此可以将race转换为因子变量，这样方便调整因子先后顺序 wages_fct &lt;- wages %&gt;% mutate(race = factor(race, levels = c(&quot;hispanic&quot;, &quot;white&quot;, &quot;black&quot;, &quot;other&quot;))) %&gt;% select(earn, race) head(wages_fct) wages_fct替换wages，然后建立线性模型 mod4 &lt;- lm(earn ~ race, data = wages_fct) broom::tidy(mod4) 以hispanic组作为基线，各组系数也调整了，但加上截距后，实际值是没有变的。 大家可以用sex变量试试看 lm(earn ~ sex, data = wages) 28.8.5 一个分类变量和一个连续变量 如果预测变量是一个分类变量和一个连续变量 mod5 &lt;- lm(earn ~ height + sex, data = wages) coef(mod5) ## (Intercept) height sexmale ## -32479.9 879.4 16874.2 height = 879.424 当sex保持不变时，height变化引起的earn变化 sexmale = 16874.158 当height保持不变时，sex变化(female变为male)引起的earn变化 p1 &lt;- wages %&gt;% ggplot(aes(x = height, y = earn, color = sex)) + geom_point(alpha = 0.1) + geom_line(aes(y = predict(mod5))) + scale_y_continuous(limits = c(0, 100000)) p1 28.8.6 偷懒的写法 . is shorthand for “everything else.” lm(earn ~ height + sex + race + ed + age, data = wages) lm(earn ~ ., data = wages) lm(earn ~ height + sex + race + ed, data = wages) lm(earn ~ . - age, data = wages) R 语言很多时候都出现了.，不同的场景，含义是不一样的。我会在后面第 36 章专门讨论这个问题， 这是一个非常重要的问题 28.8.7 交互项 lm(earn ~ height + sex + height:sex, data = wages) lm(earn ~ height * sex, data = wages) lm(earn ~ (height + sex)^2, data = wages) lm(earn ~ height:sex, data = wages) lm(earn ~ height:sex:race, data = wages) mod6 &lt;- lm(earn ~ height + sex + height:sex, data = wages) coef(mod6) ## (Intercept) height sexmale ## -12167.0 564.5 -30510.4 ## height:sexmale ## 701.4 对于女性，height增长1个单位，引起earn的增长564.5102 对于男性，height增长1个单位，引起earn的增长564.5102 + 701.4065 = 1265.92 p2 &lt;- wages %&gt;% ggplot(aes(x = height, y = earn, color = sex)) + geom_point(alpha = 0.1) + geom_line(aes(y = predict(mod6))) + scale_y_continuous(limits = c(0, 100000)) p2 注意，没有相互项和有相互项的区别 library(patchwork) combined &lt;- p1 + p2 &amp; theme(legend.position = &quot;bottom&quot;) combined + plot_layout(guides = &quot;collect&quot;) 28.8.8 虚拟变量 交互项，有点不好理解？我们再细致说一遍 earn ~ height + sex + height:sex 对应的数学表达式 \\[ \\begin{aligned} \\text{earn} &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 \\text{sex} +\\beta_3 \\text{(height*sex)}+ \\epsilon \\\\ \\end{aligned} \\] 我们要求出其中的\\(\\alpha, \\beta_1, \\beta_2, \\beta_3\\)，事实上，分类变量在R语言代码里，会转换成0和1这种虚拟变量，然后再计算。类似 wages %&gt;% mutate(sexmale = if_else(sex == &quot;female&quot;, 0, 1)) 那么上面的公式变为 \\[ \\begin{aligned} \\text{earn} &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 \\text{sexmale} +\\beta_3 \\text{(height*sexmale)}+ \\epsilon \\\\ \\end{aligned} \\] 于是，可以将上面的公式里男性(sexmale = 1)和女性(sexmale = 0)分别表示 \\[ \\begin{aligned} \\text{female}\\qquad earn &amp;= \\alpha + \\beta_1 \\text{height} +\\epsilon \\\\ \\text{male}\\qquad earn &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 *1 +\\beta_3 \\text{(height*1)}+ \\epsilon \\\\ &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 +\\beta_3 \\text{height}+ \\epsilon \\\\ &amp; = (\\alpha + \\beta_2) + (\\beta_1 + \\beta_3)\\text{height} + \\epsilon \\\\ \\end{aligned} \\] 我们再对比mod6结果中的系数\\(\\alpha, \\beta_1, \\beta_2, \\beta_3\\) mod6 ## ## Call: ## lm(formula = earn ~ height + sex + height:sex, data = wages) ## ## Coefficients: ## (Intercept) height sexmale ## -12167 565 -30510 ## height:sexmale ## 701 是不是更容易理解呢？ 对于女性，(截距\\(\\alpha\\)，系数\\(\\beta_1\\))，height增长1个单位，引起earn的增长564.5102 对于男性，(截距\\(\\alpha + \\beta_2\\)，系数\\(\\beta_1 + \\beta_3\\))，height增长1个单位，引起earn的增长564.5102 + 701.4065 = 1265.92 事实上，对于男性和女性，截距和系数都不同，因此这种情形等价于，按照sex分成两组，男性算男性的斜率，女性算女性的斜率 wages %&gt;% group_by(sex) %&gt;% group_modify( ~ broom::tidy(lm(earn ~ height, data = .)) ) wages %&gt;% ggplot(aes(x = height, y = earn, color = sex)) + geom_smooth(method = lm, se = F) wages %&gt;% ggplot(aes(x = height, y = earn, color = sex)) + geom_line(aes(y = predict(mod6))) 如果再特殊一点的模型（有点过分了） mod7 &lt;- lm(earn ~ height + height:sex, data = wages) coef(mod7) ## (Intercept) height height:sexmale ## -24632.7 757.5 251.3 这又怎么理解呢？ 我们还是按照数学模型来理解，这里对应的数学表达式 \\[ \\begin{aligned} \\text{earn} &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_4 \\text{(height*sex)}+ \\epsilon \\\\ \\end{aligned} \\] 引入虚拟变量 \\[ \\begin{aligned} \\text{earn} &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_4 \\text{(height*sexmale)}+ \\epsilon \\\\ \\end{aligned} \\] 同样假定男性(sexmale = 1)和女性(sexmale = 0)，那么 \\[ \\begin{aligned} \\text{female}\\qquad earn &amp;= \\alpha + \\beta_1 \\text{height} +\\epsilon \\\\ \\text{male}\\qquad earn &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_4 \\text{(height*1)}+ \\epsilon \\\\ &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_4 \\text{height}+ \\epsilon \\\\ &amp; = \\alpha + (\\beta_1 + \\beta_4)\\text{height} + \\epsilon \\\\ \\end{aligned} \\] 对照模型mod7的结果，我们可以理解： 对于女性(截距\\(\\alpha\\)，系数\\(\\beta_1\\))，height增长1个单位，引起earn的增长757.4661 对于男性(截距\\(\\alpha\\)，系数$_1 + _4 $)，height增长1个单位，引起earn的增长757.4661 + 251.2915 = 1008.758 注意到，mod6和mod7是两个不同的模型, mod7中男女拟合曲线在y轴的截距是相同的，而mod6在y轴的截距是不同的 28.8.9 predict vs fit fitted() , 模型一旦建立，可以使用拟合函数fitted()返回拟合值，建模和拟合使用的是同一数据 predict()， 模型建立后，可以用新的数据进行预测，predict()要求数据框包含新的预测变量，如果没有提供，那么就使用建模时的预测变量进行预测，这种情况下，得出的结果和fitted()就时一回事了。 predict()函数和fitted()函数不同的地方，还在于predict()函数往往带有返回何种类型的选项，可以是具体数值，也可以是分类变量。具体会在第 32 章介绍。 28.8.10 回归和相关的关系 相关，比如求两个变量的相关系数cor(x, y) 回归，也是探寻自变量和因变量的关系，一般用来预测 回归分析中，如果自变量只有一个\\(x\\)，也就是模型lm(y~x)，那么回归和相关就有关联了。 比如：计算身高和收入两者的Pearson相关系数的平方 r &lt;- cor(wages$height, wages$earn) print( r^2 ) ## [1] 0.08503 然后看看，身高和收入的线性模型 lm(formula = earn ~ height, data = wages) %&gt;% broom::glance() %&gt;% pull(r.squared) ## [1] 0.08503 相关系数的平方 和 线性模型的\\(R^2\\)是相等的 28.9 延伸阅读 一篇极富思考性和启发性的文章《常见统计检验的本质是线性模型》 "],
["lmm.html", "第 29 章 多层线性模型 29.1 分组数据 29.2 案例 29.3 线性模型 29.4 变化的截距 29.5 变化的斜率 29.6 变化的斜率 + 变化的截距 29.7 信息池 29.8 更多", " 第 29 章 多层线性模型 29.1 分组数据 在实验设计和数据分析中，我们可能经常会遇到分组的数据结构。所谓的分组，就是每一次观察，属于某个特定的组，比如考察学生的成绩，这些学生属于某个班级，班级又属于某个学校。有时候发现这种分组的数据，会给数据分析带来很多有意思的内容。 29.2 案例 我们从一个有意思的案例开始。 不同院系教职员工的收入 一般情况下，不同的院系，制定教师收入的依据和标准可能是不同的。我们假定有一份大学教职员的收入清单，这个学校包括信息学院、外国语学院、社会政治学、生物学院、统计学院共五个机构，我们通过数据建模，探索这个学校的薪酬制定规则。 create_data &lt;- function() { df &lt;- tibble( ids = 1:100, department = rep(c(&quot;sociology&quot;, &quot;biology&quot;, &quot;english&quot;, &quot;informatics&quot;, &quot;statistics&quot;), 20), bases = rep(c(40000, 50000, 60000, 70000, 80000), 20) * runif(100, .9, 1.1), experience = floor(runif(100, 0, 10)), raises = rep(c(2000, 500, 500, 1700, 500), 20) * runif(100, .9, 1.1) ) df &lt;- df %&gt;% mutate( salary = bases + experience * raises ) df } library(tidyverse) library(lme4) library(modelr) library(broom) library(broom.mixed) df &lt;- create_data() df 29.3 线性模型 薪酬制定规则一：假定教师收入主要取决于他从事工作的时间，也就说说工作时间越长收入越高。意味着，每个院系的起始薪酬（起薪）是一样的，并有相同的年度增长率。那么，这个收入问题就是一个简单线性模型： \\[\\hat{y} = \\alpha + \\beta_1x_1 + ... + \\beta_nx_n\\] 具体到我们的案例中，薪酬模型可以写为 \\[ \\hat{salary_i} = \\alpha + \\beta * experience_i \\] 通过这个等式，可以计算出各个系数，即截距\\(\\alpha\\)就是起薪，斜率\\(\\beta\\)就是年度增长率。确定了斜率和截距，也就确定了每个教职员工的收入曲线。 # Model without respect to grouping m1 &lt;- lm(salary ~ experience, data = df) m1 ## ## Call: ## lm(formula = salary ~ experience, data = df) ## ## Coefficients: ## (Intercept) experience ## 63439 296 broom::tidy(m1) df %&gt;% modelr::add_predictions(m1) # Model without respect to grouping df %&gt;% add_predictions(m1) %&gt;% ggplot(aes(x = experience, y = salary)) + geom_point() + geom_line(aes(x = experience, y = pred)) + labs(x = &quot;Experience&quot;, y = &quot;Predicted Salary&quot;) + ggtitle(&quot;linear model Salary Prediction&quot;) + scale_colour_discrete(&quot;Department&quot;) 注意到，对每个教师来说，不管来自哪个学院的，系数\\(\\alpha\\)和\\(\\beta\\)是一样的，是固定的，因此这种简单线性模型也称之为固定效应模型。 事实上，这种线性模型的方法太过于粗狂，构建的线性直线不能反映收入随院系的变化。 29.4 变化的截距 薪酬制定规则二，假定不同的院系起薪不同，但年度增长率是相同的。 这种统计模型，相比于之前的固定效应模型（简单线性模型）而言，加入了截距会随所在学院不同而变化的思想，统计模型写为 \\[\\hat{y_i} = \\alpha_{j[i]} + \\beta x_i\\] 这个等式中，斜率\\(\\beta\\)代表着年度增长率，是一个固定值，也就前面说的固定效应项，而截距\\(\\alpha\\)代表着起薪，随学院变化，是五个值，因为一个学院对应一个，称之为变化效应项（也叫随机效应项）。这里模型中既有固定效应项又有变化效应项，因此称之为混合效应模型。 教师\\(i\\)，他所在的学院\\(j\\)，记为\\(j[i]\\)，那么教师\\(i\\)所在学院\\(j\\)对应的\\(\\alpha\\)，很自然的记为\\(\\alpha_{j[i]}\\) # Model with varying intercept m2 &lt;- lmer(salary ~ experience + (1 | department), data = df) m2 ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: salary ~ experience + (1 | department) ## Data: df ## REML criterion at convergence: 1930 ## Random effects: ## Groups Name Std.Dev. ## department (Intercept) 15227 ## Residual 3841 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) experience ## 59876 1108 broom.mixed::tidy(m2, effects = &quot;fixed&quot;) broom.mixed::tidy(m2, effects = &quot;ran_vals&quot;) df %&gt;% add_predictions(m2) %&gt;% ggplot(aes( x = experience, y = salary, group = department, colour = department )) + geom_point() + geom_line(aes(x = experience, y = pred)) + labs(x = &quot;Experience&quot;, y = &quot;Predicted Salary&quot;) + ggtitle(&quot;Varying Intercept Salary Prediction&quot;) + scale_colour_discrete(&quot;Department&quot;) 这种模型，我们就能看到院系不同 带来的员工收入的差别。 29.5 变化的斜率 薪酬制定规则三，不同的院系起始薪酬是相同的，但年度增长率不同。 与薪酬模型规则二的统计模型比较，我们只需要把变化的截距变成变化的斜率，那么统计模型可写为 \\[\\hat{y_i} = \\alpha + \\beta_{j[i]}x_i\\] 这里，截距(\\(\\alpha\\))对所有教师而言是固定不变的，而斜率(\\(\\beta\\))会随学院不同而变化，5个学院对应着5个斜率。 # Model with varying slope m3 &lt;- lmer(salary ~ experience + (0 + experience | department), data = df) m3 ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## salary ~ experience + (0 + experience | department) ## Data: df ## REML criterion at convergence: 2095 ## Random effects: ## Groups Name Std.Dev. ## department experience 2366 ## Residual 9296 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) experience ## 62220 803 broom.mixed::tidy(m3, effects = &quot;fixed&quot;) broom.mixed::tidy(m3, effects = &quot;ran_vals&quot;) df %&gt;% add_predictions(m3) %&gt;% ggplot(aes( x = experience, y = salary, group = department, colour = department )) + geom_point() + geom_line(aes(x = experience, y = pred)) + labs(x = &quot;Experience&quot;, y = &quot;Predicted Salary&quot;) + ggtitle(&quot;Varying slope Salary Prediction&quot;) + scale_colour_discrete(&quot;Department&quot;) 29.6 变化的斜率 + 变化的截距 薪酬制定规则四，不同的学院起始薪酬和年度增长率也不同。 这可能是最现实的一种情形了，它实际上是规则二和规则三的一种组合，要求截距和斜率都会随学院的不同变化，数学上记为 \\[\\hat{y_i} = \\alpha_{j[i]} + \\beta_{j[i]}x_i\\] 具体来说，教师\\(i\\)，所在的学院\\(j\\), 他的入职的起始收入表示为 (\\(\\alpha_{j[i]}\\))，年度增长率表示为(\\(\\beta_{j[i]}\\)). # Model with varying slope and intercept m4 &lt;- lmer(salary ~ experience + (1 + experience | department), data = df) m4 ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## salary ~ experience + (1 + experience | department) ## Data: df ## REML criterion at convergence: 1921 ## Random effects: ## Groups Name Std.Dev. Corr ## department (Intercept) 16879 ## experience 554 -0.74 ## Residual 3580 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) experience ## 59856 1058 broom.mixed::tidy(m4, effects = &quot;fixed&quot;) broom.mixed::tidy(m4, effects = &quot;ran_vals&quot;) df %&gt;% add_predictions(m4) %&gt;% ggplot(aes( x = experience, y = salary, group = department, colour = department )) + geom_point() + geom_line(aes(x = experience, y = pred)) + labs(x = &quot;Experience&quot;, y = &quot;Predicted Salary&quot;) + ggtitle(&quot;Varying Intercept and Slopes Salary Prediction&quot;) + scale_colour_discrete(&quot;Department&quot;) 29.7 信息池 29.7.1 提问 问题：薪酬制定规则四中，不同的院系起薪不同，年度增长率也不同，我们得出了5组不同的截距和斜率，那么是不是可以等价为，先按照院系分5组，然后各算各的截距和斜率? 比如 df %&gt;% group_by(department) %&gt;% group_modify( ~ broom::tidy(lm(salary ~ 1 + experience, data = .)) ) 分组各自回归，与这里的（变化的截距+变化的斜率）模型，不是一回事。 29.7.2 信息共享 完全共享 broom::tidy(m1) complete_pooling &lt;- broom::tidy(m1) %&gt;% dplyr::select(term, estimate) %&gt;% tidyr::pivot_wider( names_from = term, values_from = estimate ) %&gt;% dplyr::rename(Intercept = `(Intercept)`, slope = experience) %&gt;% dplyr::mutate(pooled = &quot;complete_pool&quot;) %&gt;% dplyr::select(pooled, Intercept, slope) complete_pooling 部分共享 fix_effect &lt;- broom.mixed::tidy(m4, effects = &quot;fixed&quot;) fix_effect fix_effect$estimate[1] fix_effect$estimate[2] var_effect &lt;- broom.mixed::tidy(m4, effects = &quot;ran_vals&quot;) var_effect # random effects plus fixed effect parameters partial_pooling &lt;- var_effect %&gt;% dplyr::select(level, term, estimate) %&gt;% tidyr::pivot_wider( names_from = term, values_from = estimate ) %&gt;% dplyr::rename(Intercept = `(Intercept)`, estimate = experience) %&gt;% dplyr::mutate( Intercept = Intercept + fix_effect$estimate[1], estimate = estimate + fix_effect$estimate[2] ) %&gt;% dplyr::mutate(pool = &quot;partial_pool&quot;) %&gt;% dplyr::select(pool, level, Intercept, estimate) partial_pooling partial_pooling &lt;- coef(m4)$department %&gt;% tibble::rownames_to_column() %&gt;% dplyr::rename(level = rowname, Intercept = `(Intercept)`, slope = experience) %&gt;% dplyr::mutate(pooled = &quot;partial_pool&quot;) %&gt;% dplyr::select(pooled, level, Intercept, slope) partial_pooling 不共享 no_pool &lt;- df %&gt;% dplyr::group_by(department) %&gt;% dplyr::group_modify( ~ broom::tidy(lm(salary ~ 1 + experience, data = .)) ) no_pool un_pooling &lt;- no_pool %&gt;% dplyr::select(department, term, estimate) %&gt;% tidyr::pivot_wider( names_from = term, values_from = estimate ) %&gt;% dplyr::rename(Intercept = `(Intercept)`, slope = experience) %&gt;% dplyr::mutate(pooled = &quot;no_pool&quot;) %&gt;% dplyr::select(pooled, level = department, Intercept, slope) un_pooling 29.7.3 可视化 library(ggrepel) un_pooling %&gt;% dplyr::bind_rows(partial_pooling) %&gt;% ggplot(aes(x = Intercept, y = slope)) + purrr::map( c(seq(from = 0.1, to = 0.9, by = 0.1)), .f = function(level) { stat_ellipse( geom = &quot;polygon&quot;, type = &quot;norm&quot;, size = 0, alpha = 1 / 10, fill = &quot;gray10&quot;, level = level ) } ) + geom_point(aes(group = pooled, color = pooled)) + geom_line(aes(group = level), size = 1/4) + #geom_point(data = complete_pooling, size = 4, color = &quot;red&quot;) + geom_text_repel( data = . %&gt;% filter(pooled == &quot;no_pool&quot;), aes(label = level) ) + scale_color_manual( name = &quot;信息池&quot;, values = c( &quot;no_pool&quot; = &quot;black&quot;, &quot;partial_pool&quot; = &quot;red&quot;#, #&quot;complete_pool&quot; = &quot;#A65141&quot; ), labels = c( &quot;no_pool&quot; = &quot;不共享&quot;, &quot;partial_pool&quot; = &quot;部分共享&quot;#, #&quot;complete_pool&quot; = &quot;完全共享&quot; ) ) #+ #theme_classic() 29.8 更多 解释模型的含义 lmer(salary ~ 1 + (0 + experience | department), data = df) # vs lmer(salary ~ 1 + experience + (0 + experience | department), data = df) lmer(salary ~ 1 + ( 1 + experience | department), data = df) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: salary ~ 1 + (1 + experience | department) ## Data: df ## REML criterion at convergence: 1942 ## Random effects: ## Groups Name Std.Dev. Corr ## department (Intercept) 24867 ## experience 1156 -0.88 ## Residual 3579 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) ## 78861 # vs lmer(salary ~ 1 + ( 1 | department) + (0 + experience | department), data = df) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## salary ~ 1 + (1 | department) + (0 + experience | department) ## Data: df ## REML criterion at convergence: 1944 ## Random effects: ## Groups Name Std.Dev. ## department (Intercept) 16789 ## department.1 experience 1141 ## Residual 3582 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) ## 60205 课后阅读文献，读完后大家一起分享 "],
["glm.html", "第 30 章 广义线性模型 30.1 线性回归回顾 30.2 案例 30.3 泊松回归模型 30.4 模型解释 30.5 思考 30.6 小结", " 第 30 章 广义线性模型 30.1 线性回归回顾 从线性模型的数学记号 \\[ y_n = \\alpha + \\beta x_n + \\epsilon_n \\quad \\text{where}\\quad \\epsilon_n \\sim \\operatorname{normal}(0,\\sigma). \\] 等价于 \\[ y_n - (\\alpha + \\beta x_n) \\sim \\operatorname{normal}(0,\\sigma), \\] 又可以写为 \\[ y_n \\sim \\operatorname{normal}(\\alpha + \\beta x_n, \\, \\sigma). \\] 线性回归需要满足四个前提假设： Linearity 因变量和每个自变量都是线性关系 Indpendence 对于所有的观测值，它们的误差项相互之间是独立的 Normality 误差项服从正态分布 Equal-variance 所有的误差项具有同样方差 这四个假设的首字母，合起来就是LINE，这样很好记 把这四个前提画在一张图中 knitr::include_graphics(path = &quot;images/LINE.png&quot;) 30.2 案例 我们从一个有意思的案例开始。 在受污染的岛屿附近，金枪鱼出现次数 knitr::include_graphics(path = &quot;images/fishes.png&quot;) library(tidyverse) df &lt;- read_rds(&quot;./demo_data/fish.rds&quot;) df 我们的问题是，污染如何影响鱼类的数量？具体来说是想：建立不同位置金枪鱼的数量 与 这个位置的污染程度之间的线性关系。 30.2.1 线性模型的局限性 先看看变量之间的关系 df %&gt;% ggplot(aes(x = pollution_level, y = number_of_fish)) + geom_point() + geom_smooth(method = lm) + labs( title = &quot;Number of fish counted under different pollution level&quot;, x = &quot;Pollution level&quot;, y = &quot;Number of fish counted&quot; ) 线性关系不明显，而且被解释变量甚至出现了负值。 我们再看看线性模型的结果 m0 &lt;- lm(number_of_fish ~ pollution_level, data = df) summary(m0) ## ## Call: ## lm(formula = number_of_fish ~ pollution_level, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.499 -0.709 -0.024 0.578 4.635 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.900 0.152 19.1 &lt;2e-16 ## pollution_level -3.331 0.263 -12.6 &lt;2e-16 ## ## (Intercept) *** ## pollution_level *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.08 on 198 degrees of freedom ## Multiple R-squared: 0.447, Adjusted R-squared: 0.444 ## F-statistic: 160 on 1 and 198 DF, p-value: &lt;2e-16 线性模型的失灵！ 怎么办呢？ 30.2.2 泊松分布 我们再看看被解释变量的分布： 非负的整数0, 1, 2, 3, 4, … df %&gt;% ggplot(aes(x = number_of_fish)) + geom_histogram() + labs( title = &quot;number of fishes (Poisson distribution)&quot; ) 这是典型的泊松分布。 generate_pois &lt;- function(lambda_value) { tibble( lambda = as.character(lambda_value), x = seq(1, 10), d = dpois(x = x, lambda = lambda_value) ) } tb &lt;- seq(0.1, 1.8, by = 0.2) %&gt;% map_dfr(generate_pois) tb %&gt;% ggplot(aes(x = x, y = d, color = lambda)) + geom_point() + geom_line() + scale_x_continuous(breaks = seq(1, 10, 1)) + theme_bw() 事实上，生活中很多场合都会遇到计数、二进制、yes/no、等待时间等类型的数据，比如 医院每天急诊次数 每年摩托车死亡人数 城市发生火灾的次数 他们有个共同的特征 变量代表单位时间或者区域事件发生的次数，服从泊松分布。泊松分布有什么特点？ \\[ y_i \\sim \\text{Poisson}(\\lambda = \\lambda_i) \\] 30.2.3 正态分布换成泊松分布就行了？ 回到我们目的：建立不同位置 鱼的数量 与 这个位置的污染程度之间线性关系。 在之前线性模型中讲到，对每一次观测，被解释变量服从正态分布，那么，我们用解释变量的线性组合模拟正态分布的均值\\(\\mu_i\\)，即均值\\(\\mu_i\\)随\\(x_i\\)变化 \\[ \\begin{align*} y_i \\sim &amp; \\operatorname{normal}(\\mu_i, \\, \\sigma)\\\\ &amp;\\operatorname{normal}(\\mu_i = \\beta_0 + \\beta_1 x_i, \\, \\sigma) \\end{align*} \\] 我们也想如法炮制，正态分布换成泊松分布 \\[ \\begin{align*} y_i \\sim &amp; \\text{Poisson}(\\lambda_i)\\\\ &amp; \\text{Poisson}(\\lambda_i = \\beta_0 + \\beta_1 x_i) \\end{align*} \\] 但很遗憾，出现了问题 泊松分布的\\(\\lambda_i\\) 要求大于等于0，然而\\(\\beta_0 + \\beta_1 X_i\\)势必会出现负数 30.3 泊松回归模型 30.3.1 解决办法-连接函数之美 尽管不能使用直接线性模型，但可以间接使用，统计学家想到用log(\\(\\lambda_i\\)) 代替 \\(\\lambda_i\\)，然后让解释变量的线性组合模拟log(\\(\\lambda_i\\))，即 \\[ \\begin{align*} y_i \\sim &amp; \\text{Poisson}(\\lambda_i)\\\\ \\color{red}\\log(\\lambda_i) = &amp; \\beta_0 + \\beta_1 x_i \\end{align*} \\] 现在问题迎刃而解： - log(\\(\\lambda_i\\)) 值域范围是(\\(-\\infty\\) to \\(\\infty\\))，这样既保证了\\(\\lambda_i\\) 是正值，又保证了\\(\\beta_0 + \\beta_1 x_i\\) 可能出现的负值 这里的log()函数就是连接函数， 连接了\\(x_i\\)和\\(\\lambda_i\\) 所以泊松回归模型为 \\[ \\begin{align*} \\log(\\lambda_i) = &amp; \\beta_0 + \\beta_1 x_i \\end{align*} \\] 注意到，这里没有线性回归模型中的误差项。通过极大似然估计（Maximum Likelihood Estimation）计算系数\\((\\beta)\\) 什么叫最大相似性估计？通俗点讲，给定y的分布以及独立变量(x)的值，那么最有可能的\\(\\beta\\)系数多是多少？ step 1 \\(y\\) 服从泊松分布 \\[ \\operatorname{Pr}\\left(y_{i} | \\lambda\\right)=\\frac{\\lambda^{y_{i}} e^{-\\lambda}}{y_{i} !}, \\quad y=0,1,2, \\ldots \\quad ; \\quad \\lambda&amp;gt;0 \\] step 2 回归模型 \\[ E\\left[y_{i} | x_{i}\\right]=\\lambda_{i}=\\exp \\left(x_{i}^{\\prime} \\beta\\right) \\] step 3 \\(\\lambda_{i}\\) 代入上式，考虑观测值彼此独立，可以将所有\\(y_i\\)观测值相乘， \\[ \\operatorname{Pr}\\left(y_{1}, \\ldots, y_{N} | x_{1}, \\ldots, x_{N}\\right)=\\prod_{i=1}^{N} \\frac{e^{y_{i} x_{i}^{\\prime} \\beta} e^{-e^{x_{i}^{\\prime}} \\beta}}{y_{i} !} \\] step 4 然后取对数，得到(joint log-likelihood function) \\[ l\\left(\\beta | y_{i}, X_{i}\\right)=\\sum_{i=1}^{n} y_{i} X_{i}^{\\prime} \\beta-\\exp X_{i}^{\\prime} \\beta-\\log y_{i} ! \\] step 5 求偏导 \\[ \\frac{\\partial l}{\\partial \\beta}=\\sum_{i=1}^{n}\\left(y_{i}-\\exp X_{i}^{\\prime} \\beta\\right) X_{i} \\] step 6 令等式等于0，通过样本值，可以求出系数。 30.3.2 代码实现 使用glm()函数: glm(y ~ 1 + x , family = familytype(link=linkfunction), data=) formula: 被解释变量 ~ 解释变量 family : 误差分布（和连接函数），family = poisson(link=\"log\") data : 数据框 m &lt;- glm(number_of_fish ~ pollution_level, family = poisson(link = &quot;log&quot;), data = df) m ## ## Call: glm(formula = number_of_fish ~ pollution_level, family = poisson(link = &quot;log&quot;), ## data = df) ## ## Coefficients: ## (Intercept) pollution_level ## 1.39 -3.11 ## ## Degrees of Freedom: 199 Total (i.e. Null); 198 Residual ## Null Deviance: 363 ## Residual Deviance: 201 AIC: 492 summary(m) ## ## Call: ## glm(formula = number_of_fish ~ pollution_level, family = poisson(link = &quot;log&quot;), ## data = df) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.346 -0.923 -0.605 0.629 2.382 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.3872 0.0977 14.2 &lt;2e-16 ## pollution_level -3.1077 0.2716 -11.4 &lt;2e-16 ## ## (Intercept) *** ## pollution_level *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 363.03 on 199 degrees of freedom ## Residual deviance: 201.16 on 198 degrees of freedom ## AIC: 492.2 ## ## Number of Fisher Scoring iterations: 5 confint(m) ## 2.5 % 97.5 % ## (Intercept) 1.192 1.575 ## pollution_level -3.652 -2.586 broom::tidy(m) 30.4 模型解释 我们建立的模型是 \\[ \\begin{align*} y_i \\sim &amp; \\text{Poisson}(\\lambda_i)\\\\ \\log(\\lambda_i) = &amp; \\beta_0 + \\beta_1 x_i \\end{align*} \\] 我个人比较喜欢这样写 \\[ \\begin{align*} y_i \\sim &amp; \\;\\text{Poisson}(\\lambda_i = \\exp(\\beta_0 + \\beta_1 x_i)) \\end{align*} \\] 30.4.1 系数 \\[ \\begin{align*} \\frac{\\lambda_1}{\\lambda_0} &amp; = \\frac{\\exp(\\beta_1 + \\beta_1*x_1)}{\\exp(\\beta_0 + \\beta_1*x_0)} \\\\ &amp; = \\exp(\\beta_1(x_1 - x_0)) \\end{align*} \\] 计算当\\(x_i\\)增加一个单位时，事件平均发生次数将会是原来的\\(\\exp(\\beta_1)\\)倍。具体系数为： coef(m) ## (Intercept) pollution_level ## 1.387 -3.108 exp(coef(m)[2]) ## pollution_level ## 0.0447 exp(coef(m)) ## (Intercept) pollution_level ## 4.0036 0.0447 污染系数为0， 4.0036 污染系数从0变到0.5, 引起 (1/exp(-3.1077*0.5) = 4.7)倍数的鱼数量下降. 污染系数从0变到1, 引起 22.3704 倍数的鱼数量下降. 30.4.2 边际效应(Marginal effects) 即在其他条件不变的情况下，\\(x_i\\)增加一个单位，事件的平均发生次数会增加 \\(100\\beta_1 \\%\\)： 类似求偏导\\(\\frac{\\partial{\\lambda}}{\\partial{x}}\\) margins::margins(m, type = &quot;link&quot;) 模型是非线性的，所以我们常用更直观的方式评估边际效应，即，自变量直接对因变量的贡献，可以令type = \"response\"，类似求偏导\\(\\frac{\\partial{y}}{\\partial{x}}\\) margins::marginal_effects(m, type = &quot;response&quot;, se = TRUE ) %&gt;% as.data.frame() %&gt;% dplyr::mutate(pollution_level = df$pollution_level) %&gt;% ggplot(aes(x = pollution_level, y = dydx_pollution_level)) + geom_point() 纵坐标是事件的平均发生次数（增加）下降的比例，可以看到随着x变大，下降趋缓。更多边际效应的内容，可参考这里 30.4.3 拟合 fitted(m) ## 1 2 3 4 5 6 7 ## 4.0036 3.9415 3.8805 3.8203 3.7611 3.7029 3.6455 ## 8 9 10 11 12 13 14 ## 3.5890 3.5334 3.4786 3.4247 3.3717 3.3194 3.2680 ## 15 16 17 18 19 20 21 ## 3.2173 3.1675 3.1184 3.0701 3.0225 2.9757 2.9296 ## 22 23 24 25 26 27 28 ## 2.8842 2.8395 2.7955 2.7522 2.7095 2.6675 2.6262 ## 29 30 31 32 33 34 35 ## 2.5855 2.5454 2.5060 2.4672 2.4289 2.3913 2.3542 ## 36 37 38 39 40 41 42 ## 2.3178 2.2818 2.2465 2.2117 2.1774 2.1437 2.1104 ## 43 44 45 46 47 48 49 ## 2.0777 2.0455 2.0139 1.9826 1.9519 1.9217 1.8919 ## 50 51 52 53 54 55 56 ## 1.8626 1.8337 1.8053 1.7773 1.7498 1.7227 1.6960 ## 57 58 59 60 61 62 63 ## 1.6697 1.6438 1.6184 1.5933 1.5686 1.5443 1.5204 ## 64 65 66 67 68 69 70 ## 1.4968 1.4736 1.4508 1.4283 1.4062 1.3844 1.3629 ## 71 72 73 74 75 76 77 ## 1.3418 1.3210 1.3005 1.2804 1.2605 1.2410 1.2218 ## 78 79 80 81 82 83 84 ## 1.2029 1.1842 1.1659 1.1478 1.1300 1.1125 1.0953 ## 85 86 87 88 89 90 91 ## 1.0783 1.0616 1.0451 1.0289 1.0130 0.9973 0.9818 ## 92 93 94 95 96 97 98 ## 0.9666 0.9517 0.9369 0.9224 0.9081 0.8940 0.8802 ## 99 100 101 102 103 104 105 ## 0.8665 0.8531 0.8399 0.8269 0.8141 0.8014 0.7890 ## 106 107 108 109 110 111 112 ## 0.7768 0.7648 0.7529 0.7412 0.7298 0.7185 0.7073 ## 113 114 115 116 117 118 119 ## 0.6964 0.6856 0.6749 0.6645 0.6542 0.6441 0.6341 ## 120 121 122 123 124 125 126 ## 0.6242 0.6146 0.6051 0.5957 0.5864 0.5774 0.5684 ## 127 128 129 130 131 132 133 ## 0.5596 0.5509 0.5424 0.5340 0.5257 0.5176 0.5095 ## 134 135 136 137 138 139 140 ## 0.5017 0.4939 0.4862 0.4787 0.4713 0.4640 0.4568 ## 141 142 143 144 145 146 147 ## 0.4497 0.4427 0.4359 0.4291 0.4225 0.4159 0.4095 ## 148 149 150 151 152 153 154 ## 0.4031 0.3969 0.3907 0.3847 0.3787 0.3729 0.3671 ## 155 156 157 158 159 160 161 ## 0.3614 0.3558 0.3503 0.3448 0.3395 0.3342 0.3291 ## 162 163 164 165 166 167 168 ## 0.3240 0.3189 0.3140 0.3091 0.3043 0.2996 0.2950 ## 169 170 171 172 173 174 175 ## 0.2904 0.2859 0.2815 0.2771 0.2728 0.2686 0.2644 ## 176 177 178 179 180 181 182 ## 0.2603 0.2563 0.2523 0.2484 0.2446 0.2408 0.2371 ## 183 184 185 186 187 188 189 ## 0.2334 0.2298 0.2262 0.2227 0.2193 0.2159 0.2125 ## 190 191 192 193 194 195 196 ## 0.2092 0.2060 0.2028 0.1996 0.1965 0.1935 0.1905 ## 197 198 199 200 ## 0.1876 0.1846 0.1818 0.1790 实质上就是\\(exp(\\beta_0 + \\beta_1 * pollution_level)\\) intercept &lt;- coef(m)[1] beta &lt;- coef(m)[2] df %&gt;% dplyr::mutate(theory_pred = fitted(m)) %&gt;% dplyr::mutate( myguess_pred = exp(intercept + beta * pollution_level) ) df %&gt;% dplyr::mutate(theory_pred = fitted(m)) %&gt;% ggplot(aes(x = pollution_level, y = theory_pred)) + geom_point() pred &lt;- predict(m, type = &quot;response&quot;, se = TRUE) %&gt;% as.data.frame() pred df_pred &lt;- df %&gt;% dplyr::mutate(fit = pred$fit, se_fit = pred$se.fit) df_pred real_df &lt;- tibble(x = seq(0, 1, length.out = 100), y = 4 * exp(-3.2 * x) ) df_pred %&gt;% ggplot(aes(x = pollution_level, y = number_of_fish)) + geom_point() + geom_pointrange(aes(y = fit, ymax = fit + se_fit, ymin = fit - se_fit), color = &quot;red&quot;) + #geom_point(aes(y = fit + se_fit), color = &quot;red&quot;) + #geom_point(aes(y = fit - se_fit), color = &quot;red&quot;) + geom_line(data= real_df, aes(x = x, y = y), color = &quot;black&quot;) + labs( title = &quot;Number of fish counted under different pollution level&quot;, x = &quot;Pollution level&quot;, y = &quot;Number of fish counted&quot; ) 30.4.4 模型评估 knitr::include_graphics(path = &quot;images/model_evaluation.png&quot;) 过度离散，负二项式分布模型 零膨胀 margins::margins(m) ggeffects::ggpredict(m) ggeffects::ggpredict(m, terms = c(&quot;pollution_level&quot;)) performance::model_performance(m) performance::check_model(m) performance::check_overdispersion(m) performance::check_zeroinflation(m) 30.5 思考 30.5.1 这两者为什么是相等的？ d &lt;- tibble(x = 1:100, y = 4 + 2 * x + rnorm(100)) lm(y ~ x, data = d) ## ## Call: ## lm(formula = y ~ x, data = d) ## ## Coefficients: ## (Intercept) x ## 3.9 2.0 glm(y ~ x, family = gaussian(link = &quot;identity&quot;), data = d) ## ## Call: glm(formula = y ~ x, family = gaussian(link = &quot;identity&quot;), data = d) ## ## Coefficients: ## (Intercept) x ## 3.9 2.0 ## ## Degrees of Freedom: 99 Total (i.e. Null); 98 Residual ## Null Deviance: 334000 ## Residual Deviance: 94.6 AIC: 284 lm 是 glm的一种特殊情形。 30.5.2 log link 与 log transforming 在案例中 log link glm(number_of_fish ~ pollution_level, family = gaussian(link = &quot;log&quot;), data = df) 先对 number_of_fish 取对数后，然后线性回归 #lm(log(number_of_fish) ~ pollution_level, data = df) glm(log(number_of_fish) ~ pollution_level, family = gaussian(link = &quot;identity&quot;), data = df) 这两者有什么区别？ 比较两者的结果，发现有很大的差别，尤其是斜率，为什么呢？ 因为这是两个不同的模型： 第一个模型中 link=\"log\"，模型并没有直接变换数据，只是使用了原始数据的均值，均值对数计算后，建立线性关系，即 \\[ \\begin{align*} \\log(\\lambda_i) &amp; = \\beta_0 + \\beta_1 x_i \\\\ \\lambda_i &amp; = \\exp(\\beta_0 + \\beta_1 x_i) \\end{align*} \\] 注意到这里family = gaussian, 因此，误差项满足高斯分布 \\[ \\begin{align*} y_i - \\lambda_i &amp;\\sim \\operatorname{normal}(0,\\sigma)\\\\ y_i - \\exp(\\beta_0 + \\beta_1 x_i) &amp;\\sim \\operatorname{normal}(0,\\sigma) \\\\ y_i &amp;\\sim \\operatorname{normal}(\\exp(\\beta_0 + \\beta_1 x_i), \\, \\sigma) \\end{align*} \\] \\[ y_i = \\exp(\\beta_0 + \\beta_1 x_i) + \\epsilon_i\\quad \\epsilon_i \\sim \\operatorname{normal}(0,\\sigma) \\] 因此对不同均值\\(\\lambda_i\\)，误差项的方差是一样的 第二个模型 log transforming，是直接转换原始数据，然后建立模型\\(\\log(y_i) = \\alpha + \\beta x_i\\)，原始数据y的均值和方差都改变了，一旦log(y) 变回 y时， \\[ \\log(y_i) =\\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad \\epsilon_i \\sim \\operatorname{normal}(0,\\sigma) \\] \\[ y_i = \\exp(\\beta_0 + \\beta_1 x_i) * \\exp(\\epsilon_i), \\quad \\epsilon_i \\sim \\operatorname{normal}(0,\\sigma) \\] 误差的方差也会随着均值变化。 30.5.3 更多分布 x &lt;- c(1, 2, 3, 4, 5) y &lt;- c(1, 2, 4, 2, 6) regNId &lt;- glm(y ~ x, family = gaussian(link = &quot;identity&quot;)) regNlog &lt;- glm(y ~ x, family = gaussian(link = &quot;log&quot;)) regPId &lt;- glm(y ~ x, family = poisson(link = &quot;identity&quot;)) regPlog &lt;- glm(y ~ x, family = poisson(link = &quot;log&quot;)) regGId &lt;- glm(y ~ x, family = Gamma(link = &quot;identity&quot;)) regGlog &lt;- glm(y ~ x, family = Gamma(link = &quot;log&quot;)) regIGId &lt;- glm(y ~ x, family = inverse.gaussian(link = &quot;identity&quot;)) regIGlog &lt;- glm(y ~ x, family = inverse.gaussian(link = &quot;log&quot;)) dx &lt;- tibble( x = c(1, 2, 3, 4, 5), y = c(1, 2, 4, 2, 6) ) dx %&gt;% ggplot(aes(x =x, y = y)) + geom_point() regNId &lt;- glm(y ~ x, family = gaussian(link = &quot;identity&quot;), data = dx) regNId dx %&gt;% mutate(pred = predict(regNId, type = &quot;response&quot;)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + geom_line(aes(y = pred, group =1)) regPlog &lt;- glm(y ~ x, family = poisson(link = &quot;log&quot;), data = dx) regPlog dx %&gt;% mutate(pred = predict(regPlog, type = &quot;response&quot;)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + geom_line(aes(y = pred, group =1)) regGId &lt;- glm(y ~ x, family = Gamma(link = &quot;identity&quot;), data = dx) regGId dx %&gt;% mutate(pred = predict(regGId, type = &quot;response&quot;)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + geom_line(aes(y = pred, group =1)) 30.5.4 更复杂的模型 以后再说 glm(number_of_fish ~ 1 + (1| pollution_level), family = poisson(link = &quot;log&quot;), data = df) 30.6 小结 knitr::include_graphics(path = &quot;images/One_Picture.png&quot;) "],
["ordinal.html", "第 31 章 有序logistic回归 31.1 logistic回归 31.2 生活中的有序logistic回归 31.3 案例 31.4 问题的提出 31.5 其他宏包", " 第 31 章 有序logistic回归 本节课，是广义线性模型的延续 library(tidyverse) 31.1 logistic回归 二元logistic回归：Y为定类且为2个，比如是否购买(1购买；0不购买) 多分类logistic回归：Y为定类且选项大于2个，比如总统候选人偏好(特朗普、希拉里、卢比奥) 有序logistic回归：Y为定类且有序，幸福感(不幸福、比较幸福和非常幸福) 31.2 生活中的有序logistic回归 人们在肯德基里点餐，一般都会买可乐，可乐有四种型号(small, medium, large or extra large)，选择何种型号的可乐会与哪些因素有关呢？是否购买了汉堡、是否购买了薯条，消费者的年龄等。我们这里考察的被解释变量，可乐的大小就是一个有序的值。 问卷调查。问大三的学生是否申请读研究生，有三个选项：1不愿意，2有点愿意，3非常愿意。那么这里的被解释变量是三个有序的类别，影响读研意愿的因素可能与父母的教育水平、本科阶段学习成绩、经济压力等有关。 31.3 案例 教育代际传递。通俗点说子女的教育程度是否受到父母教育程度的影响。我这个案例思路参考了南京大学池彪的《教育人力资本的代际传递研究》硕士论文，这篇文章思路很清晰，建议大家可以看看。根据文中提供的数据来源，我们下载2016年的中国家庭追踪调查数据CFPS，并整理了部分数据。 tb &lt;- readr::read_rds(&quot;./demo_data/cfps.rds&quot;) head(tb) tb %&gt;% count(edu) tb %&gt;% count(edu_f) tb %&gt;% count(edu_m) 为了方便处理，减少分类，我们将大专以及大专以上的都归为一类 df &lt;- tb %&gt;% dplyr::mutate( across( starts_with(&quot;edu&quot;), ~ case_when( . %in% c(5, 6, 7, 8) ~ 5, TRUE ~ . ) ) ) df 看起很复杂？那我写简单点 tb %&gt;% dplyr::mutate( across( starts_with(&quot;edu&quot;), ~ if_else(. %in% c(5, 6, 7, 8), 5, .) ) ) df %&gt;% count(edu) df %&gt;% count(edu_f) df %&gt;% count(edu_m) 31.4 问题的提出 问题的提出： - 学历上父母是否门当户对？ - 父母的受教育程度对子女的受教育水平是正向影响？ - 父亲和母亲谁的影响大？ - 对男孩影响大？还是对女孩影响大？ - 以上情况城乡有无差异？ 31.4.1 父母门当户对？ 数据还是比较有意思的，我们来看看父母是否门当户对 多大比例选择门当户对? df df %&gt;% dplyr::summarise( eq_n = sum(edu_m == edu_f), n = n() ) %&gt;% dplyr::mutate(prop = eq_n/n) df %&gt;% dplyr::count(edu_m, edu_f) %&gt;% dplyr::group_by(edu_m) %&gt;% dplyr::mutate(prop = n /sum(n)) %&gt;% dplyr::ungroup() df %&gt;% dplyr::count(edu_m, edu_f) %&gt;% dplyr::group_by(edu_m) %&gt;% dplyr::mutate(percent = n/sum(n) ) %&gt;% dplyr::select(-n) %&gt;% tidyr::pivot_wider(names_from = edu_f, values_from = percent) 31.4.2 母亲的教育程度对子女的影响 library(ggridges) df %&gt;% dplyr::mutate( across(edu_m, as.factor) ) %&gt;% ggplot(aes(x = edu, y = edu_m)) + geom_density_ridges() + scale_x_continuous(limits = c(0, 6), breaks = c(1:5)) + labs(title = &quot;家庭中母亲的教育程度对子女的影响&quot;, subtitle = &quot;数字越大，教育程度越高&quot;, x = &quot;子女的教育程度&quot;, y = &quot;母亲的教育程度&quot;) 31.4.3 父亲和母亲谁的影响大 这里需要用到有序logistic回归，我们使用MASS::polr函数。 为了理解模型的输出，我们需要先简单介绍下模型的含义。假定被解释变量\\(Y\\)有\\(J\\)类且有序，那么\\(Y\\) 小于等于某个具体类别\\(j\\)的累积概率，可以写为\\(P(Y \\le j)\\)，这里\\(j = 1, \\cdots, J-1\\). 从而，小于等于某个具体类别\\(j\\)的比率就可以定义为 \\[\\frac{P(Y \\le j)}{P(Y&gt;j)}\\] 对这个比率取对数，就是我们熟知的logit \\[log \\frac{P(Y \\le j)}{P(Y&gt;j)} = logit (P(Y \\le j)).\\] 在R语言中，有序logistic回归的数学模型就是 \\[logit (P(Y \\le j)) = \\alpha_{j} + \\beta_{1}x_1 + \\beta_{2}x_2 \\] \\(\\alpha\\) 是截距 \\(\\beta\\) 是回归系数，注意到有序分类 logistic 回归模型中就有 \\(J-1\\) 个 logit 模型。对于每个模型，系数是相同的，截距不同。下面我们通过代码来演示 library(MASS) df1 &lt;- df %&gt;% dplyr::mutate( across(c(edu, sex, urban), as.factor), across(edu, ~fct_inseq(., ordered = TRUE)) ) mod_mass &lt;- polr(edu ~ edu_f + edu_m + sex + num_siblings + urban, data = df1, method = c(&quot;logistic&quot;) ) summary(mod_mass) ## Call: ## polr(formula = edu ~ edu_f + edu_m + sex + num_siblings + urban, ## data = df1, method = c(&quot;logistic&quot;)) ## ## Coefficients: ## Value Std. Error t value ## edu_f 0.461 0.0284 16.26 ## edu_m 0.507 0.0323 15.72 ## sex1 -0.461 0.0693 -6.65 ## num_siblings -0.154 0.0436 -3.53 ## urban1 0.957 0.0601 15.91 ## ## Intercepts: ## Value Std. Error t value ## 1|2 -0.838 0.122 -6.893 ## 2|3 0.674 0.117 5.742 ## 3|4 2.509 0.124 20.295 ## 4|5 3.545 0.129 27.430 ## ## Residual Deviance: 11680.22 ## AIC: 11698.22 输出结果得到有序分类 logistic 回归模型中截距和回归系数的最大似然估计值，确定出回归方程为： \\[ \\begin{aligned} \\text{logit}(\\hat{P}(Y \\le 1))&amp;= \\text{logit}\\left(p_{1}\\right) = \\ln \\left(\\frac{p_{1}}{1 - p_{1}}\\right) = -0.8385 + \\\\ \\text{logit}(\\hat{P}(Y \\le 2))&amp;= \\text{logit}\\left(p_{1} + p_{2}\\right) = \\ln \\left(\\frac{p_{1} + p_{2}}{1 - p_{1} - p_{2}}\\right) = 0.6742 + \\\\ \\text{logit}(\\hat{P}(Y \\le 3))&amp;= \\text{logit}\\left(p_{1} + p_{2} + p_{3}\\right) = \\ln \\left(\\frac{p_{1} + p_{2} + p_{3}}{1 - p_{1} - p_{2} - p_{3}}\\right) = 2.5093\\\\ \\text{logit}(\\hat{P}(Y \\le 4))&amp;= \\text{logit}\\left(p_{1} + p_{2} + p_{3} + p_{4}\\right) = \\ln \\left(\\frac{p_{1} + p_{2} + p_{3} + p_{4}}{1 - p_{1} - p_{2} - p_{3} - p_{4}}\\right) = 3.5454\\\\ \\end{aligned} \\] 写起很麻烦，偷个懒吧 library(equatiomatic) extract_eq(mod_mass, use_coefs = TRUE) ## $$ ## \\begin{aligned} ## \\log\\left[ \\frac { P( \\operatorname{1} \\geq \\operatorname{2} ) }{ 1 - P( \\operatorname{1} \\geq \\operatorname{2} ) } \\right] &amp;= -0.84 + 0.46(\\operatorname{edu\\_f}) + 0.51(\\operatorname{edu\\_m}) - 0.46(\\operatorname{sex}_{\\operatorname{1}}) - 0.15(\\operatorname{num\\_siblings}) + 0.96(\\operatorname{urban}_{\\operatorname{1}}) + \\epsilon \\\\ ## \\log\\left[ \\frac { P( \\operatorname{2} \\geq \\operatorname{3} ) }{ 1 - P( \\operatorname{2} \\geq \\operatorname{3} ) } \\right] &amp;= 0.67 + 0.46(\\operatorname{edu\\_f}) + 0.51(\\operatorname{edu\\_m}) - 0.46(\\operatorname{sex}_{\\operatorname{1}}) - 0.15(\\operatorname{num\\_siblings}) + 0.96(\\operatorname{urban}_{\\operatorname{1}}) + \\epsilon \\\\ ## \\log\\left[ \\frac { P( \\operatorname{3} \\geq \\operatorname{4} ) }{ 1 - P( \\operatorname{3} \\geq \\operatorname{4} ) } \\right] &amp;= 2.51 + 0.46(\\operatorname{edu\\_f}) + 0.51(\\operatorname{edu\\_m}) - 0.46(\\operatorname{sex}_{\\operatorname{1}}) - 0.15(\\operatorname{num\\_siblings}) + 0.96(\\operatorname{urban}_{\\operatorname{1}}) + \\epsilon \\\\ ## \\log\\left[ \\frac { P( \\operatorname{4} \\geq \\operatorname{5} ) }{ 1 - P( \\operatorname{4} \\geq \\operatorname{5} ) } \\right] &amp;= 3.55 + 0.46(\\operatorname{edu\\_f}) + 0.51(\\operatorname{edu\\_m}) - 0.46(\\operatorname{sex}_{\\operatorname{1}}) - 0.15(\\operatorname{num\\_siblings}) + 0.96(\\operatorname{urban}_{\\operatorname{1}}) + \\epsilon ## \\end{aligned} ## $$ 31.4.4 系数的解释 先将系数转换成odds ratios(OR) coef(mod_mass) %&gt;% exp() ## edu_f edu_m sex1 num_siblings ## 1.5859 1.6610 0.6307 0.8572 ## urban1 ## 2.6038 在其它因素不变的情况下，父亲教育程度每增加一个等级（比如，大专到本科）， 会增加子女教育程度向上提高一个级别的概率1.58倍，也就是增加了58%。 在其它因素不变的情况下，母亲教育程度每提高一个等级，会增加提升子女教育水平的概率1.66倍. 从子女的性别差异来看, 在其它因素不变的情况下，女性的受教育水平向上提高一个级别的概率更大，是男性的(1/0.630)倍，或者说，男性受教育水平向上提高一个级别的概率比女性减少37%(1 - 0.63). 从城乡差异来看，城镇子女提升教育水平的概率是农村的2.6倍 31.4.5 边际效应 library(margins) #me_mass &lt;- marginal_effects(mod_mass, variables = &quot;sex&quot;) me_mass &lt;- marginal_effects(mod_mass, variables = &quot;edu_m&quot;) me_mass 从边际效应图可以看到，随着父母教育程度的增加，子女低学历的的概率减少，高学历的概率增加 31.5 其他宏包 31.5.1 ordinal 包 library(ordinal) mod_ordinal &lt;- clm(edu ~ edu_f + edu_m + sex + num_siblings + urban, data = df1, link = &quot;logit&quot;, thresholds = &quot;flexible&quot; ) broom::tidy(mod_ordinal) "],
["tidymodels.html", "第 32 章 机器学习 32.1 数据 32.2 机器学习 32.3 model01 32.4 model02 32.5 model03 32.6 model04", " 第 32 章 机器学习 library(tidyverse) library(tidymodels) 32.1 数据 penguins &lt;- read_csv(&quot;./demo_data/penguins.csv&quot;) %&gt;% janitor::clean_names() %&gt;% drop_na() penguins %&gt;% head() penguins %&gt;% ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species) ) + geom_point() 32.2 机器学习 split &lt;- penguins %&gt;% mutate(species = as_factor(species)) %&gt;% mutate(species = fct_lump(species, 1)) %&gt;% initial_split() split training_data &lt;- training(split) training_data testing_data &lt;- testing(split) testing_data 32.3 model01 model_logistic &lt;- parsnip::logistic_reg() %&gt;% set_engine(&quot;glm&quot;) %&gt;% set_mode(&quot;classification&quot;) %&gt;% fit(species ~ bill_length_mm + bill_depth_mm, data = training_data) bind_cols( predict(model_logistic, new_data = testing_data, type = &quot;class&quot;), predict(model_logistic, new_data = testing_data, type = &quot;prob&quot;), testing_data ) predict(model, new_data = testing_data) %&gt;% bind_cols(testing_data) %&gt;% count(.pred_class, species) 32.4 model02 model_neighbor &lt;- parsnip::nearest_neighbor(neighbors = 10) %&gt;% set_engine(&quot;kknn&quot;) %&gt;% set_mode(&quot;classification&quot;) %&gt;% fit(species ~ bill_length_mm, data = training_data) predict(model_neighbor, new_data = testing_data) %&gt;% bind_cols(testing_data) %&gt;% count(.pred_class, species) 32.5 model03 model_multinom &lt;- parsnip::multinom_reg() %&gt;% set_engine(&quot;nnet&quot;) %&gt;% set_mode(&quot;classification&quot;) %&gt;% fit(species ~ bill_length_mm, data = training_data) predict(model_multinom, new_data = testing_data) %&gt;% bind_cols(testing_data) %&gt;% count(.pred_class, species) 32.6 model04 model_decision &lt;- parsnip::decision_tree() %&gt;% set_engine(&quot;rpart&quot;) %&gt;% set_mode(&quot;classification&quot;) %&gt;% fit(species ~ bill_length_mm, data = training_data) predict(model_decision, new_data = testing_data) %&gt;% bind_cols(testing_data) %&gt;% count(.pred_class, species) "],
["tidyeval.html", "第 33 章 非标准性评估 33.1 编写函数 33.2 看看发生了什么 33.3 处理多个参数 33.4 调整输入的表达式 33.5 案例 33.6 可能会用到的函数 33.7 Resources", " 第 33 章 非标准性评估 Tidy Evaluation (Tidy Eval)，不是一个宏包，而是一个非标准评估的框架，也叫延迟评估。主要目的是更方便地与tidyverse里的函数配合使用，事实上，很多时候我们不一定需要用到它。我这里尽可能规避较专业的词汇，用通俗的语言介绍一些简单用法，表述可能不准确。如果想了解背后复杂的机制请阅读advance R。 33.1 编写函数 library(tidyverse) library(rlang) 写代码的过程中，我们会遇到对不同的数据框，执行相同的操作。比如 df1 %&gt;% group_by(x1) %&gt;% summarise(mean = mean(y1)) df2 %&gt;% group_by(x2) %&gt;% summarise(mean = mean(y2)) df3 %&gt;% group_by(x3) %&gt;% summarise(mean = mean(y3)) df4 %&gt;% group_by(x4) %&gt;% summarise(mean = mean(y4)) 为了减少代码的重复，我们考虑将共同的部分保留，变化的部分用参数名提取出来 data %&gt;% group_by(group_var) %&gt;% summarise(mean = mean(summary_var)) 很自然地，我们想到写一个子函数的形式，比如 grouped_mean &lt;- function(data, group_var, summary_var) { data %&gt;% group_by(group_var) %&gt;% summarise(mean = mean(summary_var)) } 当我们试图运行这段代码的时候，却发现报错了 grouped_mean(mtcars, cyl, mpg) ## Error: Must group by variables found in `.data`. ## * Column `group_var` is not found. Hadley Wickham告诉我们，正确的写法应该是， grouped_mean &lt;- function(data, group_var, summary_var) { group_var &lt;- enquo(group_var) summary_var &lt;- enquo(summary_var) data %&gt;% group_by(!!group_var) %&gt;% summarise(mean = mean(!!summary_var)) } 然后再运行 grouped_mean(mtcars, cyl, mpg) 或者更简便的 grouped_mean &lt;- function(data, group_var, summary_var) { data %&gt;% group_by({{group_var}}) %&gt;% summarise(mean = mean({{summary_var}})) } grouped_mean(mtcars, cyl, mpg) dplyr1.0之后，可以这样写 sum_group_vars &lt;- function(df, group_vars, sum_vars){ df %&gt;% group_by(across({{ group_vars }})) %&gt;% summarise(n = n(), across({{ sum_vars }}, list(mean = mean, sd = sd)) ) } sum_group_vars(mpg, c(model, year), c(hwy, cty)) 下面我们讲讲为什么要这样写。 33.2 看看发生了什么 弄清楚之前，这里需要明白两个概念： 环境变量(env-variables) ，一般你在Rstuido右上角的Environment中发现它。比如n &lt;- 10这里的n 数据变量(data-variables)，一般指数据框的某个变量。比如data &lt;- data.frame(x = 1, n = 2)中的data$n 那么，对于我们这里编写的函数中 grouped_mean(mtcars, cyl, mpg) cyl和mpg是打算传递的参数，是环境变量，但我们期望他们在函数中当作mtcars中的数据变量，即当做mtcars的一个列的名字来使用， 那么要完成这个角色转换，就需要引用(quote)和解引用(unquote)两个工序： 第一步，用 enquo()把用户传递过来的参数引用起来（引用可以理解为冷冻起来） 第二步，用 !! 解开这个引用（解引用可以理解为解冷），然后使用参数的内容 这个quote-unquote的过程让环境变量名变成了数据变量，也可以理解为在函数评估过程中，数据变量（data-variable）遮盖了环境变量（env-variable），即数据遮盖（data masking），看到cyl，正常情况下，本来应该是到环境变量里去找这个cyl对应的值，然而，数据遮盖机制，插队了，让代码去数据变量中去找cyl以及对应的值。 我们通过rlang::qq_show()看看这个quote-unquote机制是怎么工作的 先看看qq_show() var &lt;- quote(height) qq_show(!!var) ## height 再看看grouped_mean()的代码 group_var &lt;- quote(cyl) summary_var &lt;- quote(mpg) rlang::qq_show( data %&gt;% group_by(!!group_var) %&gt;% summarise(mean = mean(!!summary_var)) ) ## data %&gt;% group_by(cyl) %&gt;% summarise(mean = mean(mpg)) 关于数据遮盖更多细节请看Quote and unquote。 33.3 处理多个参数 前面讲了如何传递分组参数和统计参数到子函数。如果传递更多的参数，可以用...代替group_var ，然后传递到group_by()，比如 grouped_mean &lt;- function(data, summary_var, ...) { summary_var &lt;- enquo(summary_var) group_var &lt;- enquos(...) data %&gt;% group_by(!!!group_var) %&gt;% summarise(mean = mean(!!summary_var)) } 指定统计参数disp，分组参数(cyl am)，然后运行代码, grouped_mean(mtcars, disp, cyl, am) 或者指定统计参数disp，更多的分组参数(cyl, am, vs) grouped_mean(mtcars, disp, cyl, am, vs) 注意到...代表的是多个参数，因此在引用的时候用的是enquos()，在解引用的时候 用的是group_by(!!!group_var). 事实上, ...是一个特殊的符号，我们可以省略引用后再解引用的过程，直接传给给group_by()， 比如 grouped_mean &lt;- function(data, summary_var, ...) { summary_var &lt;- enquo(summary_var) data %&gt;% group_by(...) %&gt;% summarise(mean = mean(!!summary_var)) } grouped_mean(mtcars, disp, cyl, am, vs) 33.4 调整输入的表达式 33.4.1 修改引用参数的默认名 我们希望输出的统计结果中，统计参数名加一个前缀 “avg_”， 可以分三步完成 获取引用参数的默认名 修改参数的默认名，比如加前缀或者后缀 !! 解引用并放在 := 左边 grouped_mean2 &lt;- function(.data, .summary_var, ...) { summary_var &lt;- enquo(.summary_var) group_vars &lt;- enquos(...) # Get and modify the default name summary_nm &lt;- as_label(summary_var) summary_nm &lt;- paste0(&quot;avg_&quot;, summary_nm) .data %&gt;% group_by(!!!group_vars) %&gt;% summarise(!!summary_nm := mean(!!summary_var)) # Unquote the name } grouped_mean2(mtcars, disp, cyl, am) 或者更简洁的办法 my_summarise &lt;- function(data, group_var, summarise_var) { data %&gt;% group_by(across({{ group_var }})) %&gt;% summarise(across({{ summarise_var }}, mean, .names = &quot;mean_{col}&quot;)) } my_summarise(starwars, species, height) 如果想调整多个分组变量的默认名，比如加个前缀“groups_”，方法和上面的步骤类似 引用传递过来的参数名，.enquos(..., .named = TRUE), 增加了控制语句.named = TRUE 修改在每个参数的默认名，比如加前缀或者后缀 !! 解引用并放在 := 左边 grouped_mean3 &lt;- function(.data, .summary_var, ...) { summary_var &lt;- enquo(.summary_var) # Quote the dots with default names group_vars &lt;- enquos(..., .named = TRUE) summary_nm &lt;- as_label(summary_var) summary_nm &lt;- paste0(&quot;avg_&quot;, summary_nm) # Modify the names of the list of quoted dots names(group_vars) &lt;- paste0(&quot;groups_&quot;, names(group_vars)) .data %&gt;% group_by(!!!group_vars) %&gt;% # Unquote-splice as usual summarise(!!summary_nm := mean(!!summary_var)) } grouped_mean3(mtcars, disp, cyl, am) 33.4.2 修改引用的表达式 有时候，我们不想“按多个变量分组，对一个变量统计”。而是“按一个变量分组，对多个变量统计”。这种情况，我们就需要调整引用的表达式 .group_var放分组的变量species ... 放需要统计的多个变量height, mass，期望完成 mean(height), mean(mass) 需要用purrr:map()配合调整表达式， 如 vars &lt;- list(quote(mass), quote(height)) purrr::map(vars, function(var) expr(mean(!!var, na.rm = TRUE))) ## [[1]] ## mean(mass, na.rm = TRUE) ## ## [[2]] ## mean(height, na.rm = TRUE) 完整代码可以这样写 grouped_mean4 &lt;- function(.data, .group_var, ...) { group_var &lt;- enquo(.group_var) summary_vars &lt;- enquos(..., .named = TRUE) # Wrap the summary variables with mean() summary_vars &lt;- purrr::map(summary_vars, function(var) { expr(mean(!!var, na.rm = TRUE)) }) # Prefix the names with `avg_` names(summary_vars) &lt;- paste0(&quot;avg_&quot;, names(summary_vars)) .data %&gt;% group_by(!!group_var) %&gt;% summarise(!!!summary_vars) } grouped_mean4(starwars, species, height, mass) 33.5 案例 33.5.1 统计并过滤 df &lt;- tibble(index = sample(letters[1:4], size = 100, replace = TRUE) ) df filter_which &lt;- function(df, var, val) { which_var &lt;- enquo(var) which_val &lt;- as_name(enquo(val)) df %&gt;% count(!!which_var) %&gt;% filter(!!which_var == which_val) } df %&gt;% filter_which(index, a) 33.5.2 自定义统计输出 my_summarise &lt;- function(data, expr) { data %&gt;% summarise( &quot;mean_{{expr}}&quot; := mean({{ expr }}), &quot;sum_{{expr}}&quot; := sum({{ expr }}), &quot;n_{{expr}}&quot; := n() ) } mtcars %&gt;% my_summarise(mpg) 33.5.3 形成依次下滑的列 d &lt;- tibble(x = seq_len(10)) jetlag &lt;- function(data, variable, n = 10){ variable &lt;- enquo(variable) indices &lt;- seq_len(n) quosures &lt;- purrr::map( indices, ~quo(lag(!!variable, !!.x)) ) %&gt;% purrr::set_names(nm = purrr::map_chr(indices, ~paste0(&quot;lag_&quot;, .x))) dplyr::mutate(data, !!!quosures) } d %&gt;% jetlag(x, 3) 33.6 可能会用到的函数 enquo() vs quo() vs expr() vs as_name() vs as_label() vs sym() a &lt;- 1 b &lt;- 1 var &lt;- quote(a + b) # returns a single quoted expression for the delayed computation var ## a + b qq_show(!!var) ## a + b # quotes a new expression locally expr(mean(!!var, na.rm = TRUE)) ## mean(a + b, na.rm = TRUE) var &lt;- quo(height) # transforms a quoted variable name into a string. as_name(var) ## [1] &quot;height&quot; # also returns a single string but supports any kind of R object as input, including quoted function calls and vectors. Its purpose is to summarise that object into a single label. That label is often suitable as a default name. as_label(var) ## [1] &quot;height&quot; # creates a symbol from a string sym(&quot;height&quot;) ## height 33.7 Resources tidyeval book - https://tidyeval.tidyverse.org/ or tidyeval post - https://rpubs.com/lionel-/tidyeval-introduction tidyeval webinar - https://www.rstudio.com/resources/webinars/tidy-eval/ “Tidy evaluation in 5 minutes” by Hadley Wickham - https://www.youtube.com/watch?v=nERXS3ssntw Metaprogramming chapters in “Advanced R” - https://adv-r.hadley.nz/meta.html tidyeval cheatsheet - https://www.rstudio.com/resources/cheatsheets/ https://github.com/tidyverse/dplyr/blob/master/vignettes/programming.Rmd https://github.com/romatik/touring_the_tidyverse https://tidyeval.tidyverse.org/dplyr.html "],
["advR.html", "第 34 章 tidyverse进阶 34.1 scoped 函数 34.2 summarise_if 34.3 filter_if() 34.4 group_by 34.5 列名清理 34.6 缺失值检查与处理 34.7 标准化 34.8 across函数 34.9 参考资料", " 第 34 章 tidyverse进阶 让我们继续聊聊，相见恨晚的tidyverse library(tidyverse) 34.1 scoped 函数 在第 6 章介绍了dplyr的一些函数（mutate(), select()等等），事实上，这些函数加上后缀 _all, _at, _if，形成三组变体函数，可以方便对特定的子集进行操作。比如 对数据框所有列操作，可以用_all 对数据框指定的几列操作，可以用_at 对数据框符合条件的几列进行操作，可以用_if Operate _all _at _if select() select_all() select_at() select_if() mutate() mutate_all() mutate_at() mutate_if() rename() rename_all() rename_at() rename_if() arrange() arrange_all() arrange_at() arrange_if() filter() filter_all() filter_at() filter_if() distinct() distinct_all() distinct_at() distinct_if() group_by() group_by_all() group_by_at() group_by_if() summarise() summarise_all() summarise_at() summarise_if() map() map_all() map_at() map_if() modify() modify_all() modify_at() modify_if() 下面选取其中几个函数加以说明 34.1.1 mutate_if df_iris &lt;- iris %&gt;% head(5) df_iris df_iris %&gt;% mutate_if(is.double, as.integer) 可以一次性增加多列 df_iris %&gt;% mutate_if(is.numeric, list(scale, log)) 也可以把函数放在list()中，用 Purrr-style lambda 形式写出 df_iris %&gt;% mutate_if(is.numeric, list(~ scale(.), ~ log(.))) 34.1.2 select_if() df &lt;- tibble::tibble( x = letters[1:3], y = c(1:3), z = c(0, 0, 0) ) df df %&gt;% select_if(is.numeric) df %&gt;% select_if(~ n_distinct(.) &gt; 2) select_if 多个条件的情况 df %&gt;% select_if( list(~ (is.numeric(.) | is.character(.))) ) df %&gt;% select_if( ~ (is.numeric(.) | is.character(.)) ) to_keep &lt;- function(x) is.numeric(x) | is.character(x) df %&gt;% select_if(to_keep) df %&gt;% select_if( list(~ (is.numeric(.) &amp;&amp; sum(.) &gt; 2)) ) df %&gt;% select_if( list(~ (is.numeric(.) &amp;&amp; mean(.) &gt; 1)) ) 我们也可以写成函数的形式 to_want &lt;- function(x) is.numeric(x) &amp;&amp; sum(x) &gt; 3 df %&gt;% select_if(to_want) 34.2 summarise_if msleep &lt;- ggplot2::msleep msleep %&gt;% dplyr::group_by(vore) %&gt;% dplyr::summarise_all(~ mean(., na.rm = TRUE)) msleep &lt;- ggplot2::msleep msleep %&gt;% dplyr::group_by(vore) %&gt;% # summarise_if(is.numeric, ~mean(., na.rm = TRUE)) dplyr::summarise_if(is.numeric, mean, na.rm = TRUE) 34.3 filter_if() 事实上，filter已经很强大了，有了scoped函数，就如虎添翼了 msleep &lt;- ggplot2::msleep msleep %&gt;% dplyr::select(name, sleep_total) %&gt;% dplyr::filter(sleep_total &gt; 18) msleep %&gt;% dplyr::select(name, sleep_total) %&gt;% dplyr::filter(between(sleep_total, 16, 18)) msleep %&gt;% dplyr::select(name, sleep_total) %&gt;% # filter(near(sleep_total, 17, tol=sd(sleep_total))) dplyr::filter(near(sleep_total, mean(sleep_total), tol = 0.5 * sd(sleep_total))) mtcars是 R内置数据集，记录了32种不同品牌的轿车的的11个属性 mtcars filter_if()配合all_vars(), any_vars()函数，可以完成很酷的工作. 比如，要求一行中所有变量的值都大于150 mtcars %&gt;% filter_all(all_vars(. &gt; 150)) 比如，要求一行中至少有一个变量的值都大于150 # Or the union: mtcars %&gt;% filter_all(any_vars(. &gt; 150)) # You can vary the selection of columns on which to apply the predicate. # filter_at() takes a vars() specification: mtcars %&gt;% filter_at(vars(starts_with(&quot;d&quot;)), any_vars((. %% 2) == 0)) filter_if(.tbl, .predicate, .vars_predicate) 相对复杂点，我这里多说几句。 filter_if() 有三个参数： .tbl, 数据框 .predicate, 应用在列上的函数，一般作为列的选择条件 .vars_predicate, 应用在一行上的函数，通过 all_vars(), any_vars()返回值决定是否选取该行。 # And filter_if() selects variables with a predicate function: # filter_if(.tbl, .predicate, .vars_predicate) # mtcars %&gt;% map_df(~ all(floor(.) == .) ) # mtcars %&gt;% select_if( ~ all(floor(.) == .) ) mtcars %&gt;% filter_if(~ all(floor(.) == .), all_vars(. != 0)) 所以这里是，先通过.predicate = ~ all(floor(.) == .) 选取变量值为整数的列，然后再看选取的这些列的行方向，如果每一行的值.vars_predicate = all_vars(. != 0) ，都不为0，就保留下来，否则过滤掉。 简单点说，这段代码的意思，数值全部为整数的列，不能同时为0 34.4 group_by group_by() 用的很多，所以要多讲讲 mtcars %&gt;% dplyr::group_by(cyl) mtcars %&gt;% group_by_at(vars(cyl)) # Group a data frame by all variables: mtcars %&gt;% group_by_all() # Group by variables selected with a predicate: iris %&gt;% group_by_if(is.factor) 34.4.1 group_split(), group_map(), group_modify() iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::group_split() ## &lt;list_of&lt; ## tbl_df&lt; ## Sepal.Length: double ## Sepal.Width : double ## Petal.Length: double ## Petal.Width : double ## Species : factor&lt;12d60&gt; ## &gt; ## &gt;[3]&gt; ## [[1]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[2]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7 3.2 4.7 1.4 ## 2 6.4 3.2 4.5 1.5 ## 3 6.9 3.1 4.9 1.5 ## 4 5.5 2.3 4 1.3 ## 5 6.5 2.8 4.6 1.5 ## 6 5.7 2.8 4.5 1.3 ## 7 6.3 3.3 4.7 1.6 ## 8 4.9 2.4 3.3 1 ## 9 6.6 2.9 4.6 1.3 ## 10 5.2 2.7 3.9 1.4 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[3]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.3 3.3 6 2.5 ## 2 5.8 2.7 5.1 1.9 ## 3 7.1 3 5.9 2.1 ## 4 6.3 2.9 5.6 1.8 ## 5 6.5 3 5.8 2.2 ## 6 7.6 3 6.6 2.1 ## 7 4.9 2.5 4.5 1.7 ## 8 7.3 2.9 6.3 1.8 ## 9 6.7 2.5 5.8 1.8 ## 10 7.2 3.6 6.1 2.5 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; 简单点写，就是 iris %&gt;% dplyr::group_split(Species) ## &lt;list_of&lt; ## tbl_df&lt; ## Sepal.Length: double ## Sepal.Width : double ## Petal.Length: double ## Petal.Width : double ## Species : factor&lt;12d60&gt; ## &gt; ## &gt;[3]&gt; ## [[1]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[2]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7 3.2 4.7 1.4 ## 2 6.4 3.2 4.5 1.5 ## 3 6.9 3.1 4.9 1.5 ## 4 5.5 2.3 4 1.3 ## 5 6.5 2.8 4.6 1.5 ## 6 5.7 2.8 4.5 1.3 ## 7 6.3 3.3 4.7 1.6 ## 8 4.9 2.4 3.3 1 ## 9 6.6 2.9 4.6 1.3 ## 10 5.2 2.7 3.9 1.4 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[3]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.3 3.3 6 2.5 ## 2 5.8 2.7 5.1 1.9 ## 3 7.1 3 5.9 2.1 ## 4 6.3 2.9 5.6 1.8 ## 5 6.5 3 5.8 2.2 ## 6 7.6 3 6.6 2.1 ## 7 4.9 2.5 4.5 1.7 ## 8 7.3 2.9 6.3 1.8 ## 9 6.7 2.5 5.8 1.8 ## 10 7.2 3.6 6.1 2.5 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; 如果使用group_split(), 注意分组后，返回的是列表 iris %&gt;% dplyr::group_split(Species) ## &lt;list_of&lt; ## tbl_df&lt; ## Sepal.Length: double ## Sepal.Width : double ## Petal.Length: double ## Petal.Width : double ## Species : factor&lt;12d60&gt; ## &gt; ## &gt;[3]&gt; ## [[1]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[2]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7 3.2 4.7 1.4 ## 2 6.4 3.2 4.5 1.5 ## 3 6.9 3.1 4.9 1.5 ## 4 5.5 2.3 4 1.3 ## 5 6.5 2.8 4.6 1.5 ## 6 5.7 2.8 4.5 1.3 ## 7 6.3 3.3 4.7 1.6 ## 8 4.9 2.4 3.3 1 ## 9 6.6 2.9 4.6 1.3 ## 10 5.2 2.7 3.9 1.4 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[3]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.3 3.3 6 2.5 ## 2 5.8 2.7 5.1 1.9 ## 3 7.1 3 5.9 2.1 ## 4 6.3 2.9 5.6 1.8 ## 5 6.5 3 5.8 2.2 ## 6 7.6 3 6.6 2.1 ## 7 4.9 2.5 4.5 1.7 ## 8 7.3 2.9 6.3 1.8 ## 9 6.7 2.5 5.8 1.8 ## 10 7.2 3.6 6.1 2.5 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; 既然是列表，当然想到用前面讲到的purrr::map()家族 iris %&gt;% dplyr::group_split(Species) %&gt;% purrr::map(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x))) ## [[1]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.803 0.344 2.34 0.0238 ## 2 Sepal.Length 0.132 0.0685 1.92 0.0607 ## ## [[2]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.185 0.514 0.360 7.20e- 1 ## 2 Sepal.Length 0.686 0.0863 7.95 2.59e-10 ## ## [[3]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.610 0.417 1.46 1.50e- 1 ## 2 Sepal.Length 0.750 0.0630 11.9 6.30e-16 iris %&gt;% dplyr::group_split(Species) %&gt;% purrr::map_df(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x))) 上面这个代码，数据框分割成list, 处理完后再合并成数据框，难道不觉得折腾么？ 为什么直接点？ tidyverse不会让我们失望的，先看看group_map() ## The result of .f should be a data frame(.f 必须返回数据框) ## `group_map()` return a list of tibble(返回元素均为df的一个列表list(df1,df2,df3)) iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::group_map(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x))) ## [[1]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.803 0.344 2.34 0.0238 ## 2 Sepal.Length 0.132 0.0685 1.92 0.0607 ## ## [[2]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.185 0.514 0.360 7.20e- 1 ## 2 Sepal.Length 0.686 0.0863 7.95 2.59e-10 ## ## [[3]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.610 0.417 1.46 1.50e- 1 ## 2 Sepal.Length 0.750 0.0630 11.9 6.30e-16 数据框进来，然后分组，依次处理成一个个数据框，最后以列表形式（a list of tibble）输出。 事实上，group_map()是返回list形式，也就是说，可以是返回任何形式，（a list of tibble）是其中特殊形式。 可以看看下面这个 iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::group_map( ~ lm(Petal.Length ~ Sepal.Length, data = .x) ) ## [[1]] ## ## Call: ## lm(formula = Petal.Length ~ Sepal.Length, data = .x) ## ## Coefficients: ## (Intercept) Sepal.Length ## 0.803 0.132 ## ## ## [[2]] ## ## Call: ## lm(formula = Petal.Length ~ Sepal.Length, data = .x) ## ## Coefficients: ## (Intercept) Sepal.Length ## 0.185 0.686 ## ## ## [[3]] ## ## Call: ## lm(formula = Petal.Length ~ Sepal.Length, data = .x) ## ## Coefficients: ## (Intercept) Sepal.Length ## 0.61 0.75 group_modify() 才是真正意义上的“数据框进、数据框出”。 iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::group_modify(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x))) 为了大家方便查阅和记忆，我总结下表 函数 说明 常用组合 返回值 要求 map() 列表进、列表出 df %&gt;% group_split() %&gt;% map() list map_df() 列表进、数据框出 df %&gt;% group_split() %&gt;% map_df() df group_map() 数据框进、列表出 df %&gt;% group_by() %&gt;% group_map() 返回list(list1, list2, …) 特例list(df1, df2, …) group_modify() 数据框进、数据框出 df %&gt;% group_by() %&gt;% group_modify() 返回grouped tibble .f返回df walk 列表进 df %&gt;% group_split() %&gt;%walk() side effects group_walk() 数据框进 df %&gt;% group_by() %&gt;% group_walk() side effects 我常用的批量出图的语句 nobel_winners %&gt;% dplyr::group_split(category) %&gt;% purrr::map( ~ ggplot(data = .x, aes(x = prize_age)) + geom_density() + ggtitle(.x$category) ) nobel_winners %&gt;% dplyr::group_by(category) %&gt;% dplyr::group_map( ~ ggplot(data = .x, aes(x = prize_age)) + geom_density() + ggtitle(.y) ) nobel_winners %&gt;% dplyr::group_by(category) %&gt;% dplyr::group_walk( ~ ggsave( paste0(.y, &#39;.png&#39;), ggplot(data = .x, aes(x = prize_age) ) + geom_density() + ggtitle(.y), device = &#39;png&#39;, path = temp ) ) %&gt;% invisible() 34.4.2 其他group函数 group_nest(), group_data(), group_keys(), group_rows() 34.5 列名清理 数据框的列名，不要用有空格和中文。 如果拿到的原始数据中列比较多，手动修改麻烦，可以使用janitor::clean_names()函数 library(readxl) library(janitor) # install.packages(&quot;janitor&quot;) roster_raw &lt;- read_excel(here::here(&quot;demo_data&quot;, &quot;dirty_data.xlsx&quot;)) glimpse(roster_raw) ## Rows: 13 ## Columns: 11 ## $ `First Name` &lt;chr&gt; &quot;Jason&quot;, &quot;Jason&quot;, &quot;Ali... ## $ `Last Name` &lt;chr&gt; &quot;Bourne&quot;, &quot;Bourne&quot;, &quot;K... ## $ `Employee Status` &lt;chr&gt; &quot;Teacher&quot;, &quot;Teacher&quot;, ... ## $ Subject &lt;chr&gt; &quot;PE&quot;, &quot;Drafting&quot;, &quot;Mus... ## $ `Hire Date` &lt;dbl&gt; 39690, 39690, 37118, 2... ## $ `% Allocated` &lt;dbl&gt; 0.75, 0.25, 1.00, 1.00... ## $ `Full time?` &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;... ## $ `do not edit! ---&gt;` &lt;lgl&gt; NA, NA, NA, NA, NA, NA... ## $ Certification...9 &lt;chr&gt; &quot;Physical ed&quot;, &quot;Physic... ## $ Certification...10 &lt;chr&gt; &quot;Theater&quot;, &quot;Theater&quot;, ... ## $ Certification...11 &lt;lgl&gt; NA, NA, NA, NA, NA, NA... roster &lt;- roster_raw %&gt;% janitor::clean_names() glimpse(roster) ## Rows: 13 ## Columns: 11 ## $ first_name &lt;chr&gt; &quot;Jason&quot;, &quot;Jason&quot;, &quot;Alici... ## $ last_name &lt;chr&gt; &quot;Bourne&quot;, &quot;Bourne&quot;, &quot;Key... ## $ employee_status &lt;chr&gt; &quot;Teacher&quot;, &quot;Teacher&quot;, &quot;T... ## $ subject &lt;chr&gt; &quot;PE&quot;, &quot;Drafting&quot;, &quot;Music... ## $ hire_date &lt;dbl&gt; 39690, 39690, 37118, 275... ## $ percent_allocated &lt;dbl&gt; 0.75, 0.25, 1.00, 1.00, ... ## $ full_time &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Ye... ## $ do_not_edit &lt;lgl&gt; NA, NA, NA, NA, NA, NA, ... ## $ certification_9 &lt;chr&gt; &quot;Physical ed&quot;, &quot;Physical... ## $ certification_10 &lt;chr&gt; &quot;Theater&quot;, &quot;Theater&quot;, &quot;V... ## $ certification_11 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, ... 34.6 缺失值检查与处理 34.6.1 purrr &amp; dplyr 技巧 library(purrr) airquality %&gt;% purrr::map(~ sum(is.na(.))) ## $Ozone ## [1] 37 ## ## $Solar.R ## [1] 7 ## ## $Wind ## [1] 0 ## ## $Temp ## [1] 0 ## ## $Month ## [1] 0 ## ## $Day ## [1] 0 airquality %&gt;% purrr::map_df(~ sum(is.na(.))) airquality %&gt;% dplyr::summarise_at(2:3, ~ sum(is.na(.))) 34.6.2 缺失值替换 airquality %&gt;% mutate_all(funs(replace(., is.na(.), 0))) airquality %&gt;% mutate_all(replace_na, replace = 0) airquality %&gt;% mutate_if(is.numeric, replace_na, replace = 0) airquality %&gt;% mutate_all(as.numeric) %&gt;% mutate_all(~ coalesce(., 0)) tibble( y = c(1, 2, NA, NA, 5), z = c(NA, NA, 3, 4, 5) ) %&gt;% mutate_all(~ coalesce(., 0)) 34.7 标准化 df_mtcars df_mtcars %&gt;% select_if(funs(is.numeric)) # way 1 df_mtcars %&gt;% mutate_at(vars(mpg, disp), ~ scale(., center = T, scale = T)) # way 2 df_mtcars %&gt;% mutate_at(vars(mpg, disp), funs((. - mean(.)) / sd(.))) # way 3 func &lt;- function(x) (x - min(x)) / (max(x) - min(x)) df_mtcars %&gt;% mutate_at(vars(mpg, disp), ~ func(.)) 如果所有的列，都是数值型 func &lt;- function(x) (x - min(x)) / (max(x) - min(x)) df_mtcars %&gt;% mutate_all(~ func(.)) ## Error: Problem with `mutate()` input `rowname`. ## x 二进列运算符中有非数值参数 ## i Input `rowname` is `(structure(function (..., .x = ..1, .y = ..2, . = ..1) ...`. 但这里数据中还有其他类型（fct, chr），所以这里 mutate_all() 会报错。 这种情形，用mutate_if() func &lt;- function(x) (x - min(x)) / (max(x) - min(x)) df_mtcars %&gt;% mutate_if(is.numeric, ~ func(.)) funs &lt;- list( centered = mean, # Function object scaled = ~ . - mean(.) / sd(.) # Purrr-style lambda ) iris %&gt;% mutate_if(is.numeric, funs) 34.8 across函数 数据框中向量de方向，事实上可以看做有两个方向，横着看是row-vector，竖着看是col-vector。 colwise: group_by() %&gt;% summarise/mutate + across() rowwise: rowwise()/nest_by() %&gt;% summarise/mutate + c_across() 比如 iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::summarise( across(starts_with(&quot;Sepal&quot;), mean), Area = mean(Petal.Length * Petal.Width), across(starts_with(&quot;Petal&quot;), min) ) 34.8.1 across函数替代scope函数 强大的across()函数，替代以上scope函数(_if, _at, 和 _all函数), 同时slice_max(), slice_min(), slice_n() 将替代 top_n()函数。 df %&gt;% mutate_if(is.numeric, mean, na.rm = TRUE) # -&gt; df %&gt;% mutate(across(is.numeric, mean, na.rm = TRUE)) df %&gt;% mutate_at(vars(x, starts_with(&quot;y&quot;)), mean, na.rm = TRUE) # -&gt; df %&gt;% mutate(across(c(x, starts_with(&quot;y&quot;)), mean, na.rm = TRUE)) df %&gt;% mutate_all(mean, na.rm = TRUE) # -&gt; df %&gt;% mutate(across(everything(), mean, na.rm = TRUE)) 34.8.2 更方便的colwise操作 # multiple df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) mult &lt;- list(x = 1, y = 10, z = 100) df %&gt;% mutate(across(all_of(names(mult)), ~ .x * mult[[cur_column()]])) # weights df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) df weights &lt;- list(x = 0.2, y = 0.3, z = 0.5) df %&gt;% dplyr::mutate( across(all_of(names(weights)), list(wt = ~ .x * weights[[cur_column()]]), .names = &quot;{col}.{fn}&quot;) ) # cutoffs df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) df cutoffs &lt;- list(x = 2, y = 3, z = 7) df %&gt;% dplyr::mutate( across(all_of(names(cutoffs)), ~ if_else(.x &gt; cutoffs[[cur_column()]], 1, 0)) ) 34.9 参考资料 https://dplyr.tidyverse.org/dev/articles/rowwise.html https://dplyr.tidyverse.org/dev/articles/colwise.html "],
["rowwise.html", "第 35 章 tidyverse中行方向的操作 35.1 问题 35.2 rowwise函数 35.3 Row-wise Summaries 35.4 purrr::map方案 35.5 tidy 的方案 35.6 用slide方案 35.7 rowwise() + c_across() 35.8 用lay方案", " 第 35 章 tidyverse中行方向的操作 library(tidyverse) tidyverse 喜欢数据框，因为一列就是一个向量，一列一列的处理起来很方便。然而我们有时候也要，完成行方向的操作，所以有必要介绍tidyverse中行方向的处理机制。 35.1 问题 df &lt;- tibble(x = 1:3, y = 4:6) df 对每行的求和、求均值、最小值或者最大值？ 35.2 rowwise函数 dplyr提供了rowwise函数，但大神说不推荐 df %&gt;% rowwise() %&gt;% mutate( i = sum(x, y) ) df %&gt;% rowwise() %&gt;% mutate( i = mean(c(x, y) )) df %&gt;% rowwise() %&gt;% mutate(min = min(x,y), max = max(x,y) ) df %&gt;% rowwise() %&gt;% do(i = mean(c(.$x, .$y))) %&gt;% unnest(i) 35.3 Row-wise Summaries df %&gt;% mutate(row_sum = rowSums(.[1:2]) ) df %&gt;% mutate(row_mean = rowMeans(.[1:2]) ) df %&gt;% mutate(t_sum = rowSums(select_if(., is.numeric))) 固然可解决问题， 然而，却不是一个很好的办法，比如除了求和与计算均值，可能还要计算每行的中位数、方差等等， 因为，不是每种计算都对应的row_函数？ 既然是tidyverse ，还是用tidyverse 的方法解决 35.4 purrr::map方案 按照Jenny Bryan的方案 df %&gt;% mutate(t_sum = pmap_dbl(list(x, y), sum)) df %&gt;% mutate(t_sum = pmap_dbl(select_if(., is.numeric), sum)) 计算均值的时候， 然而报错了 df %&gt;% mutate(t_sum = pmap_dbl(select_if(., is.numeric), mean)) tidyverse 总会想出办法来解决，把mean() 变成 lift_vd(mean) df %&gt;% mutate(data = pmap_dbl(select_if(., is.numeric), lift_vd(mean))) 同理 df %&gt;% mutate(t_median = pmap_dbl(select_if(., is.numeric), lift_vd(median))) df %&gt;% mutate(t_sd = pmap_dbl(select_if(., is.numeric), lift_vd(sd))) 35.5 tidy 的方案 我个人推荐的方法(Gather, group, summarize, left_join) new_df &lt;- df %&gt;% mutate(id = row_number()) s &lt;- new_df %&gt;% gather(&quot;time&quot;, &quot;val&quot;, -id) %&gt;% group_by(id) %&gt;% summarize( t_avg = mean(val), t_sum = sum(val) ) s new_df %&gt;% left_join(s) 有点繁琐，但思路清晰 ss &lt;- new_df %&gt;% group_by(id) %&gt;% summarise(t_avg = mean(c(x, y)) ) ss new_df %&gt;% left_join(ss) 之所以有这么多的搞法，是因为没有一个很好的搞法 35.6 用slide方案 slide很强大，可以滚动喔 如果第一个参数是数据框，slide把数据框看作a vector of rows， 然后行方向的滚动，事实上， .x是一个个的小数据框（如下） 与purrr::map不同，因为map把数据框看作列方向的向量， 然后迭代 如果第一个参数是原子型向量的话，还是依次迭代逗号分隔的元素，只不过这里是slide比map更强大的是，还可以是滚动 library(slider) df &lt;- tibble(a = 1:3, b = 4:6) slide( select_if(df, is.numeric), ~.x, .before = 1 ) ## [[1]] ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 4 ## ## [[2]] ## # A tibble: 2 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 4 ## 2 2 5 ## ## [[3]] ## # A tibble: 2 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 2 5 ## 2 3 6 df %&gt;% mutate( r_mean = slide_dbl( select_if(df, is.numeric), ~mean(unlist(.x)), .before = 1 ) ) 35.7 rowwise() + c_across() df &lt;- tibble(id = 1:6, w = 10:15, x = 20:25, y = 30:35, z = 40:45) df df %&gt;% rowwise(id) %&gt;% summarise(mean = mean(c(w, x, y, z))) df %&gt;% rowwise(id) %&gt;% mutate(mean = mean(c(w, x, y, z))) df %&gt;% rowwise(id) %&gt;% mutate(total = mean(c_across(w:z))) df %&gt;% rowwise(id) %&gt;% mutate(mean = mean(c_across(is.numeric))) # across() df %&gt;% mutate(mean = rowMeans(across(is.numeric &amp; -id))) 35.8 用lay方案 lay包解决方案 library(lay) library(dplyr, warn.conflicts = FALSE) iris &lt;- as_tibble(iris) # apply mean to each &quot;row&quot; iris %&gt;% mutate(sepal = lay(across(starts_with(&quot;Sepal&quot;)), mean)) "],
["dot.html", "第 36 章 tidyverse中的dot 36.1 每一行的 . 各自代表什么意思呢? 36.2 占位符 36.3 Lambda函数 36.4 正则表达式 36.5 Unary funciton (只带一个参数的函数) 36.6 more placeholder 36.7 当mutate遇到map 36.8 Dot dot dot 36.9 Don’t confuse 36.10 小结 36.11 回答问题", " 第 36 章 tidyverse中的dot 本章介绍tidyverse的语法中经常遇到.， 不同的场景，含义不同。因此很有必要弄清楚各自的含义。 library(tidyverse) 36.1 每一行的 . 各自代表什么意思呢? read_csv(&quot;./data/wages.csv&quot;) %&gt;% mutate(letter = str_extract(race, &quot;(?&lt;=h)(.)&quot;)) %&gt;% select(., -letter) %&gt;% mutate_at(vars(race), ~ as.factor(.)) %&gt;% mutate_at(vars(sex), ~ if_else(. == &quot;male&quot;, 1, 0)) %&gt;% filter_if(~ is.numeric(.), all_vars(. != 0)) %&gt;% split(.$sex) %&gt;% map(~ lm(earn ~ ., data = .)) %&gt;% map_dfr(~ broom::tidy(.), .id = &quot;sex&quot;) 回答之前，我们先介绍一些相关知识点 36.2 占位符 管道符号%&gt;% 主要功能是传递参数。 y %&gt;% f() is equivalent to f(y) y %&gt;% f(x, .) is equivalent to f(x, y) z %&gt;% f(x, y, arg = .) is equivalent to f(x, y, arg = z) 我们经常这样写 mtcars %&gt;% select(cyl, disp, hp) %&gt;% head(2) 实际上，这里是有占位符的 mtcars %&gt;% select(., cyl, disp, hp) %&gt;% head(., 2) 36.3 Lambda函数 .出现在函数.f的位置上， 就是 purrr 风格的Lambda函数~ fun(.)， mtcars %&gt;% select_at(vars(contains(&quot;ar&quot;)), ~toupper(.)) %&gt;% head(3) 有时候程序员会将~toupper(.)简写成 toupper mtcars %&gt;% select_at(vars(contains(&quot;ar&quot;)), toupper) %&gt;% head(3) 36.4 正则表达式 words &lt;- &quot;the fattest cat.&quot; words %&gt;% str_replace_all(&quot;t.&quot;, &quot;-&quot;) ## [1] &quot;-e fa-es-ca-&quot; words %&gt;% str_replace_all(&quot;t\\\\.&quot;, &quot;-&quot;) ## [1] &quot;the fattest ca-&quot; 36.5 Unary funciton (只带一个参数的函数) mean_rm &lt;- . %&gt;% mean(na.rm = T) c(1, 2, 3, NA) %&gt;% mean_rm ## [1] 2 等价于 # is equivalent to c(1, 2, 3, NA) %&gt;% mean(., na.rm = T) ## [1] 2 36.6 more placeholder iris %&gt;% subset(1:nrow(.) %% 30 == 0) 1:10 %&gt;% {c(min(.), max(.))} ## [1] 1 10 36.7 当mutate遇到map 当dplyr::mutate遇到purrr::map，情况就复杂很多了。然而，这种情况，tidyverse比比皆是。我就多说几句吧 iris %&gt;% head(3) %&gt;% mutate(., r_sum = pmap_dbl(select_if(., is.numeric), sum)) 这里mutate()行，有两个., 实际这两个.都是等待iris %&gt;% head(3)传来的data.frame df &lt;- tibble( mean = c(1, 2), sd = c(2, 4) ) df df %&gt;% dplyr::mutate(., rand = map(mean, ~ rnorm(5, .))) %&gt;% tidyr::unnest_wider(rand) 第一个 .， 是df 第二个 .， 是df中的mean df %&gt;% dplyr::mutate(rand = map2(mean, sd, ~ rnorm(5, .x, .y))) %&gt;% tidyr::unnest_wider(rand) mean传给 .x sd传给 .y 再来一个变态的。（我们不一定要这样写，但我们尽可能的要明白它的意思。） df &lt;- tribble( ~ a, ~b, 1, 10, 2, 11 ) df %&gt;% dplyr::mutate(., sum = purrr::pmap_dbl(., ~sum(...))) 36.8 Dot dot dot commas &lt;- function(...) stringr::str_c(..., collapse = &quot;, &quot;) commas(letters[1:10]) ## [1] &quot;a, b, c, d, e, f, g, h, i, j&quot; 36.9 Don’t confuse 注意：有些函数的参数前缀是 . mutate_all(.tbl, .funs, ...) mutate_if(.tbl, .predicate, .funs, ...) mutate_at(.tbl, .vars, .funs, ..., .cols = NULL) select_all(.tbl, .funs = list(), ...) rename_all(.tbl, .funs = list(), ...) 36.10 小结 tidyvere中 占位符(时常经常和 %&gt;% 一起) Lambda函数 一元函数（LHS） 其他情形 回归公式 正则表达式 注意 有些函数参数以 . 前缀(不要混淆喔! ) 36.11 回答问题 现在回答本章开始的问题 read_csv(&quot;./demo_data/wages.csv&quot;) %&gt;% dplyr::mutate(letter = str_extract(race, &quot;(?&lt;=h)(.)&quot;)) %&gt;% dplyr::select(., -letter) %&gt;% dplyr::mutate_at(vars(race), ~ as.factor(.)) %&gt;% dplyr::mutate_at(vars(sex), ~ if_else(. == &quot;male&quot;, 1, 0)) %&gt;% dplyr::filter_if(~ is.numeric(.), all_vars(. != 0)) %&gt;% split(.$sex) %&gt;% purrr::map(~ lm(earn ~ ., data = .)) %&gt;% purrr::map_dfr(., ~ broom::tidy(.), .id = &quot;sex&quot;) 第1行：路径中.代表当前位置，如果是..表示上一级目录 第2行：正则表达式，代表任何字符 第3行：占位符，等待数据框的传入，也可以简写select(-letter) 第4行: lambda函数，~ as.factor(.)也可以简写as.factor，~和(.)要么都写，要么都不写 第5行：同上,lambda函数 第6行：第一个.代表lambda函数; 第二个.也是lambda函数，但这里它是all_vars(expr)中expr的一种特有写法，代表所有数值型变量，*行方向构成的向量, all_vars(. != 0)函数返回TRUE或FALSE，从而帮助filter()是否筛选该行 第7行：占位符，代表上面传来的数据框 第8行：回归模型lm中，第一个.代表除因变量earn之外所有的变量，第二个.占位符，留给上面的数据框 第9行：第一个.是占位符，代表上面传来的list，第二个.lambda函数，依次对list的元素迭代处理，第二个.是参数名，.id是特有的一个符号。 "],
["rvest.html", "第 37 章 网络爬虫 37.1 链家网 37.2 猪肉价格", " 第 37 章 网络爬虫 library(tidyverse) library(rvest) library(sf) 37.1 链家网 urls &lt;- paste0(&quot;https://sh.lianjia.com/ershoufang/pg&quot;, seq_along(1:2)) scrape_house_info &lt;- function(url) { web &lt;- read_html(url) title &lt;- web %&gt;% html_nodes(&#39;.clear .title a&#39;) %&gt;% html_text() houseinfo &lt;- web %&gt;% html_nodes(&#39;.houseInfo&#39;) %&gt;% html_text() price &lt;- web %&gt;% html_nodes(&#39;.totalPrice span&#39;) %&gt;% html_text() price_per &lt;- web %&gt;% html_nodes(&#39;.unitPrice span&#39;) %&gt;% html_text() df &lt;- data.frame(title, houseinfo, price, price_per) return(df) } tb &lt;- urls %&gt;% map_df(scrape_house_info) tb 37.2 猪肉价格 df_price &lt;- read_html(&quot;https://hangqing.zhuwang.cc/shengzhu/20190905/407978.html&quot;) %&gt;% html_node(&quot;.tabzj&quot;) %&gt;% html_table(header = T) %&gt;% set_names( c(&quot;region&quot;, &quot;name&quot;, &quot;price_today&quot;, &quot;price_yestoday&quot;, &quot;diff_last_day&quot;, &quot;diff_last_week&quot;) ) %&gt;% mutate_at(vars(name), ~str_remove_all(., &quot; &quot;) ) %&gt;% mutate_at(vars(name), ~if_else( name == &quot;黑龙江&quot;, &quot;黑龙江省&quot;, .)) df_price china &lt;- st_read(&quot;./demo_data/chinamap_data/bou2_4p.shp&quot;) %&gt;% st_set_crs(4326) %&gt;% group_by(NAME) %&gt;% summarize() ## Reading layer `bou2_4p&#39; from data source `G:\\R_for_Data_Science\\demo_data\\chinamap_data\\bou2_4p.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 925 features and 7 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 73.45 ymin: 6.319 xmax: 135.1 ymax: 53.56 ## CRS: NA china_uni &lt;- china %&gt;% mutate( NAME = iconv(NAME, &quot;GBK&quot;, &quot;UTF-8&quot;) ) %&gt;% mutate_at(vars(NAME), ~str_remove_all(., &quot;自治区|回族|维吾尔|壮族&quot;) ) %&gt;% mutate_at(vars(NAME), ~str_trim(.)) df &lt;- left_join(china_uni, df_price, by = c(&quot;NAME&quot; = &quot;name&quot;)) ggplot(data = df) + geom_sf( aes(fill = price_today &lt; 28), show.legend = FALSE) + geom_sf_text(aes(label = NAME), size = 3 ) + geom_sf_text(aes(label = price_today), size = 3, #nudge_x = c(-0.4, 0.5, 0.7), nudge_y = c(-1, -1, -1) ) + coord_sf(crs = 4326) + ggtitle(&quot;全国猪肉价格地图&quot;) "],
["tidygraph.html", "第 38 章 社会网络分析 38.1 图论基本知识 38.2 网络分析 38.3 Network graph manipulation 38.4 Network analysis 38.5 小结 38.6 Network Visualization 38.7 扩展阅读", " 第 38 章 社会网络分析 本章通过tidygraph宏包介绍社会网络分析。社会网络分析涉及的知识比较多，而tidygraph将网络结构规整地比较清晰，降低了学习难度，很适合入门学习。 library(tidyverse) library(tidygraph) library(ggraph) 38.1 图论基本知识 网络图有两个主要特征: nodes and edges， nodes: edges: 当然还包括其它的概念，比如 adjacency matrix: edge list: Node list: Weighted network graph: Directed and undirected network graph: 有向图 无向图 38.2 网络分析 先介绍tidygraph宏包 38.2.1 tidygraph: A tidy API for graph manipulation 38.2.2 Tidy Network Anaylsis 在 tidygraph 框架, 网络数据可以分解成两个tidy数据框: 一个是 node data 一个是 edge data tidygraph 宏包提供了node数据框和edge数据框相互切换的方案，并且可以使用dplyr的语法操控 tidygraph 提供了常用的网络结构的algorithms，比如，计算网络拓扑结构中节点的重要性、中心度等。 38.2.3 Create network objects 创建网络对象主要有两个函数: tbl_graph(). Creates a network object from nodes and edges data as_tbl_graph(). Converts network data and objects to a tbl_graph network. 案例: 欧盟总统之间通话以及次数。 library(&quot;navdata&quot;) # devtools::install_github(&quot;kassambara/navdata&quot;) data(&quot;phone.call2&quot;) node_list &lt;- phone.call2$nodes node_list edge_list &lt;- phone.call2$edges edge_list 38.2.4 Use tbl_graph Create a tbl_graph network object using the phone call data: phone.net &lt;- tbl_graph(nodes = node_list, edges = edge_list, directed = TRUE) Visualize the network graph ggraph(phone.net, layout = &quot;graphopt&quot;) + geom_edge_link(width = 1, colour = &quot;lightgray&quot;) + geom_node_point(size = 4, colour = &quot;red&quot;) + geom_node_text(aes(label = label), repel = TRUE) + theme_graph() 38.2.5 Use as_tbl_graph mtcars data set: R 的内置数据集，记录了32种不同品牌的轿车的的11个属性 1、we create a correlation matrix network graph library(corrr) res.cor &lt;- mtcars[, c(1, 3:6)] %&gt;% # (1) t() %&gt;% correlate() %&gt;% # (2) shave(upper = TRUE) %&gt;% # (3) stretch(na.rm = TRUE) %&gt;% # (4) filter(r &gt;= 0.998) # (5) res.cor 2、Create the correlation network graph: set.seed(1) cor.graph &lt;- as_tbl_graph(res.cor, directed = FALSE) ggraph(cor.graph) + geom_edge_link() + geom_node_point() + geom_node_text( aes(label = name), size = 3, repel = TRUE ) + theme_graph() 38.2.6 Print out a network object cor.graph ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Node Data: 24 x 1 (active) ## name ## &lt;chr&gt; ## 1 Mazda RX4 ## 2 Mazda RX4 Wag ## 3 Datsun 710 ## 4 Hornet 4 Drive ## 5 Hornet Sportabout ## 6 Valiant ## # ... with 18 more rows ## # ## # Edge Data: 59 x 3 ## from to r ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## # ... with 56 more rows 38.2.7 extract the current active data cor.graph %&gt;% activate(edges) %&gt;% arrange(desc(r)) ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Edge Data: 59 x 3 (active) ## from to r ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 10 11 1.00 ## 3 10 12 1.00 ## 4 11 12 1.00 ## 5 8 9 1.00 ## 6 5 18 1.00 ## # ... with 53 more rows ## # ## # Node Data: 24 x 1 ## name ## &lt;chr&gt; ## 1 Mazda RX4 ## 2 Mazda RX4 Wag ## 3 Datsun 710 ## # ... with 21 more rows Note that, to extract the current active data as a tibble, you can use the function as_tibble(cor.graph). 38.3 Network graph manipulation 38.3.1 Car groups info (Number of cylinders) # Car groups info cars.group &lt;- data_frame( name = rownames(mtcars), cyl = as.factor(mtcars$cyl) ) cars.group 38.3.2 Modify the nodes data: # Modify the nodes data cor.graph &lt;- cor.graph %&gt;% activate(nodes) %&gt;% left_join(cars.group, by = &quot;name&quot;) %&gt;% rename(label = name) cor.graph ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Node Data: 24 x 2 (active) ## label cyl ## &lt;chr&gt; &lt;fct&gt; ## 1 Mazda RX4 6 ## 2 Mazda RX4 Wag 6 ## 3 Datsun 710 4 ## 4 Hornet 4 Drive 6 ## 5 Hornet Sportabout 8 ## 6 Valiant 6 ## # ... with 18 more rows ## # ## # Edge Data: 59 x 3 ## from to r ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## # ... with 56 more rows 38.3.3 Modify the edge data. # Modify the edge data. cor.graph &lt;- cor.graph %&gt;% activate(edges) %&gt;% rename(weight = r) cor.graph ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Edge Data: 59 x 3 (active) ## from to weight ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## 4 1 9 0.999 ## 5 1 11 0.998 ## 6 2 20 1.00 ## # ... with 53 more rows ## # ## # Node Data: 24 x 2 ## label cyl ## &lt;chr&gt; &lt;fct&gt; ## 1 Mazda RX4 6 ## 2 Mazda RX4 Wag 6 ## 3 Datsun 710 4 ## # ... with 21 more rows 38.3.4 Display the final modified graphs object: cor.graph ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Edge Data: 59 x 3 (active) ## from to weight ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## 4 1 9 0.999 ## 5 1 11 0.998 ## 6 2 20 1.00 ## # ... with 53 more rows ## # ## # Node Data: 24 x 2 ## label cyl ## &lt;chr&gt; &lt;fct&gt; ## 1 Mazda RX4 6 ## 2 Mazda RX4 Wag 6 ## 3 Datsun 710 4 ## # ... with 21 more rows 38.3.5 Visualize the correlation network set.seed(1) ggraph(cor.graph) + geom_edge_link(aes(width = weight), alpha = 0.2) + scale_edge_width(range = c(0.2, 1)) + geom_node_point(aes(color = cyl), size = 2) + geom_node_text(aes(label = label), size = 3, repel = TRUE) + theme_graph() 38.4 Network analysis 38.4.1 Centrality Centrality is an important concept when analyzing network graph. The tidygraph package contains more than 10 centrality measures, prefixed with the term centrality_ : # centrality_alpha() # centrality_power() # centrality_authority() # centrality_betweenness() # centrality_closeness() # centrality_hub() # centrality_degree() # centrality_pagerank() # centrality_eigen() # centrality_subgraph # centrality_edge_betweenness() example: - use the phone call network graph ( 欧盟总统之间通话以及次数) - compute nodes centrality set.seed(123) phone.net %&gt;% activate(nodes) %&gt;% mutate(centrality = centrality_authority()) ## # A tbl_graph: 16 nodes and 18 edges ## # ## # A directed acyclic simple graph with 1 component ## # ## # Node Data: 16 x 3 (active) ## id label centrality ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 France 1.61e- 1 ## 2 2 Belgium 1.15e-16 ## 3 3 Germany 1.00e+ 0 ## 4 4 Danemark 5.74e-17 ## 5 5 Croatia 1.15e-16 ## 6 6 Slovenia 5.74e-17 ## # ... with 10 more rows ## # ## # Edge Data: 18 x 3 ## from to weight ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 3 9 ## 2 2 1 4 ## 3 1 8 3 ## # ... with 15 more rows set.seed(123) phone.net %&gt;% activate(nodes) %&gt;% mutate(centrality = centrality_authority()) %&gt;% ggraph(layout = &quot;graphopt&quot;) + geom_edge_link(width = 1, colour = &quot;lightgray&quot;) + geom_node_point(aes(size = centrality, colour = centrality)) + geom_node_text(aes(label = label), repel = TRUE) + scale_color_gradient(low = &quot;yellow&quot;, high = &quot;red&quot;) + theme_graph() 38.4.2 Clustering Clustering is a common operation in network analysis and it consists of grouping nodes based on the graph topology. Many clustering algorithms from are available in the tidygraph package and prefixed with the term group_. These include: Infomap community finding. It groups nodes by minimizing the expected description length of a random walker trajectory. R function: group_infomap() Community structure detection based on edge betweenness. It groups densely connected nodes. R function: group_edge_betweenness() example: - use the correlation network graphs (记录了32种不同品牌的轿车的的11个属性) - detect clusters or communities set.seed(123) cluster_mtcars &lt;- cor.graph %&gt;% activate(nodes) %&gt;% mutate(community = as.factor(group_infomap())) cluster_mtcars ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Node Data: 24 x 3 (active) ## label cyl community ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; ## 1 Mazda RX4 6 1 ## 2 Mazda RX4 Wag 6 1 ## 3 Datsun 710 4 3 ## 4 Hornet 4 Drive 6 2 ## 5 Hornet Sportabout 8 2 ## 6 Valiant 6 2 ## # ... with 18 more rows ## # ## # Edge Data: 59 x 3 ## from to weight ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## # ... with 56 more rows cluster_mtcars %&gt;% ggraph(layout = &quot;graphopt&quot;) + geom_edge_link(width = 1, colour = &quot;lightgray&quot;) + geom_node_point(aes(colour = community), size = 4) + geom_node_text(aes(label = label), repel = TRUE) + theme_graph() 38.4.3 More Algorithms 38.5 小结 tidybayes很聪明地将复杂的网络结构用两个数据框表征出来，node 数据框负责节点的属性，edge 数据框负责网络连接的属性，调整其中的一个数据框，另一个也会相应的调整，比如node数据框中删除一个节点，edge数据框就会自动地删除该节点的所有连接。 38.6 Network Visualization 这里主要介绍tidygraph配套的ggraph宏包，它们的作者都是同一个人。 38.6.1 ggraph: A grammar of graphics for relational data ggraph 沿袭了ggplot2的语法规则， cluster_mtcars %&gt;% # Layout ggraph(layout = &quot;graphopt&quot;) + # Edges geom_edge_link( width = 1, colour = &quot;lightgray&quot; ) + # Nodes geom_node_point( aes(colour = community), size = 4 ) + geom_node_text( aes(label = label), repel = TRUE ) + theme_graph() 38.7 扩展阅读 https://www.data-imaginist.com/2017/introducing-tidygraph/ https://github.com/thomasp85/tidygraph https://christophergandrud.github.io/networkD3/ "],
["tidytext.html", "第 39 章 文本挖掘", " 第 39 章 文本挖掘 library(tidyverse) library(tidytext) "],
["tibbletime.html", "第 40 章 时间序列分析", " 第 40 章 时间序列分析 library(tidyverse) library(tibbletime) library(slider) "],
["stars.html", "第 41 章 地理数据处理", " 第 41 章 地理数据处理 library(tidyverse) library(sf) library(stars) "],
["lazyman.html", "第 42 章 懒人系列 42.1 列名太乱了 42.2 比count()更懂我的心 42.3 比distinct()更知我心 42.4 代码太乱了，谁帮我整理下 42.5 谁帮我敲模型的公式 42.6 模型有了，不知道怎么写论文？ 42.7 模型评估一步到位 42.8 统计表格不用愁 42.9 统计结果写图上 42.10 正则表达式太南了 42.11 颜控怎么配色？ 42.12 画图颜色好看不 42.13 宏包太多 42.14 犹抱琵琶半遮面 42.15 整理Rmarkdown 42.16 如何有效的提问 42.17 程序结束后记得提醒我 42.18 多张图摆放 42.19 缺失值处理 42.20 看看数据什么情况 42.21 管道都不想 42.22 各种插件，任君选取", " 第 42 章 懒人系列 R社区上很多大神，贡献了很多非常优秀的工具，节省了我们的时间，也给我们的生活增添了无限乐趣。我平时逛github的时候时整理一些，现在分享出来供像我一样的懒人用，因此本文档叫“懒人系列”。欢迎大家补充。 42.1 列名太乱了 library(tidyverse) library(janitor) ## install.packages(&quot;janitor&quot;) ## https://github.com/sfirke/janitor fake_raw &lt;- tibble::tribble( ~id, ~`count/num`, ~W.t, ~Case, ~`time--d`, ~`%percent`, 1L, &quot;china&quot;, 3L, &quot;w&quot;, 5L, 25L, 2L, &quot;us&quot;, 4L, &quot;f&quot;, 6L, 34L, 3L, &quot;india&quot;, 5L, &quot;q&quot;, 8L, 78L ) fake_raw fake_raw %&gt;% janitor::clean_names() 42.2 比count()更懂我的心 mtcars %&gt;% count(cyl) mtcars %&gt;% janitor::tabyl(cyl) 42.3 比distinct()更知我心 df &lt;- tribble( ~id, ~date, ~store_id, ~sales, 1, &quot;2020-03-01&quot;, 1, 100, 2, &quot;2020-03-01&quot;, 2, 100, 3, &quot;2020-03-01&quot;, 3, 150, 4, &quot;2020-03-02&quot;, 1, 110, 5, &quot;2020-03-02&quot;, 3, 101 ) df %&gt;% janitor::get_dupes(store_id) df %&gt;% janitor::get_dupes(date) 42.4 代码太乱了，谁帮我整理下 ## install.packages(&quot;styler&quot;) 安装后，然后这两个地方点两下，就发现你的代码整齐很多了。或者直接输入 styler:::style_active_file() 42.5 谁帮我敲模型的公式 library(equatiomatic) ## https://github.com/datalorax/equatiomatic mod1 &lt;- lm(mpg ~ cyl + disp, mtcars) extract_eq(mod1) \\[ \\operatorname{mpg} = \\alpha + \\beta_{1}(\\operatorname{cyl}) + \\beta_{2}(\\operatorname{disp}) + \\epsilon \\] extract_eq(mod1, use_coefs = TRUE) \\[ \\operatorname{mpg} = 34.66 - 1.59(\\operatorname{cyl}) - 0.02(\\operatorname{disp}) + \\epsilon \\] 42.6 模型有了，不知道怎么写论文？ library(report) ## https://github.com/easystats/report model &lt;- lm(Sepal.Length ~ Species, data = iris) report(model) We fitted a linear model (estimated using OLS) to predict Sepal.Length with Species (formula = Sepal.Length ~ Species). Standardized parameters were obtained by fitting the model on a standardized version of the dataset. Effect sizes were labelled following Funder’s (2019) recommendations. The model explains a significant and substantial proportion of variance (R2 = 0.62, F(2, 147) = 119.26, p &lt; .001, adj. R2 = 0.61). The model’s intercept, corresponding to Sepal.Length = 0 and Species = setosa, is at 5.01 (SE = 0.07, 95% CI [4.86, 5.15], p &lt; .001). Within this model: The effect of Speciesversicolor is positive and can be considered as very large and significant (beta = 0.93, SE = 0.10, std. beta = 1.12, p &lt; .001). The effect of Speciesvirginica is positive and can be considered as very large and significant (beta = 1.58, SE = 0.10, std. beta = 1.91, p &lt; .001). 42.7 模型评估一步到位 library(performance) model &lt;- lm(mpg ~ wt * cyl + gear, data = mtcars) performance::check_model(model) 42.8 统计表格不用愁 library(gtsummary) ## https://github.com/ddsjoberg/gtsummary gtsummary::trial %&gt;% dplyr::select(trt, age, grade, response) %&gt;% gtsummary::tbl_summary(by = trt, missing = &quot;no&quot;) %&gt;% gtsummary::add_p() %&gt;% gtsummary::add_overall() %&gt;% gtsummary::add_n() %&gt;% gtsummary::bold_labels() 直接复制到论文即可 t1 &lt;- glm(response ~ trt + age + grade, trial, family = binomial) %&gt;% gtsummary::tbl_regression(exponentiate = TRUE) t2 &lt;- survival::coxph(survival::Surv(ttdeath, death) ~ trt + grade + age, trial) %&gt;% gtsummary::tbl_regression(exponentiate = TRUE) gtsummary::tbl_merge( tbls = list(t1, t2), tab_spanner = c(&quot;**Tumor Response**&quot;, &quot;**Time to Death**&quot;) ) 42.9 统计结果写图上 library(ggplot2) library(statsExpressions) # https://github.com/IndrajeetPatil/statsExpressions ggplot(mtcars, aes(x = mpg, y = wt)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs( title = &quot;Spearman&#39;s rank correlation coefficient&quot;, subtitle = expr_corr_test(mtcars, mpg, wt, type = &quot;nonparametric&quot;) ) 42.10 正则表达式太南了 library(inferregex) ## remotes::install_github(&quot;daranzolin/inferregex&quot;) s &lt;- &quot;abcd-9999-ab9&quot; infer_regex(s)$regex ## [1] &quot;^[a-z]{4}-\\\\d{4}-[a-z]{2}\\\\d$&quot; 有了它，妈妈再也不担心我的正则表达式了 42.11 颜控怎么配色？ library(ggthemr) ## devtools::install_github(&#39;cttobin/ggthemr&#39;) ggthemr(&#39;dust&#39;) mtcars %&gt;% mutate(cyl = factor(cyl)) %&gt;% ggplot(aes(x = mpg, fill = cyl, colour = cyl)) + geom_density(alpha = 0.75) + labs(fill = &#39;Cylinders&#39;, colour = &#39;Cylinders&#39;, x = &#39;MPG&#39;, y = &#39;Density&#39;) + legend_top() 用完别忘了 ggthemr_reset() 42.12 画图颜色好看不 scales也是大神的作品，功能多多 ## https://github.com/r-lib/scales library(scales) show_col(viridis_pal()(10)) 不推荐个人配色，因为我们不专业。直接用专业的配色网站 colorbrewer 先看看颜色，再选择 42.13 宏包太多 library(pacman) ##p_load(lattice, foreign, boot, rpart) 唉，这个library()都要偷懒，真服了你们了 42.14 犹抱琵琶半遮面 ##https://github.com/EmilHvitfeldt/gganonymize library(ggplot2) library(gganonymize) ggg &lt;- ggplot(mtcars, aes(as.factor(cyl))) + geom_bar() + labs(title = &quot;Test title&quot;, subtitle = &quot;Test subtitle, this one have a lot lot lot lot lot more text then the rest&quot;, caption = &quot;Test caption&quot;, tag = 1) + facet_wrap(~vs) gganonomize(ggg) 你可以看我的图，但就不想告诉你图什么意思，因为我加密了 42.15 整理Rmarkdown # remotes::install_github(&quot;tjmahr/WrapRmd&quot;) # remotes::install_github(&quot;fkeck/quickview&quot;) # remotes::install_github(&quot;mwip/beautifyR&quot;) 42.16 如何有效的提问 直接看官方网站，这里不举例了 ## install.packages(&quot;reprex&quot;) ## https://reprex.tidyverse.org/ 42.17 程序结束后记得提醒我 ## beepr::beep(sound = &quot;mario&quot;) 你听到了声音吗? 42.18 多张图摆放 library(patchwork) p1 &lt;- ggplot(mtcars) + geom_point(aes(mpg, disp)) p2 &lt;- ggplot(mtcars) + geom_boxplot(aes(gear, disp, group = gear)) p3 &lt;- ggplot(mtcars) + geom_smooth(aes(disp, qsec)) p1 + p2 + p3 42.19 缺失值处理 library(naniar) ##https://github.com/njtierney/naniar airquality %&gt;% group_by(Month) %&gt;% naniar::miss_var_summary() 42.20 看看数据什么情况 library(visdat) vis_dat(airquality) 42.21 管道都不想 管道都不想写， 写代码还有美感？ ## library(nakepipe) 42.22 各种插件，任君选取 ## https://github.com/daattali/addinslist "],
["exams.html", "A 期末考试 A.1 方式 A.2 要求 A.3 数据集", " A 期末考试 研究生生涯的主要工作就是学习，而学以致用是最好的学习路径。考虑同学们不同的学科背景，同时也参考国内其它高校的做法，本学期《数据科学中的 R 语言》期末考试安排如下： A.1 方式 结合所在学科，找一篇与自己研究方向相关的文献，用课堂上学到的R统计编程技能，重复文献的数据分析过程。 A.2 要求 在2020年06月15日前，将以下资料打包并提交38552109@qq.com邮箱 所重复的文献（并在文献中高亮你重复的部分） 数据 Rmarkdown源代码 分析结果(生成的pdf或者html文件) 注明学号和姓名 A.3 数据集 仅供参考 https://datahub.io/collections/economic-data https://cnki.net/ https://osf.io/ https://www.kaggle.com/datasets https://toolbox.google.com/datasetsearch https://chfs.swufe.edu.cn/（中国家庭金融调查） http://www.isss.pku.edu.cn/cfps/index.htm（中国家庭追踪调查） http://www.ciejournal.org/ (中国工业经济) http://www.stats.gov.cn/tjsj/ndsj/ (中国统计年鉴) https://www.oecd.org/pisa/ 国际学生评估项目 (PISA) "],
["references.html", "参考文献", " 参考文献 "]
]
