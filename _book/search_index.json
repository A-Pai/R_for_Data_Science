[["index.html", "数据科学中的 R 语言 前言 关于课程 课件中用到的宏包 RYouWithMe 致谢", " 数据科学中的 R 语言 王敏杰 2021-01-09 前言 你好，这里是四川师范大学研究生公选课《数据科学中的R语言》的课程内容。考虑到大家来自不同的学院，有着不同的学科背景，因此讲授的内容不会太深奥（要有信心喔）。 比如在课程中以下内容就不会出现 \\[ f(x)=\\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2} x^{2}} \\] 而出现更多的是 library(tidyverse) summary_monthly_temp &lt;- weather %&gt;% group_by(month) %&gt;% summarize(mean = mean(temp), std_dev = sd(temp)) 在跟进本课程的同时， 我强烈推荐大家阅读Hadley Wickham的 r4ds这本书 (Grolemund and Wickham 2017)。作者可是2019年8月刚刚获得考普斯总统奖（被誉为统计学的诺贝尔奖）的大神喔，点击这里可以看他照片。 关于课程 1、课程安排是这样的，每个章节研究的内容都是彼此独立的，大家可以单独阅读每章及运行代码。 基础篇 第 1 章介绍数据科学基础 第 2 章介绍R语言基本概念 第 3 章介绍R语言中的子集选取 tidyverse篇 第 4 章介绍可重复性报告 第 5 章介绍数据读入 第 6 章介绍数据处理 第 7 章介绍数据可视化 第 8 章介绍数据规整 第 9 章介绍字符串处理 第 10 章介绍因子类型数据 第 11 章介绍函数式编程 第 12 章介绍简单数据框 第 13 章ggplot2几何对象 第 14 章ggplot2的主题 第 15 章ggplot2的标度 第 16 章ggplot2的图例 第 17 章ggplot2扩展内容 第 18 章ggplot2统计图层 第 19 章回望tidyverse之旅 第 20 章介绍tidyverse常用技巧 第 21 章介绍tidyverse进阶技巧 第 22 章介绍数据框的列方向和行方向 第 23 章介绍tidyverse中的across()之美 第 24 章介绍tidyverse中的NA 第 25 章介绍tidyverse中的dot 第 26 章介绍非标准性评估 建模篇 第 27 章介绍模拟与抽样 第 28 章介绍线性模型 第 29 章介绍模型输出结果的规整 第 30 章介绍方差分析 第 31 章介绍统计检验与线性模型的等价性 第 32 章介绍统计推断 第 33 章介绍多层线性模型 第 34 章介绍广义线性模型中的泊松回归 第 35 章介绍logistic回归模型 第 36 章介绍有序logistic回归模型 第 37 章介绍机器学习 第 38 章介绍贝叶斯模型和Stan 应用篇 第 39 章介绍探索性数据分析-诺奖获得者 第 40 章介绍探索性数据分析-奥林匹克 第 41 章介绍探索性数据分析-新冠疫情 第 42 章介绍探索性数据分析-anscombe数据集 第 43 章介绍探索性数据分析-身高体重 第 44 章介绍探索性数据分析-驯鹿迁移 第 45 章介绍探索性数据分析-企鹅的故事 第 46 章介绍探索性数据分析-大学生职业决策 第 47 章介绍探索性数据分析-ames房屋价格 第 48 章介绍探索性数据分析-新冠疫苗有效率的计算 第 49 章介绍网页爬虫 第 50 章介绍社会网络分析 第 51 章介绍文本挖掘 第 52 章介绍时间序列分析 第 53 章介绍地理数据处理 第 54 章介绍tidyverse中行方向的操作 第 55 章介绍科研数据可视化中的统计分布图 第 56 章介绍数据可视化中的配色 第 57 章让你的数据骚动起来 第 58 章介绍我收集的一些有用和有趣的宏包 2、课件源代码和数据 我将持续改进课件，所以欢迎大家提出建议 https://github.com/perlatex/R_for_Data_Science 4、关于课程目标 课程目标: 熟悉数据科学流程，掌握统计编程技能，能运用探索性分析方法，解决基本的实际应用问题，做到学以致用，不是 learning R，而是 learning with R 授课方式: 边写代码边讲 通过案例式、问题式的方法，增强参与感和目标感 课堂要求 自带电脑，配好运行环境 光看李小龙的电影，是学不会功夫的 科学脚手架 科学脚手架，我个人比较喜欢这个比喻(我微信公众号就使用了这个名字)。在教育中，各种知识或技巧就好比建房子用的脚手架，它帮助我们加深理解，逐渐获得独立自主学习的能力。 5、关于如何提问 有的同学，这样一上来就问：老师，我的代码怎么运行不出来呢？或者图省事，干脆手机拍个照片一发。 我想说，要想获得快速的帮助，在问问题之前，请先告诉对方三个信息： 想解决的问题是什么？ 代码是什么？ 报错信息是什么？ 课件中用到的宏包 my_packages &lt;- c(&quot;brms&quot;, &quot;broom&quot;, &quot;broom.mixed&quot;, &quot;colorspace&quot;, &quot;corrr&quot;, &quot;countrycode&quot;, &quot;cowplot&quot;, &quot;cranlogs&quot;, &quot;datapasta&quot;, &quot;datasauRus&quot;, &quot;devtools&quot;, &quot;dplyr&quot;, &quot;equatiomatic&quot;, &quot;forcats&quot;, &quot;gapminder&quot;, &quot;geoshpere&quot;, &quot;gganimate&quot;, &quot;ggbeeswarm&quot;, &quot;ggeffects&quot;, &quot;ggforce&quot;, &quot;gghighlight&quot;, &quot;ggimage&quot;, &quot;ggplot2&quot;, &quot;ggpubr&quot;, &quot;ggraph&quot;, &quot;ggrepel&quot;, &quot;ggridges&quot;, &quot;ggstatsplot&quot;, &quot;ggtext&quot;, &quot;ggthemes&quot;, &quot;gt&quot;, &quot;gtsummary&quot;, &quot;haven&quot;, &quot;here&quot;, &quot;janitor&quot;, &quot;knitr&quot;, &quot;latex2exp&quot;, &quot;lme4&quot;, &quot;lubridate&quot;, &quot;maps&quot;, &quot;margins&quot;, &quot;MASS&quot;, &quot;modelr&quot;, &quot;naniar&quot;, &quot;nycflights13&quot;, &quot;ordinal&quot;, &quot;pacman&quot;, &quot;pacman&quot;, &quot;paletteer&quot;, &quot;palmerpenguins&quot;, &quot;patchwork&quot;, &quot;performance&quot;, &quot;purrr&quot;, &quot;readr&quot;, &quot;readxl&quot;, &quot;remotes&quot;, &quot;reprex&quot;, &quot;rlang&quot;, &quot;rmarkdown&quot;, &quot;rstan&quot;, &quot;rvest&quot;, &quot;scales&quot;, &quot;sf&quot;, &quot;shadowtext&quot;, &quot;showtext&quot;, &quot;slider&quot;, &quot;stars&quot;, &quot;statsExpressions&quot;, &quot;stringr&quot;, &quot;styler&quot;, &quot;tibble&quot;, &quot;tibbletime&quot;, &quot;tidybayes&quot;, &quot;tidygraph&quot;, &quot;tidymodels&quot;, &quot;tidyr&quot;, &quot;tidytext&quot;, &quot;tidyverse&quot;, &quot;tinytex&quot;, &quot;viridis&quot;, &quot;visdat&quot;, &quot;namer&quot;) install.packages(my_packages, repos = &quot;http://cran.rstudio.com&quot;, dependencies = T) 可能用到的开发版本的宏包 #remotes::install_github(&quot;datalorax/equatiomatic&quot;) devtools::install_github(&quot;easystats/report&quot;) devtools::install_github(&quot;kassambara/navdata&quot;) devtools::install_github(&#39;cttobin/ggthemr&#39;) remotes::install_github(&quot;daranzolin/inferregex&quot;) devtools::install_github(&quot;EmilHvitfeldt/gganonymize&quot;) remotes::install_github(&quot;ThinkR-open/remedy&quot;) remotes::install_git(&quot;https://git.rud.is/hrbrmstr/hrbraddins.git&quot;) devtools::install_github(&quot;hadley/emo&quot;) remotes::install_github(&quot;romainfrancois/lay&quot;) remotes::install_github(&quot;kjhealy/covdata&quot;) devtools::install_github(&quot;kbodwin/flair&quot;) devtools::install_github(&quot;seasmith/AlignAssign&quot;) RYouWithMe 致谢 非常感谢川师研究生院的信任，有了您的支持，才会有更多的川师学子了解R的美！ 王敏杰 于 川师图书馆某角落 "],["author.html", "作者简介", " 作者简介 王敏杰，四川师范大学研究生公选课《数据科学中的R语言》和《社会科学中的统计学》授课老师，西南交通大学量子物理学博士，爱好数据科学，喜欢用R和Stan统计编程， 联系方式 38552109@qq.com "],["intro-ds.html", "第 1 章 数据科学与R语言 1.1 什么是数据科学 1.2 什么是R 1.3 R能干什么 1.4 为什么选择 R 1.5 R 语言之美，你值得拥有 1.6 当今最值得学习的数据科学语言 1.7 一见钟情，还是相见恨晚？ 1.8 推荐阅读", " 第 1 章 数据科学与R语言 马克思曾说过：“一门科学只有当它达到能够成功运用数学时，才算真正得到发展。”数学为数据科学提供了坚实的理论基础，数据科学也为数学与实际应用之间建立起一个直接的桥梁。 1.1 什么是数据科学 数据科学是综合了统计学、计算机科学和领域知识的交叉学科，其基本内容就是用数据的方法研究科学，用科学的方法研究数据（鄂维南院士）。2010年，Drew Conway画了一张数据科学的韦恩图 从数据科学所涉及的学科领域来看，其知识结构不仅仅包括数学、统计学、计算机科学、信息科学等在内的基础性理论，还应该包括社会学、物理学、情报学、生物医学等在内的专业性领域理论。 （事实上，编程是工具，统计是灵魂，专业是核心，最重要的最下面那个部分，专业领域的知识） 1.2 什么是R 1.2.1 R那些事 1992年，新西兰奥克兰大学统计学教授 Ross Ihaka 和 Robert Gentleman，为了方便地给学生教授统计学课程，他们设计开发了R语言（他们名字的首字母都是R）。 2000年，R1.0.0 发布 2004年，第一届国际useR!会议（随后每年举办一次） 2005年，ggplot2宏包（2018.8 - 2019.8下载量超过 1.3 亿次） 2012年，R2.15.2 发布 2013年，R3.0.2 发布, CRAN上的宏包数量5026个 2016年，Rstudio公司推出 tidyverse 宏包（数据科学当前最流行的R宏包） 2017年，R3.4.1 发布，CRAN上的宏包数量10875个 2019年，R3.6.1 发布，CRAN上的宏包数量15102个 2020年，R4.0.0 发布，CRAN上的宏包数量16054个 想了解R语言的发展历史，可阅读The History of R 1.2.2 R是什么 官网定义：https://www.r-project.org/ R语言是用于统计分析、图形表示和报告的编程语言: R 是一个统计编程语言（statistical programming） R 可运行于多种平台之上，包括Windows、UNIX 和 Mac OS X R 拥有顶尖水准的制图功能 R 是免费的 R 应用广泛，拥有丰富的库包 活跃的社区 1.2.3 R语言发展趋势 TIOBE index 1.2.4 R路上的大神 2019 年 8 月，国际统计学年会将考普斯总统奖（The Committee of Presidents of Statistical Societies Awards，简称 COPSS 奖，被誉为统计学的诺贝尔奖）奖颁给 tidyverse的作者Hadley Wickham后，充分说明R语言得到了学术界的肯定和认可，我相信未来它在自然科学、社会科学和工业领域中的应用前景会非常光明。 Hadley Wickham R路上的大神 改变了R语言的人 1.3 R能干什么 1.3.1 数据科学流程 Hadley Wickham将数据科学流程分解成6个环节 即数据导入、数据规整、数据处理、可视化、建模以及形成可重复性报告，整个分析和探索过程都在一个程序代码中完成，这种方式对训练我们的数据思维非常有帮助。 1.3.2 tidyverse家族 tidyverse套餐，其主要成员包括 功能 宏包 有颜值担当 ggplot2 数据处理王者 dplyr 数据转换专家 tidyr 数据载入利器 readr 循环加速器 purrr 强化数据框 tibble 字符串处理 stringr 因子处理 forcats 1.3.3 R &amp; tidyverse 四大优势 序号 内容 代码演示 1 统计 Download 01_stats.R 2 可视化 Download 02_visual.R 3 探索性分析 Download 03_eda.R 4 可重复性报告 Download 04_reproducible.Rmd 看了这些代码，可能第一眼感觉是这样的 图 1.1: 图片来自电影《降临》 但我更希望这门课结束后，大家的感觉是这样的 图 1.2: 图片来自美剧《权利的游戏》 1.4 为什么选择 R 1.4.1 社会科学需要统计 看到这图，有同学可能会有同感。我认为，一个学科之所以成为一门科学，必须要有数学作 为基础。我说这话，相信很多人会反驳我。我接受反驳。但我还是会坚持我的观点。很多同学在选专业的时候，导师会说，这个专业不会用太多数学，事实上被忽悠了，尤其在（新文科建设、跨学科研究）背景下，社会科学（包括心理学、语言学）都在交叉融合，都需要用数学和计算机。所以，我们不是学统计的，但需要用统计。一个更残酷的现实，用统计的，往往不是学统计的。 1.4.2 社会科学需要可视化 我们人，都是视觉动物，都喜欢看漂亮美好的东西。如果文章或者报告太多表格，不会 给人留下深刻影响；相反，用图片，重点突出、观点明确，一图胜千言，很容易传递信息。当然，前提是，画图要画的好。 事实上，可视化，一半是科学、一半是艺术。 又一个残酷的现实，在这个看脸的时代，没有好看的皮囊，没人愿意了解你的灵魂。 1.4.3 社会科学需要编程 为什么要统计编程，回答这个问题，相 当于回答，为什么不能用 excel 做数据分析？画个图说明下 对于数据量不大，或者复杂程度不高的需求来说，excel很方便也很直观。但随着数据量或复杂程度不断增大，excel解决起来难度系数就陡增，或者无法搞定，这就需要借助编程完成。也就说，掌握了编程技能，对于简单的问题和复杂的问题，难度系数是差不多了。 所以，第三残酷的现实：现在小学生都开始学编程了。 1.4.4 社会科学需要可重复性 科学的可重复性危机，已经成为举世瞩目的热点议题。 科研结果可重复性低的原因很多很多。不可重复，说明事情没那么简单。 或许，科学固有不确定性，但我们需要从研究方法、实验 设计和统计方法方面改进。 所以，第四个残酷的现实：科学研究的方向是（开放科学 框架 (Open Science Framework, OSF)）, 正如 Nature 期刊 要求的一样，需要公布原始数据和如何分析的代码 1.5 R 语言之美，你值得拥有 我想，R语言之美，你值得拥有，因为它可以缓解你的压力 首先，R语言做统计分析，是它的看家本领，非常好用 (可以缓解第一个残酷) 其次，ggplot2画图，是颜值担当，非常好看，一直被模仿，从未被超越(可以解决第二个残酷) tidyverse来编程，代码可读性强，用的是人类语言， 非常好学 （在解决第三个残酷现实的同时，还让你感受到乐趣） 关于第四点，需要特别说明下，Rmarkdown 并不能保证研究结果可重复性，因为影响结果可重复性的原因很多很多，这不是程序语言能解决的事。但是，R语言能帮你的，就是减少低级的计算错误和复制粘贴等繁琐工作，可以生成html、word或者pdf 格式的可重复性报告文档，可以方便快捷做幻灯片、海报、论文、书籍、网页。所以还是挺好玩的. 所以，R语言之美，体现在好用、好看、好学、好玩。 序号 内容 特性 评价 1 统计分析 看家本领 好用 2 ggplot2画图 颜值担当 好看 3 tidyverse语法 人类语言 好学 4 可重复性报告 方便快捷 好玩 1.6 当今最值得学习的数据科学语言 2016年权威机构KDnuggets做过调研，显示数据科学领域最受欢迎的工具，是python和R两种语言 事实上，python和R都是非常强大的工具，两者各有优劣，作为初学者，究竟选择谁? 可以参考这篇文章，这篇文章旗帜鲜明地指出，R语言，是当今最值得学习的数据科学语言。为此做了详细的对比，并罗列了很多理由，其中的3点理由很重要，我圈了出来(传统的统计学，贝叶斯新统计、数据可视化)。 事实上，数据科学，是和数据打交道（定义：用科学的方法研究数据，用数据的方法研究科学），目的要利用（计算机和统计知识）推动学科发展，不是把大家培养成程序员。 所以，我看完这篇文章的感受是： 第一、在数据科学领域，python能做的，R也能做，甚至更好，比如可视化。 第二、有一定R基础后，对统计学的学习帮助很大，这是 python 语言不具备的 第三、我觉得 R的语法 更符合人的思维方式。尤其 tidyverse 语法一致性（学习一个宏包，可以帮助理解其他宏包） 代码可读性，接近人类语言 ( %&gt;% 太酷了 ) 1.7 一见钟情，还是相见恨晚？ 1.8 推荐阅读 为什么R语言是当今最值得学习的数据科学语言 R for Data Science https://www.tidyverse.org/ "],["intro-R.html", "第 2 章 R语言基础 2.1 安装 R 2.2 安装 RStudio 2.3 开始 2.4 一切都是对象 2.5 数据类型 2.6 数据结构 2.7 函数 2.8 脚本 2.9 宏包 2.10 可能的问题 2.11 如何获取帮助 2.12 R 语言社区 2.13 延伸阅读", " 第 2 章 R语言基础 R 软件是一个自由、开源软件平台，具有统计分析、可视化和编程的强大功能。 你可以从这里免费下载。 为了更好的使用 R 软件，我推荐大家使用 RStudio这个 IDE。这里有个在线教程帮助我们熟悉 R 和 RStudio。 2.1 安装 R 我们从官方网站http://cran.r-project.org下载, 网站界面感觉有点朴素: 2.2 安装 RStudio 安装完R， 还需要安装RStudio。有同学可能要问 R 与 RStudio 是什么关系呢？打个比方吧，R 就像汽车的发动机, RStudio 就是汽车的仪表盘。但我更觉得 R 是有趣的灵魂，而 Rstudio 是好看的皮囊。 同样，我们从官方网站下载并安装，如果你是苹果系统的用户，选择苹果系统对应的rstudio版本即可。 https://www.rstudio.com/download 选择RStudio Desktop 这里有个小小的提示： 电脑不要用中文用户名，否则Rstudio会杠上中文用户名 尽量安装在非系统盘，比如，可以选择安装在D盘 安装路径不要有中文和空格。比如，这样就比较好 D:/R D:/Rstudio 2.3 开始 安装完毕后，从windos开始菜单，点开rstudio图标，就打开了rstudio的窗口，界面效果如下 RStudio 的用户界面十分友好，想要运行一段R代码，只需要在 RStudio 控制台面板最下面 (Console)一行内键入R 代码，然后回车即可。比如我们键入1 + 1 并按回车后，RStudio 将显示如下结果 1 + 1 ## [1] 2 log(8) ## [1] 2.079 1:15 ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 2.4 一切都是对象 在R中存储的数据称为对象， R语言数据处理实际上就是不断的创建和操控这些对象。创建一个R对象，首先确定一个名称，然后使用 赋值操作符 &lt;-，将数据赋值给它。比如，如果想给变量 x 赋值为5，在命令行中可以这样写 x &lt;- 5 ，然后回车. x &lt;- 5 当键入x 然后回车，就打印出 x 的值。当然也可以使用命令print(x)，结果一样。 x ## [1] 5 x + 2 ## [1] 7 die &lt;- 1:6 die ## [1] 1 2 3 4 5 6 die / 2 ## [1] 0.5 1.0 1.5 2.0 2.5 3.0 die * die ## [1] 1 4 9 16 25 36 die %*% die ## [,1] ## [1,] 91 die %o% die ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 2 3 4 5 6 ## [2,] 2 4 6 8 10 12 ## [3,] 3 6 9 12 15 18 ## [4,] 4 8 12 16 20 24 ## [5,] 5 10 15 20 25 30 ## [6,] 6 12 18 24 30 36 2.5 数据类型 数值型 3 ## [1] 3 5000 ## [1] 5000 3e+06 ## [1] 3e+06 class(0.0001) ## [1] &quot;numeric&quot; 字符串型 &quot;hello&quot; ## [1] &quot;hello&quot; &quot;girl&quot; ## [1] &quot;girl&quot; &quot;1&quot; # 注意 1 和 &quot;1&quot; 的区别 ## [1] &quot;1&quot; class(&quot;1&quot;) ## [1] &quot;character&quot; 逻辑型 TRUE ## [1] TRUE FALSE ## [1] FALSE 3 &lt; 4 ## [1] TRUE class(T) ## [1] &quot;logical&quot; 3 &lt; 4 ## [1] TRUE 因子型 因子型可以看作是字符串向量的增强版，比如 “Alice,” “Bob,” “Carol,” “Ted” 是四个人名的字符串，因子型就在字符串的基础上，告诉计算机他们每个人都是有官阶层级的，比如 “排长”，“团长,” “师长,” “军长,” 也就说“Ted”排第一，“Carol”排第二，“Bob”排第三，“Alice” 排最后， 相比字符串而言，多了官阶层级信息。 fac &lt;- factor(c(&quot;Alice&quot;, &quot;Bob&quot;, &quot;Carol&quot;, &quot;Ted&quot;), levels = c(&quot;Ted&quot;, &quot;Carol&quot;, &quot;Bob&quot;, &quot;Alice&quot;) ) fac ## [1] Alice Bob Carol Ted ## Levels: Ted Carol Bob Alice class(fac) ## [1] &quot;factor&quot; 再比如，General上将；Colonel上校；Captain上尉, 如果没有指定层级levels，c(\"Colonel\", \"General\", \"Captain\")就是一个常规的字符串向量，若指定了层级levels，这个字符串就有了军衔信息. factor(c(&quot;Colonel&quot;, &quot;General&quot;, &quot;Captain&quot;), levels = c(&quot;General&quot;, &quot;Colonel&quot;, &quot;Captain&quot;) ) ## [1] Colonel General Captain ## Levels: General Colonel Captain 2.6 数据结构 大家前面看到x &lt;- 1 和 x &lt;- c(1, 2, 3)，这就是最简单的数据对象，叫原子型向量。 用c函数将一组数据构造成向量，要求每个元素用逗 号分隔，且每个元素的数据类型是一致的，可以把它想象成手里拿着一个糖葫芦 die &lt;- c(2, 4, 3, 1, 5, 7) die ## [1] 2 4 3 1 5 7 长度为 1 的原子型向量 x &lt;- c(1) # or x &lt;- 1 强制转换 vec &lt;- c(&quot;R&quot;, 1, TRUE) class(vec) ## [1] &quot;character&quot; 你依次输入，就发现三种类型的优先级关系 c(TRUE, 1) # 被转换成了数值型 ## [1] 1 1 c( 1, &quot;R&quot;) # 被转换成了字符串型 ## [1] &quot;1&quot; &quot;R&quot; c(TRUE, 1, &quot;R&quot;) # 被转换成了字符串型 ## [1] &quot;TRUE&quot; &quot;1&quot; &quot;R&quot; 大家看到前面die %o% die 是矩阵类型，矩阵就是二维数组 可以用matrix 函数创建，可以想象成糖葫芦太多，一个棒子串不下，就多用几根棒子串。 m &lt;- matrix(c(2, 4, 3, 1, 5, 7), nrow = 2, ncol = 3, byrow = TRUE ) m ## [,1] [,2] [,3] ## [1,] 2 4 3 ## [2,] 1 5 7 数据对象：数组 array 函数生成n维数组，可以想象成我们吃的土司面包一样。 ar &lt;- array(c(11:14, 21:24, 31:34), dim = c(2, 2, 3)) ar ## , , 1 ## ## [,1] [,2] ## [1,] 11 13 ## [2,] 12 14 ## ## , , 2 ## ## [,1] [,2] ## [1,] 21 23 ## [2,] 22 24 ## ## , , 3 ## ## [,1] [,2] ## [1,] 31 33 ## [2,] 32 34 数据对象：列表 与c函数创建向量的方式相似，不同的元素用逗号分开。不同的是，列表允许不同的数据类型（数值型，字符型，逻辑型等）， 而向量要求每个元素的数据类型必须相同。可以想象成小火车，每节车厢可以装自己喜欢的东西 list1 &lt;- list(100:110, &quot;R&quot;, c(2, 4, 3, 1, 5, 7)) list1 ## [[1]] ## [1] 100 101 102 103 104 105 106 107 108 109 110 ## ## [[2]] ## [1] &quot;R&quot; ## ## [[3]] ## [1] 2 4 3 1 5 7 数据对象：数据框，这个不用想象，它与我们经常用的excel表格一个样 data.frame函数构建 df &lt;- data.frame( name = c(&quot;ace&quot;, &quot;bob&quot;, &quot;carl&quot;, &quot;kaite&quot;), age = c(21, 14, 13, 15), sex = c(&quot;girl&quot;, &quot;boy&quot;, &quot;boy&quot;, &quot;girl&quot;) ) df R 对象的数据结构(向量、矩阵、数组、列表和数据框)，总结如下 为了更好地理解相关概念，建议大家阅读Garrett Grolemund的 hopr这本书 (Grolemund 2014)。 2.7 函数 R 语言的强大在于使用函数操控各种对象，你可以把对象看作是名词，而函数看作是动词。 我们用一个简单的例子，sum()来演示函数如何工作的。这个函数的功能正如它的名字一样，对输入的各个对象求和，然后返回求和后的值，你可以在命令行中键入?sum()查看其官方文档。 sum()后的结果可以直接显示出来，也可以赋名。比如下面代码，首先计算x + 10并赋以名字y， 然后第二行中打印出来这个新创建的对象y y &lt;- sum(x, 10) y ## [1] 11 因为代码的灵活性，可以不断地重新定义对象。只要数据发生改变，原来的代码就会返回新的值。比如，对x重新赋值为 15， 同样运行sum()函数，这次我们不赋值给对象y，而是让它直接显示 x &lt;- 15 sum(x, 10) ## [1] 25 再比如 round(3.14159) ## [1] 3 mean(1:6) ## [1] 3.5 n &lt;- 100 x &lt;- seq(1, n) sum(x) ## [1] 5050 dt &lt;- mtcars[, 1:4] head(dt) cor(dt) ## mpg cyl disp hp ## mpg 1.0000 -0.8522 -0.8476 -0.7762 ## cyl -0.8522 1.0000 0.9020 0.8324 ## disp -0.8476 0.9020 1.0000 0.7909 ## hp -0.7762 0.8324 0.7909 1.0000 2.8 脚本 如果我们已经写好了一段R程序，我们可以保存为脚本文件，脚本文件通常以.R作为文件的后缀名。比如我们可以将刚才创建x和 y对象的命令，保存为脚本文件my_script.R。 这样我们可以在其它时间修改和重新运行它。 在RStudio中，你可以通过菜单栏依此点击File &gt; New File &gt; R Script 来创建一个新的脚本。 强烈建议大家在运行代码之前，使用脚本的形式编写和编辑自己的程序，养成这样的习惯后，你今后所有的工作都有案可查，并且具有可重复性。 点击 Run 或者 Source 运行脚本 点击 Run, 运行光标所在行的代码 点击 Source，从头到尾运行全部代码 2.9 宏包 R 语言的强大还在于各种宏包，一般在The Comprehensive R Archive Network (CRAN)下载安装。宏包扩展了R语言本身的各种功能，也为解决问题提供了各种方案。截至撰写本书时止，CRAN上大约有1.4万个宏包可以使用。但由于各种包接口不统一，语法不一致，也带来一些困扰。为了解决这个问题，RStudio 公司的Hadley Wickham 与其带领的团队推出了tidyverse宏包， tidyverse将常用的宏包整合在一起，并保持了语法的一致性。可以说，tidyverse宏包是R语言入门 学习的首选。 本书正是基于tidyverse宏包而成的，本书也将通过一些例子不断地展示tidyverse在数据分析和可视化的应用。 可以用如下命令安装 ggplot2 宏包: # 安装单个包 install.packages(&quot;tidyverse&quot;) # 安装多个包 install.packages(c(&quot;ggplot2&quot;, &quot;devtools&quot;, &quot;dplyr&quot;)) 2.10 可能的问题 问题1：如果下载速度太慢，可以选择国内镜像， 然后再输入命令install.packages(\"tidyverse\")，或者直接指定清华大学镜像 install.packages(&quot;tidyverse&quot;, repos = &quot;http://mirrors.tuna.tsinghua.edu.cn/CRAN&quot;) 问题2：如果遇到如下报错信息 Warning in install.packages : unable to access index for repository http://cran.rstudio.com/src/contrib: cannot open URL &#39;http://cran.rstudio.com/src/contrib/PACKAGES&#39; 输入下面命令后，再试试 options(download.file.method=&quot;libcurl&quot;) 或者打开D:\\R\\etc\\Rprofile.site，添加以下内容： local({r &lt;- getOption(&quot;repos&quot;) r[&quot;CRAN&quot;] &lt;- &quot;http://mirrors.tuna.tsinghua.edu.cn/CRAN&quot; options(repos=r)}) options(download.file.method=&quot;libcurl&quot;) 问题3：如果打开代码是乱码，可以试试修改如下设置 问题4：如果每次打开Rstudio非常慢，可以在Rstudio里将这几个选项取消 问题5：如果 Rstudio 打开是空白 很大的可能是你的电脑用户名是中文的，修改用户名再试试 问题6：安装过程中提示，我的系统不能兼容 64 位的 Rstudio。 可能你是低版本的windows系统，建议安装旧版本的Rstudio，可以在这里找到旧版本. 更多Rstudio的使用，可参考这里introducing-the-rstudio。 2.11 如何获取帮助 记住和学习所有的函数几乎是不可能的 打开函数的帮助页面(Rstudio右下面板的Help选项卡) ?sqrt ?gather ?spread ?ggplot2 ?scale ?map_dfr 比如： 2.12 R 语言社区 R 语言社区非常友好，可以在这里找到你问题的答案 twitter: https://twitter.com/ R-Bloggers: https://www.r-bloggers.com/ kaggle: https://www.kaggle.com/ stackoverflow: https://stackoverflow.com/questions/tagged/r rstudio: https://community.rstudio.com/ 2.13 延伸阅读 如何获取向量a &lt;- c(\"a\", \"c\", \"e\")的第二个元素？矩阵和列表的时候，又该如何? 试试 c(1, FALSE) 与 c(\"a\", TRUE) 会是什么？ 1 == \"1\" 和 -1 &lt; FALSE 为什么为真？ \"one\" &lt; 2 为什么为假？ R语言里可以构造哪些数据对象？ 数据框可以装载哪些数据类型的数据？ 数据框和列表区别在哪里？ ()与[]区别？ "],["subsetting.html", "第 3 章 子集选取 3.1 向量 3.2 列表 3.3 矩阵 3.4 数据框 3.5 增强型数据框 3.6 延伸阅读", " 第 3 章 子集选取 子集选取单独作一章，说明它确实很重要。 上一章讲对象、数据类型和数据结构等概念。为了方便理解，我这里打个比方， 对象就是我们在计算机里新建了存储空间，好比一个盒子， 我们可以往盒子里面装东西，比如鞋子、袜子、糖果东西。数据类型就是指我们装的东西的类型，比如是吃的还是用的呢， 只不过计算机用的是机器语言，称之为，数值型、字符串型、因子型等等。 数据结构就是盒子里东西的摆放次序，是相同的（同质）放一起，还是不同的（异质）放一起， 相同的放一起就是向量、矩阵；不同的放一起可能是列表和数据框。 子集选取，就是从盒子里取东西出来1。 3.1 向量 对于原子型向量，我们有至少四种选取子集的方法 x &lt;- c(1.1, 2.2, 3.3, 4.4, 5.5) 正整数： 指定向量元素中的位置 x[1] ## [1] 1.1 x[c(1,3)] ## [1] 1.1 3.3 x[c(3,1)] ## [1] 3.3 1.1 负整数：删除指定位置的元素 x[-2] ## [1] 1.1 3.3 4.4 5.5 x[c(-3, -4)] ## [1] 1.1 2.2 5.5 逻辑向量：将TRUE对应位置的元素提取出来 x[c(TRUE, FALSE, TRUE, FALSE, TRUE)] ## [1] 1.1 3.3 5.5 常用的一种情形；筛选出大于某个值的所有元素 x &gt; 3 ## [1] FALSE FALSE TRUE TRUE TRUE x[x &gt; 3] ## [1] 3.3 4.4 5.5 如果是命名向量 y &lt;- c(&quot;a&quot; = 11, &quot;b&quot; = 12, &quot;c&quot; = 13, &quot;d&quot; = 14) y ## a b c d ## 11 12 13 14 我们可以用命名向量，返回其对应位置的向量 y[c(&quot;d&quot;, &quot;c&quot;, &quot;a&quot;)] ## d c a ## 14 13 11 3.2 列表 对列表取子集，和向量的方法一样。使用 [ 总是返回列表， l &lt;- list(&quot;one&quot; = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), &quot;two&quot; = c(1:5), &quot;three&quot; = c(TRUE, FALSE) ) l ## $one ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; ## ## $two ## [1] 1 2 3 4 5 ## ## $three ## [1] TRUE FALSE l[1] ## $one ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 如果想列表中的元素，需要使用 [[ l[[1]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 也可以使用其中的元素名，比如[[\"one\"]]， l[[&quot;one&quot;]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 程序员觉得以上太麻烦了，要写太多的字符了，所以用$来简写 l$one ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 所以请记住 [ 和[[的区别 x$y 是 x[[\"y\"]]的简写 3.3 矩阵 a &lt;- matrix(1:9, nrow = 3) a ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 我们取第1行到第2行的2-3列，[1:2, 2:3]，中间以逗号分隔，于是得到一个新的矩阵 a[1:2, 2:3] ## [,1] [,2] ## [1,] 4 7 ## [2,] 5 8 默认情况下, [ 会将获取的数据，以尽可能低的维度形式呈现。比如 a[1, 1:2] ## [1] 1 4 表示第1行的第1、2列，此时不是\\(1 \\times 2\\)矩阵，而是包含了两个元素的向量。 以尽可能低的维度形式呈现，换句话说，这个1, 4长的像个矩阵，又有点像向量，向量的维度比矩阵低，那就是向量吧。 有些时候，我们想保留所有的行或者列，比如 行方向，只选取第 1 行到第 2 行 列方向，选取所有列 可以这样简写 a[1:2, ] ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 对于下面这种情况，想想，会输出什么 a[ , ] ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 可以再简化点？ a[] ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 是不是可以再简化点？ a ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 3.4 数据框 数据框具有list和matrix的双重属性，因此 当选取数据框的某几列的时候，可以和list一样，指定元素位置，比如df[1:2]选取前两列 也可以像矩阵一样，使用行和列的标识选取，比如df[1:3, ]选取前三行的所有列 df &lt;- data.frame(x = 1:4, y = 4:1, z = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) ) df # Like a list df[c(&quot;x&quot;, &quot;z&quot;)] # Like a matrix df[, c(&quot;x&quot;, &quot;z&quot;)] 也可以通过行和列的位置 df[1:2] df[1:3, ] 当遇到单行或单列的时候，也和矩阵一样，数据会降维 df[, &quot;x&quot;] ## [1] 1 2 3 4 如果想避免降维，需要多写一句话 df[, &quot;x&quot;, drop = FALSE] 这样输出的还是矩阵形式, 但程序员总是偷懒的，有时候我们也容易忘记写drop = FALSE， 所以我比较喜欢下面的tibble. 3.5 增强型数据框 tibble是增强型的data.frame，选取tibble的行或者列，即使遇到单行或者单列的时候，数据也不会降维，总是返回tibble，即仍然是数据框的形式。 tb &lt;- tibble::tibble( x = 1:4, y = 4:1, z = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) ) tb tb[&quot;x&quot;] tb[, &quot;x&quot;] 除此以外，tibble还有很多优良的特性，我们会在第 12 章专门讲 3.6 延伸阅读 如何获取matrix(1:9, nrow = 3)上对角元? 对角元？ 对数据框，思考df[\"x\"]， df[[\"x\"]]， df$x三者的区别? 如果x是一个矩阵，请问 x[] &lt;- 0 和x &lt;- 0 有什么区别？ m &lt;- matrix(1:9, nrow = 3) m diag(m) upper.tri(m, diag = FALSE) m[upper.tri(m, diag = FALSE)] https://github.com/hadley/ggplot2movies/blob/master/R/movies.R "],["rmarkdown.html", "第 4 章 可重复性报告 4.1 什么是Rmarkdown 4.2 markdown 基本语法 4.3 Hello R Markdown 4.4 生成html文档 4.5 生成word文档 4.6 生成pdf文档 4.7 使用方法 4.8 延伸阅读", " 第 4 章 可重复性报告 有时候，我们需要展示和分享我们的数据分析结果给同行、老板或者老师。 那么，为了让老板能快速地的理解我们的分析思路和方法， 最好的方法，就是将分析背景、分析过程、分析结果以及图表等形成报告，让读者能重复和验证我们的结果，确保结论的真实可信。 因此，本章就将介绍如何生成分析报告（可重复性报告）。 4.1 什么是Rmarkdown 4.2 markdown 基本语法 # This is a title # 第一章 （注意 &quot;#&quot; 与 &quot;第一章&quot;之间有空格） ## 第一节 （同上，&quot;##&quot; 与 &quot;第一节&quot;之间有空格） This is a sentence. Now a list begins: - no importance - again - repeat A numbered list: 1. first 2. second __bold__, _italic_, ~~strike through~~ 4.3 Hello R Markdown Rstudio create Rmd file ： File -&gt; New File -&gt; R Markdown. 基本构成（图中绿色括号地方） metadata text code 点击knit（图中红色地方），选择想要输出的文档格式即可。 4.4 生成html文档 希望html文档有章节号、目录或者更好显示表格，可以修改头文件（用下面的内容替换Rmarkdown的头文件） --- title: Habits author: John Doe date: &quot;2021-01-09&quot; output: html_document: df_print: paged toc: yes number_sections: yes --- 4.5 生成word文档 rmarkdown 生成的word功能不是很多，推荐使用officedown , officer, flextable宏包 4.6 生成pdf文档 pdf文档可以插入漂亮的矢量图和优雅的数学公式，所以备受同学们的喜欢。但往往我们写中文的时候，编译不成功。这里就来讲讲如何解决这些问题，推荐阅读这里，或者看这个视频。 Instructions 安装最新版本 R (&gt;3.5) 和 RStudio Desktop (&gt;1.2). 安装pdf查看器，sumatrapdf网站 安装 LaTeX. 然而这个软件会比较大 (e.g. MacTeX is approximate 3.9G). 如果你之前没有安装过 LaTeX，我推荐你安装轻量级的 tinytex. 安装方法如下，打开R，然后再命令行输入: install.packages(&quot;tinytex&quot;) tinytex::install_tinytex(dir = &quot;D:\\\\Tinytex&quot;, force = T) 中途会有两次警告，按 “ 确定 ” 就可以了。 修改头文件，用下面的内容替换Rmarkdown的头文件, 不要修改缩进 --- title: &#39;Going deeper with dplyr&#39; author: &quot;王小二&quot; date: &quot;`r Sys.Date()`&quot; output: pdf_document: latex_engine: xelatex extra_dependencies: ctex: UTF8 number_sections: yes df_print: kable toc: yes classoptions: &quot;hyperref, 12pt, a4paper&quot; --- 4.7 使用方法 4.7.1 插入公式 我相信你已经熟悉了latex语法，那么我们在Rmarkdwon里输入 $$\\frac{\\sum (\\bar{x} - x_i)^2}{n-1}$$，那么实际输出: \\[\\frac{\\sum (\\bar{x} - x_i)^2}{n-1}\\] 也可以使用latex的等式环境， 比如 $$\\Theta = \\begin{pmatrix}\\alpha &amp; \\beta\\\\ \\gamma &amp; \\delta \\end{pmatrix}$$ 输出 \\[ \\Theta = \\begin{pmatrix}\\alpha &amp; \\beta\\\\ \\gamma &amp; \\delta \\end{pmatrix} \\] 4.7.2 插入图片 ```{r, out.width=&#39;35%&#39;, fig.align=&#39;left&#39;, fig.cap=&#39;this is caption&#39;} knitr::include_graphics(&quot;images/R_logo.png&quot;) ``` 图 4.1: this is caption 4.7.3 运行代码 summary(cars) ## speed dist ## Min. : 4.0 Min. : 2 ## 1st Qu.:12.0 1st Qu.: 26 ## Median :15.0 Median : 36 ## Mean :15.4 Mean : 43 ## 3rd Qu.:19.0 3rd Qu.: 56 ## Max. :25.0 Max. :120 4.7.4 表格 ```{r tables-mtcars} knitr::kable(iris[1:5, ], caption = &quot;A caption&quot;) ``` 表 4.1: A caption Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 需要更优美的表格，可参考这里 4.7.5 生成图片 ```{r} plot(pressure) ``` 或者 ```{r, out.width = &#39;85%&#39;, fig.showtext = TRUE} library(tidyverse) library(nycflights13) library(showtext) showtext_auto() flights %&gt;% group_by(dest) %&gt;% summarize( count = n(), dist = mean(distance, na.rm = TRUE), delay = mean(arr_delay, na.rm = TRUE) ) %&gt;% dplyr::filter(delay &gt; 0, count &gt; 20, dest != &quot;HNL&quot;) %&gt;% ggplot(mapping = aes(x = dist, y = delay)) + geom_point(aes(size = count), alpha = 1 / 3) + geom_smooth(se = FALSE) + ggtitle(&quot;这是我的标题&quot;) ``` Download my_pdf_document.Rmd 4.8 延伸阅读 Markdown tutorial https://www.markdowntutorial.com (10分钟学完) LaTeX tutorial https://www.latex-tutorial.com/quick-start/ Rmarkdown 介绍 https://bookdown.org/yihui/rmarkdown/ Rmarkdown 手册 https://bookdown.org/yihui/rmarkdown-cookbook/ "],["readr.html", "第 5 章 读取数据 5.1 数据科学中的文件管理 5.2 读取文件 5.3 范例 5.4 乱码情形", " 第 5 章 读取数据 在学习R语言过程中，除了使用内置的数据集外，我们更多的需要导入外部数据， 比如实验观察数据、社会调研的数据等等。 在讲如何读取数据到 R之前，先介绍下数据科学中的项目管理。 5.1 数据科学中的文件管理 把项目所需的文件（代码、数据、图片等），放在一个文件夹里 5.1.1 文件夹命名 推荐我自己的文件夹命名习惯 (项目名+日期)，注意这里不要有中文和空格, 比如下面风格的就比较好 homework20201014 project20201014 Emotional_experiment20201014 5.1.2 项目文件结构 5.2 读取文件 事实上，R语言提供了很多读取数据的函数。下表列出了常见文件格式的读取方法 文件格式 R 函数 .txt read.table() .csv read.csv() and readr::read_csv() .xls and .xlsx readxl::read_excel() and openxlsx::read.xlsx() .sav(SPSS files) haven::read_sav() and foreign::read.spss() .Rdata or rda load() .rds readRDS() and readr::read_rds() .dta haven::read_dta() and haven::read_stata() .sas7bdat(SAS files) haven::read_sas() Internet download.file() 5.3 范例 d &lt;- read.table(file= &quot;./data/txt_file.txt&quot;, header = TRUE) load(file = &quot;./data/rda_file.rda&quot;) d &lt;- readRDS(file = &quot;./data/rds_file.rds&quot;) library(readr) d &lt;- read_csv(file = &quot;./data/csv_file.csv&quot;) url &lt;- &quot;https://raw.githubusercontent.com/perlatex/R_for_Data_Science/master/demo_data/wages.csv&quot; d &lt;- read_csv(url) library(readxl) d &lt;- read_excel(&quot;./data/vowel_data.xlsx&quot;) library(haven) d &lt;- read_dta(&quot;./data/cfps2010.dta&quot;) 5.4 乱码情形 遇到乱码的情况，这里有个小小的提示： 可以先用记事本转换成“UTF-8”编码， 或者指定编码格式，比如read.table(…, fileEncoding = “UTF-8”)，再试试。 "],["dplyr.html", "第 6 章 数据处理 6.1 mutate() 6.2 管道 %&gt;% 6.3 select() 6.4 filter() 6.5 summarise()统计 6.6 group_by()分组 6.7 arrange()排序 6.8 left_join() 6.9 right_join() 6.10 延伸阅读", " 第 6 章 数据处理 本章我们介绍tidyverse里数据处理的神器dplyr宏包。首先，我们加载该宏包 library(dplyr) dplyr 定义了数据处理的规范语法，其中主要包含以下九个主要的函数。 mutate(), select(), filter() summarise(), group_by(), arrange() left_join(), right_join()， full_join() 我们依次介绍 6.1 mutate() 假定我们有一数据框，包含三位学生的英语和数学 df &lt;- data.frame( name = c(&quot;Alice&quot;, &quot;Alice&quot;, &quot;Bob&quot;, &quot;Bob&quot;, &quot;Carol&quot;, &quot;Carol&quot;), type = c(&quot;english&quot;, &quot;math&quot;, &quot;english&quot;, &quot;math&quot;, &quot;english&quot;, &quot;math&quot;) ) df ## name type ## 1 Alice english ## 2 Alice math ## 3 Bob english ## 4 Bob math ## 5 Carol english ## 6 Carol math 这里有他们的最近的考试成绩，我们想增加到数据框里去 score2020 &lt;- c(80.2, 90.5, 92.2, 90.8, 82.5, 84.6) score2020 ## [1] 80.2 90.5 92.2 90.8 82.5 84.6 使用传统的方法 df$newscore &lt;- score2020 df ## name type newscore ## 1 Alice english 80.2 ## 2 Alice math 90.5 ## 3 Bob english 92.2 ## 4 Bob math 90.8 ## 5 Carol english 82.5 ## 6 Carol math 84.6 dplyr语法这样写 mutate(df, newscore = score2020) ## name type newscore ## 1 Alice english 80.2 ## 2 Alice math 90.5 ## 3 Bob english 92.2 ## 4 Bob math 90.8 ## 5 Carol english 82.5 ## 6 Carol math 84.6 mutate() 函数 mutate(.data = df, newscore = score2020) 第一参数是我们要处理的数据框，比如这里的df， 第二个参数是newscore = score2020，等号左边的newscore是我们打算创建一个新列，而取的列名； 等号右边是装着学生成绩的向量（注意，向量 的长度要与数据框的行数相等，比如这里长度都是6） 6.2 管道 %&gt;% 这里有必要介绍下管道操作符%&gt;%. c(1:10) ## [1] 1 2 3 4 5 6 7 8 9 10 sum(c(1:10)) ## [1] 55 与下面的写法是等价的, c(1:10) %&gt;% sum() ## [1] 55 这条语句的意思，向量c(1:10) 通过管道操作符 %&gt;% ，传递到函数sum()的第一个参数位置，即sum(c(1:10))， 这个%&gt;%管道操作符还是很形象的， 当对执行多个函数操作的时候，就显得格外方便，代码可读性更强。 sqrt(sum(abs(c(-10:10)))) ## [1] 10.49 # sqrt(sum(abs(c(-10:10)))) c(-10:10) %&gt;% abs() %&gt;% sum() %&gt;% sqrt() ## [1] 10.49 那么，上面增加学生成绩的语句mutate(df, newscore = score2020)就可以使用管道 # 等价于 df %&gt;% mutate(newscore = score2020) ## name type newscore ## 1 Alice english 80.2 ## 2 Alice math 90.5 ## 3 Bob english 92.2 ## 4 Bob math 90.8 ## 5 Carol english 82.5 ## 6 Carol math 84.6 是不是很赞？ 注意此时df没有变化喔。好比把df 传给了f() 执行了f(df), 但df本身没有变化。 如果想保留f(df)结果，需要把f(df)赋值给新的对象，当然也可以赋值给df, 即替换. df &lt;- df %&gt;% mutate(newscore = score2020) df ## name type newscore ## 1 Alice english 80.2 ## 2 Alice math 90.5 ## 3 Bob english 92.2 ## 4 Bob math 90.8 ## 5 Carol english 82.5 ## 6 Carol math 84.6 6.3 select() select()顾名思义选择，就是选择数据框的某一列，或者某几列 我们还是以学生成绩的数据框为例 我们可以选择name列, 结果是只有一列的数据框（仍然数据框喔） 使用传统的方法 df[&quot;name&quot;] ## name ## 1 Alice ## 2 Alice ## 3 Bob ## 4 Bob ## 5 Carol ## 6 Carol dplyr 的方法 df %&gt;% select(name) ## name ## 1 Alice ## 2 Alice ## 3 Bob ## 4 Bob ## 5 Carol ## 6 Carol 如果选取多列，用dplyr 就只是再写一个就行了 df %&gt;% select(name, newscore) ## name newscore ## 1 Alice 80.2 ## 2 Alice 90.5 ## 3 Bob 92.2 ## 4 Bob 90.8 ## 5 Carol 82.5 ## 6 Carol 84.6 如果不想要某列， 可以在变量前面加-， 结果与上面的一样 df %&gt;% select(-type) ## name newscore ## 1 Alice 80.2 ## 2 Alice 90.5 ## 3 Bob 92.2 ## 4 Bob 90.8 ## 5 Carol 82.5 ## 6 Carol 84.6 6.4 filter() select是列方向的选择，我们还可以对数据行方向的选择和筛选，选出符合我们条件的某些行 比如这里把成绩高于90分的同学筛选出来 df %&gt;% filter(newscore &gt;= 90) ## name type newscore ## 1 Alice math 90.5 ## 2 Bob english 92.2 ## 3 Bob math 90.8 也可以限定多个条件进行筛选, 英语成绩高于90分的筛选出来 df %&gt;% filter(type == &quot;english&quot;, newscore &gt;= 90) ## name type newscore ## 1 Bob english 92.2 6.5 summarise()统计 summarise()主要用于统计，往往与其他函数配合使用，比如计算所有同学考试成绩的均值 df %&gt;% summarise( mean_score = mean(newscore)) ## mean_score ## 1 86.8 比如，计算所有同学的考试成绩的标准差 df %&gt;% summarise( mean_score = sd(newscore)) ## mean_score ## 1 5.015 还同时完成多个统计 df %&gt;% summarise( mean_score = mean(newscore), median_score = median(newscore), n = n(), sum = sum(newscore) ) ## mean_score median_score n sum ## 1 86.8 87.55 6 520.8 注意，mutate(), select() 和 filter()是在原数据框的基础上增减, 而summarise()返回的是一个新的数据框。 6.6 group_by()分组 事实上，summarise()往往配合group_by()一起使用，即，先分组再统计。比如，我们想统计每个学生的平均成绩，那么就需要先按学生name分组，然后求平均 df %&gt;% group_by(name) %&gt;% summarise( mean_score = mean(newscore), sd_score = sd(newscore) ) ## # A tibble: 3 x 3 ## name mean_score sd_score ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Alice 85.4 7.28 ## 2 Bob 91.5 0.990 ## 3 Carol 83.6 1.48 6.7 arrange()排序 这个很好理解的。比如我们按照考试成绩从低到高排序，然后输出 df %&gt;% arrange(newscore) ## name type newscore ## 1 Alice english 80.2 ## 2 Carol english 82.5 ## 3 Carol math 84.6 ## 4 Alice math 90.5 ## 5 Bob math 90.8 ## 6 Bob english 92.2 如果从高到低排序呢，有两种方法: df %&gt;% arrange(-newscore) ## name type newscore ## 1 Bob english 92.2 ## 2 Bob math 90.8 ## 3 Alice math 90.5 ## 4 Carol math 84.6 ## 5 Carol english 82.5 ## 6 Alice english 80.2 写成下面这种形式也是降序排列，但可读性更强些 df %&gt;% arrange(desc(newscore)) ## name type newscore ## 1 Bob english 92.2 ## 2 Bob math 90.8 ## 3 Alice math 90.5 ## 4 Carol math 84.6 ## 5 Carol english 82.5 ## 6 Alice english 80.2 也可对多个变量先后排序。先按学科排，然后按照成绩从高到底排序 df %&gt;% arrange(type, desc(newscore)) ## name type newscore ## 1 Bob english 92.2 ## 2 Carol english 82.5 ## 3 Alice english 80.2 ## 4 Bob math 90.8 ## 5 Alice math 90.5 ## 6 Carol math 84.6 6.8 left_join() 数据框合并，假定我们已经统计了每个同学的平均成绩，存放在df1 df1 &lt;- df %&gt;% group_by(name) %&gt;% summarise( mean_score = mean(newscore) ) df1 ## # A tibble: 3 x 2 ## name mean_score ## &lt;chr&gt; &lt;dbl&gt; ## 1 Alice 85.4 ## 2 Bob 91.5 ## 3 Carol 83.6 我们有新一个数据框df2，包含同学们的年龄信息 df2 &lt;- tibble( name = c(&quot;Alice&quot;, &quot;Bob&quot;), age = c(12, 13) ) df2 ## # A tibble: 2 x 2 ## name age ## &lt;chr&gt; &lt;dbl&gt; ## 1 Alice 12 ## 2 Bob 13 可以用 left_join把两个数据框df1和df2，合并连接再一起, 两个数据框是通过姓名name连接的，因此需要指定by = \"name\" left_join(df1, df2, by = &quot;name&quot;) ## # A tibble: 3 x 3 ## name mean_score age ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Alice 85.4 12 ## 2 Bob 91.5 13 ## 3 Carol 83.6 NA # df1 %&gt;% left_join(df2, by = &quot;name&quot;) ## # A tibble: 3 x 3 ## name mean_score age ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Alice 85.4 12 ## 2 Bob 91.5 13 ## 3 Carol 83.6 NA 大家注意到最后一行Carol的年龄是NA， 大家想想为什么呢？ 6.9 right_join() 我们再试试right_join() df1 %&gt;% right_join(df2, by = &quot;name&quot;) ## # A tibble: 2 x 3 ## name mean_score age ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Alice 85.4 12 ## 2 Bob 91.5 13 Carol同学的信息没有了？ 大家想想又为什么呢？ 事实上，答案就在函数的名字上，left_join()是左合并，即以左边数据框df1中的学生姓名name为准，在右边数据框df2里，有Alice和Bob的年龄，那么就对应合并过来，没有Carol，就为缺失值NA right_join()是右合并，即以右边数据框df2中的学生姓名name为准，只有Alice和Bob，因此而df1只需要把Alice和Bob的信息粘过来。 6.10 延伸阅读 推荐https://dplyr.tidyverse.org/. cheatsheet 作业：读懂并运行下面的代码 Download nycflights.Rmd 统计每位同学成绩高于75分的科目数 "],["ggplot2-aes.html", "第 7 章 数据可视化 7.1 为什么要可视化 7.2 什么是数据可视化 7.3 宏包ggplot2 7.4 ggplot2 的图形语法 7.5 映射 7.6 映射 vs.设置 7.7 几何对象 7.8 图层叠加 7.9 Global vs. Local 7.10 保存图片 7.11 课堂作业 7.12 延伸阅读", " 第 7 章 数据可视化 上节课介绍了R语言的基本数据结构，可能大家有种看美剧的感觉，有些懵。这很正常，我在开始学习R的时候，感觉和大家一样，所以不要惊慌，我们后面会慢慢填补这些知识点。 这节课，我们介绍R语言最强大的可视化，看看都有哪些炫酷的操作。 library(tidyverse) # install.packages(&quot;tidyverse&quot;) library(patchwork) # install.packages(&quot;patchwork&quot;) 7.1 为什么要可视化 我们先从一个故事开始，1854年伦敦爆发严重霍乱，当时流行的观点是霍乱是通过空气传播的，而John Snow医生（不是《权力的游戏》里的 Jon Snow）研究发现，霍乱是通过饮用水传播的。研究过程中，John Snow医生统计每户病亡人数，每死亡一人标注一条横线，分析发现，大多数病例的住所都围绕在Broad Street水泵附近，结合其他证据得出饮用水传播的结论，于是移掉了Broad Street水泵的把手，霍乱最终得到控制。 另一个有趣的例子就是辛普森悖论（Simpson’s Paradox）。比如我们想研究下，学习时间和考试成绩的关联。结果发现两者呈负相关性，即补课时间越长，考试成绩反而越差（下图横坐标是学习时间，纵坐标是考试成绩），很明显这个结果有违生活常识。 事实上，当我们把学生按照不同年级分成五组，再来观察学习时间和考试成绩之间的关联，发现相关性完全逆转了! 我们可以看到学习时间和考试成绩强烈正相关。 辛普森悖论在日常生活中层出不穷。 那么如何避免辛普森悖论呢？我们能做的，就是仔细地研究分析各种影响因素，不要笼统概括地、浅尝辄止地看问题。其中，可视化分析为我们提供了一个好的方法。 7.2 什么是数据可视化 7.2.1 图形属性 我们在图中画一个点，那么这个点就有（形状，大小，颜色，位置，透明度）等属性， 这些属性就是图形属性（有时也称之为图形元素或者视觉元素），下图 7.1列出了常用的图形属性。 图 7.1: 常用的图形元素 数据可视化的过程，就是我们的数据通过这些视觉上的元素表示出来，即，数值到图形属性的转换（映射）过程。 7.3 宏包ggplot2 ggplot2是RStudio首席科学家Hadley Wickham在2005年读博士期间的作品。很多人学习R语言，就是因为ggplot2宏包。目前， ggplot2已经发展成为最受欢迎的R宏包，没有之一。 我们可以看看它2019年cran的下载量 library(cranlogs) d &lt;- cran_downloads(package = &quot;ggplot2&quot;, from = &quot;2019-01-01&quot;, to = &quot;2019-12-31&quot;) sum(d$count) ## [1] 9889742 7.4 ggplot2 的图形语法 ggplot2有一套优雅的绘图语法，包名中“gg”是grammar of graphics的简称。 ggplot()函数包括9个部件： 数据 (data) （ 数据框） 映射 (mapping) 几何对象 (geom) 统计变换 (stats) 标度 (scale) 坐标系 (coord) 分面 (facet) 主题 (theme) 存储和输出 (output) 其中前三个是必需的。 Hadley Wickham将这套可视化语法诠释为: 一张统计图形就是从数据到几何对象(geometric object，缩写geom)的图形属性(aesthetic attribute，缩写aes)的一个映射。 此外，图形中还可能包含数据的统计变换(statistical transformation，缩写stats)，最后绘制在某个特定的坐标系(coordinate system，缩写coord)中，而分面(facet)则可以用来生成数据不同子集的图形。 7.4.1 语法模板 先看一个简单的案例（1880-2014年温度变化和二氧化碳排放量） library(tidyverse) d &lt;- read_csv(&quot;./demo_data/temp_carbon.csv&quot;) d ## # A tibble: 135 x 5 ## year temp_anomaly land_anomaly ocean_anomaly ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1880 -0.11 -0.48 -0.01 ## 2 1881 -0.08 -0.4 0.01 ## 3 1882 -0.1 -0.48 0 ## 4 1883 -0.18 -0.66 -0.04 ## 5 1884 -0.26 -0.69 -0.14 ## 6 1885 -0.25 -0.56 -0.17 ## 7 1886 -0.24 -0.51 -0.17 ## 8 1887 -0.28 -0.47 -0.23 ## 9 1888 -0.13 -0.41 -0.05 ## 10 1889 -0.09 -0.31 -0.02 ## # ... with 125 more rows, and 1 more variable: ## # carbon_emissions &lt;dbl&gt; library(ggplot2) ggplot(data = d, mapping = aes(x = year, y = carbon_emissions)) + geom_line() + xlab(&quot;Year&quot;) + ylab(&quot;Carbon emissions (metric tons)&quot;) + ggtitle(&quot;Annual global carbon emissions, 1880-2014&quot;) 是不是很简单? 7.5 映射 我们这里用科考人员收集的企鹅体征数据来演示。 library(tidyverse) penguins &lt;- read_csv(&quot;./demo_data/penguins.csv&quot;) %&gt;% janitor::clean_names() %&gt;% drop_na() penguins %&gt;% head() ## # A tibble: 6 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ 36.7 19.3 ## 5 Adelie Torge~ 39.3 20.6 ## 6 Adelie Torge~ 38.9 17.8 ## # ... with 4 more variables: flipper_length_mm &lt;dbl&gt;, ## # body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt; 7.5.1 变量含义 variable class description species integer 企鹅种类 (Adelie, Gentoo, Chinstrap) island integer 所在岛屿 (Biscoe, Dream, Torgersen) bill_length_mm double 嘴峰长度 (单位毫米) bill_depth_mm double 嘴峰深度 (单位毫米) flipper_length_mm integer 鰭肢长度 (单位毫米) body_mass_g integer 体重 (单位克) sex integer 性别 year integer 记录年份 7.5.2 嘴巴越长，嘴巴也会越厚？ 这里提出一个问题，嘴巴越长，嘴巴也会越厚？ 回答这个问题，我们用到penguins数据集其中的四个变量 penguins %&gt;% select(species, sex, bill_length_mm, bill_depth_mm) %&gt;% head(4) 为考察嘴峰长度(bill_length_mm)与嘴峰深度(bill_depth_mm)之间的关联，先绘制这两个变量的散点图， ggplot()表示调用该函数画图，data = penguins 表示使用penguins这个数据框来画图。 aes()表示数值和视觉属性之间的映射。 aes(x = bill_length_mm, y = bill_depth_mm)，意思是变量bill_length_mm作为（映射为）x轴方向的位置，变量bill_depth_mm作为（映射为）y轴方向的位置。 aes()除了位置上映射，还可以实现色彩、形状或透明度等视觉属性的映射。 geom_point()表示绘制散点图。 +表示添加图层。 运行脚本后生成图片： 刚才看到的是位置上的映射，ggplot()还包含了颜色、形状以及透明度等图形属性的映射， 比如我们在aes()里增加一个颜色映射color = species, 这样做就是希望，不同的企鹅类型, 用不同的颜色来表现。这里，企鹅类型有三组，那么就用三种不同的颜色来表示 ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + geom_point() 此图绘制不同类型的企鹅，嘴峰长度与嘴峰深度散点图，并用颜色来实现了分组。 大家试试下面代码呢， ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, size = species)) + geom_point() ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, shape = species)) + geom_point() ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, alpha = species)) + geom_point() 为什么图中是这样的颜色呢？那是因为ggplot()内部有一套默认的设置 不喜欢默认的颜色，可以自己定义喔。请往下看 7.6 映射 vs.设置 想把图中的点指定为某一种颜色，可以使用设置语句，比如 ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(color = &quot;blue&quot;) 大家也可以试试下面 ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(size = 5) ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(shape = 2) ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(alpha = 0.5) 7.6.1 提问 思考下左图中aes(color = \"blue\")为什么会变成了红色的点？ 7.7 几何对象 geom_point() 可以画散点图，也可以使用geom_smooth()绘制平滑曲线， p1 &lt;- ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point() p1 p2 &lt;- ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_smooth() p2 7.8 图层叠加 p3 &lt;- ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point() + geom_smooth() p3 library(patchwork) (p1 / p2) | p3 7.9 Global vs. Local ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + geom_point() ggplot(penguins) + geom_point(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) 大家可以看到，以上两段代码出来的图是一样。但背后的含义却不同。 事实上，如果映射关系aes() 写在ggplot()里, ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + geom_point() 那么映射关系x = bill_length_mm, y = bill_depth_mm, color = species 为全局变量。因此，当geom_point()画图时，发现缺少所绘图所需要的映射关系（点的位置、点的大小、点的颜色等等），就会从ggplot()全局变量中继承映射关系。 如果映射关系 aes() 写在几何对象geom_point()里, 那么此处的映射关系就为局部变量, 比如。 ggplot(penguins) + geom_point(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) 此时geom_point()绘图所需要的映射关系aes(x = bill_length_mm, y = bill_depth_mm, color = species) 已经存在，就不会继承全局变量的映射关系。 再看下面这个例子， ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(aes(color = species)) + geom_smooth() 这里的 geom_point() 和 geom_smooth() 都会从全局变量中继承位置映射关系。 再看下面这个例子， ggplot(penguins,aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + geom_point(aes(color = sex)) 局部变量中的映射关系 aes(color = )已经存在，因此不会从全局变量中继承，沿用当前的映射关系。 大家细细体会下，下面两段代码的区别 ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + geom_smooth(method = lm) + geom_point() ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_smooth(method = lm) + geom_point(aes(color = species)) 7.10 保存图片 可以使用ggsave()函数，将图片保存为所需要的格式，如“.pdf,” “.png”等 p &lt;- penguins %&gt;% ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) + geom_smooth(method = lm) + geom_point(aes(color = species)) + ggtitle(&quot;This is my first plot&quot;) ggsave( filename = &quot;myfirst_plot.pdf&quot;, plot = p, width = 8, height = 6, dpi = 300 ) 7.11 课堂作业 补充代码，要求在一张图中画出 企鹅嘴巴长度和嘴巴厚度的散点图 不同企鹅种类用不同的颜色 整体的线性拟合 不同种类分别线性拟合 ggplot(penguins, aes(x = ___, y = ___)) + geom_point() + geom_smooth() + geom_smooth() 7.12 延伸阅读 在第 13 章到第 17 章会再讲ggplot2 "],["tidyr.html", "第 8 章 数据规整 8.1 提问 8.2 宽表格变成长表格 8.3 长表格变成宽表格 8.4 复杂的情形 8.5 tidy data原则 8.6 案例", " 第 8 章 数据规整 library(tidyverse) 8.1 提问 假定这里有 A, B, C 和 D 四种植物每天生长的记录， plant_height &lt;- data.frame( Day = 1:5, A = c(0.7, 1.0, 1.5, 1.8, 2.2), B = c(0.5, 0.7, 0.9, 1.3, 1.8), C = c(0.3, 0.6, 1.0, 1.2, 2.2), D = c(0.4, 0.7, 1.2, 1.5, 3.2) ) plant_height ## Day A B C D ## 1 1 0.7 0.5 0.3 0.4 ## 2 2 1.0 0.7 0.6 0.7 ## 3 3 1.5 0.9 1.0 1.2 ## 4 4 1.8 1.3 1.2 1.5 ## 5 5 2.2 1.8 2.2 3.2 大家想想， 把植物高度大于或等于0.8cm的时刻筛选出来，怎么写语句? 用不同的颜色画出四种植物生长曲线，怎么写语句? 很显然，我们用第 6 章数据处理和第 7 章数据可视化的技术，可以写成这样 plant_height %&gt;% filter( ___ &gt;= 0.8) plant_height %&gt;% ggplot(aes(x = Day, y = ___, color = ___)) + geom_line() 然而，发现遇到了问题？数据的格式与我们期望的不一样！ 怎么解决呢？想用上面的语句，数据就得变形。那么怎么变形呢？ 下面任意一种都行： melted &lt;- gather(plant_height, variable, value, 2:3) ## Column names instead of indices melted &lt;- gather(plant_height, variable, value, A, B) ## Excluding instead of including melted &lt;- gather(plant_height, variable, value, -1) ## Excluding using column name melted &lt;- gather(plant_height, variable, value, -Day) 但我更推荐大家使用tidyr::pivot_longer(), 这是2019年9月份，tidyr 1.0.0新增的一组函数pivot_longer()/pivot_wider()，用来补充和完善原来的gather()/spread() gather()/pivot_longer 宽表格变成长表格 spread()/pivot_wider 长表格变成宽表格 8.2 宽表格变成长表格 所以现在使用pivot_longer()函数 long %&nbsp;&nbsp;pivot_longer(&nbsp;&nbsp;&nbsp;&nbsp;cols = A:D,&nbsp;&nbsp;&nbsp;&nbsp;names_to = \"plant\",&nbsp;&nbsp;&nbsp;&nbsp;values_to = \"height\"&nbsp;&nbsp;)long ## # A tibble: 20 x 3 ## Day plant height ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 A 0.7 ## 2 1 B 0.5 ## 3 1 C 0.3 ## 4 1 D 0.4 ## 5 2 A 1 ## 6 2 B 0.7 ## 7 2 C 0.6 ## 8 2 D 0.7 ## 9 3 A 1.5 ## 10 3 B 0.9 ## 11 3 C 1 ## 12 3 D 1.2 ## 13 4 A 1.8 ## 14 4 B 1.3 ## 15 4 C 1.2 ## 16 4 D 1.5 ## 17 5 A 2.2 ## 18 5 B 1.8 ## 19 5 C 2.2 ## 20 5 D 3.2 这里pivot_longer()函数有三个主要的参数： 参数cols，表示哪些列需要转换 参数names_to，表示cols选取的这些列的名字，构成了新的一列，这里需要取一个名字. 参数values_to， 表示cols选取的这些列的值，构成了新的一列，这里也需要取一个名字. 当然，参数cols 的写法可以多种形式的，具体见第 22 章select()函数. plant_height %&gt;% pivot_longer( cols = -Day, # A:D 或者 c(A, B, C, D) 或者 c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;) names_to = &quot;plant&quot;, values_to = &quot;height&quot; ) 画图的问题也就解决了 long %&gt;% ggplot(aes(x = Day, y = height, color = plant)) + geom_line() 8.3 长表格变成宽表格 如果，长表格变回宽表格呢？需要用到pivot_wider() wide &lt;- long %&gt;% pivot_wider( names_from = &quot;plant&quot;, values_from = &quot;height&quot; ) wide ## # A tibble: 5 x 5 ## Day A B C D ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.7 0.5 0.3 0.4 ## 2 2 1 0.7 0.6 0.7 ## 3 3 1.5 0.9 1 1.2 ## 4 4 1.8 1.3 1.2 1.5 ## 5 5 2.2 1.8 2.2 3.2 8.4 复杂的情形 假定 A, B, C 三种植物每天生长的记录，包括三个特征（height, width, depth） plant_record &lt;- data.frame( day = c(1L, 2L, 3L, 4L, 5L), A_height = c(1.1, 1.2, 1.3, 1.4, 1.5), A_width = c(2.1, 2.2, 2.3, 2.4, 2.5), A_depth = c(3.1, 3.2, 3.3, 3.4, 3.5), B_height = c(4.1, 4.2, 4.3, 4.4, 4.5), B_width = c(5.1, 5.2, 5.3, 5.4, 5.5), B_depth = c(6.1, 6.2, 6.3, 6.4, 6.5), C_height = c(7.1, 7.2, 7.3, 7.4, 7.5), C_width = c(8.1, 8.2, 8.3, 8.4, 8.5), C_depth = c(9.1, 9.2, 9.3, 9.4, 9.5) ) plant_record ## day A_height A_width A_depth B_height B_width ## 1 1 1.1 2.1 3.1 4.1 5.1 ## 2 2 1.2 2.2 3.2 4.2 5.2 ## 3 3 1.3 2.3 3.3 4.3 5.3 ## 4 4 1.4 2.4 3.4 4.4 5.4 ## 5 5 1.5 2.5 3.5 4.5 5.5 ## B_depth C_height C_width C_depth ## 1 6.1 7.1 8.1 9.1 ## 2 6.2 7.2 8.2 9.2 ## 3 6.3 7.3 8.3 9.3 ## 4 6.4 7.4 8.4 9.4 ## 5 6.5 7.5 8.5 9.5 我们想转换成这样的 原来的列名需要转换成多个变量，还是用pivot_longer()函数， plant_record %&gt;% tidyr::pivot_longer( cols = !day, names_to = c(&quot;species&quot;, &quot;parameter&quot;), names_pattern = &quot;(.*)_(.*)&quot;, values_to = &quot;value&quot; ) ## # A tibble: 45 x 4 ## day species parameter value ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 A height 1.1 ## 2 1 A width 2.1 ## 3 1 A depth 3.1 ## 4 1 B height 4.1 ## 5 1 B width 5.1 ## 6 1 B depth 6.1 ## 7 1 C height 7.1 ## 8 1 C width 8.1 ## 9 1 C depth 9.1 ## 10 2 A height 1.2 ## # ... with 35 more rows 感觉不是我们想要的结果，正确答案是下面这个，你看明白.value它代表的意思了吗？ plant_record %&gt;% tidyr::pivot_longer( cols = !day, names_to = c(&quot;species&quot;, &quot;.value&quot;), names_pattern = &quot;(.*)_(.*)&quot; ) ## # A tibble: 15 x 5 ## day species height width depth ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 A 1.1 2.1 3.1 ## 2 1 B 4.1 5.1 6.1 ## 3 1 C 7.1 8.1 9.1 ## 4 2 A 1.2 2.2 3.2 ## 5 2 B 4.2 5.2 6.2 ## 6 2 C 7.2 8.2 9.2 ## 7 3 A 1.3 2.3 3.3 ## 8 3 B 4.3 5.3 6.3 ## 9 3 C 7.3 8.3 9.3 ## 10 4 A 1.4 2.4 3.4 ## 11 4 B 4.4 5.4 6.4 ## 12 4 C 7.4 8.4 9.4 ## 13 5 A 1.5 2.5 3.5 ## 14 5 B 4.5 5.5 6.5 ## 15 5 C 7.5 8.5 9.5 8.5 tidy data原则 Hadley Wickhamt提出了数据科学tidy原则，我结合自己的理解，tidy思想体现在: 一切都是数据框，任何数据都可以规整 数据框的一列代表一个变量，数据框的一行代表一次观察 函数处理数据时，数据框进数据框出（函数的第一个参数始终为数据框） 根据Hadley Wickham的思想，这里的宽表格(plant_heigt和 wide)不是tidy的，只有长表格(long)才是tidy的， long ## # A tibble: 20 x 3 ## Day plant height ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 A 0.7 ## 2 1 B 0.5 ## 3 1 C 0.3 ## 4 1 D 0.4 ## 5 2 A 1 ## 6 2 B 0.7 ## 7 2 C 0.6 ## 8 2 D 0.7 ## 9 3 A 1.5 ## 10 3 B 0.9 ## 11 3 C 1 ## 12 3 D 1.2 ## 13 4 A 1.8 ## 14 4 B 1.3 ## 15 4 C 1.2 ## 16 4 D 1.5 ## 17 5 A 2.2 ## 18 5 B 1.8 ## 19 5 C 2.2 ## 20 5 D 3.2 以后，我们会意识到tidyverse中的很多函数都喜欢tidy的（尤其是ggplot2时）！ 8.6 案例 请见第 40 章、第 41 章和第 42 章. "],["stringr.html", "第 9 章 正则表达式 9.1 问题 9.2 什么是正则表达式 9.3 字符串基础 9.4 使用正则表达式进行模式匹配 9.5 解决实际问题 9.6 进阶部分 9.7 案例分析 9.8 回答提问 9.9 一些有趣的正则表达式的宏包", " 第 9 章 正则表达式 library(tidyverse) library(stringr) 9.1 问题 这是一份关于地址信息的数据 ## # A tibble: 8 x 2 ## No address ## &lt;int&gt; &lt;chr&gt; ## 1 1 Sichuan Univ, Coll Chem ## 2 2 Sichuan Univ, Coll Elect Engn ## 3 3 Sichuan Univ, Dept Phys ## 4 4 Sichuan Univ, Coll Life Sci ## 5 6 Sichuan Univ, Food Engn ## 6 7 Sichuan Univ, Coll Phys ## 7 8 Sichuan Univ, Sch Business ## 8 9 Wuhan Univ, Mat Sci 问题：如何提取Sichuan Univ后面的学院？这需要用到正则表达式的知识。 9.2 什么是正则表达式 我们在word文档或者excel中，经常使用查找和替换, 然而有些情况，word是解决不了的，比如 条件搜索 统计文中，前面有 “data,” “computer” or “statistical” 的 “analysis”，这个单词的个数 找出文中重复的单词，比如“we love love you” 拼写检查 电话号码（邮件，密码等）是否正确格式 日期书写的规范与统一 提取信息 提取文本特定位置的数据 文本挖掘 非结构化的提取成结构化 这个时候就需要用到正则表达式（Regular Expression），这一强大、便捷、高效的文本处理工具。那么，什么是正则表达式呢？简单点说，正则表达式是处理字符串的。复杂点说，正则表达式描述了一种字符串匹配的模式（pattern），通常被用来检索、替换那些符合某个模式(规则)的文本。这种固定的格式的文本，生活中常见的有电话号码、网络地址、邮件地址和日期格式等等。 正则表达式并不是R语言特有的，事实上，几乎所有程序语言都支持正则表达式 (e.g. Perl, Python, Java, Ruby, etc). R 语言中很多函数都需要使用正则表达式，然而正则表达式不太好学。幸运的是，大神Hadley Wickham开发的stringr包让正则表达式简单易懂，因此今天我们就介绍这个包。本章的内容与《R for data science》第10章基本一致。本章目的教大家写简单的正则表示式就行了。 9.3 字符串基础 9.3.1 字符串长度 想获取字符串的长度，可以使用str_length()函数 str_length(&quot;R for data science&quot;) ## [1] 18 字符串向量，也适用 str_length(c(&quot;a&quot;, &quot;R for data science&quot;, NA)) ## [1] 1 18 NA 数据框里配合dplyr函数，同样很方便 data.frame( x = c(&quot;a&quot;, &quot;R for data science&quot;, NA) ) %&gt;% mutate(y = str_length(x)) ## x y ## 1 a 1 ## 2 R for data science 18 ## 3 &lt;NA&gt; NA 9.3.2 字符串组合 把字符串拼接在一起，使用 str_c() 函数 str_c(&quot;x&quot;, &quot;y&quot;) ## [1] &quot;xy&quot; 把字符串拼接在一起，可以设置中间的间隔 str_c(&quot;x&quot;, &quot;y&quot;, sep = &quot;, &quot;) ## [1] &quot;x, y&quot; str_c(c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), sep = &quot;, &quot;) ## [1] &quot;x&quot; &quot;y&quot; &quot;z&quot; 是不是和你想象的不一样，那就?str_c，或者试试这个 str_c(c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), sep = &quot;, &quot;) ## [1] &quot;x, x&quot; &quot;y, y&quot; &quot;z, z&quot; 用在数据框里 data.frame( x = c(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;), y = c(&quot;you&quot;, &quot;like&quot;, &quot;me&quot;) ) %&gt;% mutate(z = str_c(x, y, sep = &quot;|&quot;)) ## x y z ## 1 I you I|you ## 2 love like love|like ## 3 you me you|me 使用collapse选项，是先组合，然后再转换成单个字符串，大家对比下 str_c(c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), sep = &quot;|&quot;) ## [1] &quot;x|a&quot; &quot;y|b&quot; &quot;z|c&quot; str_c(c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), collapse = &quot;|&quot;) ## [1] &quot;xa|yb|zc&quot; 9.3.3 字符串取子集 截取字符串的一部分，需要指定截取的开始位置和结束位置 x &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;) str_sub(x, 1, 3) ## [1] &quot;App&quot; &quot;Ban&quot; &quot;Pea&quot; 开始位置和结束位置如果是负整数，就表示位置是从后往前数，比如下面这段代码，截取倒数第3个至倒数第1个位置上的字符串 x &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;) str_sub(x, -3, -1) ## [1] &quot;ple&quot; &quot;ana&quot; &quot;ear&quot; 也可以进行赋值，如果该位置上有字符，就用新的字符替换旧的字符 x &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;) x ## [1] &quot;Apple&quot; &quot;Banana&quot; &quot;Pear&quot; str_sub(x, 1, 1) ## [1] &quot;A&quot; &quot;B&quot; &quot;P&quot; str_sub(x, 1, 1) &lt;- &quot;Q&quot; x ## [1] &quot;Qpple&quot; &quot;Qanana&quot; &quot;Qear&quot; 9.4 使用正则表达式进行模式匹配 正则表示式慢慢会呈现了 9.4.1 基础匹配 str_view() 是查看string是否匹配pattern，如果匹配，就高亮显示 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(string = x, pattern = &quot;an&quot;) 有时候，我们希望在字符a前后都有字符（即，a处在两字符中间，如rap, bad, sad, wave，spear等等） x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;.a.&quot;) 这里的. 代表任意字符。如果向表达.本身呢？ c(&quot;s.d&quot;) %&gt;% str_view(&quot;.&quot;) c(&quot;s.d&quot;) %&gt;% str_view(&quot;\\\\.&quot;) 9.4.2 锚点 希望a是字符串的开始 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;^a&quot;) 希望a是一字符串的末尾 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;a$&quot;) x &lt;- c(&quot;apple pie&quot;, &quot;apple&quot;, &quot;apple cake&quot;) str_view(x, &quot;^apple$&quot;) 9.4.3 字符类与字符选项 前面提到，.匹配任意字符，事实上还有很多这种特殊含义的字符： \\d: matches any digit. \\s: matches any whitespace (e.g. space, tab, newline). [abc]: matches a, b, or c. [^abc]: matches anything except a, b, or c. str_view(c(&quot;grey&quot;, &quot;gray&quot;), &quot;gr[ea]y&quot;) 9.4.4 重复 控制匹配次数: ?: 0 or 1 +: 1 or more *: 0 or more x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;CC?&quot;) str_view(x, &quot;X+&quot;) 控制匹配次数: {n}: exactly n {n,}: n or more {,m}: at most m {n,m}: between n and m x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;C{2}&quot;) str_view(x, &quot;C{2,}&quot;) str_view(x, &quot;C{2,3}&quot;) 默认的情况，*, + 匹配都是贪婪的，也就是它会尽可能的匹配更多 如果想让它不贪婪，而是变得懒惰起来，可以在*, + 加个? x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;CLX+&quot;) str_view(x, &quot;CLX+?&quot;) 小结一下呢 9.4.5 分组与回溯引用 ft &lt;- fruit %&gt;% head(10) ft ## [1] &quot;apple&quot; &quot;apricot&quot; &quot;avocado&quot; ## [4] &quot;banana&quot; &quot;bell pepper&quot; &quot;bilberry&quot; ## [7] &quot;blackberry&quot; &quot;blackcurrant&quot; &quot;blood orange&quot; ## [10] &quot;blueberry&quot; 我们想看看这些单词里，有哪些字母是重复两次的，比如aa, pp. 如果用上面学的方法 str_view(ft, &quot;.{2}&quot;, match = TRUE) 发现不是和我们的预想不一样呢。 所以需要用到新技术 分组与回溯引用， str_view(ft, &quot;(.)\\\\1&quot;, match = TRUE) . 是匹配任何字符 (.) 将匹配项括起来，它就用了一个名字，叫\\\\1； 如果有两个括号，就叫\\\\1和\\\\2 \\\\1 表示回溯引用，表示引用\\\\1对于的(.) 所以(.)\\\\1的意思就是，匹配到了字符，后面还希望有个同样的字符 如果是匹配abab, wcwc str_view(ft, &quot;(..)\\\\1&quot;, match = TRUE) 如果是匹配abba, wccw呢？ str_view(ft, &quot;(.)(.)\\\\2\\\\1&quot;, match = TRUE) 是不是很神奇？ 9.5 解决实际问题 9.5.1 确定一个字符向量是否匹配一种模式 实际问题中，想判断是否匹配？可以用到str_detect()函数 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_detect(x, &quot;e&quot;) ## [1] TRUE FALSE TRUE 数据框中也是一样 ## # A tibble: 3 x 1 ## x ## &lt;chr&gt; ## 1 apple ## 2 banana ## 3 pear d %&gt;% mutate(has_e = str_detect(x, &quot;e&quot;)) ## # A tibble: 3 x 2 ## x has_e ## &lt;chr&gt; &lt;lgl&gt; ## 1 apple TRUE ## 2 banana FALSE ## 3 pear TRUE 用于筛选也很方便 d %&gt;% dplyr::filter(str_detect(x, &quot;e&quot;)) ## # A tibble: 2 x 1 ## x ## &lt;chr&gt; ## 1 apple ## 2 pear stringr::words包含了牛津字典里常用单词 stringr::words %&gt;% head() ## [1] &quot;a&quot; &quot;able&quot; &quot;about&quot; &quot;absolute&quot; ## [5] &quot;accept&quot; &quot;account&quot; 我们统计下以t开头的单词，有多少个？ # How many common words start with t? sum(str_detect(words, &quot;^t&quot;)) ## [1] 65 我们又一次看到了强制转换. 以元音结尾的单词，占比多少？ # proportion of common words end with a vowel? mean(str_detect(words, &quot;[aeiou]$&quot;)) ## [1] 0.2765 放在数据框里看看, 看看以x结尾的单词是哪些？ tibble( word = words ) %&gt;% dplyr::filter(str_detect(word, &quot;x$&quot;)) ## # A tibble: 4 x 1 ## word ## &lt;chr&gt; ## 1 box ## 2 sex ## 3 six ## 4 tax str_detect() 有一个功能类似的函数str_count()，区别在于，后者不是简单地返回是或否，而是返回字符串中匹配的数量 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_count(x, &quot;a&quot;) ## [1] 1 3 1 tibble( word = words ) %&gt;% mutate( vowels = str_count(word, &quot;[aeiou]&quot;), consonants = str_count(word, &quot;[^aeiou]&quot;) ) ## # A tibble: 980 x 3 ## word vowels consonants ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 a 1 0 ## 2 able 2 2 ## 3 about 3 2 ## 4 absolute 4 4 ## 5 accept 2 4 ## 6 account 3 4 ## 7 achieve 4 3 ## 8 across 2 4 ## 9 act 1 2 ## 10 active 3 3 ## # ... with 970 more rows 9.5.2 确定匹配的位置 大家放心，正则表达式不会重叠匹配。比如用\"aba\"去匹配\"abababa\"，肉眼感觉是三次，但正则表达式告诉我们是两次，因为不会重叠匹配 str_count(&quot;abababa&quot;, &quot;aba&quot;) ## [1] 2 str_view_all(&quot;abababa&quot;, &quot;aba&quot;) 9.5.3 提取匹配的内容 colours &lt;- c( &quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;purple&quot; ) colour_match &lt;- str_c(colours, collapse = &quot;|&quot;) colour_match ## [1] &quot;red|orange|yellow|green|blue|purple&quot; colour_match 这里是一个字符串，放在pattern参数位置上也是正则表达式了, 这里注意以下两者的区别 str_view(&quot;abcd&quot;, &quot;ab|cd&quot;) str_view(&quot;abc&quot;, &quot;a[bc]d&quot;) more &lt;- &quot;It is hard to erase blue or red ink.&quot; str_extract(more, pattern = colour_match) ## [1] &quot;blue&quot; str_extract_all(more, pattern = colour_match) ## [[1]] ## [1] &quot;blue&quot; &quot;red&quot; more &lt;- sentences[str_count(sentences, colour_match) &gt; 1] more ## [1] &quot;It is hard to erase blue or red ink.&quot; ## [2] &quot;The green light in the brown box flickered.&quot; ## [3] &quot;The sky in the west is tinged with orange red.&quot; 取出sentences中，含有有两种和两种颜色以上的句子。不过，不喜欢这种写法，看着费劲，还是用tidyverse的方法 tibble(sentence = sentences) %&gt;% filter(str_count(sentences, colour_match) &gt; 1) ## # A tibble: 3 x 1 ## sentence ## &lt;chr&gt; ## 1 It is hard to erase blue or red ink. ## 2 The green light in the brown box flickered. ## 3 The sky in the west is tinged with orange red. str_extract()提取匹配, 谁先匹配就提取谁 tibble(x = more) %&gt;% mutate(color = str_extract(x, colour_match)) ## # A tibble: 3 x 2 ## x color ## &lt;chr&gt; &lt;chr&gt; ## 1 It is hard to erase blue or red ink. blue ## 2 The green light in the brown box flickered. green ## 3 The sky in the west is tinged with orange red. orange str_extract_all()提取全部匹配项 tibble(x = more) %&gt;% mutate(color = str_extract_all(x, colour_match)) ## # A tibble: 3 x 2 ## x color ## &lt;chr&gt; &lt;list&gt; ## 1 It is hard to erase blue or red ink. &lt;chr [2~ ## 2 The green light in the brown box flickered. &lt;chr [2~ ## 3 The sky in the west is tinged with orange r~ &lt;chr [2~ tibble(x = more) %&gt;% mutate(color = str_extract_all(x, colour_match)) %&gt;% unnest(color) ## # A tibble: 6 x 2 ## x color ## &lt;chr&gt; &lt;chr&gt; ## 1 It is hard to erase blue or red ink. blue ## 2 It is hard to erase blue or red ink. red ## 3 The green light in the brown box flickered. green ## 4 The green light in the brown box flickered. red ## 5 The sky in the west is tinged with orange red. orange ## 6 The sky in the west is tinged with orange red. red 9.5.4 替换匹配内容 只替换匹配的第一项 x &lt;- c(&quot;apple&quot;, &quot;pear&quot;, &quot;banana&quot;) str_replace(x, &quot;[aeiou]&quot;, &quot;-&quot;) ## [1] &quot;-pple&quot; &quot;p-ar&quot; &quot;b-nana&quot; 替换全部匹配项 str_replace_all(x, &quot;[aeiou]&quot;, &quot;-&quot;) ## [1] &quot;-ppl-&quot; &quot;p--r&quot; &quot;b-n-n-&quot; 9.5.5 拆分字符串 这个和str_c()是相反的操作 lines &lt;- &quot;I love my country&quot; lines ## [1] &quot;I love my country&quot; str_split(lines, &quot; &quot;) ## [[1]] ## [1] &quot;I&quot; &quot;love&quot; &quot;my&quot; &quot;country&quot; fields &lt;- c(&quot;Name: Hadley&quot;, &quot;Country: NZ&quot;, &quot;Age: 35&quot;) fields %&gt;% str_split(&quot;: &quot;, n = 2, simplify = TRUE) ## [,1] [,2] ## [1,] &quot;Name&quot; &quot;Hadley&quot; ## [2,] &quot;Country&quot; &quot;NZ&quot; ## [3,] &quot;Age&quot; &quot;35&quot; 9.6 进阶部分 带有条件的匹配 9.6.1 look ahead 想匹配Windows，同时希望Windows右侧是\"95\", \"98\", \"NT\", \"2000\"中的一个 win &lt;- c(&quot;Windows2000&quot;, &quot;Windows&quot;, &quot;Windows3.1&quot;) str_view(win, &quot;Windows(?=95|98|NT|2000)&quot;) win &lt;- c(&quot;Windows2000&quot;, &quot;Windows&quot;, &quot;Windows3.1&quot;) str_view(win, &quot;Windows(?!95|98|NT|2000)&quot;) Windows后面的 () 是匹配条件，事实上，有四种情形： (?=pattern) 要求此位置的后面必须匹配表达式pattern (?!pattern) 要求此位置的后面不能匹配表达式pattern (?&lt;=pattern) 要求此位置的前面必须匹配表达式pattern (?&lt;!pattern) 要求此位置的前面不能匹配表达式pattern 注意：对于正则表达式引擎来说，它是从文本头部向尾部（从左到右）开始解析的，因此对于文本尾部方向，称为“前”，因为这个时候，正则引擎还没走到那块；而对文本头部方向，则称为“后”，因为正则引擎已经走过了那一块地方。 9.6.2 look behind win &lt;- c(&quot;2000Windows&quot;, &quot;Windows&quot;, &quot;3.1Windows&quot;) str_view(win, &quot;(?&lt;=95|98|NT|2000)Windows&quot;) win &lt;- c(&quot;2000Windows&quot;, &quot;Windows&quot;, &quot;3.1Windows&quot;) str_view(win, &quot;(?&lt;!95|98|NT|2000)Windows&quot;) 9.7 案例分析 9.7.1 案例1 我们希望能提取第二列中的数值，构成新的一列 dt &lt;- tibble( x = 1:4, y = c(&quot;wk 3&quot;, &quot;week-1&quot;, &quot;7&quot;, &quot;w#9&quot;) ) dt ## # A tibble: 4 x 2 ## x y ## &lt;int&gt; &lt;chr&gt; ## 1 1 wk 3 ## 2 2 week-1 ## 3 3 7 ## 4 4 w#9 dt %&gt;% mutate( z = str_extract(y, &quot;[0-9]&quot;) ) ## # A tibble: 4 x 3 ## x y z ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 wk 3 3 ## 2 2 week-1 1 ## 3 3 7 7 ## 4 4 w#9 9 9.7.2 案例2 提取第二列中的大写字母 df &lt;- data.frame( x = seq_along(1:7), y = c(&quot;2016123456&quot;, &quot;20150513&quot;, &quot;AB2016123456&quot;, &quot;J2017000987&quot;, &quot;B2017000987C&quot;, &quot;aksdf&quot;, &quot;2014&quot;) ) df ## x y ## 1 1 2016123456 ## 2 2 20150513 ## 3 3 AB2016123456 ## 4 4 J2017000987 ## 5 5 B2017000987C ## 6 6 aksdf ## 7 7 2014 df %&gt;% mutate( item = str_extract_all(y, &quot;[A-Z]&quot;) ) %&gt;% tidyr::unnest(item) ## # A tibble: 5 x 3 ## x y item ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 3 AB2016123456 A ## 2 3 AB2016123456 B ## 3 4 J2017000987 J ## 4 5 B2017000987C B ## 5 5 B2017000987C C 9.7.3 案例3 要求：中英文分开 tb &lt;- tibble(x = c(&quot;I我&quot;, &quot;love爱&quot;, &quot;you你&quot;)) tb ## # A tibble: 3 x 1 ## x ## &lt;chr&gt; ## 1 I我 ## 2 love爱 ## 3 you你 tb %&gt;% tidyr::extract( # x, c(&quot;en&quot;, &quot;cn&quot;), &quot;([:alpha:]+)([^:alpha:]+)&quot;, x, c(&quot;en&quot;, &quot;cn&quot;), &quot;([a-zA-Z]+)([^a-zA-Z]+)&quot;, remove = FALSE ) ## # A tibble: 3 x 3 ## x en cn ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 I我 I 我 ## 2 love爱 love 爱 ## 3 you你 you 你 9.7.4 案例4 要求：提取起始数字 df &lt;- tibble(x = c(&quot;1-12周&quot;, &quot;1-10周&quot;, &quot;5-12周&quot;)) df ## # A tibble: 3 x 1 ## x ## &lt;chr&gt; ## 1 1-12周 ## 2 1-10周 ## 3 5-12周 df %&gt;% extract( x, # c(&quot;start&quot;, &quot;end&quot;, &quot;cn&quot;), &quot;([:digit:]+)-([:digit:]+)([^:alpha:]+)&quot;, c(&quot;start&quot;, &quot;end&quot;, &quot;cn&quot;), &quot;(\\\\d+)-(\\\\d+)(\\\\D+)&quot;, remove = FALSE ) ## # A tibble: 3 x 4 ## x start end cn ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1-12周 1 12 周 ## 2 1-10周 1 10 周 ## 3 5-12周 5 12 周 9.7.5 案例5 要求：提取大写字母后的数字 df &lt;- tibble( x = c(&quot;12W34&quot;, &quot;AB2C46&quot;, &quot;B217C&quot;, &quot;akTs6df&quot;, &quot;21WD4&quot;) ) df %&gt;% mutate(item = str_extract_all(x, &quot;(?&lt;=[A-Z])[0-9]&quot;)) %&gt;% tidyr::unnest(item) ## # A tibble: 5 x 2 ## x item ## &lt;chr&gt; &lt;chr&gt; ## 1 12W34 3 ## 2 AB2C46 2 ## 3 AB2C46 4 ## 4 B217C 2 ## 5 21WD4 4 思考题， 如何提取大写字母后的连续数字，比如B217C后面的217 如何提取提取数字前的大写字母？ 为什么第一个正则表达式返回结果为\"\" x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_match_all(x, &quot;C?&quot;) # &quot;?&quot;的意思是匹配0次或者1次 ## [[1]] ## [,1] ## [1,] &quot;&quot; ## [2,] &quot;&quot; ## [3,] &quot;&quot; ## [4,] &quot;&quot; ## [5,] &quot;&quot; ## [6,] &quot;&quot; ## [7,] &quot;&quot; ## [8,] &quot;&quot; ## [9,] &quot;&quot; ## [10,] &quot;&quot; ## [11,] &quot;&quot; ## [12,] &quot;&quot; ## [13,] &quot;&quot; ## [14,] &quot;&quot; ## [15,] &quot;&quot; ## [16,] &quot;&quot; ## [17,] &quot;&quot; ## [18,] &quot;&quot; ## [19,] &quot;C&quot; ## [20,] &quot;C&quot; ## [21,] &quot;C&quot; ## [22,] &quot;&quot; ## [23,] &quot;&quot; ## [24,] &quot;&quot; ## [25,] &quot;&quot; ## [26,] &quot;&quot; ## [27,] &quot;&quot; ## [28,] &quot;&quot; ## [29,] &quot;&quot; ## [30,] &quot;&quot; str_match_all(x, &quot;CC?&quot;) ## [[1]] ## [,1] ## [1,] &quot;CC&quot; ## [2,] &quot;C&quot; 9.7.6 案例6 提取数字并求和 df &lt;- tibble( x = c(&quot;1234&quot;, &quot;B246&quot;, &quot;217C&quot;, &quot;2357f&quot;, &quot;21WD4&quot;) ) df ## # A tibble: 5 x 1 ## x ## &lt;chr&gt; ## 1 1234 ## 2 B246 ## 3 217C ## 4 2357f ## 5 21WD4 df %&gt;% mutate(num = str_match_all(x, &quot;\\\\d&quot;)) %&gt;% unnest(num) %&gt;% mutate_at(vars(num), as.numeric) %&gt;% group_by(x) %&gt;% summarise(sum = sum(num)) ## # A tibble: 5 x 2 ## x sum ## &lt;chr&gt; &lt;dbl&gt; ## 1 1234 10 ## 2 217C 10 ## 3 21WD4 7 ## 4 2357f 17 ## 5 B246 12 9.7.7 案例7 text &lt;- &quot;Quantum entanglement is a physical phenomenon that occurs when pairs or groups of particles are generated, interact, or share spatial proximity in ways such that the quantum state of each particle cannot be described independently of the state of the others, even when the particles are separated by a large distance.&quot; pairs &lt;- tibble::tribble( ~item, ~code, &quot;Quantum entanglement&quot;, &quot;A01&quot;, &quot;physical phenomenon&quot;, &quot;A02&quot;, &quot;quantum state&quot;, &quot;A03&quot;, &quot;quantum mechanics&quot;, &quot;A04&quot; ) %&gt;% tibble::deframe() text %&gt;% str_replace_all(pairs) ## [1] &quot;A01 is a A02 that occurs when pairs or groups of particles are generated, interact, or share spatial proximity in ways such that the A03 of each particle cannot be described independently of the state of the others, even when the particles are separated by a large distance.&quot; 9.8 回答提问 回到上课前的提问：如何提取Sichuan Univ后面的学院？ ## # A tibble: 8 x 2 ## No address ## &lt;int&gt; &lt;chr&gt; ## 1 1 Sichuan Univ, Coll Chem ## 2 2 Sichuan Univ, Coll Elect Engn ## 3 3 Sichuan Univ, Dept Phys ## 4 4 Sichuan Univ, Coll Life Sci ## 5 6 Sichuan Univ, Food Engn ## 6 7 Sichuan Univ, Coll Phys ## 7 8 Sichuan Univ, Sch Business ## 8 9 Wuhan Univ, Mat Sci d %&gt;% dplyr::mutate( coll = str_extract(address, &quot;(?&lt;=Sichuan Univ,).*&quot;) ) %&gt;% tidyr::unnest(coll, keep_empty = TRUE) ## # A tibble: 8 x 3 ## No address coll ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 Sichuan Univ, Coll Chem &quot; Coll Chem&quot; ## 2 2 Sichuan Univ, Coll Elect Engn &quot; Coll Elect Eng~ ## 3 3 Sichuan Univ, Dept Phys &quot; Dept Phys&quot; ## 4 4 Sichuan Univ, Coll Life Sci &quot; Coll Life Sci&quot; ## 5 6 Sichuan Univ, Food Engn &quot; Food Engn&quot; ## 6 7 Sichuan Univ, Coll Phys &quot; Coll Phys&quot; ## 7 8 Sichuan Univ, Sch Business &quot; Sch Business&quot; ## 8 9 Wuhan Univ, Mat Sci &lt;NA&gt; 当然还有其他的解决办法 d %&gt;% mutate( coll = str_remove_all(address, &quot;.*,&quot;) ) d %&gt;% tidyr::separate( address, into = c(&quot;univ&quot;, &quot;coll&quot;), sep = &quot;,&quot;, remove = FALSE ) d %&gt;% tidyr::extract( address, c(&quot;univ&quot;, &quot;coll&quot;), &quot;(Sichuan Univ), (.+)&quot;, remove = FALSE ) 9.9 一些有趣的正则表达式的宏包 https://github.com/gadenbuie/regexplain https://github.com/daranzolin/inferregex https://github.com/VerbalExpressions/RVerbalExpressions library(inferregex) # remotes::install_github(&quot;daranzolin/inferregex&quot;) s &lt;- &quot;abcd-9999-ab9&quot; infer_regex(s)$regex ## [1] &quot;^[a-z]{4}-\\\\d{4}-[a-z]{2}\\\\d$&quot; "],["forcats.html", "第 10 章 因子型变量 10.1 什么是因子 10.2 创建因子 10.3 调整因子顺序 10.4 应用", " 第 10 章 因子型变量 本章介绍R语言中的因子类型数据。因子型变量常用于数据处理和可视化中，尤其在希望不以字母顺序排序的时候，因子就格外有用。 10.1 什么是因子 因子是把数据进行分类并标记为不同层级(level，有时候也翻译成因子水平， 我个人觉得翻译为层级，更接近它的特性，因此，我都会用层级来描述)的数据对象，他们可以存储字符串和整数。因子类型有三个属性： 存储类别的数据类型 离散变量 因子的层级是有限的，只能取因子层级中的值或缺失(NA) 10.2 创建因子 library(tidyverse) income &lt;- c(&quot;low&quot;, &quot;high&quot;, &quot;medium&quot;, &quot;medium&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;) factor(income) ## [1] low high medium medium low high high ## Levels: high low medium 因子层级会自动按照字符串的字母顺序排序，比如high low medium。也可以指定顺序， factor(income, levels = c(&quot;low&quot;, &quot;high&quot;, &quot;medium&quot;) ) ## [1] low high medium medium low high high ## Levels: low high medium 不属于因子层级中的值, 比如这里因子层只有c(\"low\", \"high\")，那么income中的“medium”会被当作缺省值NA factor(income, levels = c(&quot;low&quot;, &quot;high&quot;) ) ## [1] low high &lt;NA&gt; &lt;NA&gt; low high high ## Levels: low high 相比较字符串而言，因子类型更容易处理，因子很多函数会自动的将字符串转换为因子来处理，但事实上，这也会造成，不想当做因子的却又当做了因子的情形，最典型的是在R 4.0之前，data.frame()中stringsAsFactors选项，默认将字符串类型转换为因子类型，但这个默认也带来一些不方便，因此在R 4.0之后取消了这个默认。在tidyverse集合里，有专门处理因子的宏包forcats，因此，本章将围绕forcats宏包讲解如何处理因子类型变量，更多内容可以参考这里。 library(forcats) 10.3 调整因子顺序 前面看到因子层级是按照字母顺序排序 x &lt;- factor(income) x ## [1] low high medium medium low high high ## Levels: high low medium 也可以指定顺序 x %&gt;% fct_relevel(levels = c(&quot;high&quot;, &quot;medium&quot;, &quot;low&quot;)) ## [1] low high medium medium low high high ## Levels: high medium low 或者让“medium” 移动到最前面 x %&gt;% fct_relevel(levels = c(&quot;medium&quot;)) ## [1] low high medium medium low high high ## Levels: medium high low 或者让“medium” 移动到最后面 x %&gt;% fct_relevel(&quot;medium&quot;, after = Inf) ## [1] low high medium medium low high high ## Levels: high low medium 可以按照字符串第一次出现的次序 x %&gt;% fct_inorder() ## [1] low high medium medium low high high ## Levels: low high medium 按照其他变量的中位数的升序排序 x %&gt;% fct_reorder(c(1:7), .fun = median) ## [1] low high medium medium low high high ## Levels: low medium high 10.4 应用 调整因子层级有什么用呢？ 这个功能在ggplot可视化中调整分类变量的顺序非常方便。这里为了方便演示，我们假定有数据框 d &lt;- tibble( x = c(&quot;a&quot;,&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;), y = c(2, 2, 1, 5, 0, 3) ) d ## # A tibble: 6 x 2 ## x y ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 2 ## 2 a 2 ## 3 b 1 ## 4 b 5 ## 5 c 0 ## 6 c 3 先画个散点图看看吧 d %&gt;% ggplot(aes(x = x, y = y)) + geom_point() 我们看到，横坐标上是a-b-c的顺序。 10.4.1 fct_reorder() fct_reorder()可以让x的顺序按照x中每个分类变量对应y值的中位数升序排序，具体为 a对应的y值c(2, 2) 中位数是median(c(2, 2)) = 2 b对应的y值c(1, 5) 中位数是median(c(1, 5)) = 3 c对应的y值c(0, 3) 中位数是median(c(0, 3)) = 1.5 因此，x的因子层级的顺序调整为c-a-b d %&gt;% ggplot(aes(x = fct_reorder(x, y, .fun = median), y = y)) + geom_point() 当然，我们可以加一个参数.desc = TRUE让因子层级变为降序排列b-a-c d %&gt;% ggplot(aes(x = fct_reorder(x, y, .fun = median, .desc = TRUE), y = y)) + geom_point() 但这样会造成x坐标标签一大串，因此建议可以写mutate()函数里 d %&gt;% mutate(x = fct_reorder(x, y, .fun = median, .desc = TRUE)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() 我们还可以按照y值中最小值的大小降序排列 d %&gt;% mutate(x = fct_reorder(x, y, .fun = min, .desc = TRUE)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() 10.4.2 fct_rev() 按照因子层级的逆序排序 d %&gt;% mutate(x = fct_rev(x)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() 10.4.3 fct_relevel() d %&gt;% mutate( x = fct_relevel(x, c(&quot;c&quot;, &quot;a&quot;, &quot;b&quot;)) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() "],["purrr.html", "第 11 章 函数式编程 11.1 简单回顾 11.2 向量化运算 11.3 多说说列表 11.4 列表 vs 向量 11.5 purrr 11.6 自定义函数 11.7 在dplyr函数中的运用map 11.8 延伸阅读", " 第 11 章 函数式编程 很多教材都是讲函数和循环，都是从for, while, ifelse讲起 ，如果我也这样讲，又回到了Base R的老路上去了。考虑到大家都没有编程背景，也不会立志当程序员，所以我直接讲purrr包，留坑以后填吧。 11.1 简单回顾 大家知道R常用的数据结构是向量、矩阵、列表和数据框，如下图 他们构造起来，很多相似性。 list(a = 1, b = &quot;a&quot;) # 列表 c(a = 1, b = 2) # 命名向量 data.frame(a = 1, b = 2) # 数据框 tibble(a = 1, b = 2) # 增强型数据框 11.2 向量化运算 a &lt;- c(2, 4, 3, 1, 5, 7) 用for()循环，让向量的每个元素乘以2 for (i in 1:length(a)) { print(a[i] * 2) } ## [1] 4 ## [1] 8 ## [1] 6 ## [1] 2 ## [1] 10 ## [1] 14 事实上，R语言是支持向量化（将运算符或者函数作用在向量的每一个元素上），可以用向量化代替循环 a * 2 ## [1] 4 8 6 2 10 14 达到同样的效果。 再比如，找出向量a中元素大于2的所有值 for (i in 1:length(a)) { if (a[i] &gt; 2) print(a[i]) } ## [1] 4 ## [1] 3 ## [1] 5 ## [1] 7 用向量化的运算，可以轻松实现 a[a &gt; 2] ## [1] 4 3 5 7 向量是R中最基础的一种数据结构，有种说法是“一切都是向量”，R中的矩阵、数组甚至是列表都可以看成是某种意义上的向量。因此，使用向量化操作可以大大提高代码的运行效率。 11.3 多说说列表 我们构造一个列表 a_list &lt;- list( num = c(8, 9), log = TRUE, cha = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) ) a_list ## $num ## [1] 8 9 ## ## $log ## [1] TRUE ## ## $cha ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; 要想访问某个元素，可以这样 a_list[&quot;num&quot;] ## $num ## [1] 8 9 注意返回结果，第一行是$num，说明返回的结果仍然是列表, 相比a_list来说，a_list[\"num\"]是只包含一个元素的列表。 想将num元素里面的向量提取出来，就得用两个[[ a_list[[&quot;num&quot;]] ## [1] 8 9 大家知道程序员都是偷懒的，为了节省体力，用一个美元符号$代替[[\" \"]]六个字符 a_list$num ## [1] 8 9 在tidyverse里，还可以用 a_list %&gt;% pluck(1) ## [1] 8 9 或者 a_list %&gt;% pluck(&quot;num&quot;) ## [1] 8 9 11.4 列表 vs 向量 假定一向量 v &lt;- c(-2, -1, 0, 1, 2) v ## [1] -2 -1 0 1 2 我们对元素分别取绝对值 abs(v) ## [1] 2 1 0 1 2 如果是列表形式，abs函数应用到列表中就会报错 lst &lt;- list(-2, -1, 0, 1, 2) abs(lst) ## Error in abs(lst): 数学函数中用了非数值参数 报错了。用在向量的函数用在list上，往往行不通。 再来一个例子：我们模拟了5个学生的10次考试的成绩 exams &lt;- list( student1 = round(runif(10, 50, 100)), student2 = round(runif(10, 50, 100)), student3 = round(runif(10, 50, 100)), student4 = round(runif(10, 50, 100)), student5 = round(runif(10, 50, 100)) ) exams ## $student1 ## [1] 82 77 68 71 78 62 70 67 100 53 ## ## $student2 ## [1] 96 93 85 58 50 88 69 65 51 51 ## ## $student3 ## [1] 55 70 76 87 75 72 97 80 50 74 ## ## $student4 ## [1] 84 73 54 58 54 64 57 84 67 63 ## ## $student5 ## [1] 95 66 52 70 61 74 84 61 71 71 很显然，exams是一个列表。那么，每个学生的平均成绩是多呢？ 我们可能会想到用mean函数，但是 mean(exams) ## [1] NA 发现报错了，可以看看帮助文档看看问题出在什么地方 ?mean() 帮助文档告诉我们，mean()要求第一个参数是数值型或者逻辑型的向量。 而我们这里的exams是列表，因此无法运行。 那好，我们就用笨办法吧 list( student1 = mean(exams$student1), student2 = mean(exams$student2), student3 = mean(exams$student3), student4 = mean(exams$student4), student5 = mean(exams$student5) ) ## $student1 ## [1] 72.8 ## ## $student2 ## [1] 70.6 ## ## $student3 ## [1] 73.6 ## ## $student4 ## [1] 65.8 ## ## $student5 ## [1] 70.5 成功了。但发现我们写了好多代码，如果有100个学生，那就得写更多的代码，如果是这样，程序员就不高兴了，这太累了啊。于是purrr包的map函数来解救我们，下面主角出场了。 11.5 purrr 介绍之前，先试试 exams %&gt;% map(mean) ## $student1 ## [1] 72.8 ## ## $student2 ## [1] 70.6 ## ## $student3 ## [1] 73.6 ## ## $student4 ## [1] 65.8 ## ## $student5 ## [1] 70.5 哇，短短几句话，得出了相同的结果。如果希望返回的是数值型的向量，可以这样写 exams %&gt;% map_dbl(mean) ## student1 student2 student3 student4 student5 ## 72.8 70.6 73.6 65.8 70.5 如果希望返回的结果是数据框 exams %&gt;% map_df(mean) ## # A tibble: 1 x 5 ## student1 student2 student3 student4 student5 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 72.8 70.6 73.6 65.8 70.5 是不是很酷？ 事实上，map函数 第一个参数是向量或列表（数据框是列表的一种特殊形式，因此数据框也是可以的） 第二个参数是函数，这个函数会应用到列表的每一个元素，比如这里map函数执行过程如下 ： 具体为，exams有5个元素，一个元素装着一个学生的10次考试成绩， 运行map(exams, mean)函数后， 首先取出exams第一个元素exams$student1(它是向量)，然后执行 mean(exams$student1), 然后将计算结果存放在列表result中的第一个位置result1上； 做完第一个学生的，紧接着取出exams第二个元素exams$student2，执行 mean(exams$student2), 然后将计算结果存放在列表result中的第一个位置result2上； 如此这般，直到所有学生都处理完毕。我们得到了最终结果—一个新的列表result。 当然，我们也可以根据需要，让map返回我们需要的数据格式, purrr也提供了方便的函数，具体如下 我们将mean函数换成求方差var函数试试， exams %&gt;% map_df(var) ## # A tibble: 1 x 5 ## student1 student2 student3 student4 student5 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 161. 338. 188. 127. 149. 11.6 自定义函数 刚才我们是让学生成绩执行求平均mean，求方差var等函数。我们也可以自定义函数。 比如我们这里定义了将向量中心化的函数（先求出10次考试的平均值，然后每次考试成绩去减这个平均值） my_fun &lt;- function(x){ x - mean(x) } exams %&gt;% map_df(my_fun) ## # A tibble: 10 x 5 ## student1 student2 student3 student4 student5 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 9.2 25.4 -18.6 18.2 24.5 ## 2 4.2 22.4 -3.60 7.2 -4.5 ## 3 -4.80 14.4 2.4 -11.8 -18.5 ## 4 -1.80 -12.6 13.4 -7.80 -0.5 ## 5 5.2 -20.6 1.4 -11.8 -9.5 ## 6 -10.8 17.4 -1.60 -1.80 3.5 ## 7 -2.80 -1.60 23.4 -8.80 13.5 ## 8 -5.80 -5.60 6.4 18.2 -9.5 ## 9 27.2 -19.6 -23.6 1.2 0.5 ## 10 -19.8 -19.6 0.4 -2.80 0.5 当然可以偷懒将函数直接写在map()里，用~代替my_fun， 但代价是参数必须是规定的写法，比如.x exams %&gt;% map_df(~ .x - mean(.x)) ## # A tibble: 10 x 5 ## student1 student2 student3 student4 student5 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 9.2 25.4 -18.6 18.2 24.5 ## 2 4.2 22.4 -3.60 7.2 -4.5 ## 3 -4.80 14.4 2.4 -11.8 -18.5 ## 4 -1.80 -12.6 13.4 -7.80 -0.5 ## 5 5.2 -20.6 1.4 -11.8 -9.5 ## 6 -10.8 17.4 -1.60 -1.80 3.5 ## 7 -2.80 -1.60 23.4 -8.80 13.5 ## 8 -5.80 -5.60 6.4 18.2 -9.5 ## 9 27.2 -19.6 -23.6 1.2 0.5 ## 10 -19.8 -19.6 0.4 -2.80 0.5 有时候，程序员觉得x还是有点多余，于是更够懒一点，只用.， 也是可以的 exams %&gt;% map_df(~ . - mean(.)) ## # A tibble: 10 x 5 ## student1 student2 student3 student4 student5 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 9.2 25.4 -18.6 18.2 24.5 ## 2 4.2 22.4 -3.60 7.2 -4.5 ## 3 -4.80 14.4 2.4 -11.8 -18.5 ## 4 -1.80 -12.6 13.4 -7.80 -0.5 ## 5 5.2 -20.6 1.4 -11.8 -9.5 ## 6 -10.8 17.4 -1.60 -1.80 3.5 ## 7 -2.80 -1.60 23.4 -8.80 13.5 ## 8 -5.80 -5.60 6.4 18.2 -9.5 ## 9 27.2 -19.6 -23.6 1.2 0.5 ## 10 -19.8 -19.6 0.4 -2.80 0.5 总之，有三种方法将函数传递给map() 直接传递 map(.x, mean, na.rm = TRUE ) 匿名函数 map(.x, funciton(.x) { mean(.x, na.rm = TRUE) } ) 使用 ~ function(.x) { .x *2 } # 程序员偷懒了 ~ .x * 2 map(.x, ~ mean(.x, na.rm = TRUE) ) 11.7 在dplyr函数中的运用map 如果想显示列表中每个元素的长度，可以这样写 tibble( x = list(1, 2:3, 4:6) ) %&gt;% mutate(l = purrr::map_int(x, length)) ## # A tibble: 3 x 2 ## x l ## &lt;list&gt; &lt;int&gt; ## 1 &lt;dbl [1]&gt; 1 ## 2 &lt;int [2]&gt; 2 ## 3 &lt;int [3]&gt; 3 用于各种函数，比如产生随机数 tibble( x = c(3, 5, 6) ) %&gt;% mutate(r = purrr::map(x, ~rnorm(.x, mean = 0, sd = 1))) ## # A tibble: 3 x 2 ## x r ## &lt;dbl&gt; &lt;list&gt; ## 1 3 &lt;dbl [3]&gt; ## 2 5 &lt;dbl [5]&gt; ## 3 6 &lt;dbl [6]&gt; 用于建模 mtcars %&gt;% group_by(cyl) %&gt;% nest() %&gt;% mutate(model = purrr::map(data, ~ lm(mpg ~ wt, data = .))) %&gt;% mutate(result = purrr::map(model, ~ broom::tidy(.))) %&gt;% unnest(result) ## # A tibble: 6 x 8 ## # Groups: cyl [3] ## cyl data model term estimate std.error statistic ## &lt;dbl&gt; &lt;lis&gt; &lt;lis&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6 &lt;tib~ &lt;lm&gt; (Int~ 28.4 4.18 6.79 ## 2 6 &lt;tib~ &lt;lm&gt; wt -2.78 1.33 -2.08 ## 3 4 &lt;tib~ &lt;lm&gt; (Int~ 39.6 4.35 9.10 ## 4 4 &lt;tib~ &lt;lm&gt; wt -5.65 1.85 -3.05 ## 5 8 &lt;tib~ &lt;lm&gt; (Int~ 23.9 3.01 7.94 ## 6 8 &lt;tib~ &lt;lm&gt; wt -2.19 0.739 -2.97 ## # ... with 1 more variable: p.value &lt;dbl&gt; 更多内容和方法可参考第 22 章数据框列方向和行方向。 11.8 延伸阅读 1、阅读Hadley Wickham的r4ds这本书第16章。 2、看手册?purrr::modify()， 思考下它与map()的区别 exams %&gt;% map(~ . - mean(.)) exams %&gt;% modify(~ . - mean(.)) exams %&gt;% as_tibble() %&gt;% map(~ . - mean(.)) exams %&gt;% as_tibble() %&gt;% modify(~ . - mean(.)) 3、他们的区别哪里？函数能否互换？ mtcars %&gt;% map_chr(typeof) mtcars %&gt;% map_lgl(is.double) mtcars %&gt;% map_int(n_unique) mtcars %&gt;% map_dbl(mean) "],["tibble.html", "第 12 章 简单数据框 12.1 tidyverse 家族 12.2 人性化的tibble 12.3 tibble 与 data.frame 12.4 tibble数据操作 12.5 关于行名 12.6 修复列名 12.7 nested tibble 12.8 延伸阅读", " 第 12 章 简单数据框 library(tidyverse) library(tibble) # 事实上，library(tidyverse)已经加装了library(tibble) 12.1 tidyverse 家族 前面陆续介绍了tidyverse家族，家庭主要成员包括 功能 宏包 有颜值担当 ggplot2 数据处理王者 dplyr 数据转换专家 tidyr 数据载入利器 readr 循环加速器 purrr 强化数据框 tibble 字符串处理 stringr 因子处理 forcats 12.2 人性化的tibble tibble是用来替换data.frame类型的扩展的数据框 tibble继承了data.frame，是弱类型的。换句话说，tibble是data.frame的子类型 tibble与data.frame有相同的语法，使用起来更方便 tibble更早的检查数据，方便写出更干净、更多富有表现力的代码 tibble对data.frame做了重新的设定： tibble，不关心输入类型，可存储任意类型，包括list类型 tibble，没有行名设置 row.names tibble，支持任意的列名 tibble，会自动添加列名 tibble，类型只能回收长度为1的输入 tibble，会懒加载参数，并按顺序运行 tibble，是tbl_df类型 12.3 tibble 与 data.frame 传统创建数据框 data.frame( a = 1:5, b = letters[1:5] ) ## a b ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e 发现，data.frame()会自动将字符串型的变量转换成因子型，如果想保持原来的字符串型，就得 data.frame( a = 1:5, b = letters[1:5], stringsAsFactors = FALSE ) ## a b ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e Note： - 在R 4.0 后，data.frame() 不会将字符串型变量自动转换成因子型 用tibble创建数据框，不会这么麻烦，输出的就是原来的字符串类型 tibble( a = 1:5, b = letters[1:5] ) ## # A tibble: 5 x 2 ## a b ## &lt;int&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e 我们有时候喜欢这样，构建两个有关联的变量， 比如 tb &lt;- tibble( x = 1:3, y = x + 2 ) tb ## # A tibble: 3 x 2 ## x y ## &lt;int&gt; &lt;dbl&gt; ## 1 1 3 ## 2 2 4 ## 3 3 5 但是，如果用传统的data.frame()来构建，会报错 df &lt;- data.frame( x = 1:3, y = x + 2 ) ## Error in data.frame(x = 1:3, y = x + 2): 找不到对象&#39;x&#39; df ## function (x, df1, df2, ncp, log = FALSE) ## { ## if (missing(ncp)) ## .Call(C_df, x, df1, df2, log) ## else .Call(C_dnf, x, df1, df2, ncp, log) ## } ## &lt;bytecode: 0x000000002b736f28&gt; ## &lt;environment: namespace:stats&gt; 因此，在这一点上tibble()做的比较人性化。 大家还可以发现tibble另一个优势：tibble输出时，会显示多一行，用来指定每一列的类型。 tibble用缩写定义了7种类型： 类型 含义 int 代表integer dbl 代表double chr 代表character向量或字符串 dttm 代表日期+时间(date+time) lgl 代表逻辑判断TRUE或者FALSE fctr 代表因子类型factor date 代表日期dates 12.4 tibble数据操作 12.4.1 创建tibble tibble()创建一个tibble类型的data.frame: tibble(a = 1:5, b = letters[1:5]) ## # A tibble: 5 x 2 ## a b ## &lt;int&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e 刚才提到了，可以这样， tibble( a = 1:5, b = 10:14, c = a + b ) ## # A tibble: 5 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 10 11 ## 2 2 11 13 ## 3 3 12 15 ## 4 4 13 17 ## 5 5 14 19 为了让每列更加直观，也可以tribble()创建，数据量不大的时候，挺方便的 tribble( ~x, ~y, ~z, &quot;a&quot;, 2, 3.6, &quot;b&quot;, 1, 8.5 ) ## # A tibble: 2 x 3 ## x y z ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a 2 3.6 ## 2 b 1 8.5 12.4.2 转换成tibble类型 转换成tibble类型意思就是说，刚开始不是tibble, 现在转换成tibble， 包括 data.frame转换成tibble vector转换成tibble list转换成tibble matrix转换成tibble 12.4.2.1 data.frame转换成tibble t1 &lt;- iris[1:6, 1:4] # data.frame类型: class(t1) ## [1] &quot;data.frame&quot; as_tibble(t1) ## # A tibble: 6 x 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 12.4.2.2 vector转型到tibble x &lt;- as_tibble(1:5) # Use `tibble::enframe() x ## # A tibble: 5 x 1 ## value ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 12.4.2.3 把list转型为tibble df &lt;- as_tibble(list(x = 1:6, y = runif(6), z = 6:1)) df ## # A tibble: 6 x 3 ## x y z ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 0.720 6 ## 2 2 0.589 5 ## 3 3 0.553 4 ## 4 4 0.999 3 ## 5 5 0.0202 2 ## 6 6 0.568 1 把tibble再转为list? as.list(df) 12.4.2.4 把matrix转型为tibble。 m &lt;- matrix(rnorm(15), ncol = 5) as_tibble(m) ## # A tibble: 3 x 5 ## V1 V2 V3 V4 V5 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.748 1.20 0.653 -0.00353 -0.636 ## 2 -1.49 0.766 0.402 -1.68 -0.464 ## 3 0.0560 0.0957 0.0967 -0.958 1.25 tibble转回matrix? as.matrix(df) 12.4.3 tibble简单操作 构建一个简单的数据框 df &lt;- tibble( x = 1:2, y = 2:1 ) df ## # A tibble: 2 x 2 ## x y ## &lt;int&gt; &lt;int&gt; ## 1 1 2 ## 2 2 1 增加一列 add_column(df, z = 0:1, w = 0) ## # A tibble: 2 x 4 ## x y z w ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 0 0 ## 2 2 1 1 0 增加一行 add_row(df, x = 99, y = 9) ## # A tibble: 3 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 ## 2 2 1 ## 3 99 9 在第二行，增加一行 add_row(df, x = 99, y = 9, .before = 2) ## # A tibble: 3 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 ## 2 99 9 ## 3 2 1 12.4.4 有用的函数lst lst，创建一个list，具有tibble特性的list。 lst(n = 5, x = runif(n), y = TRUE) ## $n ## [1] 5 ## ## $x ## [1] 0.668265 0.388227 0.318994 0.563726 0.007567 ## ## $y ## [1] TRUE 12.4.5 有用的函数enframe enframe()将矢量快速创建tibble，，创建的tibble只有2列: name和value enframe(1:3) ## # A tibble: 3 x 2 ## name value ## &lt;int&gt; &lt;int&gt; ## 1 1 1 ## 2 2 2 ## 3 3 3 enframe(c(a = 5, b = 7, c = 9)) ## # A tibble: 3 x 2 ## name value ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 5 ## 2 b 7 ## 3 c 9 12.4.6 有用的函数deframe deframe()可以看做是enframe() 的反操作，把tibble反向转成向量 df &lt;- enframe(c(a = 5, b = 7)) df ## # A tibble: 2 x 2 ## name value ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 5 ## 2 b 7 # 转为vector deframe(df) ## a b ## 5 7 12.4.7 读取文件 read_csv()读取文件时，生成的直接就是tibble read_csv(&quot;./demo_data/wages.csv&quot;) ## # A tibble: 1,379 x 6 ## earn height sex race ed age ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 79571. 73.9 male white 16 49 ## 2 96397. 66.2 female white 16 62 ## 3 48711. 63.8 female white 16 33 ## 4 80478. 63.2 female other 16 95 ## 5 82089. 63.1 female white 17 43 ## 6 15313. 64.5 female white 15 30 ## 7 47104. 61.5 female white 12 53 ## 8 50960. 73.3 male white 17 50 ## 9 3213. 72.2 male hispanic 15 25 ## 10 42997. 72.4 male white 12 30 ## # ... with 1,369 more rows 12.5 关于行名 data.frame是支持行名的，但tibble不支持行名，这也是两者不同的地方 # 创建data.frame df &lt;- data.frame(x = 1:3, y = 3:1) # 给df增加行名 row.names(df) &lt;- LETTERS[1:3] df ## x y ## A 1 3 ## B 2 2 ## C 3 1 # 判断是否有行名 has_rownames(df) ## [1] TRUE 但是对于tibble tb &lt;- tibble(x = 1:3, y = 3:1) row.names(tb) &lt;- LETTERS[1:3] 需要注意的： 有时候遇到含有行名的data.frame，转换成tibble后，行名会被丢弃 如果想保留行名，就需要把行名转换成单独的一列 举个例子 df &lt;- mtcars[1:3, 1:3] df ## mpg cyl disp ## Mazda RX4 21.0 6 160 ## Mazda RX4 Wag 21.0 6 160 ## Datsun 710 22.8 4 108 # 把行名转换为单独的一列 rownames_to_column(df, var = &quot;rowname&quot;) ## rowname mpg cyl disp ## 1 Mazda RX4 21.0 6 160 ## 2 Mazda RX4 Wag 21.0 6 160 ## 3 Datsun 710 22.8 4 108 # 把行索引转换为单独的一列 rowid_to_column(df, var = &quot;rowid&quot;) ## rowid mpg cyl disp ## 1 1 21.0 6 160 ## 2 2 21.0 6 160 ## 3 3 22.8 4 108 12.6 修复列名 规范的来说，数据框的列名应该是唯一。但现实中代码是人写的，因此可能会稀奇古怪的，所幸的是tibble也提供了人性化的解决方案 tibble(x = 1, x = 2) ## Error: Column name `x` must not be duplicated. .name_repair = \"check_unique\" 检查列名唯一性，但不做修复（默认） .name_repair = \"minimal\"， 不检查也不修复，维持现状 .name_repair = \"unique\" 修复列名，使得列名唯一且不为空 .name_repair = \"universal\" 修复列名，使得列名唯一且语法可读 具体使用方法： tibble(x = 1, x = 2, .name_repair = &quot;minimal&quot;) ## # A tibble: 1 x 2 ## x x ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 tibble(x = 1, x = 2, .name_repair = &quot;unique&quot;) ## # A tibble: 1 x 2 ## x...1 x...2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 tibble(x = 1, x = 2, .name_repair = &quot;universal&quot;) ## # A tibble: 1 x 2 ## x...1 x...2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 tibble(`a 1` = 1, `a 2` = 2, .name_repair = &quot;universal&quot;) ## # A tibble: 1 x 2 ## a.1 a.2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 如果认为x...1, x...2 不符合自己的审美，可以指定修复函数 tibble(x = 1, x = 2, .name_repair = make.unique) ## # A tibble: 1 x 2 ## x x.1 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 tibble(x = 1, x = 2, .name_repair = ~ make.unique(.x, sep = &quot;_&quot;)) ## # A tibble: 1 x 2 ## x x_1 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 tibble(x = 1, x = 2, .name_repair = ~ make.names(., unique = TRUE)) ## # A tibble: 1 x 2 ## x x.1 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 注意make.unique(names, sep = \".\")和make.names(names, unique = FALSE, allow_ = TRUE) 是基础包的函数，可通过?make.unique()或者make.names()获取说明文档。 当然也可以自定义函数 fix_names &lt;- function(x) gsub(&quot;\\\\s+&quot;, &quot;_&quot;, x) tibble(`year 1` = 1, `year 2` = 2, .name_repair = fix_names) ## # A tibble: 1 x 2 ## year_1 year_2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 感觉越说越复杂了，事实上，我们写数据框的时候，完全可以避免上述问题，只要做到规范列名。 如果真正遇到比较乱的列名，推荐使用janitor::clean_names()一步到位。 library(janitor) tibble(`year 1` = 1, `year 2` = 2) %&gt;% clean_names() ## # A tibble: 1 x 2 ## year_1 year_2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 12.7 nested tibble nested tibble 和 List-columns (列表列) 会在后面的章节详细介绍。 iris %&gt;% group_by(Species) %&gt;% nest() ## # A tibble: 3 x 2 ## # Groups: Species [3] ## Species data ## &lt;fct&gt; &lt;list&gt; ## 1 setosa &lt;tibble [50 x 4]&gt; ## 2 versicolor &lt;tibble [50 x 4]&gt; ## 3 virginica &lt;tibble [50 x 4]&gt; 12.8 延伸阅读 1、阅读Hadley Wickham的r4ds这本书第10章。 2、 tibble的官方主页：https://tibble.tidyverse.org/ 3、创建列表列的方法，可以参考nested tibble和 list-columns "],["ggplot2-geom.html", "第 13 章 ggplot2之几何对象 13.1 一个有趣的案例 13.2 学习目标 13.3 开始 13.4 基本绘图 13.5 主题风格 13.6 参考资料", " 第 13 章 ggplot2之几何对象 采菊东篱下，悠然见南山。 根据大家投票，觉得ggplot2是最想掌握的技能，我想这就是R语言中最有质感的部分吧。所以，这里专门拿出一节课讲ggplot2，也算是补上之前第 7 章数据可视化没讲的内容。 library(tidyverse) 13.1 一个有趣的案例 先看一组数据 df &lt;- read_csv(&quot;./demo_data/datasaurus.csv&quot;) df ## # A tibble: 1,846 x 3 ## dataset x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 dino 55.4 97.2 ## 2 dino 51.5 96.0 ## 3 dino 46.2 94.5 ## 4 dino 42.8 91.4 ## 5 dino 40.8 88.3 ## 6 dino 38.7 84.9 ## 7 dino 35.6 79.9 ## 8 dino 33.1 77.6 ## 9 dino 29.0 74.5 ## 10 dino 26.2 71.4 ## # ... with 1,836 more rows 先用dataset分组后，然后计算每组下x的均值和方差，y的均值和方差，以及x，y两者的相关系数，我们发现每组数据下它们几乎都是相等的 df %&gt;% group_by(dataset) %&gt;% summarise( across(everything(), list(mean = mean, sd = sd), .names = &quot;{fn}_{col}&quot;) ) %&gt;% mutate( across(is.numeric, round, 3) ) ## # A tibble: 13 x 5 ## dataset mean_x sd_x mean_y sd_y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 away 54.3 16.8 47.8 26.9 ## 2 bullseye 54.3 16.8 47.8 26.9 ## 3 circle 54.3 16.8 47.8 26.9 ## 4 dino 54.3 16.8 47.8 26.9 ## 5 dots 54.3 16.8 47.8 26.9 ## 6 h_lines 54.3 16.8 47.8 26.9 ## 7 high_lines 54.3 16.8 47.8 26.9 ## 8 slant_down 54.3 16.8 47.8 26.9 ## 9 slant_up 54.3 16.8 47.8 26.9 ## 10 star 54.3 16.8 47.8 26.9 ## 11 v_lines 54.3 16.8 47.8 26.9 ## 12 wide_lines 54.3 16.8 47.8 26.9 ## 13 x_shape 54.3 16.8 47.8 26.9 如果上面代码不熟悉，可以用第 6 章的代码重新表达，也是一样的 df %&gt;% group_by(dataset) %&gt;% summarize( mean_x = mean(x), mean_y = mean(y), std_dev_x = sd(x), std_dev_y = sd(y), corr_x_y = cor(x, y) ) ## # A tibble: 13 x 6 ## dataset mean_x mean_y std_dev_x std_dev_y corr_x_y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 away 54.3 47.8 16.8 26.9 -0.0641 ## 2 bullseye 54.3 47.8 16.8 26.9 -0.0686 ## 3 circle 54.3 47.8 16.8 26.9 -0.0683 ## 4 dino 54.3 47.8 16.8 26.9 -0.0645 ## 5 dots 54.3 47.8 16.8 26.9 -0.0603 ## 6 h_lines 54.3 47.8 16.8 26.9 -0.0617 ## 7 high_lin~ 54.3 47.8 16.8 26.9 -0.0685 ## 8 slant_do~ 54.3 47.8 16.8 26.9 -0.0690 ## 9 slant_up 54.3 47.8 16.8 26.9 -0.0686 ## 10 star 54.3 47.8 16.8 26.9 -0.0630 ## 11 v_lines 54.3 47.8 16.8 26.9 -0.0694 ## 12 wide_lin~ 54.3 47.8 16.8 26.9 -0.0666 ## 13 x_shape 54.3 47.8 16.8 26.9 -0.0656 那么，我们是否能得出结论，每组的数据长的差不多呢？然而，我们画图发现 ggplot(df, aes(x = x, y = y, colour = dataset)) + geom_point() + # geom_smooth(method = lm) + theme(legend.position = &quot;none&quot;) + facet_wrap(~dataset, ncol = 3) 事实上，每张图都相差很大。所以，这里想说明的是，眼见为实。换句话说，可视化是数据探索中非常重要的部分。本章的目的就是带领大家学习ggplot2基本的绘图技能。 13.2 学习目标 13.2.1 图形语法 13.2.2 图形部件 data: 数据框data.frame (注意，不支持向量vector和列表list类型） aes: 数据框中的数据变量映射到图形属性。什么叫图形属性？就是图中点的位置、形状，大小，颜色等眼睛能看到的东西。什么叫映射？就是一种对应关系，比如数学中的函数b = f(a)就是a和b之间的一种映射关系, a的值决定或者控制了b的值，在ggplot2语法里，a就是我们输入的数据变量，b就是图形属性， 这些图形属性包括： x（x轴方向的位置） y（y轴方向的位置） color（点或者线等元素的颜色） size（点或者线等元素的大小） shape（点或者线等元素的形状） alpha（点或者线等元素的透明度） geoms: 几何对象，确定我们想画什么样的图，一个geom_***确定一种图形。更多几何对象推荐阅读这里 geom_bar() geom_density() geom_freqpoly() geom_histogram() geom_violin() geom_boxplot() geom_col() geom_point() geom_smooth() geom_tile() geom_density2d() geom_bin2d() geom_hex() geom_count() geom_text() geom_sf() stats: 统计变换 scales: 标度 coord: 坐标系统 facet: 分面 layer： 增加图层 theme: 主题风格 save: 保存图片 ggplot2图层语法框架 13.3 开始 前面讲到R语言数据类型有字符串型、数值型、因子型、逻辑型、日期型等，ggplot2会将字符串型、因子型、逻辑型、日期型默认为离散变量，而数值型默认为连续变量。我们在而呈现数据的时候，可能会同时用到多种类型的数据，比如 一个离散 一个连续 两个离散 两个连续 一个离散, 一个连续 三个连续 13.3.1 导入数据 gapdata &lt;- read_csv(&quot;./demo_data/gapminder.csv&quot;) gapdata ## # A tibble: 1,704 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanist~ Asia 1952 28.8 8.43e6 779. ## 2 Afghanist~ Asia 1957 30.3 9.24e6 821. ## 3 Afghanist~ Asia 1962 32.0 1.03e7 853. ## 4 Afghanist~ Asia 1967 34.0 1.15e7 836. ## 5 Afghanist~ Asia 1972 36.1 1.31e7 740. ## 6 Afghanist~ Asia 1977 38.4 1.49e7 786. ## 7 Afghanist~ Asia 1982 39.9 1.29e7 978. ## 8 Afghanist~ Asia 1987 40.8 1.39e7 852. ## 9 Afghanist~ Asia 1992 41.7 1.63e7 649. ## 10 Afghanist~ Asia 1997 41.8 2.22e7 635. ## # ... with 1,694 more rows 13.3.2 检查数据 # 是否有缺失值 gapdata %&gt;% summarise( across(everything(), ~ sum(is.na(.))) ) ## # A tibble: 1 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 0 country 代表国家 countinet 表示所在的洲 year 时间 lifeExp 平均寿命 pop 人口数量 gdpPercap 人均GDP 接下来，我们需要思考我们应该选择什么样的图，呈现这些不同类型的数据，探索数据背后的故事 13.4 基本绘图 13.4.1 柱状图 常用于一个离散变量 gapdata %&gt;% ggplot(aes(x = continent)) + geom_bar() gapdata %&gt;% ggplot(aes(x = reorder(continent, continent, length))) + geom_bar() gapdata %&gt;% ggplot(aes(x = reorder(continent, continent, length))) + geom_bar() + coord_flip() # geom_bar vs stat_count gapdata %&gt;% ggplot(aes(x = continent)) + stat_count() gapdata %&gt;% count(continent) ## # A tibble: 5 x 2 ## continent n ## &lt;chr&gt; &lt;int&gt; ## 1 Africa 624 ## 2 Americas 300 ## 3 Asia 396 ## 4 Europe 360 ## 5 Oceania 24 可见，geom_bar() 自动完成了这个统计，更多geom与stat对应关系见这里 gapdata %&gt;% distinct(continent, country) %&gt;% ggplot(aes(x = continent)) + geom_bar() 我个人比较喜欢先统计，然后画图 gapdata %&gt;% distinct(continent, country) %&gt;% group_by(continent) %&gt;% summarise(num = n()) %&gt;% ggplot(aes(x = continent, y = num)) + geom_col() 13.4.2 直方图 常用于一个连续变量 gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_histogram() # 对应的stat_bin() gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_histogram(binwidth = 1) #&#39; histograms, 默认使用 `position = &quot;stack&quot;` gapdata %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_histogram() #&#39; 使用`position = &quot;identity&quot;` gapdata %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_histogram(position = &quot;identity&quot;) gapdata %&gt;% ggplot(aes(x = lifeExp, color = continent)) + geom_freqpoly() #&#39; smooth histogram = densityplot gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_density() 如果不喜欢下面那条线，可以这样 gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_line(stat = &quot;density&quot;) # adjust 调节bandwidth, # adjust = 1/2 means use half of the default bandwidth. gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_density(adjust = 1) gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_density(adjust = 0.2) gapdata %&gt;% ggplot(aes(x = lifeExp, color = continent)) + geom_density() gapdata %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_density(alpha = 0.2) gapdata %&gt;% filter(continent != &quot;Oceania&quot;) %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_density(alpha = 0.2) gapdata %&gt;% ggplot(aes(x = lifeExp)) + geom_density() + # facet_wrap(vars(continent)) facet_grid(. ~ continent) gapdata %&gt;% filter(continent != &quot;Oceania&quot;) %&gt;% ggplot(aes(x = lifeExp, fill = continent)) + geom_histogram() + facet_grid(continent ~ .) 直方图和密度图画在一起。注意y = stat(density)表示y是由x新生成的变量，这是一种固定写法，类似的还有stat(count), stat(level) gapdata %&gt;% filter(continent != &quot;Oceania&quot;) %&gt;% ggplot(aes(x = lifeExp, y = stat(density))) + geom_histogram(aes(fill = continent)) + geom_density() + facet_grid(continent ~ .) 13.4.3 箱线图 一个离散变量 + 一个连续变量 #&#39; 思考下结果为什么是这样？ gapdata %&gt;% ggplot(aes(x = year, y = lifeExp)) + geom_boxplot() # 数据框中的year变量是数值型，需要先转换成因子型，弄成离散型变量 gapdata %&gt;% ggplot(aes(x = as.factor(year), y = lifeExp)) + geom_boxplot() # 明确指定分组变量 gapdata %&gt;% ggplot(aes(x = year, y = lifeExp)) + geom_boxplot(aes(group = year)) gapdata %&gt;% ggplot(aes(x = year, y = lifeExp)) + geom_violin(aes(group = year)) + geom_jitter(alpha = 1 / 4) + geom_smooth(se = FALSE) 13.4.4 抖散图 点重叠的处理方案 gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_point() gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_jitter() gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_boxplot() gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_boxplot() + geom_jitter() gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_jitter() + stat_summary(fun.y = median, colour = &quot;red&quot;, geom = &quot;point&quot;, size = 5) gapdata %&gt;% ggplot(aes(reorder(x = continent, lifeExp), y = lifeExp)) + geom_jitter() + stat_summary(fun.y = median, colour = &quot;red&quot;, geom = &quot;point&quot;, size = 5) 注意到我们已经提到过 stat_count / stat_bin / stat_summary gapdata %&gt;% ggplot(aes(x = continent, y = lifeExp)) + geom_violin( trim = FALSE, alpha = 0.5 ) + stat_summary( fun.y = mean, fun.ymax = function(x) { mean(x) + sd(x) }, fun.ymin = function(x) { mean(x) - sd(x) }, geom = &quot;pointrange&quot; ) 13.4.5 山峦图 常用于一个离散变量 + 一个连续变量 gapdata %&gt;% ggplot(aes( x = lifeExp, y = continent, fill = continent )) + ggridges::geom_density_ridges() # https://learnui.design/tools/data-color-picker.html#palette gapdata %&gt;% ggplot(aes( x = lifeExp, y = continent, fill = continent )) + ggridges::geom_density_ridges() + scale_fill_manual( values = c(&quot;#003f5c&quot;, &quot;#58508d&quot;, &quot;#bc5090&quot;, &quot;#ff6361&quot;, &quot;#ffa600&quot;) ) gapdata %&gt;% ggplot(aes( x = lifeExp, y = continent, fill = continent )) + ggridges::geom_density_ridges() + scale_fill_manual( values = colorspace::sequential_hcl(5, palette = &quot;Peach&quot;) ) 13.4.6 散点图 常用于两个连续变量 gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() gapdata %&gt;% ggplot(aes(x = log(gdpPercap), y = lifeExp)) + geom_point() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + scale_x_log10() # A better way to log transform gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent)) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(alpha = (1 / 3), size = 2) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + geom_smooth() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + geom_smooth(lwd = 3, se = FALSE) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point(show.legend = FALSE) + facet_wrap(~continent) jCountries &lt;- c(&quot;Canada&quot;, &quot;Rwanda&quot;, &quot;Cambodia&quot;, &quot;Mexico&quot;) gapdata %&gt;% filter(country %in% jCountries) %&gt;% ggplot(aes(x = year, y = lifeExp, color = country)) + geom_line() + geom_point() gapdata %&gt;% filter(country %in% jCountries) %&gt;% ggplot(aes( x = year, y = lifeExp, color = reorder(country, -1 * lifeExp, max) )) + geom_line() + geom_point() 这是一种技巧，但我更推荐以下方法 d1 &lt;- gapdata %&gt;% filter(country %in% jCountries) %&gt;% group_by(country) %&gt;% mutate(end_label = if_else(year == max(year), country, NA_character_)) d1 ## # A tibble: 48 x 7 ## # Groups: country [4] ## country continent year lifeExp pop gdpPercap ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Cambod~ Asia 1952 39.4 4.69e6 368. ## 2 Cambod~ Asia 1957 41.4 5.32e6 434. ## 3 Cambod~ Asia 1962 43.4 6.08e6 497. ## 4 Cambod~ Asia 1967 45.4 6.96e6 523. ## 5 Cambod~ Asia 1972 40.3 7.45e6 422. ## 6 Cambod~ Asia 1977 31.2 6.98e6 525. ## 7 Cambod~ Asia 1982 51.0 7.27e6 624. ## 8 Cambod~ Asia 1987 53.9 8.37e6 684. ## 9 Cambod~ Asia 1992 55.8 1.02e7 682. ## 10 Cambod~ Asia 1997 56.5 1.18e7 734. ## # ... with 38 more rows, and 1 more variable: ## # end_label &lt;chr&gt; d1 %&gt;% ggplot(aes( x = year, y = lifeExp, color = country )) + geom_line() + geom_point() + geom_label(aes(label = end_label)) + theme(legend.position = &quot;none&quot;) 如果觉得麻烦，就用gghighlight宏包吧 gapdata %&gt;% filter(country %in% jCountries) %&gt;% ggplot(aes( x = year, y = lifeExp, color = country )) + geom_line() + geom_point() + gghighlight::gghighlight() 13.4.7 点线图 gapdata %&gt;% filter(continent == &quot;Asia&quot; &amp; year == 2007) %&gt;% ggplot(aes(x = lifeExp, y = country)) + geom_point() gapdata %&gt;% filter(continent == &quot;Asia&quot; &amp; year == 2007) %&gt;% ggplot(aes( x = lifeExp, y = reorder(country, lifeExp) )) + geom_point(color = &quot;blue&quot;, size = 2) + geom_segment(aes( x = 40, xend = lifeExp, y = reorder(country, lifeExp), yend = reorder(country, lifeExp) ), color = &quot;lightgrey&quot; ) + labs( x = &quot;Life Expectancy (years)&quot;, y = &quot;&quot;, title = &quot;Life Expectancy by Country&quot;, subtitle = &quot;GapMinder data for Asia - 2007&quot; ) + theme_minimal() + theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank() ) 13.4.8 文本标注 gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + ggforce::geom_mark_ellipse(aes( filter = gdpPercap &gt; 70000, label = &quot;有钱的国家&quot;, description = &quot;他们是什么国家?&quot; )) ten_countries &lt;- gapdata %&gt;% distinct(country) %&gt;% pull() %&gt;% sample(10) library(ggrepel) gapdata %&gt;% filter(year == 2007) %&gt;% mutate( label = ifelse(country %in% ten_countries, as.character(country), &quot;&quot;) ) %&gt;% ggplot(aes(log(gdpPercap), lifeExp)) + geom_point( size = 3.5, alpha = .9, shape = 21, col = &quot;white&quot;, fill = &quot;#0162B2&quot; ) + geom_text_repel( aes(label = label), size = 4.5, point.padding = .2, box.padding = .3, force = 1, min.segment.length = 0 ) + theme_minimal(14) + theme( legend.position = &quot;none&quot;, panel.grid.minor = element_blank() ) + labs( x = &quot;log(GDP per capita)&quot;, y = &quot;life expectancy&quot; ) 13.4.9 errorbar图 avg_gapdata &lt;- gapdata %&gt;% group_by(continent) %&gt;% summarise( mean = mean(lifeExp), sd = sd(lifeExp) ) avg_gapdata ## # A tibble: 5 x 3 ## continent mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Africa 48.9 9.15 ## 2 Americas 64.7 9.35 ## 3 Asia 60.1 11.9 ## 4 Europe 71.9 5.43 ## 5 Oceania 74.3 3.80 avg_gapdata %&gt;% ggplot(aes(continent, mean, fill = continent)) + # geom_col(alpha = 0.5) + geom_point() + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.25) 13.4.10 椭圆图 gapdata %&gt;% ggplot(aes(x = log(gdpPercap), y = lifeExp)) + geom_point() + stat_ellipse(type = &quot;norm&quot;, level = 0.95) 13.4.11 2D 密度图 与一维的情形geom_density()类似， geom_density_2d(), geom_bin2d(), geom_hex()常用于刻画两个变量构成的二维区间的密度 gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_bin2d() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_hex() 13.4.12 马赛克图 geom_tile()， geom_contour()， geom_raster()常用于3个变量 gapdata %&gt;% group_by(continent, year) %&gt;% summarise(mean_lifeExp = mean(lifeExp)) %&gt;% ggplot(aes(x = year, y = continent, fill = mean_lifeExp)) + geom_tile() + scale_fill_viridis_c() 事实上可以有更好的呈现方式 gapdata %&gt;% group_by(continent, year) %&gt;% summarise(mean_lifeExp = mean(lifeExp)) %&gt;% ggplot(aes(x = year, y = continent, size = mean_lifeExp)) + geom_point() gapdata %&gt;% group_by(continent, year) %&gt;% summarise(mean_lifeExp = mean(lifeExp)) %&gt;% ggplot(aes(x = year, y = continent, size = mean_lifeExp)) + geom_point(shape = 21, color = &quot;red&quot;, fill = &quot;white&quot;) + scale_size_continuous(range = c(7, 15)) + geom_text(aes(label = round(mean_lifeExp, 2)), size = 3, color = &quot;black&quot;) + theme(legend.position = &quot;none&quot;) 13.5 主题风格 gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggtitle(&quot;Life expectancy over time by continent&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + theme_grey() # the default gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + theme_bw() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_calc() + ggtitle(&quot;ggthemes::theme_calc()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_economist() + ggtitle(&quot;ggthemes::theme_economist()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_economist_white() + ggtitle(&quot;ggthemes::theme_economist_white()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_few() + ggtitle(&quot;ggthemes::theme_few()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_gdocs() + ggtitle(&quot;ggthemes::theme_gdocs()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_tufte() + ggtitle(&quot;ggthemes::theme_tufte()&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + geom_smooth(lwd = 3, se = FALSE, method = &quot;lm&quot;) + ggthemes::theme_wsj() + ggtitle(&quot;ggthemes::theme_wsj()&quot;) 13.6 参考资料 Look at Data from Data Vizualization for Social Science Chapter 3: Data Visualisation of R for Data Science Chapter 28: Graphics for communication of R for Data Science Graphs in R Graphics Cookbook ggplot2 cheat sheet ggplot2 documentation The R Graph Gallery (this is really useful) Top 50 ggplot2 Visualizations R Graphics Cookbook by Winston Chang ggplot extensions plotly for creating interactive graphs "],["ggplot2-theme.html", "第 14 章 ggplot2之主题设置 14.1 图表整体元素 14.2 坐标轴元素 14.3 面板元素 14.4 图例元素 14.5 分面元素 14.6 案例 14.7 小结 14.8 提问", " 第 14 章 ggplot2之主题设置 这一章我们一起学习ggplot2中的theme elements 语法，感谢Henry Wang提供了很好的思路。如果需要详细了解，可以参考Hadley Wickham最新版的《ggplot2: Elegant Graphics for Data Analysis》，最推荐的是ggplot2官方文档 theme(element_name = element_function()) 这里element_function()有四个 element_text() element_line() element_rect() element_blank() 望文生义吧，内置元素函数有四个基础类型： element_text(), 文本，一般用于控制标签和标题的字体风格 element_line(), 线条，一般用于控制线条或线段的颜色或线条类型 element_rect(), 矩形区域，一般用于控制背景矩形的颜色或者边界线条类型 element_blank() , 空白，就是不分配相应的绘图空间，即删去这个地方的绘图元素。 每个元素函数都有一系列控制外观的参数，下面我们通过具体的案例来一一介绍吧。 library(tidyverse) 还是用让人生厌的ggplot2::mpg数据包吧，具体介绍请见?? 章。 glimpse(mpg) ## Rows: 234 ## Columns: 11 ## $ manufacturer &lt;chr&gt; &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;audi... ## $ model &lt;chr&gt; &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;,... ## $ displ &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8,... ## $ year &lt;int&gt; 1999, 1999, 2008, 2008, 1999,... ## $ cyl &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4,... ## $ trans &lt;chr&gt; &quot;auto(l5)&quot;, &quot;manual(m5)&quot;, &quot;ma... ## $ drv &lt;chr&gt; &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;,... ## $ cty &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 1... ## $ hwy &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 2... ## $ fl &lt;chr&gt; &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;,... ## $ class &lt;chr&gt; &quot;compact&quot;, &quot;compact&quot;, &quot;compac... 稍微做点数据整理 df &lt;- mpg %&gt;% as_tibble() %&gt;% filter(class != &quot;2seater&quot;, manufacturer %in% c(&quot;toyota&quot;, &quot;volkswagen&quot;)) df ## # A tibble: 61 x 11 ## manufacturer model displ year cyl trans drv ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 toyota 4run~ 2.7 1999 4 manu~ 4 ## 2 toyota 4run~ 2.7 1999 4 auto~ 4 ## 3 toyota 4run~ 3.4 1999 6 auto~ 4 ## 4 toyota 4run~ 3.4 1999 6 manu~ 4 ## 5 toyota 4run~ 4 2008 6 auto~ 4 ## 6 toyota 4run~ 4.7 2008 8 auto~ 4 ## 7 toyota camry 2.2 1999 4 manu~ f ## 8 toyota camry 2.2 1999 4 auto~ f ## 9 toyota camry 2.4 2008 4 manu~ f ## 10 toyota camry 2.4 2008 4 auto~ f ## # ... with 51 more rows, and 4 more variables: ## # cty &lt;int&gt;, hwy &lt;int&gt;, fl &lt;chr&gt;, class &lt;chr&gt; 我相信这种图你们已经会画了吧 df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) 想让这张图，符合你的想法？如何控制呢？come on 14.1 图表整体元素 图表整体元素包括: 描述 主题元素 类型 整个图形背景 plot.background element_rect() 图形标题 plot.title element_text() 图形边距 plot.margin margin() df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( plot.background = element_rect(fill = &quot;orange&quot;, color = &quot;black&quot;, size = 10), plot.title = element_text(hjust = 1, color = &quot;red&quot;, face = &quot;italic&quot;), plot.margin = margin(t = 20, r = 20, b = 20, l = 20, unit = &quot;pt&quot;) ) 14.2 坐标轴元素 坐标轴元素包括: 描述 主题元素 类型 坐标轴刻度 axis.ticks element_line() 坐标轴标题 axis.title element_text() 坐标轴标签 axis.text element_text() 直线和坐标轴 axis.line element_line() df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( axis.line = element_line(color = &quot;orange&quot;, size = 2), axis.title = element_text(color = &quot;red&quot;, face = &quot;italic&quot;), axis.ticks = element_line(color = &quot;purple&quot;, size = 3), axis.text = element_text(color = &quot;blue&quot;), axis.text.x = element_text(angle = 45, hjust = 1) ) 14.3 面板元素 面板元素包括: 描述 主题元素 类型 面板背景 panel.background element_rect() 面板网格线 panel.grid element_line() 面板边界 panel.border element_rect() df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( panel.background = element_rect(fill = &quot;orange&quot;, color = &quot;red&quot;), panel.grid = element_line(color = &quot;grey80&quot;, size = 0.5) ) 或者 df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( panel.background = element_rect(fill = &quot;orange&quot;), panel.grid = element_line(color = &quot;grey80&quot;, size = 0.5), panel.border = element_rect(color = &quot;red&quot;, fill = NA) ) 14.4 图例元素 图例元素包括: 描述 主题元素 类型 图例背景 legend.background element_rect() 图例符号 legend.key element_rect() 图例标签 legend.text element_text() 图例标题 legend.title element_text() 图例边距 legend.margin margin 图例位置 legend.postion “top,” “bottom,” “left,” “right” df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( legend.background = element_rect(fill = &quot;orange&quot;), legend.title = element_text(color = &quot;blue&quot;, size = 10), legend.key = element_rect(fill = &quot;grey80&quot;), legend.text = element_text(color = &quot;red&quot;), legend.margin = margin(t = 20, r = 20, b = 20, l = 20, unit = &quot;pt&quot;), legend.position = &quot;bottom&quot; ) 14.5 分面元素 分面元素包括: 描述 主题元素 类型 分面标签背景 strip.background element_rect() 条状文本 strip.text element_text() 分面间隔 panel.spacing unit df %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + facet_grid(vars(manufacturer), vars(class)) + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + theme( strip.background = element_rect(fill = &quot;orange&quot;), strip.text = element_text(color = &quot;red&quot;), panel.spacing = unit(0.3, &quot;inch&quot;) # , # strip.switch.pad.grid = ) 14.6 案例 diamonds %&gt;% ggplot(aes(carat, price)) + geom_hex() + labs(title = &quot;Diamond&quot;) + theme( axis.title.x = element_text( size = 30, color = &quot;red&quot;, face = &quot;bold&quot;, angle = 10 ), legend.title = element_text( size = 25, color = &quot;#ff6361&quot;, margin = margin(b = 5) ), plot.title = element_text( size = 35, face = &quot;bold&quot;, color = &quot;blue&quot; ) ) 你肯定不会觉得这图好看。 library(palmerpenguins) penguins %&gt;% ggplot(aes(bill_length_mm, bill_depth_mm)) + geom_point() + theme( axis.line.y = element_line( color = &quot;black&quot;, size = 1.2, arrow = grid::arrow() ), axis.line.x = element_line( linetype = &quot;dashed&quot;, color = &quot;brown&quot;, size = 1.2 ), axis.ticks = element_line(color = &quot;red&quot;, size = 1.1), axis.ticks.length = unit(3, &quot;mm&quot;), panel.grid.major = element_line( color = &quot;blue&quot;, size = 1.2 ), panel.grid.minor = element_line( color = &quot;#58508d&quot;, size = 1.2, linetype = &quot;dotted&quot; ) ) penguins %&gt;% ggplot(aes(bill_length_mm, bill_depth_mm)) + geom_point(aes(color = species)) + theme( legend.background = element_rect( fill = &quot;#fff6c2&quot;, color = &quot;black&quot;, linetype = &quot;dashed&quot; ), legend.key = element_rect(fill = &quot;grey&quot;, color = &quot;brown&quot;), panel.background = element_rect( fill = &quot;#005F59&quot;, color = &quot;red&quot;, size = 3 ), panel.border = element_rect( color = &quot;black&quot;, fill = &quot;transparent&quot;, linetype = &quot;dashed&quot;, size = 3 ), plot.background = element_rect( fill = &quot;#a1dce9&quot;, color = &quot;black&quot;, size = 1.3 ), legend.position = &quot;bottom&quot; ) 14.7 小结 14.8 提问 ggplot2中 plot 与 panel 有区别？ 假定数据是这样 library(tidyverse) set.seed(12) d1 &lt;- data.frame(x = rnorm(50, 10, 2), type = &quot;Island #1&quot;) d2 &lt;- data.frame(x = rnorm(50, 18, 1.2), type = &quot;Island #2&quot;) dd &lt;- bind_rows(d1, d2) %&gt;% set_names(c(&quot;Height&quot;, &quot;Location&quot;)) head(dd) ## Height Location ## 1 7.039 Island #1 ## 2 13.154 Island #1 ## 3 8.087 Island #1 ## 4 8.160 Island #1 ## 5 6.005 Island #1 ## 6 9.455 Island #1 你画图后，交给老板看 dd %&gt;% ggplot(aes(x = Height, fill = Location)) + geom_histogram(binwidth = 1, color = &quot;white&quot;) + scale_fill_manual(values = c(&quot;green3&quot;, &quot;turquoise3&quot;)) 然而，老板有点不满意，希望你要这样改 请用前后两章学到的内容让老板满意吧 "],["ggplot2-scales.html", "第 15 章 ggplot2之标度 15.1 标度 15.2 图形属性和变量类型 15.3 坐标轴和图例是同样的东西 15.4 丰富的标度体系 15.5 案例详解 15.6 用标度还是主题？ 15.7 小测试", " 第 15 章 ggplot2之标度 这一章我们一起学习ggplot2中的scales语法，推荐大家阅读Hadley Wickham最新版的《ggplot2: Elegant Graphics for Data Analysis》，但如果需要详细了解标度参数体系，还是要看ggplot2官方文档 15.1 标度 在 13章，我们了解到ggplot2中，映射是数据转化到图形属性，这里的图形属性是指视觉可以感知的东西，比如大小，形状，颜色和位置等。我们今天讨论的标度（scale）是控制着数据到图形属性映射的函数，每一种标度都是从数据空间的某个区域（标度的定义域）到图形属性空间的某个区域（标度的值域）的一个函数。 简单点来说，标度是用于调整数据映射的图形属性。 在ggplot2中，每一种图形属性都拥有一个默认的标度，也许你对这个默认的标度不满意，可以就需要学习如何修改默认的标度。比如， 系统默认\"a\"对应红色，\"b\"对应蓝色，我们想让\"a\"对应紫色，\"b\"对应橙色。 15.2 图形属性和变量类型 还是用我们熟悉的ggplot2::mpg，可能有同学说，我画图没接触到scale啊，比如 library(tidyverse) mpg %&gt;% ggplot(aes(x = displ, y = hwy)) + geom_point(aes(colour = class)) 能画个很漂亮的图，那是因为ggplot2默认缺省条件下，已经很美观了。（据说Hadley Wickham很后悔使用了这么漂亮的缺省值，因为很漂亮了大家都不认真学画图了。马云好像也说后悔创立了阿里巴巴？） 事实上，根据映射关系和变量名，我们将标度写完整，应该是这样的 ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = class)) + scale_x_continuous() + scale_y_continuous() + scale_colour_discrete() 如果每次都要手动设置一次标度函数，那将是比较繁琐的事情。因此ggplot2使用了默认了设置，如果不满意ggplot2的默认值，可以手动调整或者改写标度，比如 ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = class)) + scale_x_continuous(name = &quot;这是我的x坐标&quot;) + scale_y_continuous(name = &quot;这是我的y坐标&quot;) + scale_colour_brewer() 15.3 坐标轴和图例是同样的东西 15.4 丰富的标度体系 注意到，标度函数是由\"_\"分割的三个部分构成的 - scale - 视觉属性名 (e.g., colour, shape or x) - 标度名 (e.g., continuous, discrete, brewer). 每个标度函数内部都有丰富的参数系统 scale_colour_manual( palette = function(), limits = NULL, name = waiver(), labels = waiver(), breaks = waiver(), minor_breaks = waiver(), values = waiver(), ... ) 参数name，坐标和图例的名字，如果不想要图例的名字，就可以 name = NULL 参数limits, 坐标或图例的范围区间。连续性c(n, m)，离散型c(\"a\", \"b\", \"c\") 参数breaks, 控制显示在坐标轴或者图例上的值（元素） 参数labels, 坐标和图例的间隔标签 一般情况下，内置函数会自动完成 也可人工指定一个字符型向量，与breaks提供的字符型向量一一对应 也可以是函数，把breaks提供的字符型向量当做函数的输入 NULL，就是去掉标签 参数values 指的是（颜色、形状等）视觉属性值, 要么，与数值的顺序一致； 要么，与breaks提供的字符型向量长度一致 要么，用命名向量c(\"数据标签\" = \"视觉属性\")提供 参数expand, 控制参数溢出量 参数range, 设置尺寸大小范围，比如针对点的相对大小 下面，我们通过具体的案例讲解如何使用参数，把图形变成我们想要的模样。 15.5 案例详解 先导入一个数据 gapdata &lt;- read_csv(&quot;./demo_data/gapminder.csv&quot;) newgapdata &lt;- gapdata %&gt;% group_by(continent, country) %&gt;% summarise( across(c(lifeExp, gdpPercap, pop), mean) ) newgapdata ## # A tibble: 142 x 5 ## # Groups: continent [5] ## continent country lifeExp gdpPercap pop ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Africa Algeria 59.0 4426. 1.99e7 ## 2 Africa Angola 37.9 3607. 7.31e6 ## 3 Africa Benin 48.8 1155. 4.02e6 ## 4 Africa Botswana 54.6 5032. 9.71e5 ## 5 Africa Burkina Faso 44.7 844. 7.55e6 ## 6 Africa Burundi 44.8 472. 4.65e6 ## 7 Africa Cameroon 48.1 1775. 9.82e6 ## 8 Africa Central African~ 43.9 959. 2.56e6 ## 9 Africa Chad 46.8 1165. 5.33e6 ## 10 Africa Comoros 52.4 1314. 3.62e5 ## # ... with 132 more rows newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_continuous() newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10() newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10(breaks = c(500, 1000, 3000, 10000, 30000), labels = scales::dollar) newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10( name = &quot;人均GDP&quot;, breaks = c(500, 1000, 3000, 10000, 30000), labels = scales::unit_format(unit = &quot;美元&quot;)) newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10() + scale_color_viridis_d() 离散变量映射到色彩的情形，可以使用ColorBrewer色彩。 newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10() + scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Set1&quot;) newgapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = continent, size = pop)) + scale_x_log10() + scale_color_manual( name = &quot;五大洲&quot;, values = c(&quot;Africa&quot; = &quot;red&quot;, &quot;Americas&quot; = &quot;blue&quot;, &quot;Asia&quot; = &quot;orange&quot;, &quot;Europe&quot; = &quot;black&quot;, &quot;Oceania&quot; = &quot;gray&quot;), breaks = c(&quot;Africa&quot;, &quot;Americas&quot;, &quot;Asia&quot;, &quot;Europe&quot;, &quot;Oceania&quot;), labels = c(&quot;非洲&quot;, &quot;美洲&quot;, &quot;亚洲&quot;, &quot;欧洲&quot;, &quot;大洋洲&quot;) ) + scale_size( name = &quot;人口数量&quot;, breaks = c(2e8, 5e8, 7e8), labels = c(&quot;2亿&quot;, &quot;5亿&quot;, &quot;7亿&quot;) ) 15.6 用标度还是主题？ 那什么时候用标度，什么时候用主题？这里有个原则：主题风格不会增加标签，也不会改变变量的范围，主题只会改变字体、大小、颜色等等。 15.7 小测试 用 ggplot2 重复这张lego图 "],["ggplot2-guides.html", "第 16 章 ggplot2之图例系统 16.1 图例系统 16.2 案例详解 16.3 删除其中一个图例 16.4 小结", " 第 16 章 ggplot2之图例系统 这一章，我们一起学习ggplot2中的图例系统，内容相对简单，但还是推荐大家阅读ggplot2官方文档 16.1 图例系统 为了方便演示，我们还是用熟悉的配方ggplot2::mpg library(tidyverse) mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() 如果想调整图例的样式，可以使用guides()函数，用法类似上节课中的theme函数, 具体参数为： 要么是字符串 (i.e. \"color = colorbar\" or \"color = legend\"), 要么是特定的函数 (i.e. color = guide_colourbar() or color = guide_legend()) 16.2 案例详解 mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + guides(color = &quot;legend&quot;) mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + guides(color = guide_bins( title = &quot;my title&quot;, label.hjust = 1 ) ) mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + guides(color = guide_legend( ncol = 4 ) ) mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = factor(cyl))) + geom_point() + ggtitle(&quot;这是我的标题&quot;) + labs(x = &quot;x_displ&quot;, y = &quot;y_hwy&quot;) + guides(color = guide_legend( title = &quot;标题好像有点高&quot;, title.position = &quot;top&quot;, title.vjust = 5, label.position = &quot;left&quot;, label.hjust = 1, label.theme = element_text(size = 15, face = &quot;italic&quot;, colour = &quot;red&quot;, angle = 0), keywidth = 5, reverse = TRUE ) ) 16.3 删除其中一个图例 mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = class, size = cyl)) + geom_point() 比如，我们想删除size这个图例，那么需要这样做 mpg %&gt;% ggplot(aes(x = displ, y = hwy, color = class, size = cyl)) + geom_point() + guides(color = guide_legend(&quot;汽车类型&quot;), # keep size = FALSE # remove ) 16.4 小结 到了这里，ggplot2内容的差不多介绍完了，最后做下自我测试，能读懂下面代码(来源 Emi Tanaka)的意思？ mtcars %&gt;% as_tibble() %&gt;% ggplot(aes(x = wt, y = mpg, shape = factor(vs), color = hp)) + geom_point(size = 3) + colorspace::scale_color_continuous_sequential(palette = &quot;Dark Mint&quot;) + scale_shape_discrete(labels = c(&quot;V-shaped&quot;, &quot;Straight&quot;)) + labs( x = &quot;Weight (1000 lbs)&quot;, y = &quot;Miles per gallon&quot;, title = &quot;Motor Trend Car Road Tests&quot;, shape = &quot;Engine&quot;, color = &quot;Horsepower&quot; ) + theme( text = element_text(size = 18, color = &quot;white&quot;), rect = element_rect(fill = &quot;black&quot;), panel.background = element_rect(fill = &quot;black&quot;), legend.key = element_rect(fill = &quot;black&quot;), axis.text = element_text(color = &quot;white&quot;), plot.title.position = &quot;plot&quot;, plot.margin = margin(10, 10, 10, 10) ) + guides( shape = guide_legend(override.aes = list(color = &quot;white&quot;)) ) "],["ggplot2-customize.html", "第 17 章 ggplot2之扩展内容 17.1 你喜欢哪个图 17.2 定制 17.3 组合图片 17.4 中文字体 17.5 高亮某一组 17.6 函数图 17.7 地图", " 第 17 章 ggplot2之扩展内容 ggplot2的强大，还在于它的扩展包。本章在介绍ggplot2新的内容的同时还会引入一些新的宏包，需要提前安装 install.packages(c(&quot;sf&quot;, &quot;cowplot&quot;, &quot;patchwork&quot;, &quot;gghighlight&quot;, &quot;ggforce&quot;)) 如果安装不成功，请先update宏包，再执行上面安装命令 library(tidyverse) library(gghighlight) library(cowplot) library(patchwork) library(ggforce) library(ggridges) 17.1 你喜欢哪个图 p1 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + geom_point() + geom_smooth() + labs(title = &quot;1: geom_point() + geom_smooth()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p2 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + geom_hex() + labs(title = &quot;2: geom_hex()&quot;) + guides(fill = FALSE) + theme(plot.title = element_text(face = &quot;bold&quot;)) p3 &lt;- ggplot(mpg, aes(x = drv, fill = drv)) + geom_bar() + labs(title = &quot;3: geom_bar()&quot;) + guides(fill = FALSE) + theme(plot.title = element_text(face = &quot;bold&quot;)) p4 &lt;- ggplot(mpg, aes(x = cty)) + geom_histogram(binwidth = 2, color = &quot;white&quot;) + labs(title = &quot;4: geom_histogram()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p5 &lt;- ggplot(mpg, aes(x = cty, y = drv, fill = drv)) + geom_violin() + guides(fill = FALSE) + labs(title = &quot;5: geom_violin()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p6 &lt;- ggplot(mpg, aes(x = cty, y = drv, fill = drv)) + geom_boxplot() + guides(fill = FALSE) + labs(title = &quot;6: geom_boxplot()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p7 &lt;- ggplot(mpg, aes(x = cty, fill = drv)) + geom_density(alpha = 0.7) + guides(fill = FALSE) + labs(title = &quot;7: geom_density()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p8 &lt;- ggplot(mpg, aes(x = cty, y = drv, fill = drv)) + geom_density_ridges() + guides(fill = FALSE) + labs(title = &quot;8: ggridges::geom_density_ridges()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p9 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + geom_density_2d() + labs(title = &quot;9: geom_density_2d()&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 + plot_layout(nrow = 3) 17.2 定制 17.2.1 标签 gapdata &lt;- read_csv(&quot;./demo_data/gapminder.csv&quot;) gapdata ## # A tibble: 1,704 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanist~ Asia 1952 28.8 8.43e6 779. ## 2 Afghanist~ Asia 1957 30.3 9.24e6 821. ## 3 Afghanist~ Asia 1962 32.0 1.03e7 853. ## 4 Afghanist~ Asia 1967 34.0 1.15e7 836. ## 5 Afghanist~ Asia 1972 36.1 1.31e7 740. ## 6 Afghanist~ Asia 1977 38.4 1.49e7 786. ## 7 Afghanist~ Asia 1982 39.9 1.29e7 978. ## 8 Afghanist~ Asia 1987 40.8 1.39e7 852. ## 9 Afghanist~ Asia 1992 41.7 1.63e7 649. ## 10 Afghanist~ Asia 1997 41.8 2.22e7 635. ## # ... with 1,694 more rows gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + ggtitle(&quot;My Plot Title&quot;) + xlab(&quot;The X Variable&quot;) + ylab(&quot;The Y Variable&quot;) gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + labs( title = &quot;My Plot Title&quot;, subtitle = &quot;My Plot subtitle&quot;, x = &quot;The X Variable&quot;, y = &quot;The Y Variable&quot; ) 17.2.2 定制颜色 我喜欢用这两个函数定制喜欢的绘图色彩，scale_colour_manual() 和 scale_fill_manual(). 更多方法可以参考 Colours chapter in Cookbook for R gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + scale_color_manual( values = c(&quot;#195744&quot;, &quot;#008148&quot;, &quot;#C6C013&quot;, &quot;#EF8A17&quot;, &quot;#EF2917&quot;) ) 17.3 组合图片 我们有时候想把多张图组合到一起 17.3.1 cowplot 可以使用 cowplot 宏包的plot_grid()函数完成多张图片的组合，使用方法很简单。 p1 &lt;- gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point(aes(color = lifeExp &gt; mean(lifeExp))) + scale_x_log10() + theme(legend.position = &quot;none&quot;) + scale_color_manual(values = c(&quot;orange&quot;, &quot;pink&quot;)) + labs( title = &quot;My Plot Title&quot;, x = &quot;The X Variable&quot;, y = &quot;The Y Variable&quot; ) p2 &lt;- gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + scale_color_manual( values = c(&quot;#195744&quot;, &quot;#008148&quot;, &quot;#C6C013&quot;, &quot;#EF8A17&quot;, &quot;#EF2917&quot;) ) + theme(legend.position = &quot;none&quot;) + labs( title = &quot;My Plot Title&quot;, x = &quot;The X Variable&quot;, y = &quot;The Y Variable&quot; ) cowplot::plot_grid( p1, p2, labels = c(&quot;A&quot;, &quot;B&quot;) ) 也可以使用patchwork宏包，更简单的方法 library(patchwork) p1 + p2 p1 / p2 p1 + p2 + plot_annotation( tag_levels = &quot;A&quot;, title = &quot;The surprising truth about mtcars&quot;, subtitle = &quot;These 3 plots will reveal yet-untold secrets about our beloved data-set&quot;, caption = &quot;Disclaimer: None of these plots are insightful&quot; ) 再来一个 library(palmerpenguins) g1 &lt;- penguins %&gt;% ggplot(aes(bill_length_mm, body_mass_g, color = species)) + geom_point() + theme_bw(base_size = 14) + labs(tag = &quot;(A)&quot;, x = &quot;Bill length (mm)&quot;, y = &quot;Body mass (g)&quot;, color = &quot;Species&quot;) g2 &lt;- penguins %&gt;% ggplot(aes(bill_length_mm, bill_depth_mm, color = species)) + geom_point() + theme_bw(base_size = 14) + labs(tag = &quot;(B)&quot;, x = &quot;Bill length (mm)&quot;, y = &quot;Bill depth (mm)&quot;, color = &quot;Species&quot;) g1 + g2 + patchwork::plot_layout(guides = &quot;collect&quot;) patchwork 使用方法很简单，根本不需要记 17.3.2 保存图片 使用ggsave()函数，将图片保存为所需要的格式，如“.pdf,” “.png”等， 还可以指定图片的高度和宽度，默认units是英寸，也可以使用“cm,” or “mm.” pp &lt;- gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + scale_color_manual( values = c(&quot;#195744&quot;, &quot;#008148&quot;, &quot;#C6C013&quot;, &quot;#EF8A17&quot;, &quot;#EF2917&quot;) ) + theme(legend.position = &quot;none&quot;) + labs( title = &quot;My Plot Title&quot;, x = &quot;The X Variable&quot;, y = &quot;The Y Variable&quot; ) # ggsave(&quot;demo_plot.pdf&quot;, plot = pp, width = 8, height = 6) 17.4 中文字体 library(showtext) showtext_auto() gapdata %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10() + scale_color_manual( values = c(&quot;#195744&quot;, &quot;#008148&quot;, &quot;#C6C013&quot;, &quot;#EF8A17&quot;, &quot;#EF2917&quot;) ) + theme(legend.position = &quot;none&quot;) + labs( title = &quot;这是我的标题美美哒&quot;, x = &quot;这是我的x坐标&quot;, y = &quot;这是我的y坐标&quot; ) # ggsave(&quot;myfirst.pdf&quot;, width = 8, height = 6) 17.5 高亮某一组 画图很容易，然而画一张好图，不容易。图片质量好不好，其原则就是不增加看图者的心智负担，有些图片的色彩很丰富，然而需要看图人配合文字和图注等信息才能看懂作者想表达的意思，这样就失去了图片“一图胜千言”的价值。 分析数据过程中，我们可以使用高亮我们某组数据，突出我们想表达的信息，是非常好的一种可视化探索手段。 17.5.1 ggplot2方法 这种方法是将背景部分和高亮部分分两步来画 drop_facet &lt;- function(x) select(x, -continent) gapdata %&gt;% ggplot() + geom_line( data = drop_facet, aes(x = year, y = lifeExp, group = country), color = &quot;grey&quot;, ) + geom_line(aes(x = year, y = lifeExp, color = country, group = country)) + facet_wrap(vars(continent)) + theme(legend.position = &quot;none&quot;) 再来一个 gapdata %&gt;% mutate(group = country) %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% ggplot() + geom_line( data = function(d) select(d, -country), aes(x = year, y = lifeExp, group = group), color = &quot;grey&quot;, ) + geom_line(aes(x = year, y = lifeExp, group = country), color = &quot;red&quot;) + facet_wrap(vars(country)) + theme(legend.position = &quot;none&quot;) 17.5.2 gghighlight方法 这里推荐gghighlight宏包 dplyr has filter() ggplot has Highlighting gapdata %&gt;% filter(country == &quot;China&quot;) ## # A tibble: 12 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 China Asia 1952 44 556263527 400. ## 2 China Asia 1957 50.5 637408000 576. ## 3 China Asia 1962 44.5 665770000 488. ## 4 China Asia 1967 58.4 754550000 613. ## 5 China Asia 1972 63.1 862030000 677. ## 6 China Asia 1977 64.0 943455000 741. ## 7 China Asia 1982 65.5 1000281000 962. ## 8 China Asia 1987 67.3 1084035000 1379. ## 9 China Asia 1992 68.7 1164970000 1656. ## 10 China Asia 1997 70.4 1230075000 2289. ## 11 China Asia 2002 72.0 1280400000 3119. ## 12 China Asia 2007 73.0 1318683096 4959. gapdata %&gt;% ggplot( aes(x = year, y = lifeExp, color = continent, group = country) ) + geom_line() + gghighlight( country == &quot;China&quot;, # which is passed to dplyr::filter(). label_key = country ) gapdata %&gt;% filter(continent == &quot;Asia&quot;) ## # A tibble: 396 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanist~ Asia 1952 28.8 8.43e6 779. ## 2 Afghanist~ Asia 1957 30.3 9.24e6 821. ## 3 Afghanist~ Asia 1962 32.0 1.03e7 853. ## 4 Afghanist~ Asia 1967 34.0 1.15e7 836. ## 5 Afghanist~ Asia 1972 36.1 1.31e7 740. ## 6 Afghanist~ Asia 1977 38.4 1.49e7 786. ## 7 Afghanist~ Asia 1982 39.9 1.29e7 978. ## 8 Afghanist~ Asia 1987 40.8 1.39e7 852. ## 9 Afghanist~ Asia 1992 41.7 1.63e7 649. ## 10 Afghanist~ Asia 1997 41.8 2.22e7 635. ## # ... with 386 more rows gapdata %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% ggplot(aes(year, lifeExp, color = country, group = country)) + geom_line(size = 1.2, alpha = .9, color = &quot;#E58C23&quot;) + theme_minimal(base_size = 14) + theme( legend.position = &quot;none&quot;, panel.grid.major.x = element_blank(), panel.grid.minor = element_blank() ) + gghighlight( country %in% c(&quot;China&quot;, &quot;India&quot;, &quot;Japan&quot;, &quot;Korea, Rep.&quot;), use_group_by = FALSE, use_direct_label = FALSE, unhighlighted_params = list(color = &quot;grey90&quot;) ) + facet_wrap(vars(country)) 17.6 函数图 有时候我们想画一个函数图，比如正态分布的函数，可能会想到先产生数据，然后画图，比如下面的代码 tibble(x = seq(from = -3, to = 3, by = .01)) %&gt;% mutate(y = dnorm(x, mean = 0, sd = 1)) %&gt;% ggplot(aes(x = x, y = y)) + geom_line(color = &quot;grey33&quot;) 事实上，stat_function()可以简化这个过程 ggplot(data = data.frame(x = c(-3, 3)), aes(x = x)) + stat_function(fun = dnorm) 当然我们也可以绘制自定义函数 myfun &lt;- function(x) { (x - 1)**2 } ggplot(data = data.frame(x = c(-1, 3)), aes(x = x)) + stat_function(fun = myfun, geom = &quot;line&quot;, colour = &quot;red&quot;) 下面这是一个很不错的例子，细细体会下 d &lt;- tibble(x = rnorm(2000, mean = 2, sd = 4)) ggplot(data = d, aes(x = x)) + geom_histogram(aes(y = stat(density))) + geom_density() + stat_function(fun = dnorm, args = list(mean = 2, sd = 4), colour = &quot;red&quot;) 17.7 地图 小时候画地图很容易，长大了画地图却不容易了。 这是一个公园地图和公园里松鼠数量的数据集 nyc_squirrels &lt;- read_csv(&quot;./demo_data/nyc_squirrels.csv&quot;) central_park &lt;- sf::read_sf(&quot;./demo_data/central_park&quot;) 先来一个地图， ggplot() + geom_sf(data = central_park) 一个geom_sf就搞定了，貌似没那么难呢？ 好吧，换个姿势，在地图上标注松鼠出现的位置 nyc_squirrels %&gt;% drop_na(primary_fur_color) %&gt;% ggplot() + geom_sf(data = central_park, color = &quot;grey85&quot;) + geom_point( aes(x = long, y = lat, color = primary_fur_color), size = .8 ) 分开画呢 nyc_squirrels %&gt;% drop_na(primary_fur_color) %&gt;% ggplot() + geom_sf(data = central_park, color = &quot;grey85&quot;) + geom_point( aes(x = long, y = lat, color = primary_fur_color), size = .8 ) + facet_wrap(vars(primary_fur_color)) + theme(legend.position = &quot;none&quot;) label_colors &lt;- c(&quot;all squirrels&quot; = &quot;grey75&quot;, &quot;highlighted group&quot; = &quot;#0072B2&quot;) nyc_squirrels %&gt;% drop_na(primary_fur_color) %&gt;% ggplot() + geom_sf(data = central_park, color = &quot;grey85&quot;) + geom_point( data = function(x) select(x, -primary_fur_color), aes(x = long, y = lat, color = &quot;all squirrels&quot;), size = .8 ) + geom_point( aes(x = long, y = lat, color = &quot;highlighted group&quot;), size = .8 ) + cowplot::theme_map(16) + theme( legend.position = &quot;bottom&quot;, legend.justification = &quot;center&quot; ) + facet_wrap(vars(primary_fur_color)) + scale_color_manual(name = NULL, values = label_colors) + guides(color = guide_legend(override.aes = list(size = 2))) # ggsave(&quot;Squirrels.pdf&quot;, width = 9, height = 6) 当然，也可以用gghighlight的方法 nyc_squirrels %&gt;% drop_na(primary_fur_color) %&gt;% ggplot() + geom_sf(data = central_park, color = &quot;grey85&quot;) + geom_point( aes(x = long, y = lat, color = primary_fur_color), size = .8 ) + gghighlight( label_key = primary_fur_color, use_direct_label = FALSE ) + facet_wrap(vars(primary_fur_color)) + cowplot::theme_map(16) + theme(legend.position = &quot;none&quot;) library(ggplot2) library(showtext) showtext_auto() font_families() ## [1] &quot;sans&quot; &quot;serif&quot; &quot;mono&quot; ## [4] &quot;wqy-microhei&quot; font_paths() ## [1] &quot;C:\\\\Windows\\\\Fonts&quot; # font_files() ## Add fonts that are available on Windows(默认路径&quot;C:\\\\Windows\\\\Fonts&quot;) font_add(&quot;heiti&quot;, &quot;simhei.ttf&quot;) font_add(&quot;constan&quot;, &quot;constan.ttf&quot;, italic = &quot;constani.ttf&quot;) font_add(&quot;kaishu&quot;, &quot;simkai.ttf&quot;) # font_add(&quot;Noto&quot;, &quot;NotoSansCJKsc-Regular.otf&quot;) font_add(&quot;Yahei&quot;, &quot;Yahei.ttf&quot;) # 也可放在指定的目录(尽量英文) # https://github.com/yixuan/showtext/issues/18 font_add(&quot;fzfsj&quot;, here::here(&quot;myfont&quot;, &quot;fzfsj.ttf&quot;)) font_add(&quot;fzxbsj&quot;, here::here(&quot;myfont&quot;, &quot;FZXBSJW.ttf&quot;)) font_add(&quot;maoti&quot;, here::here(&quot;myfont&quot;, &quot;maoti.ttf&quot;)) font_add(&quot;fzshuliu&quot;, here::here(&quot;myfont&quot;, &quot;fzshuliu.ttf&quot;)) font_families() ## [1] &quot;sans&quot; &quot;serif&quot; &quot;mono&quot; ## [4] &quot;wqy-microhei&quot; &quot;heiti&quot; &quot;constan&quot; ## [7] &quot;kaishu&quot; &quot;Yahei&quot; &quot;fzfsj&quot; ## [10] &quot;fzxbsj&quot; &quot;maoti&quot; &quot;fzshuliu&quot; ## maybe, 保存为pdf图，才能看到有效字体 ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + ggtitle(&quot;这是我的小标宋简体&quot;) + theme( plot.title = element_text(family = &quot;fzxbsj&quot;) ) + geom_text(aes(x = 5, y = 40), label = &quot;方正仿宋简体&quot;, family = &quot;fzfsj&quot; ) + geom_text(aes(x = 5, y = 38), label = &quot;这是我的雅黑&quot;, family = &quot;Yahei&quot; ) + geom_text(aes(x = 5, y = 35), label = &quot;方正楷书简体&quot;, family = &quot;kaishu&quot; ) + geom_text(aes(x = 5, y = 30), label = &quot;草檀斋毛泽东字体&quot;, family = &quot;maoti&quot; ) + geom_text(aes(x = 5, y = 28), label = &quot;方正苏新诗柳楷简体&quot;, family = &quot;fzshuliu&quot; ) # ggsave(&quot;showtext-example-9.pdf&quot;, width = 7, height = 4, dpi = 200) 根据往年大家提交的作业，有同学用rmarkdown生成pdf，图片标题使用了中文字体，但中文字体无法显示 。解决方案是R code chunks加上fig.showtext=TRUE ```{r, fig.showtext=TRUE} 详细资料可参考这里 17.7.1 latex公式 library(ggplot2) library(latex2exp) ggplot(mpg, aes(x = displ, y = hwy)) + geom_point() + annotate(&quot;text&quot;, x = 4, y = 40, label = TeX(&quot;$\\\\alpha^2 + \\\\theta^2 = \\\\omega^2 $&quot;), size = 9 ) + labs( title = TeX(&quot;The ratio of 1 and 2 is $\\\\,\\\\, \\\\frac{1}{2}$&quot;), x = TeX(&quot;$\\\\alpha$&quot;), y = TeX(&quot;$\\\\alpha^2$&quot;) ) "],["ggplot2-stat-layer.html", "第 18 章 ggplot2之统计图层 18.1 导言 18.2 为何及何时使用统计图层 18.3 用 stat_summary() 理解统计图层 18.4 使用统计图层 18.5 总结", " 第 18 章 ggplot2之统计图层 18.1 导言 美学映射是图形语法中非常重要的一个概念，变量映射到视觉元素，然后通过几何对象GEOM画出图形。（下图是每个几何对象所对应的视觉元素） 图 18.1: ggplot2中的几何对象与美学映射 比如geom_point(mapping = aes(x = mass, y = height)) 将会画出散点图，这里的x轴代表mass变量，而y轴代表height变量. 因为geom_*()很强大而且也很容易理解，所以一般我们不会去思考我们的数据在喂给ggplot()后发生了什么，只希望能出图就行了。比如下面的直方图例子 library(tidyverse) library(palmerpenguins) ggplot(data = penguins, mapping = aes(x = body_mass_g)) + geom_histogram() 这里发生了什么呢？你可能看到body_mass_g这个变量代表了x轴，这个没错，但想弄清楚这个直方图，需要回答下面的问题 映射到x轴的变量被分成了若干离散的小区间（bins) 需要计算每个小区间中有多少观测值落入其中 用于y轴上是一个新的变量 最终，用户提供的x变量和经过计算处理后的y变量，共同确定了柱状图中每个柱子的位置和高度 我并不是说，不能给出geom_histogram()详细说明就是一个傻子。相反，我这里的本意是强调数据-&gt;视觉元素的映射并不是理所当然的，尽管看上去往往非常自然、直观和客观。 我们这里是提醒下，我们是否想过，修改上面中间过程，比如第1步和第2步，然后看看输出的图形是否还是直方图。 这个想法非常重要，但我们很少想到。某种程度是因为在我们最初学习ggplot画图的时候，ggplot已经影响了我们的思维方式。比如，初学者可能经历过拿到数据却还不出图形的受挫感，举个例子来说，这里有个数据 d &lt;- tibble::tribble( ~variable, ~subject1, ~subject2, ~subject3, &quot;mass&quot;, 75, 70, 55, &quot;height&quot;, 154, 172, 144 ) d ## # A tibble: 2 x 4 ## variable subject1 subject2 subject3 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 mass 75 70 55 ## 2 height 154 172 144 用geom_point(aes(x = mass, y = height)) 画图，却报错了。初学者可能苦苦搜索答案，然后被告知，ggplot画图需要先弄成tidy格式 d %&gt;% pivot_longer( cols = subject1:subject3, names_to = &quot;subject&quot;, names_pattern = &quot;subject(\\\\d)&quot;, values_to = &quot;value&quot; ) %&gt;% pivot_wider(names_from = variable, values_from = value) ## # A tibble: 3 x 3 ## subject mass height ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 75 154 ## 2 2 70 172 ## 3 3 55 144 现在数据tidy了，你可以使用ggplot()，问题得以解决。于是我们得出了一个结论：想要ggplot工作就需要tidy data。 如果这样想，那么今天的内容ggplot2统计图层就更加有必要了。 18.2 为何及何时使用统计图层 你可能每天都在用ggplot，却用不到stat_*()函数，这样也可以胜任很多工作。事实上，因为我们仅仅只使用geom_*()函数，你会发现stat_*()是开发者才使用的深奥和神秘的部分，如果这样想，你可能怀疑你是否有必要了解这些stat_*()函数。 好吧，学习 STAT 最主要的原因 “Even though the data is tidy, it may not represent the values you want to display” 我们这里再用一个例子说明，假定我们有一数据框simple_data simple_data &lt;- tibble(group = factor(rep(c(&quot;A&quot;, &quot;B&quot;), each = 15)), subject = 1:30, score = c(rnorm(15, 40, 20), rnorm(15, 60, 10))) simple_data ## # A tibble: 30 x 3 ## group subject score ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 A 1 76.9 ## 2 A 2 66.2 ## 3 A 3 28.5 ## 4 A 4 31.4 ## 5 A 5 18.3 ## 6 A 6 46.0 ## 7 A 7 64.9 ## 8 A 8 46.8 ## 9 A 9 17.9 ## 10 A 10 51.6 ## # ... with 20 more rows 假定我们现在想画一个柱状图，一个柱子代表每一组group，柱子的高度代表的score的均值。 好比，按照我们的想法，我们首先规整(tidy)数据，并且确保数据包含每个geom所需的美学映射，最后传递给ggplot() simple_data %&gt;% group_by(group) %&gt;% summarize( mean_score = mean(score), .groups = &#39;drop&#39; ) %&gt;% ggplot(aes(x = group, y = mean_score)) + geom_col() 那么，传递给ggplot()的数据是 simple_data %&gt;% group_by(group) %&gt;% summarize( mean_score = mean(score), .groups = &#39;drop&#39; ) ## # A tibble: 2 x 2 ## group mean_score ## &lt;fct&gt; &lt;dbl&gt; ## 1 A 41.8 ## 2 B 61.5 需求很简单，很容易搞定。但如果我们想加误差棒(stand error)呢? 那我们需要再对数据整理统计，然后再传给ggplot(). 于是，我们再计算误差棒，这里变型的数据是这个样子的 simple_data %&gt;% group_by(group) %&gt;% summarize( mean_score = mean(score), se = sqrt(var(score)/length(score)), .groups = &#39;drop&#39; ) %&gt;% mutate( lower = mean_score - se, upper = mean_score + se ) ## # A tibble: 2 x 5 ## group mean_score se lower upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 41.8 4.82 37.0 46.7 ## 2 B 61.5 2.83 58.6 64.3 然后把变型的数据传递给ggplot() simple_data %&gt;% group_by(group) %&gt;% summarize( mean_score = mean(score), se = sqrt(var(score)/length(score)), .groups = &#39;drop&#39; ) %&gt;% mutate( lower = mean_score - se, upper = mean_score + se ) %&gt;% ggplot(aes(x = group, y = mean_score, ymin = lower, ymax = upper)) + geom_errorbar() 最后，我们把两个数据框组会到一起，一个用于柱状图，一个用于画误差棒。 simple_data_bar &lt;- simple_data %&gt;% group_by(group) %&gt;% summarize( mean_score = mean(score), .groups = &#39;drop&#39; ) simple_data_errorbar &lt;- simple_data %&gt;% group_by(group) %&gt;% summarize( mean_score = mean(score), se = sqrt(var(score)/length(score)), .groups = &#39;drop&#39; ) %&gt;% mutate( lower = mean_score - se, upper = mean_score + se ) ggplot() + geom_col( aes(x = group, y = mean_score), data = simple_data_bar ) + geom_errorbar( aes(x = group, y = mean_score, ymin = lower, ymax = upper), data = simple_data_errorbar ) OMG, 为了画一个简单的图，我们需要写这么长的一段代码。究其原因就是，我们认为，一定要准备好一个tidy的数据，并且把想画的几何对象所需要的美学映射，都整理到这个tidy的数据框中 事实上，理论上讲，simple_data_bar 和 simple_data_errorbar 并不是真正的tidy格式。因为按照Hadley Wickham的对tidy的定义是，一行代表一次观察。 而这里的柱子的高度以及误差棒的两端不是观察出来的，而是统计计算出来的。 所以我们的观点是，辛辛苦苦创建一个（包含每个几何对象所需的美学映射）的数据框，太低效了，而且这种方法也不支持tidy原则。 既然 simple_data_bar 和 simple_data_errorbar都来源于simple_data，那为何不直接传递simple_data给ggplot()，让数据在内部转换，得到每个几何对象所需的美学映射呢？ 或许，你想要的是这样？ simple_data %&gt;% ggplot(aes(group, score)) + stat_summary(geom = &quot;bar&quot;) + stat_summary(geom = &quot;errorbar&quot;) Bingo 18.2.1 小结 这一节，我们用一个很长的数据整理的代码，借助geom_*()画了一张含有误差棒的柱状图，而用stat_summary()不需要数据整理，只需要两行代码就实现相同效果。 感受到了stat_summary()的强大了？ 不忙，好戏才慢慢开始… 18.3 用 stat_summary() 理解统计图层 前面讲到的 stat_summary() 是学习和理解 stat_*() 很好的例子，理解了stat_summary()的工作原理，其它的stat_*()也就都明白了， 事实上，stat_summary()也是在数据视化中最常用的，因此我们接着讲它。 那么，我们现在模拟一个测试数据height_df height_df &lt;- tibble(group = &quot;A&quot;, height = rnorm(30, 170, 10)) 用我们熟悉的geom_point() height_df %&gt;% ggplot(aes(x = group, y = height)) + geom_point() 然后用stat_summary()代替geom_point()，然后看看发生了什么 height_df %&gt;% ggplot(aes(x = group, y = height)) + stat_summary() 看到了一个点和经过这个点的一条线，实际上，它也是一个几何对象pointrange. 那么geom_pointrange() 是怎么数据转换的呢？回答这个问题，我们需要了解下geom_pointrange()需要哪些美学映射（参见图 18.1）： x or y ymin or xmin ymax or xmax 所以，我们回去看看ggplot(aes(x = group, y = height))中aes()里的参数，group 映射到 x, height映射到了y, 但我们没有发现有ymin / xmin或者ymax / xmax的踪迹。问题来了，我们没有给出geom_pointrange()需要的美学映射，那stat_summmary()是怎么画出pointrange的呢？ 我们先猜测一下，stat_summary()先计算出必要的数据值，然后传递给pointrange? 是不是呢？我们先看上图过程中有个提示 No summary function supplied, defaulting to `mean_se()` 看到了吧，summary function，说明我们猜对了，这就是stat_*()神秘的地方。 首先，对于stat_summary()中的fun.data参数，它的默认值是mean_se() 其次，我们看看这个函数 mean_se function (x, mult = 1) { x &lt;- stats::na.omit(x) se &lt;- mult * sqrt(stats::var(x)/length(x)) mean &lt;- mean(x) new_data_frame(list(y = mean, ymin = mean - se, ymax = mean + se), n = 1) } &lt;bytecode: 0x0000021aef28aa10&gt; &lt;environment: namespace:ggplot2&gt; 这个mean_se()函数有两个参数，一个是x，一个是mult（默认为1）， 那么这个函数的功能，一步步来说 删除缺失值NA 计算出se, 公式为\\(SE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N(x_i-\\bar{x})^2}\\) 计算x的均值 创建一个数据框（一行三列），y = mean, ymin = mean - se, ymax = mean + se 很酷的一件事情是，mean_se()看上去是在ggplot()内部使用，实际上加载ggplot2宏包后，在全局环境变量里就可以访问到，不妨试试看， 注意到stat_summary()是对向量（单维度）做统计，因此要传height_df$height给它 mean_se(height_df$height) ## y ymin ymax ## 1 170.2 168.6 171.9 数据看上去和我们前面 stat_summary() 画的点线图一样。当然为了保险起见，我们还是核对下，这里用到ggplot2包中的一个神奇的函数layer_data(), 它可以拉取在图层中使用的数据，第二个参数是指定拉取哪个图层的数据，这里只有唯一的一个图层，因此指定为1。 pointrange_plot &lt;- height_df %&gt;% ggplot(aes(x = group, y = height)) + stat_summary() layer_data(pointrange_plot, 1) ## x group y ymin ymax PANEL flipped_aes colour ## 1 1 1 170.2 168.6 171.9 1 FALSE black ## size linetype shape fill alpha stroke ## 1 0.5 1 19 NA NA 1 喔喔，结果很丰富，我们注意到y, ymin, and ymax 的值与 mean_se() 计算的结果一致。 18.3.1 小结 我们揭开了stat_summary()统计图层的神秘面纱的一角： 函数stat_summary()里若没有指定数据，那就会从ggplot(data = .)里继承 参数fun.data 会调用函数将数据变形，这个函数默认是mean_se() fun.data 返回的是数据框，这个数据框将用于geom参数画图，这里缺省的geom是pointrange 如果fun.data 返回的数据框包含了所需要的美学映射，图形就会显示出来。 为了让大家看的更明白，我们在stat_summary()中显式地给出fun.data和geom两个参数 height_df %&gt;% ggplot(aes(x = group, y = height)) + stat_summary( geom = &quot;pointrange&quot;, fun.data = mean_se ) Look, it’s the same plot! 18.4 使用统计图层 现在我们进入了stat_summary()有趣的环节: 调整其中的参数画出各种图 18.4.1 包含95%置信区间的误差棒 我们用企鹅数据画出不同性别sex下的企鹅体重均值，同时误差棒要给出95%的置信区间（ 即均值加减 1.96倍的标准误） my_penguins &lt;- na.omit(penguins) my_penguins %&gt;% ggplot(aes(sex, body_mass_g)) + stat_summary( fun.data = ~mean_se(., mult = 1.96), # Increase `mult` value for bigger interval! geom = &quot;errorbar&quot;, ) 那么这里在stat_summary()函数内部发生了什么呢？ 分组分别各自的mean_se()， female_mean_se &lt;- my_penguins %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(body_mass_g) %&gt;% mean_se(., mult = 1.96) male_mean_se &lt;- my_penguins %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(body_mass_g) %&gt;% mean_se(., mult = 1.96) bind_rows(female_mean_se, male_mean_se) ## y ymin ymax ## 1 3862 3761 3964 ## 2 4546 4427 4665 当ggplot()中提供了分组变量（比如这里的sex），stat_summary()会分组计算， 再次感受到ggplot2的强大气息！ 18.4.2 带有彩色填充色的柱状图 不同的企鹅种类，画出bill_length_mm长度的中位数（不再是均值），同时，让中位数小于40的用粉红色标出。这里需要自定义fun.data函数 calc_median_and_color &lt;- function(x, threshold = 40) { tibble(y = median(x)) %&gt;% mutate(fill = ifelse(y &lt; threshold, &quot;pink&quot;, &quot;grey35&quot;)) } my_penguins %&gt;% ggplot(aes(species, bill_length_mm)) + stat_summary( fun.data = calc_median_and_color, geom = &quot;bar&quot; ) 我们再来看看，stat_summary()内部发生了什么？ my_penguins %&gt;% group_split(species) %&gt;% map(~ pull(., bill_length_mm)) %&gt;% map_dfr(calc_median_and_color) ## # A tibble: 3 x 2 ## y fill ## &lt;dbl&gt; &lt;chr&gt; ## 1 38.8 pink ## 2 49.6 grey35 ## 3 47.4 grey35 注意到，fun.data中的定制函数还可以计算fill美学映射，最后一起传递给geom画图，强大！ 18.4.3 大小变化的点线图 我们现在想画不同岛屿islands上企鹅bill_depth_mm均值，要求点线图中点的大小随观测数量（该岛屿企鹅的数量）变化 my_penguins %&gt;% ggplot(aes(species, bill_depth_mm)) + stat_summary( fun.data = function(x) { scaled_size &lt;- length(x)/nrow(my_penguins) mean_se(x) %&gt;% mutate(size = scaled_size) } ) 这张图其实听酷的，每个岛屿观察值越小（也就说样本量越小），pointrange的不确定性就越大（图中的误差棒范围就越长）。我们再看看，这里的stat_summary()内部发生了什么，或者说数据是怎么转换的。 my_penguins %&gt;% group_split(species) %&gt;% map(~ pull(., bill_depth_mm)) %&gt;% map_dfr( function(x) { scaled_size &lt;- length(x)/nrow(my_penguins) mean_se(x) %&gt;% mutate(size = scaled_size) } ) ## y ymin ymax size ## 1 18.35 18.25 18.45 0.4384 ## 2 18.42 18.28 18.56 0.2042 ## 3 15.00 14.91 15.09 0.3574 18.5 总结 18.5.1 主要结论 尽管数据是tidy的，但它未必能代表你想展示的值 解决办法不是去规整数据以符合几何对象的要求，而是将原初tidy数据传递给ggplot(), 让stat_*()函数在内部实现变型 可以stat_*()函数可以定制geom以及相应的变形函数。当然，定制自己的函数，需要核对stat_*()所需要的变量和数据类型 如果想用不同的geom，确保变换函数能计算出(几何对象所需要的)美学映射 18.5.2 STAT vs. GEOM or STAT and GEOM? 尽管我们在谈论geom_*()的局限性，从而衬托出stat_*()的强大，但并不意味了后者可以取代前者，因为这不是一个非此即彼的问题，事实上，他们彼此依赖– 我们看到stat_summary() 有 geom 参数, geom_*() 也有 stat 参数。 在更高的层级上讲，stat_*()和 geom_*() 都只是ggplot里构建图层的layer()函数的一个便利的方法，用曹植的《七步诗》来说, 本是同根生，相煎何太急。 将layer()分成stat_*()和 geom_*()两块，或许是一个失误，最后我们用Hadley的原话来结束本章内容 Unfortunately, due to an early design mistake I called these either stat_() or geom_(). A better decision would have been to call them layer_() functions: that’s a more accurate description because every layer involves a stat and a geom 本文档翻译自Demystifying stat_ layers in ggplot2 "],["workflow.html", "第 19 章 回望tidyverse之旅 19.1 readr 宏包 19.2 tibble 宏包 19.3 ggplot2 宏包 19.4 dplyr 宏包 19.5 forcats 宏包 19.6 stringr 宏包 19.7 tidyr 宏包 19.8 purrr 宏包", " 第 19 章 回望tidyverse之旅 library(tidyverse) 前面几章先后介绍了tidyverse套餐的若干部件。感觉很难吗？如果是，那说明你认真听了。 本章做个小结，通过案例复习和串讲下tidyverse中常用的核心部件（事实上，tidyverse套餐比我们列出的要丰富）。 图 19.1: 图片来源Silvia Canelón在R-Ladies Chicago的报告 19.1 readr 宏包 读入数据是第一步，我们可以用readr导入数据 提示： 逗号(,)分割的文件 read_csv() 制表符(tab)分割的文件 read_tsv() 任意的分割符 read_delim() 固定宽度的文件 read_fwf() 空格分割的文件 read_table() 网页log文件 read_log() 读取外部数据 penguins &lt;- read_csv(&quot;./demo_data/penguins.csv&quot;) 保存到外部文件 penguins %&gt;% write_csv(&quot;newdata.csv&quot;) 19.2 tibble 宏包 tibble 是升级版的 dataframe, 之所以是升级版，是因为在tidyverse中tibble做很多优化。下面你可以看到两者的区别： as_tibble(penguins) ## # A tibble: 344 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ NA NA ## 5 Adelie Torge~ 36.7 19.3 ## 6 Adelie Torge~ 39.3 20.6 ## 7 Adelie Torge~ 38.9 17.8 ## 8 Adelie Torge~ 39.2 19.6 ## 9 Adelie Torge~ 34.1 18.1 ## 10 Adelie Torge~ 42 20.2 ## # ... with 334 more rows, and 4 more variables: ## # flipper_length_mm &lt;dbl&gt;, body_mass_g &lt;dbl&gt;, ## # sex &lt;chr&gt;, year &lt;dbl&gt; as.data.frame(penguins) %&gt;% head() ## species island bill_length_mm bill_depth_mm ## 1 Adelie Torgersen 39.1 18.7 ## 2 Adelie Torgersen 39.5 17.4 ## 3 Adelie Torgersen 40.3 18.0 ## 4 Adelie Torgersen NA NA ## 5 Adelie Torgersen 36.7 19.3 ## 6 Adelie Torgersen 39.3 20.6 ## flipper_length_mm body_mass_g sex year ## 1 181 3750 male 2007 ## 2 186 3800 female 2007 ## 3 195 3250 female 2007 ## 4 NA NA &lt;NA&gt; 2007 ## 5 193 3450 female 2007 ## 6 190 3650 male 2007 在R Markdown里两者区别不大，但在console中，区别很明显的。比如tibble不一样的地方有： 列出了变量的类型(这个很不错) 只列出10行 只列出有限的列数（与屏幕适应的） 高亮 NAs 19.3 ggplot2 宏包 19.3.1 查看数据 我们先查看下数据 glimpse(penguins) ## Rows: 344 ## Columns: 8 ## $ species &lt;chr&gt; &quot;Adelie&quot;, &quot;Adelie&quot;, &quot;Ade... ## $ island &lt;chr&gt; &quot;Torgersen&quot;, &quot;Torgersen&quot;... ## $ bill_length_mm &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36... ## $ bill_depth_mm &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19... ## $ flipper_length_mm &lt;dbl&gt; 181, 186, 195, NA, 193, ... ## $ body_mass_g &lt;dbl&gt; 3750, 3800, 3250, NA, 34... ## $ sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;femal... ## $ year &lt;dbl&gt; 2007, 2007, 2007, 2007, ... 19.3.2 散点图 体重在性别上有很大区别？ ggplot(data = penguins, aes(x = sex, y = body_mass_g)) + geom_point() 19.3.3 箱线图 ggplot(data = penguins, aes(x = sex, y = body_mass_g)) + geom_boxplot() ggplot(data = penguins, aes(x = sex, y = body_mass_g)) + geom_boxplot(aes(fill = species)) 我们可能看到： Gentoo 类的企鹅 比 Adelie 和 Chinstrap 类的企鹅体重更重 Gentoo 类型中，雄性企鹅比雌性企鹅体重更重 Adelie 和 Chinstrap 两种类型的企鹅，区别不是很明显 sex 这个变量有缺失值，主要集中在 Gentoo 和 Chinstrap 两种类型 那么每种类型的企鹅，数据中有多少是NA呢？ 上dplyr吧！ 19.4 dplyr 宏包 dplyr 宏包可以: 创建新变量 mutate() 分组统计 summarize() + group_by() 筛选 filter() 重命名变量 rename() 排序 arrange() 更多 19.4.1 选取列 下面两个有什么区别？ select(penguins, species, sex, body_mass_g) ## # A tibble: 344 x 3 ## species sex body_mass_g ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Adelie male 3750 ## 2 Adelie female 3800 ## 3 Adelie female 3250 ## 4 Adelie &lt;NA&gt; NA ## 5 Adelie female 3450 ## 6 Adelie male 3650 ## 7 Adelie female 3625 ## 8 Adelie male 4675 ## 9 Adelie &lt;NA&gt; 3475 ## 10 Adelie &lt;NA&gt; 4250 ## # ... with 334 more rows penguins %&gt;% select(species, sex, body_mass_g) ## # A tibble: 344 x 3 ## species sex body_mass_g ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Adelie male 3750 ## 2 Adelie female 3800 ## 3 Adelie female 3250 ## 4 Adelie &lt;NA&gt; NA ## 5 Adelie female 3450 ## 6 Adelie male 3650 ## 7 Adelie female 3625 ## 8 Adelie male 4675 ## 9 Adelie &lt;NA&gt; 3475 ## 10 Adelie &lt;NA&gt; 4250 ## # ... with 334 more rows 19.4.2 行方向排序 glimpse(penguins) ## Rows: 344 ## Columns: 8 ## $ species &lt;chr&gt; &quot;Adelie&quot;, &quot;Adelie&quot;, &quot;Ade... ## $ island &lt;chr&gt; &quot;Torgersen&quot;, &quot;Torgersen&quot;... ## $ bill_length_mm &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36... ## $ bill_depth_mm &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19... ## $ flipper_length_mm &lt;dbl&gt; 181, 186, 195, NA, 193, ... ## $ body_mass_g &lt;dbl&gt; 3750, 3800, 3250, NA, 34... ## $ sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;femal... ## $ year &lt;dbl&gt; 2007, 2007, 2007, 2007, ... penguins %&gt;% select(species, sex, body_mass_g) %&gt;% arrange(desc(body_mass_g)) ## # A tibble: 344 x 3 ## species sex body_mass_g ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Gentoo male 6300 ## 2 Gentoo male 6050 ## 3 Gentoo male 6000 ## 4 Gentoo male 6000 ## 5 Gentoo male 5950 ## 6 Gentoo male 5950 ## 7 Gentoo male 5850 ## 8 Gentoo male 5850 ## 9 Gentoo male 5850 ## 10 Gentoo male 5800 ## # ... with 334 more rows 19.4.3 分组统计 penguins %&gt;% group_by(species, sex) %&gt;% summarize(count = n()) ## # A tibble: 8 x 3 ## # Groups: species [3] ## species sex count ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Adelie female 73 ## 2 Adelie male 73 ## 3 Adelie &lt;NA&gt; 6 ## 4 Chinstrap female 34 ## 5 Chinstrap male 34 ## 6 Gentoo female 58 ## 7 Gentoo male 61 ## 8 Gentoo &lt;NA&gt; 5 19.4.4 增加列 penguins %&gt;% group_by(species) %&gt;% mutate(count_species = n()) %&gt;% ungroup() %&gt;% group_by(species, sex, count_species) %&gt;% summarize(count = n()) %&gt;% mutate(prop = count/count_species*100) ## # A tibble: 8 x 5 ## # Groups: species, sex [8] ## species sex count_species count prop ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Adelie female 152 73 48.0 ## 2 Adelie male 152 73 48.0 ## 3 Adelie &lt;NA&gt; 152 6 3.95 ## 4 Chinstrap female 68 34 50 ## 5 Chinstrap male 68 34 50 ## 6 Gentoo female 124 58 46.8 ## 7 Gentoo male 124 61 49.2 ## 8 Gentoo &lt;NA&gt; 124 5 4.03 19.4.5 筛选 penguins %&gt;% group_by(species) %&gt;% mutate(count_species = n()) %&gt;% ungroup() %&gt;% group_by(species, sex, count_species) %&gt;% summarize(count = n()) %&gt;% mutate(percentage = count/count_species*100) %&gt;% filter(species == &quot;Chinstrap&quot;) ## # A tibble: 2 x 5 ## # Groups: species, sex [2] ## species sex count_species count percentage ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Chinstrap female 68 34 50 ## 2 Chinstrap male 68 34 50 19.5 forcats 宏包 forcats 宏包主要用于分类变量和因子型变量，比如这里的 species, island, sex. 对于不是因子型的变量，比如这里 year 是数值型变量，我们也可以通过 factor() 函数 将它转换成因子型变量。 penguins %&gt;% mutate(year_factor = factor(year, levels = unique(year))) ## # A tibble: 344 x 9 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ NA NA ## 5 Adelie Torge~ 36.7 19.3 ## 6 Adelie Torge~ 39.3 20.6 ## 7 Adelie Torge~ 38.9 17.8 ## 8 Adelie Torge~ 39.2 19.6 ## 9 Adelie Torge~ 34.1 18.1 ## 10 Adelie Torge~ 42 20.2 ## # ... with 334 more rows, and 5 more variables: ## # flipper_length_mm &lt;dbl&gt;, body_mass_g &lt;dbl&gt;, ## # sex &lt;chr&gt;, year &lt;dbl&gt;, year_factor &lt;fct&gt; 我们保存到新的数据集中，再看看有什么变化 penguins_new &lt;- penguins %&gt;% mutate(year_factor = factor(year, levels = unique(year))) penguins_new ## # A tibble: 344 x 9 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ NA NA ## 5 Adelie Torge~ 36.7 19.3 ## 6 Adelie Torge~ 39.3 20.6 ## 7 Adelie Torge~ 38.9 17.8 ## 8 Adelie Torge~ 39.2 19.6 ## 9 Adelie Torge~ 34.1 18.1 ## 10 Adelie Torge~ 42 20.2 ## # ... with 334 more rows, and 5 more variables: ## # flipper_length_mm &lt;dbl&gt;, body_mass_g &lt;dbl&gt;, ## # sex &lt;chr&gt;, year &lt;dbl&gt;, year_factor &lt;fct&gt; class(penguins_new$year_factor) ## [1] &quot;factor&quot; levels(penguins_new$year_factor) ## [1] &quot;2007&quot; &quot;2008&quot; &quot;2009&quot; 大家回想下，弄成因子型变量有什么好处呢？ 19.6 stringr 宏包 stringr宏包包含了非常丰富的处理字符串的函数，比如 匹配 字符串子集 字符串长度 字符串合并 字符串分割 更多 19.6.1 字符串转换 penguins %&gt;% select(species, island) %&gt;% mutate(ISLAND = str_to_upper(island)) ## # A tibble: 344 x 3 ## species island ISLAND ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Adelie Torgersen TORGERSEN ## 2 Adelie Torgersen TORGERSEN ## 3 Adelie Torgersen TORGERSEN ## 4 Adelie Torgersen TORGERSEN ## 5 Adelie Torgersen TORGERSEN ## 6 Adelie Torgersen TORGERSEN ## 7 Adelie Torgersen TORGERSEN ## 8 Adelie Torgersen TORGERSEN ## 9 Adelie Torgersen TORGERSEN ## 10 Adelie Torgersen TORGERSEN ## # ... with 334 more rows 19.6.2 字符串合并 penguins %&gt;% select(species, island) %&gt;% mutate(ISLAND = str_to_upper(island)) %&gt;% mutate(species_island = str_c(species, ISLAND, sep = &quot;_&quot;)) ## # A tibble: 344 x 4 ## species island ISLAND species_island ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## 2 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## 3 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## 4 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## 5 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## 6 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## 7 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## 8 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## 9 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## 10 Adelie Torgersen TORGERSEN Adelie_TORGERSEN ## # ... with 334 more rows 19.7 tidyr 宏包 想想什么叫tidy data？ 19.7.1 长表格变宽表格 untidy_penguins &lt;- penguins %&gt;% pivot_wider(names_from = sex, values_from = body_mass_g) untidy_penguins ## # A tibble: 344 x 9 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ NA NA ## 5 Adelie Torge~ 36.7 19.3 ## 6 Adelie Torge~ 39.3 20.6 ## 7 Adelie Torge~ 38.9 17.8 ## 8 Adelie Torge~ 39.2 19.6 ## 9 Adelie Torge~ 34.1 18.1 ## 10 Adelie Torge~ 42 20.2 ## # ... with 334 more rows, and 5 more variables: ## # flipper_length_mm &lt;dbl&gt;, year &lt;dbl&gt;, male &lt;dbl&gt;, ## # female &lt;dbl&gt;, `NA` &lt;dbl&gt; 19.7.2 宽表格变长表格 untidy_penguins %&gt;% pivot_longer(cols = male:`NA`, names_to = &quot;sex&quot;, values_to = &quot;body_mass_g&quot;) ## # A tibble: 1,032 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.1 18.7 ## 3 Adelie Torge~ 39.1 18.7 ## 4 Adelie Torge~ 39.5 17.4 ## 5 Adelie Torge~ 39.5 17.4 ## 6 Adelie Torge~ 39.5 17.4 ## 7 Adelie Torge~ 40.3 18 ## 8 Adelie Torge~ 40.3 18 ## 9 Adelie Torge~ 40.3 18 ## 10 Adelie Torge~ NA NA ## # ... with 1,022 more rows, and 4 more variables: ## # flipper_length_mm &lt;dbl&gt;, year &lt;dbl&gt;, sex &lt;chr&gt;, ## # body_mass_g &lt;dbl&gt; 19.8 purrr 宏包 purrr 宏包提供了map()等一系列函数，取代 for 和 while循环方式，实现高效迭代，保持语法一致性，同时增强了代码的可读性。 penguins %&gt;% map(~sum(is.na(.))) ## $species ## [1] 0 ## ## $island ## [1] 0 ## ## $bill_length_mm ## [1] 2 ## ## $bill_depth_mm ## [1] 2 ## ## $flipper_length_mm ## [1] 2 ## ## $body_mass_g ## [1] 2 ## ## $sex ## [1] 11 ## ## $year ## [1] 0 penguins %&gt;% group_nest(species) %&gt;% mutate(model = purrr::map(data, ~ lm(bill_depth_mm ~ bill_length_mm, data = .))) %&gt;% mutate(result = purrr::map(model, ~ broom::tidy(.))) %&gt;% tidyr::unnest(result) ## # A tibble: 6 x 8 ## species data model term estimate std.error ## &lt;chr&gt; &lt;list&lt;tb&gt; &lt;lis&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie [152 x 7] &lt;lm&gt; (Int~ 11.4 1.34 ## 2 Adelie [152 x 7] &lt;lm&gt; bill~ 0.179 0.0344 ## 3 Chinst~ [68 x 7] &lt;lm&gt; (Int~ 7.57 1.55 ## 4 Chinst~ [68 x 7] &lt;lm&gt; bill~ 0.222 0.0317 ## 5 Gentoo [124 x 7] &lt;lm&gt; (Int~ 5.25 1.05 ## 6 Gentoo [124 x 7] &lt;lm&gt; bill~ 0.205 0.0222 ## # ... with 2 more variables: statistic &lt;dbl&gt;, ## # p.value &lt;dbl&gt; "],["tips.html", "第 20 章 tidyverse中的若干技巧 20.1 count() 20.2 在 count() 中创建新变量 20.3 add_count() 20.4 nth(), first(), last() 20.5 列变量重新排序 20.6 if_else 20.7 case_when 20.8 找出前几名 20.9 去除多余的空白 20.10 取反操作 20.11 drop_na() 20.12 replace_na() 20.13 coalesce 20.14 summarise() 生成 list-column 20.15 count() + fct_reorder() + geom_col() + coord_flip() 20.16 scale_x/y_log10 20.17 fct_lump 20.18 fct_reoder2 20.19 unite 20.20 separate() 20.21 extract() 20.22 crossing()", " 第 20 章 tidyverse中的若干技巧 聊聊tidyverse中常用的一些小技巧 “most of data science is counting, and sometimes dividing” — Hadley Wickham library(tidyverse) library(patchwork) # install.packages(&quot;patchwork&quot;) 20.1 count() 我之前多次用到count()函数，其功能就是统计某个变量中各组出现的次数 df &lt;- tibble( name = c(&quot;Alice&quot;, &quot;Alice&quot;, &quot;Bob&quot;, &quot;Bob&quot;, &quot;Carol&quot;, &quot;Carol&quot;), type = c(&quot;english&quot;, &quot;math&quot;, &quot;english&quot;, &quot;math&quot;, &quot;english&quot;, &quot;math&quot;), score = c(60.2, 90.5, 92.2, 98.8, 82.5, 74.6) ) df ## # A tibble: 6 x 3 ## name type score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Alice english 60.2 ## 2 Alice math 90.5 ## 3 Bob english 92.2 ## 4 Bob math 98.8 ## 5 Carol english 82.5 ## 6 Carol math 74.6 df %&gt;% count(name) ## # A tibble: 3 x 2 ## name n ## &lt;chr&gt; &lt;int&gt; ## 1 Alice 2 ## 2 Bob 2 ## 3 Carol 2 如果用之前讲的group_by() + summarise()来写， df %&gt;% group_by(name) %&gt;% summarise( n = n()) ## # A tibble: 3 x 2 ## name n ## &lt;chr&gt; &lt;int&gt; ## 1 Alice 2 ## 2 Bob 2 ## 3 Carol 2 count() 还有更多强大的参数， 比如 df %&gt;% count(name, sort = TRUE, wt = score, name = &quot;total_score&quot; ) ## # A tibble: 3 x 2 ## name total_score ## &lt;chr&gt; &lt;dbl&gt; ## 1 Bob 191 ## 2 Carol 157. ## 3 Alice 151. 如果不用count()，用group_by() + summarise()写， df %&gt;% group_by(name) %&gt;% summarise( n = n(), total_score = sum(score, na.rm = TRUE) ) %&gt;% arrange(desc(total_score)) ## # A tibble: 3 x 3 ## name n total_score ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Bob 2 191 ## 2 Carol 2 157. ## 3 Alice 2 151. 当然，count()在特定场合下的简便写法，遇到复杂的分组统计，还是得用用group_by() + summarise()组合。 20.2 在 count() 中创建新变量 可以在count()里构建新变量，并利用这个新变量完成统计 df %&gt;% count(range = 10 * (score %/% 10)) ## # A tibble: 4 x 2 ## range n ## &lt;dbl&gt; &lt;int&gt; ## 1 60 1 ## 2 70 1 ## 3 80 1 ## 4 90 3 20.3 add_count() 想增加一列，代表每人参加的考试次数 df %&gt;% group_by(name) %&gt;% mutate(n = n()) %&gt;% ungroup() ## # A tibble: 6 x 4 ## name type score n ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Alice english 60.2 2 ## 2 Alice math 90.5 2 ## 3 Bob english 92.2 2 ## 4 Bob math 98.8 2 ## 5 Carol english 82.5 2 ## 6 Carol math 74.6 2 可以有更简单的方法 df %&gt;% add_count(name) ## # A tibble: 6 x 4 ## name type score n ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Alice english 60.2 2 ## 2 Alice math 90.5 2 ## 3 Bob english 92.2 2 ## 4 Bob math 98.8 2 ## 5 Carol english 82.5 2 ## 6 Carol math 74.6 2 20.4 nth(), first(), last() v &lt;- c(&quot;a&quot;, &quot;c&quot;, &quot;d&quot;, &quot;k&quot;) v[1] ## [1] &quot;a&quot; v[length(v)] ## [1] &quot;k&quot; c(&quot;a&quot;, &quot;c&quot;, &quot;d&quot;, &quot;k&quot;) %&gt;% nth(3) ## [1] &quot;d&quot; c(&quot;a&quot;, &quot;c&quot;, &quot;d&quot;, &quot;k&quot;) %&gt;% first() ## [1] &quot;a&quot; c(&quot;a&quot;, &quot;c&quot;, &quot;d&quot;, &quot;k&quot;) %&gt;% last() ## [1] &quot;k&quot; 用在数据框中，同样可以使用 df %&gt;% filter(score == first(score)) ## # A tibble: 1 x 3 ## name type score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Alice english 60.2 df %&gt;% group_by(name) %&gt;% filter(score == last(score)) ## # A tibble: 3 x 3 ## # Groups: name [3] ## name type score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Alice math 90.5 ## 2 Bob math 98.8 ## 3 Carol math 74.6 20.5 列变量重新排序 比如想把score放在第一列 df %&gt;% select(score, everything()) ## # A tibble: 6 x 3 ## score name type ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 60.2 Alice english ## 2 90.5 Alice math ## 3 92.2 Bob english ## 4 98.8 Bob math ## 5 82.5 Carol english ## 6 74.6 Carol math 这个方法，对列变量较多的情形非常适用。 20.6 if_else df %&gt;% mutate( assess = if_else(score &gt; 85, &quot;very_good&quot;, &quot;good&quot;) ) ## # A tibble: 6 x 4 ## name type score assess ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Alice english 60.2 good ## 2 Alice math 90.5 very_good ## 3 Bob english 92.2 very_good ## 4 Bob math 98.8 very_good ## 5 Carol english 82.5 good ## 6 Carol math 74.6 good 20.7 case_when df %&gt;% mutate( assess = case_when( score &lt; 70 ~ &quot;general&quot;, score &gt;= 70 &amp; score &lt; 80 ~ &quot;good&quot;, score &gt;= 80 &amp; score &lt; 90 ~ &quot;very_good&quot;, score &gt;= 90 ~ &quot;best&quot;, TRUE ~ &quot;other&quot; ) ) ## # A tibble: 6 x 4 ## name type score assess ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Alice english 60.2 general ## 2 Alice math 90.5 best ## 3 Bob english 92.2 best ## 4 Bob math 98.8 best ## 5 Carol english 82.5 very_good ## 6 Carol math 74.6 good 20.8 找出前几名 df %&gt;% top_n(2, score) ## # A tibble: 2 x 3 ## name type score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Bob english 92.2 ## 2 Bob math 98.8 20.9 去除多余的空白 library(stringr) str_trim(&quot; excess whitespace in a string be gone!&quot;) ## [1] &quot;excess whitespace in a string be gone!&quot; # Use str_squish() to remove any leading, trailing, or excess whitespace str_squish(&quot; excess whitespace in a string be gone!&quot;) ## [1] &quot;excess whitespace in a string be gone!&quot; 20.10 取反操作 3:10 %in% c(1:5) ## [1] TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE 有时候需要一个不属于的操作符 # 自定义一个不属于操作符 `%nin%` &lt;- Negate(`%in%`) 3:10 %nin% c(1:5) ## [1] FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE # 使用purrr::negate()自定义反向操作符 `%nin%` &lt;- purrr::negate(`%in%`) 3:10 %nin% c(1:5) ## [1] FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE 20.11 drop_na() dt &lt;- tribble( ~x, ~y, 1, NA, 2, NA, NA, -3, NA, -4, 5, -5 ) dt ## # A tibble: 5 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 NA ## 2 2 NA ## 3 NA -3 ## 4 NA -4 ## 5 5 -5 dt %&gt;% drop_na() ## # A tibble: 1 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 5 -5 # dt %&gt;% drop_na(x) 20.12 replace_na() dt &lt;- tribble( ~x, ~y, 1, NA, 2, NA, NA, -3, NA, -4, 5, -5 ) dt %&gt;% mutate(x = replace_na(x, 0)) ## # A tibble: 5 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 NA ## 2 2 NA ## 3 0 -3 ## 4 0 -4 ## 5 5 -5 dt %&gt;% mutate( x = replace_na(x, mean(x, na.rm = TRUE)) ) ## # A tibble: 5 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 NA ## 2 2 NA ## 3 2.67 -3 ## 4 2.67 -4 ## 5 5 -5 之前讲正则表达式也有类似的函数stringr::str_replace_na()， 20.13 coalesce dt &lt;- tribble( ~x, ~y, 1, NA, 2, NA, NA, -3, NA, -4, 5, -5 ) dt %&gt;% mutate( z = coalesce(x, 0) # z = coalesce(x, y) ) ## # A tibble: 5 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 NA 1 ## 2 2 NA 2 ## 3 NA -3 0 ## 4 NA -4 0 ## 5 5 -5 5 有时候，我们可能为了减少信息丢失，想填充NA dt &lt;- tribble( ~name, ~age, &quot;a&quot;, 1, &quot;b&quot;, 2, &quot;c&quot;, NA, &quot;d&quot;, 2 ) dt %&gt;% mutate( age_adj = ifelse(is.na(age), mean(age, na.rm = TRUE), age) ) ## # A tibble: 4 x 3 ## name age age_adj ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a 1 1 ## 2 b 2 2 ## 3 c NA 1.67 ## 4 d 2 2 20.14 summarise() 生成 list-column summarize()会生成一个value， library(gapminder) gapminder %&gt;% group_by(continent) %&gt;% summarise( avg_gdpPercap = mean(gdpPercap) ) ## # A tibble: 5 x 2 ## continent avg_gdpPercap ## &lt;fct&gt; &lt;dbl&gt; ## 1 Africa 2194. ## 2 Americas 7136. ## 3 Asia 7902. ## 4 Europe 14469. ## 5 Oceania 18622. summarize()也可以生成一个list， library(gapminder) gapminder %&gt;% group_by(continent) %&gt;% summarise(test = list(t.test(gdpPercap))) %&gt;% # 单样本的t检验 mutate(tidied = purrr::map(test, broom::tidy)) %&gt;% unnest(tidied) %&gt;% ggplot(aes(estimate, continent)) + geom_point() + geom_errorbarh(aes( xmin = conf.low, xmax = conf.high )) gapminder %&gt;% group_by(continent) %&gt;% summarise(test = list(lm(lifeExp ~ gdpPercap))) %&gt;% # 线性回归 mutate(tidied = purrr::map(test, broom::tidy, conf.int = TRUE)) %&gt;% unnest(tidied) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% ggplot(aes(estimate, continent)) + geom_point() + geom_errorbarh(aes( xmin = conf.low, xmax = conf.high, height = .3 )) 以下两种方法，同样完成上面的工作，具体方法会在第 21 章介绍 gapminder %&gt;% group_nest(continent) %&gt;% mutate(test = map(data, ~ t.test(.x$gdpPercap))) %&gt;% mutate(tidied = map(test, broom::tidy)) %&gt;% unnest(tidied) gapminder %&gt;% group_by(continent) %&gt;% group_modify( ~ broom::tidy(t.test(.x$gdpPercap)) ) 20.15 count() + fct_reorder() + geom_col() + coord_flip() 最好用的四件套 gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) %&gt;% ggplot(aes(x = continent, y = n)) + geom_col() gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) %&gt;% ggplot(aes(x = fct_reorder(continent, n), y = n)) + geom_col() + coord_flip() 画图容易，但画出一张好图并不容易 gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) %&gt;% mutate(coll = if_else(continent == &quot;Asia&quot;, &quot;red&quot;, &quot;gray&quot;)) %&gt;% ggplot(aes(x = fct_reorder(continent, n), y = n)) + geom_text(aes(label = n), hjust = -0.25) + geom_col(width = 0.8, aes(fill = coll) ) + coord_flip() + theme_classic() + scale_fill_manual(values = c(&quot;#b3b3b3a0&quot;, &quot;#D55E00&quot;)) + theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 11) ) + labs(title = &quot;我的标题&quot;, x = &quot;&quot;) 或者偷懒，将continent == \"Asia\"的结果直接赋值给aes(fill = ___ )， 效果与上面是一样的。 gapminder %&gt;% distinct(continent, country) %&gt;% count(continent) %&gt;% ggplot(aes(x = fct_reorder(continent, n), y = n)) + geom_text(aes(label = n), hjust = -0.25) + geom_col(width = 0.8, aes(fill = continent == &quot;Asia&quot;) ) + coord_flip() + theme_classic() + scale_fill_manual(values = c(&quot;#b3b3b3a0&quot;, &quot;#D55E00&quot;)) + annotate(&quot;text&quot;, x = 3.8, y = 48, label = &quot;this is important\\ncase&quot;, color = &quot;#D55E00&quot;, size = 5) + annotate( geom = &quot;curve&quot;, x = 4.1, y = 48, xend = 4.1, yend = 35, curvature = .3, arrow = arrow(length = unit(2, &quot;mm&quot;)) ) + theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 11) ) + labs(title = &quot;我的标题&quot;, x = &quot;&quot;) 20.16 scale_x/y_log10 现实世界很多满足对数规则 各国人均GDP 各国人口 不同人士的收入 公司的营业额 gapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() gapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp)) + geom_point() + scale_x_log10() # A better way to log transform 20.17 fct_lump 门诊病症的流水记录 tb &lt;- tibble::tribble( ~disease, ~n, &quot;鼻塞&quot;, 112, &quot;流涕&quot;, 130, &quot;发热&quot;, 89, &quot;腹泻&quot;, 5, &quot;呕吐&quot;, 12, &quot;咳嗽&quot;, 102, &quot;咽痛&quot;, 98, &quot;乏力&quot;, 15, &quot;腹痛&quot;, 2, &quot;妄想&quot;, 3, &quot;幻听&quot;, 6, &quot;失眠&quot;, 1, &quot;贫血&quot;, 8, &quot;多动&quot;, 2, &quot;胸痛&quot;, 4, &quot;胸闷&quot;, 5 ) p1 &lt;- tb %&gt;% uncount(n) %&gt;% ggplot(aes(x = disease, fill = disease)) + geom_bar() + coord_flip() + theme(legend.position = &quot;none&quot;) p2 &lt;- tb %&gt;% uncount(n) %&gt;% mutate( disease = forcats::fct_lump(disease, 5), disease = forcats::fct_reorder(disease, .x = disease, .fun = length) ) %&gt;% ggplot(aes(x = disease, fill = disease)) + geom_bar() + coord_flip() + theme(legend.position = &quot;none&quot;) p1 + p2 20.18 fct_reoder2 让图例的顺序与图的曲线顺序一致 dat_wide &lt;- tibble( x = 1:3, top = c(4.5, 4, 5.5), middle = c(4, 4.75, 5), bottom = c(3.5, 3.75, 4.5) ) dat_wide %&gt;% pivot_longer( cols = c(top, middle, bottom), names_to = &quot;region&quot;, values_to = &quot;awfulness&quot;) ## # A tibble: 9 x 3 ## x region awfulness ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 top 4.5 ## 2 1 middle 4 ## 3 1 bottom 3.5 ## 4 2 top 4 ## 5 2 middle 4.75 ## 6 2 bottom 3.75 ## 7 3 top 5.5 ## 8 3 middle 5 ## 9 3 bottom 4.5 dat &lt;- dat_wide %&gt;% pivot_longer( cols = c(top, middle, bottom), names_to = &quot;region&quot;, values_to = &quot;awfulness&quot;) %&gt;% mutate( region_ABCD = factor(region), region_sane = fct_reorder2(region, x, awfulness) ) p_ABCD &lt;- ggplot(dat, aes(x, awfulness, colour = region_ABCD)) + geom_line() + theme(legend.justification = c(1, 0.85)) p_sane &lt;- ggplot(dat, aes(x, awfulness, colour = region_sane)) + geom_line() + theme(legend.justification = c(1, 0.85)) p_ABCD + p_sane + plot_annotation( title = &#39;Make the legend order = data order, with forcats::fct_reorder2()&#39;) 20.19 unite dfa &lt;- tribble( ~school, ~class, &quot;chuansi&quot;, &quot;01&quot;, &quot;chuansi&quot;, &quot;02&quot;, &quot;shude&quot;, &quot;07&quot;, &quot;shude&quot;, &quot;08&quot;, &quot;huapulu&quot;, &quot;101&quot;, &quot;huapulu&quot;, &quot;103&quot; ) dfa ## # A tibble: 6 x 2 ## school class ## &lt;chr&gt; &lt;chr&gt; ## 1 chuansi 01 ## 2 chuansi 02 ## 3 shude 07 ## 4 shude 08 ## 5 huapulu 101 ## 6 huapulu 103 df_united &lt;- dfa %&gt;% tidyr::unite(school, class, col = &quot;school_plus_class&quot;, sep = &quot;_&quot;, remove = FALSE) df_united ## # A tibble: 6 x 3 ## school_plus_class school class ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chuansi_01 chuansi 01 ## 2 chuansi_02 chuansi 02 ## 3 shude_07 shude 07 ## 4 shude_08 shude 08 ## 5 huapulu_101 huapulu 101 ## 6 huapulu_103 huapulu 103 当然，简单的情况也可以用mutate()实现 dfa %&gt;% mutate(newcol = str_c(school, &quot;_&quot;, class)) ## # A tibble: 6 x 3 ## school class newcol ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chuansi 01 chuansi_01 ## 2 chuansi 02 chuansi_02 ## 3 shude 07 shude_07 ## 4 shude 08 shude_08 ## 5 huapulu 101 huapulu_101 ## 6 huapulu 103 huapulu_103 20.20 separate() df_united %&gt;% tidyr::separate(school_plus_class, into = c(&quot;sch&quot;, &quot;cls&quot;), sep = &quot;_&quot;, remove = F) 如果用mutate()来实现，语句就会比较复杂些 df_united %&gt;% mutate(sch = str_split(school_plus_class, &quot;_&quot;) %&gt;% map_chr(1)) %&gt;% mutate(cls = str_split(school_plus_class, &quot;_&quot;) %&gt;% map_chr(2)) ## # A tibble: 6 x 5 ## school_plus_class school class sch cls ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chuansi_01 chuansi 01 chuansi 01 ## 2 chuansi_02 chuansi 02 chuansi 02 ## 3 shude_07 shude 07 shude 07 ## 4 shude_08 shude 08 shude 08 ## 5 huapulu_101 huapulu 101 huapulu 101 ## 6 huapulu_103 huapulu 103 huapulu 103 如果每行不是都恰好分隔成两部分呢？就需要tidyr::extract(), 使用方法和tidyr::separate()类似 dfb &lt;- tribble( ~school_class, &quot;chuansi_01&quot;, &quot;chuansi_02_03&quot;, &quot;shude_07_0&quot;, &quot;shude_08_0&quot;, &quot;huapulu_101_u&quot;, &quot;huapulu_103__p&quot; ) dfb ## # A tibble: 6 x 1 ## school_class ## &lt;chr&gt; ## 1 chuansi_01 ## 2 chuansi_02_03 ## 3 shude_07_0 ## 4 shude_08_0 ## 5 huapulu_101_u ## 6 huapulu_103__p dfb %&gt;% tidyr::separate(school_class, into = c(&quot;sch&quot;, &quot;cls&quot;), sep = &quot;_&quot;, extra = &quot;drop&quot;, remove = F) 20.21 extract() 有时候分隔符搞不定的，可以用正则表达式，讲捕获的每组弄成一列 dfc &lt;- tibble(x = c(&quot;1-12week&quot;, &quot;1-10wk&quot;, &quot;5-12w&quot;, &quot;01-05weeks&quot;)) dfc ## # A tibble: 4 x 1 ## x ## &lt;chr&gt; ## 1 1-12week ## 2 1-10wk ## 3 5-12w ## 4 01-05weeks dfc %&gt;% tidyr::extract( x, c(&quot;start&quot;, &quot;end&quot;, &quot;letter&quot;), &quot;(\\\\d+)-(\\\\d+)([a-z]+)&quot;, remove = FALSE ) ## # A tibble: 4 x 4 ## x start end letter ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1-12week 1 12 week ## 2 1-10wk 1 10 wk ## 3 5-12w 5 12 w ## 4 01-05weeks 01 05 weeks 20.22 crossing() 先看看效果 tidyr::crossing(x = c(&quot;F&quot;, &quot;M&quot;), y = c(&quot;a&quot;, &quot;b&quot;), z = c(1:2)) ## # A tibble: 8 x 3 ## x y z ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 F a 1 ## 2 F a 2 ## 3 F b 1 ## 4 F b 2 ## 5 M a 1 ## 6 M a 2 ## 7 M b 1 ## 8 M b 2 这个函数在数据模拟的时候很方便， tidyr::crossing(trials = 1:10, m = 1:5) %&gt;% group_by(trials) %&gt;% mutate( guess = sample.int(5, n()), result = m == guess ) %&gt;% summarise(score = sum(result) / n()) ## # A tibble: 10 x 2 ## trials score ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.4 ## 2 2 0 ## 3 3 0.2 ## 4 4 0.2 ## 5 5 0.2 ## 6 6 0.4 ## 7 7 0.4 ## 8 8 0.4 ## 9 9 0.2 ## 10 10 0.4 再来一个例子 sim &lt;- tribble( ~f, ~params, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 10) ) sim %&gt;% mutate(sim = invoke_map(f, params)) ## # A tibble: 1 x 3 ## f params sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 rbinom &lt;named list [3]&gt; &lt;int [10]&gt; rep_sim &lt;- sim %&gt;% crossing(rep = 1:1e5) %&gt;% mutate(sim = invoke_map(f, params)) %&gt;% unnest(sim) %&gt;% group_by(rep) %&gt;% summarise(mean_sim = mean(sim)) head(rep_sim) ## # A tibble: 6 x 2 ## rep mean_sim ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.6 ## 2 2 0.5 ## 3 3 0.7 ## 4 4 0.6 ## 5 5 0.5 ## 6 6 0.5 rep_sim %&gt;% ggplot(aes(x = mean_sim)) + geom_histogram(binwidth = 0.05, fill = &quot;skyblue&quot;) + theme_classic() 也可用在较复杂的模拟，比如下面介绍的大数极限定理， sim &lt;- tribble( ~n_tosses, ~f, ~params, 10, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 15), 30, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 30), 100, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 100), 1000, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 1000), 10000, &quot;rbinom&quot;, list(size = 1, prob = 0.5, n = 1e4) ) sim_rep &lt;- sim %&gt;% crossing(replication = 1:50) %&gt;% mutate(sims = invoke_map(f, params)) %&gt;% unnest(sims) %&gt;% group_by(replication, n_tosses) %&gt;% summarise(avg = mean(sims)) sim_rep %&gt;% ggplot(aes(x = factor(n_tosses), y = avg)) + ggbeeswarm::geom_quasirandom(color = &quot;lightgrey&quot;) + scale_y_continuous(limits = c(0, 1)) + geom_hline( yintercept = 0.5, color = &quot;skyblue&quot;, lty = 1, size = 1, alpha = 3 / 4 ) + ggthemes::theme_pander() + labs( title = &quot;50 Replicates Of Mean &#39;Heads&#39; As Number Of Tosses Increase&quot;, y = &quot;mean&quot;, x = &quot;Number Of Tosses&quot; ) 数值模拟我们会在第 27 章专门介绍。 "],["advR.html", "第 21 章 tidyverse进阶 21.1 scoped 函数 21.2 summarise_if 21.3 filter_if() 21.4 group_by 21.5 列名清理 21.6 缺失值检查与处理 21.7 标准化 21.8 across函数 21.9 参考资料", " 第 21 章 tidyverse进阶 让我们继续聊聊，相见恨晚的tidyverse library(tidyverse) 21.1 scoped 函数 在第 6 章介绍了dplyr的一些函数（mutate(), select()等等），事实上，这些函数加上后缀 _all, _at, _if，形成三组变体函数，可以方便对特定的子集进行操作。比如 对数据框所有列操作，可以用_all 对数据框指定的几列操作，可以用_at 对数据框符合条件的几列进行操作，可以用_if Operate _all _at _if select() select_all() select_at() select_if() mutate() mutate_all() mutate_at() mutate_if() rename() rename_all() rename_at() rename_if() arrange() arrange_all() arrange_at() arrange_if() filter() filter_all() filter_at() filter_if() distinct() distinct_all() distinct_at() distinct_if() group_by() group_by_all() group_by_at() group_by_if() summarise() summarise_all() summarise_at() summarise_if() map() map_all() map_at() map_if() modify() modify_all() modify_at() modify_if() 下面选取其中几个函数加以说明 21.1.1 mutate_if iris &lt;- iris %&gt;% as_tibble() df_iris &lt;- iris %&gt;% head(5) df_iris %&gt;% mutate_if(is.double, as.integer) ## # A tibble: 5 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 5 3 1 0 ## 2 4 3 1 0 ## 3 4 3 1 0 ## 4 4 3 1 0 ## 5 5 3 1 0 ## # ... with 1 more variable: Species &lt;fct&gt; 可以一次性增加多列 df_iris %&gt;% mutate_if(is.numeric, list(scale, log)) ## # A tibble: 5 x 13 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## # ... with 9 more variables: Species &lt;fct&gt;, ## # Sepal.Length_fn1[,1] &lt;dbl&gt;, ## # Sepal.Width_fn1[,1] &lt;dbl&gt;, ## # Petal.Length_fn1[,1] &lt;dbl&gt;, ## # Petal.Width_fn1[,1] &lt;dbl&gt;, Sepal.Length_fn2 &lt;dbl&gt;, ## # Sepal.Width_fn2 &lt;dbl&gt;, Petal.Length_fn2 &lt;dbl&gt;, ## # Petal.Width_fn2 &lt;dbl&gt; 也可以把函数放在list()中，用 Purrr-style lambda 形式写出 df_iris %&gt;% mutate_if(is.numeric, list(~ scale(.), ~ log(.))) ## # A tibble: 5 x 13 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## # ... with 9 more variables: Species &lt;fct&gt;, ## # Sepal.Length_scale[,1] &lt;dbl&gt;, ## # Sepal.Width_scale[,1] &lt;dbl&gt;, ## # Petal.Length_scale[,1] &lt;dbl&gt;, ## # Petal.Width_scale[,1] &lt;dbl&gt;, ## # Sepal.Length_log &lt;dbl&gt;, Sepal.Width_log &lt;dbl&gt;, ## # Petal.Length_log &lt;dbl&gt;, Petal.Width_log &lt;dbl&gt; 21.1.2 select_if() df &lt;- tibble::tibble( x = letters[1:3], y = c(1:3), z = c(0, 0, 0) ) df ## # A tibble: 3 x 3 ## x y z ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 1 0 ## 2 b 2 0 ## 3 c 3 0 df %&gt;% select_if(is.numeric) ## # A tibble: 3 x 2 ## y z ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0 ## 2 2 0 ## 3 3 0 df %&gt;% select_if(~ n_distinct(.) &gt; 2) ## # A tibble: 3 x 2 ## x y ## &lt;chr&gt; &lt;int&gt; ## 1 a 1 ## 2 b 2 ## 3 c 3 select_if 多个条件的情况 df %&gt;% select_if( list(~ (is.numeric(.) | is.character(.))) ) ## # A tibble: 3 x 3 ## x y z ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 1 0 ## 2 b 2 0 ## 3 c 3 0 df %&gt;% select_if( ~ (is.numeric(.) | is.character(.)) ) ## # A tibble: 3 x 3 ## x y z ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 1 0 ## 2 b 2 0 ## 3 c 3 0 to_keep &lt;- function(x) is.numeric(x) | is.character(x) df %&gt;% select_if(to_keep) ## # A tibble: 3 x 3 ## x y z ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 1 0 ## 2 b 2 0 ## 3 c 3 0 df %&gt;% select_if( list(~ (is.numeric(.) &amp;&amp; sum(.) &gt; 2)) ) ## # A tibble: 3 x 1 ## y ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 df %&gt;% select_if( list(~ (is.numeric(.) &amp;&amp; mean(.) &gt; 1)) ) ## # A tibble: 3 x 1 ## y ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 我们也可以写成函数的形式 to_want &lt;- function(x) is.numeric(x) &amp;&amp; sum(x) &gt; 3 df %&gt;% select_if(to_want) ## # A tibble: 3 x 1 ## y ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 21.2 summarise_if msleep &lt;- ggplot2::msleep msleep %&gt;% dplyr::group_by(vore) %&gt;% dplyr::summarise_all(~ mean(., na.rm = TRUE)) ## # A tibble: 5 x 11 ## vore name genus order conservation sleep_total ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 carni NA NA NA NA 10.4 ## 2 herbi NA NA NA NA 9.51 ## 3 inse~ NA NA NA NA 14.9 ## 4 omni NA NA NA NA 10.9 ## 5 &lt;NA&gt; NA NA NA NA 10.2 ## # ... with 5 more variables: sleep_rem &lt;dbl&gt;, ## # sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;, brainwt &lt;dbl&gt;, ## # bodywt &lt;dbl&gt; msleep &lt;- ggplot2::msleep msleep %&gt;% dplyr::group_by(vore) %&gt;% # summarise_if(is.numeric, ~mean(., na.rm = TRUE)) dplyr::summarise_if(is.numeric, mean, na.rm = TRUE) ## # A tibble: 5 x 7 ## vore sleep_total sleep_rem sleep_cycle awake brainwt ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 carni 10.4 2.29 0.373 13.6 0.0793 ## 2 herbi 9.51 1.37 0.418 14.5 0.622 ## 3 inse~ 14.9 3.52 0.161 9.06 0.0216 ## 4 omni 10.9 1.96 0.592 13.1 0.146 ## 5 &lt;NA&gt; 10.2 1.88 0.183 13.8 0.00763 ## # ... with 1 more variable: bodywt &lt;dbl&gt; 21.3 filter_if() 事实上，filter已经很强大了，有了scoped函数，就如虎添翼了 msleep &lt;- ggplot2::msleep msleep %&gt;% dplyr::select(name, sleep_total) %&gt;% dplyr::filter(sleep_total &gt; 18) ## # A tibble: 4 x 2 ## name sleep_total ## &lt;chr&gt; &lt;dbl&gt; ## 1 Big brown bat 19.7 ## 2 Thick-tailed opposum 19.4 ## 3 Little brown bat 19.9 ## 4 Giant armadillo 18.1 msleep %&gt;% dplyr::select(name, sleep_total) %&gt;% dplyr::filter(between(sleep_total, 16, 18)) ## # A tibble: 4 x 2 ## name sleep_total ## &lt;chr&gt; &lt;dbl&gt; ## 1 Owl monkey 17 ## 2 Long-nosed armadillo 17.4 ## 3 North American Opossum 18 ## 4 Arctic ground squirrel 16.6 msleep %&gt;% dplyr::select(name, sleep_total) %&gt;% # filter(near(sleep_total, 17, tol=sd(sleep_total))) dplyr::filter(near(sleep_total, mean(sleep_total), tol = 0.5 * sd(sleep_total))) ## # A tibble: 35 x 2 ## name sleep_total ## &lt;chr&gt; &lt;dbl&gt; ## 1 Cheetah 12.1 ## 2 Northern fur seal 8.7 ## 3 Dog 10.1 ## 4 Guinea pig 9.4 ## 5 Grivet 10 ## 6 Chinchilla 12.5 ## 7 Star-nosed mole 10.3 ## 8 African giant pouched rat 8.3 ## 9 Lesser short-tailed shrew 9.1 ## 10 European hedgehog 10.1 ## # ... with 25 more rows mtcars是 R内置数据集，记录了32种不同品牌的轿车的的11个属性 mtcars &lt;- mtcars %&gt;% as_tibble() mtcars ## # A tibble: 32 x 11 ## mpg cyl disp hp drat wt qsec vs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 ## 2 21 6 160 110 3.9 2.88 17.0 0 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 ## 8 24.4 4 147. 62 3.69 3.19 20 1 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 ## # ... with 22 more rows, and 3 more variables: ## # am &lt;dbl&gt;, gear &lt;dbl&gt;, carb &lt;dbl&gt; filter_if()配合all_vars(), any_vars()函数，可以完成很酷的工作. 比如，要求一行中所有变量的值都大于150 mtcars %&gt;% filter_all(all_vars(. &gt; 150)) ## # A tibble: 0 x 11 ## # ... with 11 variables: mpg &lt;dbl&gt;, cyl &lt;dbl&gt;, ## # disp &lt;dbl&gt;, hp &lt;dbl&gt;, drat &lt;dbl&gt;, wt &lt;dbl&gt;, ## # qsec &lt;dbl&gt;, vs &lt;dbl&gt;, am &lt;dbl&gt;, gear &lt;dbl&gt;, ## # carb &lt;dbl&gt; 比如，要求一行中至少有一个变量的值都大于150 # Or the union: mtcars %&gt;% filter_all(any_vars(. &gt; 150)) ## # A tibble: 21 x 11 ## mpg cyl disp hp drat wt qsec vs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 ## 2 21 6 160 110 3.9 2.88 17.0 0 ## 3 21.4 6 258 110 3.08 3.22 19.4 1 ## 4 18.7 8 360 175 3.15 3.44 17.0 0 ## 5 18.1 6 225 105 2.76 3.46 20.2 1 ## 6 14.3 8 360 245 3.21 3.57 15.8 0 ## 7 19.2 6 168. 123 3.92 3.44 18.3 1 ## 8 17.8 6 168. 123 3.92 3.44 18.9 1 ## 9 16.4 8 276. 180 3.07 4.07 17.4 0 ## 10 17.3 8 276. 180 3.07 3.73 17.6 0 ## # ... with 11 more rows, and 3 more variables: ## # am &lt;dbl&gt;, gear &lt;dbl&gt;, carb &lt;dbl&gt; # You can vary the selection of columns on which to apply the predicate. # filter_at() takes a vars() specification: mtcars %&gt;% filter_at(vars(starts_with(&quot;d&quot;)), any_vars((. %% 2) == 0)) ## # A tibble: 13 x 11 ## mpg cyl disp hp drat wt qsec vs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 ## 2 21 6 160 110 3.9 2.88 17.0 0 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 ## 6 14.3 8 360 245 3.21 3.57 15.8 0 ## 7 10.4 8 472 205 2.93 5.25 18.0 0 ## 8 10.4 8 460 215 3 5.42 17.8 0 ## 9 14.7 8 440 230 3.23 5.34 17.4 0 ## 10 15.5 8 318 150 2.76 3.52 16.9 0 ## 11 15.2 8 304 150 3.15 3.44 17.3 0 ## 12 13.3 8 350 245 3.73 3.84 15.4 0 ## 13 19.2 8 400 175 3.08 3.84 17.0 0 ## # ... with 3 more variables: am &lt;dbl&gt;, gear &lt;dbl&gt;, ## # carb &lt;dbl&gt; filter_if(.tbl, .predicate, .vars_predicate) 相对复杂点，我这里多说几句。 filter_if() 有三个参数： .tbl, 数据框 .predicate, 应用在列上的函数，一般作为列的选择条件 .vars_predicate, 应用在一行上的函数，通过 all_vars(), any_vars()返回值决定是否选取该行。 # And filter_if() selects variables with a predicate function: # filter_if(.tbl, .predicate, .vars_predicate) # mtcars %&gt;% map_df(~ all(floor(.) == .) ) # mtcars %&gt;% select_if( ~ all(floor(.) == .) ) mtcars %&gt;% filter_if(~ all(floor(.) == .), all_vars(. != 0)) ## # A tibble: 7 x 11 ## mpg cyl disp hp drat wt qsec vs am ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 22.8 4 108 93 3.85 2.32 18.6 1 1 ## 2 32.4 4 78.7 66 4.08 2.2 19.5 1 1 ## 3 30.4 4 75.7 52 4.93 1.62 18.5 1 1 ## 4 33.9 4 71.1 65 4.22 1.84 19.9 1 1 ## 5 27.3 4 79 66 4.08 1.94 18.9 1 1 ## 6 30.4 4 95.1 113 3.77 1.51 16.9 1 1 ## 7 21.4 4 121 109 4.11 2.78 18.6 1 1 ## # ... with 2 more variables: gear &lt;dbl&gt;, carb &lt;dbl&gt; 所以这里是，先通过.predicate = ~ all(floor(.) == .) 选取变量值为整数的列，然后再看选取的这些列的行方向，如果每一行的值.vars_predicate = all_vars(. != 0) ，都不为0，就保留下来，否则过滤掉。 简单点说，这段代码的意思，数值全部为整数的列，不能同时为0 21.4 group_by group_by() 用的很多，所以要多讲讲 mtcars %&gt;% dplyr::group_by(cyl) ## # A tibble: 32 x 11 ## # Groups: cyl [3] ## mpg cyl disp hp drat wt qsec vs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 ## 2 21 6 160 110 3.9 2.88 17.0 0 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 ## 8 24.4 4 147. 62 3.69 3.19 20 1 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 ## # ... with 22 more rows, and 3 more variables: ## # am &lt;dbl&gt;, gear &lt;dbl&gt;, carb &lt;dbl&gt; mtcars %&gt;% group_by_at(vars(cyl)) ## # A tibble: 32 x 11 ## # Groups: cyl [3] ## mpg cyl disp hp drat wt qsec vs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 ## 2 21 6 160 110 3.9 2.88 17.0 0 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 ## 8 24.4 4 147. 62 3.69 3.19 20 1 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 ## # ... with 22 more rows, and 3 more variables: ## # am &lt;dbl&gt;, gear &lt;dbl&gt;, carb &lt;dbl&gt; # Group a data frame by all variables: mtcars %&gt;% group_by_all() ## # A tibble: 32 x 11 ## # Groups: mpg, cyl, disp, hp, drat, wt, qsec, vs, ## # am, gear, carb [32] ## mpg cyl disp hp drat wt qsec vs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 ## 2 21 6 160 110 3.9 2.88 17.0 0 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 ## 8 24.4 4 147. 62 3.69 3.19 20 1 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 ## # ... with 22 more rows, and 3 more variables: ## # am &lt;dbl&gt;, gear &lt;dbl&gt;, carb &lt;dbl&gt; # Group by variables selected with a predicate: iris %&gt;% group_by_if(is.factor) ## # A tibble: 150 x 5 ## # Groups: Species [3] ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 140 more rows, and 1 more variable: ## # Species &lt;fct&gt; 21.4.1 group_split(), group_map(), group_modify() iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::group_split() ## &lt;list_of&lt; ## tbl_df&lt; ## Sepal.Length: double ## Sepal.Width : double ## Petal.Length: double ## Petal.Width : double ## Species : factor&lt;12d60&gt; ## &gt; ## &gt;[3]&gt; ## [[1]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[2]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7 3.2 4.7 1.4 ## 2 6.4 3.2 4.5 1.5 ## 3 6.9 3.1 4.9 1.5 ## 4 5.5 2.3 4 1.3 ## 5 6.5 2.8 4.6 1.5 ## 6 5.7 2.8 4.5 1.3 ## 7 6.3 3.3 4.7 1.6 ## 8 4.9 2.4 3.3 1 ## 9 6.6 2.9 4.6 1.3 ## 10 5.2 2.7 3.9 1.4 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[3]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.3 3.3 6 2.5 ## 2 5.8 2.7 5.1 1.9 ## 3 7.1 3 5.9 2.1 ## 4 6.3 2.9 5.6 1.8 ## 5 6.5 3 5.8 2.2 ## 6 7.6 3 6.6 2.1 ## 7 4.9 2.5 4.5 1.7 ## 8 7.3 2.9 6.3 1.8 ## 9 6.7 2.5 5.8 1.8 ## 10 7.2 3.6 6.1 2.5 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; 简单点写，就是 iris %&gt;% dplyr::group_split(Species) ## &lt;list_of&lt; ## tbl_df&lt; ## Sepal.Length: double ## Sepal.Width : double ## Petal.Length: double ## Petal.Width : double ## Species : factor&lt;12d60&gt; ## &gt; ## &gt;[3]&gt; ## [[1]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[2]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7 3.2 4.7 1.4 ## 2 6.4 3.2 4.5 1.5 ## 3 6.9 3.1 4.9 1.5 ## 4 5.5 2.3 4 1.3 ## 5 6.5 2.8 4.6 1.5 ## 6 5.7 2.8 4.5 1.3 ## 7 6.3 3.3 4.7 1.6 ## 8 4.9 2.4 3.3 1 ## 9 6.6 2.9 4.6 1.3 ## 10 5.2 2.7 3.9 1.4 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[3]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.3 3.3 6 2.5 ## 2 5.8 2.7 5.1 1.9 ## 3 7.1 3 5.9 2.1 ## 4 6.3 2.9 5.6 1.8 ## 5 6.5 3 5.8 2.2 ## 6 7.6 3 6.6 2.1 ## 7 4.9 2.5 4.5 1.7 ## 8 7.3 2.9 6.3 1.8 ## 9 6.7 2.5 5.8 1.8 ## 10 7.2 3.6 6.1 2.5 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; 如果使用group_split(), 注意分组后，返回的是列表 iris %&gt;% dplyr::group_split(Species) ## &lt;list_of&lt; ## tbl_df&lt; ## Sepal.Length: double ## Sepal.Width : double ## Petal.Length: double ## Petal.Width : double ## Species : factor&lt;12d60&gt; ## &gt; ## &gt;[3]&gt; ## [[1]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[2]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7 3.2 4.7 1.4 ## 2 6.4 3.2 4.5 1.5 ## 3 6.9 3.1 4.9 1.5 ## 4 5.5 2.3 4 1.3 ## 5 6.5 2.8 4.6 1.5 ## 6 5.7 2.8 4.5 1.3 ## 7 6.3 3.3 4.7 1.6 ## 8 4.9 2.4 3.3 1 ## 9 6.6 2.9 4.6 1.3 ## 10 5.2 2.7 3.9 1.4 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; ## ## [[3]] ## # A tibble: 50 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.3 3.3 6 2.5 ## 2 5.8 2.7 5.1 1.9 ## 3 7.1 3 5.9 2.1 ## 4 6.3 2.9 5.6 1.8 ## 5 6.5 3 5.8 2.2 ## 6 7.6 3 6.6 2.1 ## 7 4.9 2.5 4.5 1.7 ## 8 7.3 2.9 6.3 1.8 ## 9 6.7 2.5 5.8 1.8 ## 10 7.2 3.6 6.1 2.5 ## # ... with 40 more rows, and 1 more variable: ## # Species &lt;fct&gt; 既然是列表，当然想到用前面讲到的purrr::map()家族 iris %&gt;% dplyr::group_split(Species) %&gt;% purrr::map(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x))) ## [[1]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.803 0.344 2.34 0.0238 ## 2 Sepal.Length 0.132 0.0685 1.92 0.0607 ## ## [[2]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.185 0.514 0.360 7.20e- 1 ## 2 Sepal.Length 0.686 0.0863 7.95 2.59e-10 ## ## [[3]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.610 0.417 1.46 1.50e- 1 ## 2 Sepal.Length 0.750 0.0630 11.9 6.30e-16 iris %&gt;% dplyr::group_split(Species) %&gt;% purrr::map_df(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x))) ## # A tibble: 6 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.803 0.344 2.34 2.38e- 2 ## 2 Sepal.Length 0.132 0.0685 1.92 6.07e- 2 ## 3 (Intercept) 0.185 0.514 0.360 7.20e- 1 ## 4 Sepal.Length 0.686 0.0863 7.95 2.59e-10 ## 5 (Intercept) 0.610 0.417 1.46 1.50e- 1 ## 6 Sepal.Length 0.750 0.0630 11.9 6.30e-16 上面这个代码，数据框分割成list, 处理完后再合并成数据框，难道不觉得折腾么？ 为什么直接点？ tidyverse不会让我们失望的，先看看group_map() ## The result of .f should be a data frame(.f 必须返回数据框) ## `group_map()` return a list of tibble(返回元素均为df的一个列表list(df1,df2,df3)) iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::group_map(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x))) ## [[1]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.803 0.344 2.34 0.0238 ## 2 Sepal.Length 0.132 0.0685 1.92 0.0607 ## ## [[2]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.185 0.514 0.360 7.20e- 1 ## 2 Sepal.Length 0.686 0.0863 7.95 2.59e-10 ## ## [[3]] ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.610 0.417 1.46 1.50e- 1 ## 2 Sepal.Length 0.750 0.0630 11.9 6.30e-16 数据框进来，然后分组，依次处理成一个个数据框，最后以列表形式（a list of tibble）输出。 事实上，group_map()是返回list形式，也就是说，可以是返回任何形式，（a list of tibble）是其中特殊形式。 可以看看下面这个 iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::group_map( ~ lm(Petal.Length ~ Sepal.Length, data = .x) ) ## [[1]] ## ## Call: ## lm(formula = Petal.Length ~ Sepal.Length, data = .x) ## ## Coefficients: ## (Intercept) Sepal.Length ## 0.803 0.132 ## ## ## [[2]] ## ## Call: ## lm(formula = Petal.Length ~ Sepal.Length, data = .x) ## ## Coefficients: ## (Intercept) Sepal.Length ## 0.185 0.686 ## ## ## [[3]] ## ## Call: ## lm(formula = Petal.Length ~ Sepal.Length, data = .x) ## ## Coefficients: ## (Intercept) Sepal.Length ## 0.61 0.75 group_modify() 才是真正意义上的“数据框进、数据框出”。 iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::group_modify(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x))) ## # A tibble: 6 x 6 ## # Groups: Species [3] ## Species term estimate std.error statistic p.value ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa (Inte~ 0.803 0.344 2.34 2.38e- 2 ## 2 setosa Sepal~ 0.132 0.0685 1.92 6.07e- 2 ## 3 versico~ (Inte~ 0.185 0.514 0.360 7.20e- 1 ## 4 versico~ Sepal~ 0.686 0.0863 7.95 2.59e-10 ## 5 virgini~ (Inte~ 0.610 0.417 1.46 1.50e- 1 ## 6 virgini~ Sepal~ 0.750 0.0630 11.9 6.30e-16 为了大家方便查阅和记忆，我总结下表 函数 说明 常用组合 返回值 要求 map() 列表进、列表出 df %&gt;% group_split() %&gt;% map() list map_df() 列表进、数据框出 df %&gt;% group_split() %&gt;% map_df() df group_map() 数据框进、列表出 df %&gt;% group_by() %&gt;% group_map() 返回list(list1, list2, …) 特例list(df1, df2, …) group_modify() 数据框进、数据框出 df %&gt;% group_by() %&gt;% group_modify() 返回grouped tibble .f返回df walk 列表进 df %&gt;% group_split() %&gt;%walk() side effects group_walk() 数据框进 df %&gt;% group_by() %&gt;% group_walk() side effects 我常用的批量出图的语句 nobel_winners %&gt;% dplyr::group_split(category) %&gt;% purrr::map( ~ ggplot(data = .x, aes(x = prize_age)) + geom_density() + ggtitle(.x$category) ) nobel_winners %&gt;% dplyr::group_by(category) %&gt;% dplyr::group_map( ~ ggplot(data = .x, aes(x = prize_age)) + geom_density() + ggtitle(.y) ) nobel_winners %&gt;% dplyr::group_by(category) %&gt;% dplyr::group_walk( ~ ggsave( paste0(.y, &quot;.png&quot;), ggplot(data = .x, aes(x = prize_age)) + geom_density() + ggtitle(.y), device = &quot;png&quot;, path = temp ) ) %&gt;% invisible() 21.4.2 其他group函数 group_nest(), group_data(), group_keys(), group_rows() 21.5 列名清理 数据框的列名，不要用有空格和中文。 如果拿到的原始数据中列比较多，手动修改麻烦，可以使用janitor::clean_names()函数 library(readxl) library(janitor) # install.packages(&quot;janitor&quot;) roster_raw &lt;- read_excel(here::here(&quot;demo_data&quot;, &quot;dirty_data.xlsx&quot;)) glimpse(roster_raw) ## Rows: 13 ## Columns: 11 ## $ `First Name` &lt;chr&gt; &quot;Jason&quot;, &quot;Jason&quot;, &quot;Ali... ## $ `Last Name` &lt;chr&gt; &quot;Bourne&quot;, &quot;Bourne&quot;, &quot;K... ## $ `Employee Status` &lt;chr&gt; &quot;Teacher&quot;, &quot;Teacher&quot;, ... ## $ Subject &lt;chr&gt; &quot;PE&quot;, &quot;Drafting&quot;, &quot;Mus... ## $ `Hire Date` &lt;dbl&gt; 39690, 39690, 37118, 2... ## $ `% Allocated` &lt;dbl&gt; 0.75, 0.25, 1.00, 1.00... ## $ `Full time?` &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;... ## $ `do not edit! ---&gt;` &lt;lgl&gt; NA, NA, NA, NA, NA, NA... ## $ Certification...9 &lt;chr&gt; &quot;Physical ed&quot;, &quot;Physic... ## $ Certification...10 &lt;chr&gt; &quot;Theater&quot;, &quot;Theater&quot;, ... ## $ Certification...11 &lt;lgl&gt; NA, NA, NA, NA, NA, NA... roster &lt;- roster_raw %&gt;% janitor::clean_names() glimpse(roster) ## Rows: 13 ## Columns: 11 ## $ first_name &lt;chr&gt; &quot;Jason&quot;, &quot;Jason&quot;, &quot;Alici... ## $ last_name &lt;chr&gt; &quot;Bourne&quot;, &quot;Bourne&quot;, &quot;Key... ## $ employee_status &lt;chr&gt; &quot;Teacher&quot;, &quot;Teacher&quot;, &quot;T... ## $ subject &lt;chr&gt; &quot;PE&quot;, &quot;Drafting&quot;, &quot;Music... ## $ hire_date &lt;dbl&gt; 39690, 39690, 37118, 275... ## $ percent_allocated &lt;dbl&gt; 0.75, 0.25, 1.00, 1.00, ... ## $ full_time &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Ye... ## $ do_not_edit &lt;lgl&gt; NA, NA, NA, NA, NA, NA, ... ## $ certification_9 &lt;chr&gt; &quot;Physical ed&quot;, &quot;Physical... ## $ certification_10 &lt;chr&gt; &quot;Theater&quot;, &quot;Theater&quot;, &quot;V... ## $ certification_11 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, ... 21.6 缺失值检查与处理 21.6.1 purrr &amp; dplyr 技巧 library(purrr) airquality &lt;- as_tibble(airquality) airquality %&gt;% purrr::map(~ sum(is.na(.))) ## $Ozone ## [1] 37 ## ## $Solar.R ## [1] 7 ## ## $Wind ## [1] 0 ## ## $Temp ## [1] 0 ## ## $Month ## [1] 0 ## ## $Day ## [1] 0 airquality %&gt;% purrr::map_df(~ sum(is.na(.))) ## # A tibble: 1 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 37 7 0 0 0 0 airquality %&gt;% dplyr::summarise_at(2:3, ~ sum(is.na(.))) ## # A tibble: 1 x 2 ## Solar.R Wind ## &lt;int&gt; &lt;int&gt; ## 1 7 0 21.6.2 缺失值替换 airquality %&gt;% mutate_all(funs(replace(., is.na(.), 0))) ## # A tibble: 153 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 41 190 7.4 67 5 1 ## 2 36 118 8 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 0 0 14.3 56 5 5 ## 6 28 0 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 0 194 8.6 69 5 10 ## # ... with 143 more rows airquality %&gt;% mutate_all(replace_na, replace = 0) ## # A tibble: 153 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 41 190 7.4 67 5 1 ## 2 36 118 8 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 0 0 14.3 56 5 5 ## 6 28 0 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 0 194 8.6 69 5 10 ## # ... with 143 more rows airquality %&gt;% mutate_if(is.numeric, replace_na, replace = 0) ## # A tibble: 153 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 41 190 7.4 67 5 1 ## 2 36 118 8 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 0 0 14.3 56 5 5 ## 6 28 0 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 0 194 8.6 69 5 10 ## # ... with 143 more rows airquality %&gt;% mutate_all(as.numeric) %&gt;% mutate_all(~ coalesce(., 0)) ## # A tibble: 153 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 41 190 7.4 67 5 1 ## 2 36 118 8 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 0 0 14.3 56 5 5 ## 6 28 0 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 0 194 8.6 69 5 10 ## # ... with 143 more rows tibble( y = c(1, 2, NA, NA, 5), z = c(NA, NA, 3, 4, 5) ) %&gt;% mutate_all(~ coalesce(., 0)) ## # A tibble: 5 x 2 ## y z ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0 ## 2 2 0 ## 3 0 3 ## 4 0 4 ## 5 5 5 21.7 标准化 数据变量，在标准化之前是有单位的，如mm,kg等，标准之后就没有量纲了，而是偏离均值的程度，一般用多少方差，几个方差来度量。 标准化的好处在于，不同量纲的变量可以比较分析。 df_mtcars ## # A tibble: 32 x 12 ## rowname mpg cyl disp hp drat wt qsec ## &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 21 6 160 110 3.9 2.62 16.5 ## 2 2 21 6 160 110 3.9 2.88 17.0 ## 3 3 22.8 4 108 93 3.85 2.32 18.6 ## 4 4 21.4 6 258 110 3.08 3.22 19.4 ## 5 5 18.7 8 360 175 3.15 3.44 17.0 ## 6 6 18.1 6 225 105 2.76 3.46 20.2 ## 7 7 14.3 8 360 245 3.21 3.57 15.8 ## 8 8 24.4 4 147. 62 3.69 3.19 20 ## 9 9 22.8 4 141. 95 3.92 3.15 22.9 ## 10 10 19.2 6 168. 123 3.92 3.44 18.3 ## # ... with 22 more rows, and 4 more variables: ## # vs &lt;fct&gt;, am &lt;fct&gt;, gear &lt;fct&gt;, carb &lt;fct&gt; df_mtcars %&gt;% select_if(funs(is.numeric)) ## # A tibble: 32 x 6 ## mpg disp hp drat wt qsec ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 160 110 3.9 2.62 16.5 ## 2 21 160 110 3.9 2.88 17.0 ## 3 22.8 108 93 3.85 2.32 18.6 ## 4 21.4 258 110 3.08 3.22 19.4 ## 5 18.7 360 175 3.15 3.44 17.0 ## 6 18.1 225 105 2.76 3.46 20.2 ## 7 14.3 360 245 3.21 3.57 15.8 ## 8 24.4 147. 62 3.69 3.19 20 ## 9 22.8 141. 95 3.92 3.15 22.9 ## 10 19.2 168. 123 3.92 3.44 18.3 ## # ... with 22 more rows # way 1 df_mtcars %&gt;% mutate_at(vars(mpg, disp), ~ scale(., center = T, scale = T)) ## # A tibble: 32 x 12 ## rowname mpg[,1] cyl disp[,1] hp drat wt ## &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.151 6 -0.571 110 3.9 2.62 ## 2 2 0.151 6 -0.571 110 3.9 2.88 ## 3 3 0.450 4 -0.990 93 3.85 2.32 ## 4 4 0.217 6 0.220 110 3.08 3.22 ## 5 5 -0.231 8 1.04 175 3.15 3.44 ## 6 6 -0.330 6 -0.0462 105 2.76 3.46 ## 7 7 -0.961 8 1.04 245 3.21 3.57 ## 8 8 0.715 4 -0.678 62 3.69 3.19 ## 9 9 0.450 4 -0.726 95 3.92 3.15 ## 10 10 -0.148 6 -0.509 123 3.92 3.44 ## # ... with 22 more rows, and 5 more variables: ## # qsec &lt;dbl&gt;, vs &lt;fct&gt;, am &lt;fct&gt;, gear &lt;fct&gt;, ## # carb &lt;fct&gt; # way 2 df_mtcars %&gt;% mutate_at(vars(mpg, disp), funs((. - mean(.)) / sd(.))) ## # A tibble: 32 x 12 ## rowname mpg cyl disp hp drat wt qsec ## &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.151 6 -0.571 110 3.9 2.62 16.5 ## 2 2 0.151 6 -0.571 110 3.9 2.88 17.0 ## 3 3 0.450 4 -0.990 93 3.85 2.32 18.6 ## 4 4 0.217 6 0.220 110 3.08 3.22 19.4 ## 5 5 -0.231 8 1.04 175 3.15 3.44 17.0 ## 6 6 -0.330 6 -0.0462 105 2.76 3.46 20.2 ## 7 7 -0.961 8 1.04 245 3.21 3.57 15.8 ## 8 8 0.715 4 -0.678 62 3.69 3.19 20 ## 9 9 0.450 4 -0.726 95 3.92 3.15 22.9 ## 10 10 -0.148 6 -0.509 123 3.92 3.44 18.3 ## # ... with 22 more rows, and 4 more variables: ## # vs &lt;fct&gt;, am &lt;fct&gt;, gear &lt;fct&gt;, carb &lt;fct&gt; # way 3 func &lt;- function(x) (x - min(x)) / (max(x) - min(x)) df_mtcars %&gt;% mutate_at(vars(mpg, disp), ~ func(.)) ## # A tibble: 32 x 12 ## rowname mpg cyl disp hp drat wt qsec ## &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.451 6 0.222 110 3.9 2.62 16.5 ## 2 2 0.451 6 0.222 110 3.9 2.88 17.0 ## 3 3 0.528 4 0.0920 93 3.85 2.32 18.6 ## 4 4 0.468 6 0.466 110 3.08 3.22 19.4 ## 5 5 0.353 8 0.721 175 3.15 3.44 17.0 ## 6 6 0.328 6 0.384 105 2.76 3.46 20.2 ## 7 7 0.166 8 0.721 245 3.21 3.57 15.8 ## 8 8 0.596 4 0.189 62 3.69 3.19 20 ## 9 9 0.528 4 0.174 95 3.92 3.15 22.9 ## 10 10 0.374 6 0.241 123 3.92 3.44 18.3 ## # ... with 22 more rows, and 4 more variables: ## # vs &lt;fct&gt;, am &lt;fct&gt;, gear &lt;fct&gt;, carb &lt;fct&gt; 如果所有的列，都是数值型 func &lt;- function(x) (x - min(x)) / (max(x) - min(x)) df_mtcars %&gt;% mutate_all(~ func(.)) ## Error: Problem with `mutate()` input `rowname`. ## x 二进列运算符中有非数值参数 ## i Input `rowname` is `(structure(function (..., .x = ..1, .y = ..2, . = ..1) ...`. 但这里数据中还有其他类型（fct, chr），所以这里 mutate_all() 会报错。 这种情形，用mutate_if() func &lt;- function(x) (x - min(x)) / (max(x) - min(x)) df_mtcars %&gt;% mutate_if(is.numeric, ~ func(.)) ## # A tibble: 32 x 12 ## rowname mpg cyl disp hp drat wt qsec ## &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.451 6 0.222 0.205 0.525 0.283 0.233 ## 2 2 0.451 6 0.222 0.205 0.525 0.348 0.3 ## 3 3 0.528 4 0.0920 0.145 0.502 0.206 0.489 ## 4 4 0.468 6 0.466 0.205 0.147 0.435 0.588 ## 5 5 0.353 8 0.721 0.435 0.180 0.493 0.3 ## 6 6 0.328 6 0.384 0.187 0 0.498 0.681 ## 7 7 0.166 8 0.721 0.682 0.207 0.526 0.160 ## 8 8 0.596 4 0.189 0.0353 0.429 0.429 0.655 ## 9 9 0.528 4 0.174 0.152 0.535 0.419 1 ## 10 10 0.374 6 0.241 0.251 0.535 0.493 0.452 ## # ... with 22 more rows, and 4 more variables: ## # vs &lt;fct&gt;, am &lt;fct&gt;, gear &lt;fct&gt;, carb &lt;fct&gt; funs &lt;- list( centered = mean, # Function object scaled = ~ . - mean(.) / sd(.) # Purrr-style lambda ) iris %&gt;% mutate_if(is.numeric, funs) ## # A tibble: 150 x 13 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 140 more rows, and 9 more variables: ## # Species &lt;fct&gt;, Sepal.Length_centered &lt;dbl&gt;, ## # Sepal.Width_centered &lt;dbl&gt;, ## # Petal.Length_centered &lt;dbl&gt;, ## # Petal.Width_centered &lt;dbl&gt;, ## # Sepal.Length_scaled &lt;dbl&gt;, ## # Sepal.Width_scaled &lt;dbl&gt;, ## # Petal.Length_scaled &lt;dbl&gt;, ## # Petal.Width_scaled &lt;dbl&gt; 21.8 across函数 数据框中向量de方向，事实上可以看做有两个方向，横着看是row-vector，竖着看是col-vector。 colwise: group_by() %&gt;% summarise/mutate + across() rowwise: rowwise()/nest_by() %&gt;% summarise/mutate + c_across() 比如 iris %&gt;% dplyr::group_by(Species) %&gt;% dplyr::summarise( across(starts_with(&quot;Sepal&quot;), mean), Area = mean(Petal.Length * Petal.Width), across(starts_with(&quot;Petal&quot;), min) ) 21.8.1 across函数替代scope函数 强大的across()函数，替代以上scope函数(_if, _at, 和 _all函数), 同时slice_max(), slice_min(), slice_n() 将替代 top_n()函数。请参考阅读第22 章。 df %&gt;% mutate_if(is.numeric, mean, na.rm = TRUE) # -&gt; df %&gt;% mutate(across(is.numeric, mean, na.rm = TRUE)) df %&gt;% mutate_at(vars(x, starts_with(&quot;y&quot;)), mean, na.rm = TRUE) # -&gt; df %&gt;% mutate(across(c(x, starts_with(&quot;y&quot;)), mean, na.rm = TRUE)) df %&gt;% mutate_all(mean, na.rm = TRUE) # -&gt; df %&gt;% mutate(across(everything(), mean, na.rm = TRUE)) 21.8.2 更方便的colwise操作 # multiple df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) mult &lt;- list(x = 1, y = 10, z = 100) df %&gt;% mutate(across(all_of(names(mult)), ~ .x * mult[[cur_column()]])) # weights df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) df weights &lt;- list(x = 0.2, y = 0.3, z = 0.5) df %&gt;% dplyr::mutate( across(all_of(names(weights)), list(wt = ~ .x * weights[[cur_column()]]), .names = &quot;{col}.{fn}&quot; ) ) # cutoffs df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) df cutoffs &lt;- list(x = 2, y = 3, z = 7) df %&gt;% dplyr::mutate( across(all_of(names(cutoffs)), ~ if_else(.x &gt; cutoffs[[cur_column()]], 1, 0)) ) 21.9 参考资料 https://dplyr.tidyverse.org/dev/articles/rowwise.html https://dplyr.tidyverse.org/dev/articles/colwise.html "],["colwise.html", "第 22 章 列方向和行方向 22.1 体验新版本 22.2 简单回顾 22.3 summarise()更强大了 22.4 summarise()后的分组信息是去是留？ 22.5 选择某列 22.6 重命名某列 22.7 调整列的位置 22.8 强大的across函数 22.9 “current” group or “current” variable 22.10 行方向操作 22.11 参考资料", " 第 22 章 列方向和行方向 dplyr宏包是数据科学tidyverse集合的核心部件之一，Hadley Wickham大神说将会在5月15日发布dplyr 1.0版本，欢呼。 为迎接新时代的到来，我在线上同大家一起分享dplyr 1.0版本新的特点和功能，看看都为我们带来哪些惊喜？ 22.1 体验新版本 New dplyr - 8 things to know: Built in tidyselect relocate() Superpowered summarise() colwise using across() cur_data(), cur_group() and cur_column() new rowwise() grammar easy modeling inside dataframes nest_by() library(dplyr, warn.conflicts = FALSE) library(tidyr) 22.2 简单回顾 mutate() select() filter() group_by() summarise() arrange() rename() left_join() 22.3 summarise()更强大了 在dplyr 1.0之前，summarise()会把统计结果整理成一行一列的数据框，现在可以根据函数返回的结果，可以有多种形式： 长度为 1 的向量，比如，min(x), n(), or sum(is.na(y)) 长度为 n 的向量，比如，quantile() 数据框 df &lt;- tibble( grp = rep(c(&quot;a&quot;, &quot;b&quot;), each = 5), x = c(rnorm(5, -0.25, 1), rnorm(5, 0, 1.5)), y = c(rnorm(5, 0.25, 1), rnorm(5, 0, 0.5)) ) df ## # A tibble: 10 x 3 ## grp x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a -0.665 -0.387 ## 2 a -0.270 -0.839 ## 3 a 0.791 0.0371 ## 4 a -1.38 -0.144 ## 5 a 0.903 0.148 ## 6 b 1.55 0.143 ## 7 b 1.10 0.0986 ## 8 b -0.400 -1.11 ## 9 b -2.47 -0.670 ## 10 b -0.374 -0.440 df %&gt;% group_by(grp) %&gt;% summarise(rng = mean(x)) ## # A tibble: 2 x 2 ## grp rng ## &lt;chr&gt; &lt;dbl&gt; ## 1 a -0.124 ## 2 b -0.117 当统计函数返回多个值的时候，比如range()返回是最小值和最大值，summarise()很贴心地将结果整理成多行，这样符合tidy的格式。 df %&gt;% group_by(grp) %&gt;% summarise(rng = range(x)) ## # A tibble: 4 x 2 ## # Groups: grp [2] ## grp rng ## &lt;chr&gt; &lt;dbl&gt; ## 1 a -1.38 ## 2 a 0.903 ## 3 b -2.47 ## 4 b 1.55 类似的还有quantile()函数，也是返回多个值 df %&gt;% group_by(grp) %&gt;% summarise( rng = quantile(x, probs = c(0.05, 0.5, 0.95)) ) ## # A tibble: 6 x 2 ## # Groups: grp [2] ## grp rng ## &lt;chr&gt; &lt;dbl&gt; ## 1 a -1.23 ## 2 a -0.270 ## 3 a 0.881 ## 4 b -2.05 ## 5 b -0.374 ## 6 b 1.46 df %&gt;% group_by(grp) %&gt;% summarise( x = quantile(x, c(0.25, 0.5, 0.75)), q = c(0.25, 0.5, 0.75) ) ## # A tibble: 6 x 3 ## # Groups: grp [2] ## grp x q ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a -0.665 0.25 ## 2 a -0.270 0.5 ## 3 a 0.791 0.75 ## 4 b -0.400 0.25 ## 5 b -0.374 0.5 ## 6 b 1.10 0.75 summarise()可以输出数据框，比如 my_quantile &lt;- function(x, probs) { tibble(x = quantile(x, probs), probs = probs) } mtcars %&gt;% group_by(cyl) %&gt;% summarise(my_quantile(disp, c(0.25, 0.75))) ## # A tibble: 6 x 3 ## # Groups: cyl [3] ## cyl x probs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 78.8 0.25 ## 2 4 121. 0.75 ## 3 6 160 0.25 ## 4 6 196. 0.75 ## 5 8 302. 0.25 ## 6 8 390 0.75 再比如： dplyr 1.0 之前是需要group_modify()来实现数据框进，数据框出 mtcars %&gt;% group_by(cyl) %&gt;% group_modify( ~ broom::tidy(lm(mpg ~ wt, data = .)) ) ## # A tibble: 6 x 6 ## # Groups: cyl [3] ## cyl term estimate std.error statistic p.value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 (Interce~ 39.6 4.35 9.10 7.77e-6 ## 2 4 wt -5.65 1.85 -3.05 1.37e-2 ## 3 6 (Interce~ 28.4 4.18 6.79 1.05e-3 ## 4 6 wt -2.78 1.33 -2.08 9.18e-2 ## 5 8 (Interce~ 23.9 3.01 7.94 4.05e-6 ## 6 8 wt -2.19 0.739 -2.97 1.18e-2 dplyr 1.0 之后，有了新的方案 mtcars %&gt;% group_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt)) ) ## # A tibble: 6 x 6 ## # Groups: cyl [3] ## cyl term estimate std.error statistic p.value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 (Interce~ 39.6 4.35 9.10 7.77e-6 ## 2 4 wt -5.65 1.85 -3.05 1.37e-2 ## 3 6 (Interce~ 28.4 4.18 6.79 1.05e-3 ## 4 6 wt -2.78 1.33 -2.08 9.18e-2 ## 5 8 (Interce~ 23.9 3.01 7.94 4.05e-6 ## 6 8 wt -2.19 0.739 -2.97 1.18e-2 22.4 summarise()后的分组信息是去是留？ 当 group_by()与summarise()配合使用的时候，summarise()默认会抵消掉最近一次的分组信息，比如下面按照cyl和vs分组，但summarise()后，就只剩下cyl的分组信息了。 mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n()) ## # A tibble: 5 x 3 ## # Groups: cyl [3] ## cyl vs cyl_n ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 4 0 1 ## 2 4 1 10 ## 3 6 0 3 ## 4 6 1 4 ## 5 8 0 14 mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n()) %&gt;% group_vars() ## [1] &quot;cyl&quot; 如果想保留vs的分组信息，就需要设置.groups = keep参数 mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n(), .groups = &quot;keep&quot;) %&gt;% group_vars() ## [1] &quot;cyl&quot; &quot;vs&quot; 当然summarise()可以控制输出的更多形式 丢弃所有的分组信息 mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n(), .groups = &quot;drop&quot;) %&gt;% group_vars() ## character(0) 变成行方向分组，即，每行是一个分组 mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(cyl_n = n(), .groups = &quot;rowwise&quot;) %&gt;% group_vars() ## [1] &quot;cyl&quot; &quot;vs&quot; 22.5 选择某列 通过位置索引进行选取 df %&gt;% select(1, 3) ## # A tibble: 10 x 2 ## grp y ## &lt;chr&gt; &lt;dbl&gt; ## 1 a -0.387 ## 2 a -0.839 ## 3 a 0.0371 ## 4 a -0.144 ## 5 a 0.148 ## 6 b 0.143 ## 7 b 0.0986 ## 8 b -1.11 ## 9 b -0.670 ## 10 b -0.440 df %&gt;% select(2:3) ## # A tibble: 10 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.665 -0.387 ## 2 -0.270 -0.839 ## 3 0.791 0.0371 ## 4 -1.38 -0.144 ## 5 0.903 0.148 ## 6 1.55 0.143 ## 7 1.10 0.0986 ## 8 -0.400 -1.11 ## 9 -2.47 -0.670 ## 10 -0.374 -0.440 通过列名 df %&gt;% select(grp, x, y) ## # A tibble: 10 x 3 ## grp x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a -0.665 -0.387 ## 2 a -0.270 -0.839 ## 3 a 0.791 0.0371 ## 4 a -1.38 -0.144 ## 5 a 0.903 0.148 ## 6 b 1.55 0.143 ## 7 b 1.10 0.0986 ## 8 b -0.400 -1.11 ## 9 b -2.47 -0.670 ## 10 b -0.374 -0.440 df %&gt;% select(x:y) ## # A tibble: 10 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.665 -0.387 ## 2 -0.270 -0.839 ## 3 0.791 0.0371 ## 4 -1.38 -0.144 ## 5 0.903 0.148 ## 6 1.55 0.143 ## 7 1.10 0.0986 ## 8 -0.400 -1.11 ## 9 -2.47 -0.670 ## 10 -0.374 -0.440 通过函数选取 df %&gt;% select(starts_with(&quot;x&quot;)) ## # A tibble: 10 x 1 ## x ## &lt;dbl&gt; ## 1 -0.665 ## 2 -0.270 ## 3 0.791 ## 4 -1.38 ## 5 0.903 ## 6 1.55 ## 7 1.10 ## 8 -0.400 ## 9 -2.47 ## 10 -0.374 df %&gt;% select(ends_with(&quot;p&quot;)) ## # A tibble: 10 x 1 ## grp ## &lt;chr&gt; ## 1 a ## 2 a ## 3 a ## 4 a ## 5 a ## 6 b ## 7 b ## 8 b ## 9 b ## 10 b df %&gt;% select(contains(&quot;x&quot;)) ## # A tibble: 10 x 1 ## x ## &lt;dbl&gt; ## 1 -0.665 ## 2 -0.270 ## 3 0.791 ## 4 -1.38 ## 5 0.903 ## 6 1.55 ## 7 1.10 ## 8 -0.400 ## 9 -2.47 ## 10 -0.374 df %&gt;% select(matches(&quot;x&quot;)) ## # A tibble: 10 x 1 ## x ## &lt;dbl&gt; ## 1 -0.665 ## 2 -0.270 ## 3 0.791 ## 4 -1.38 ## 5 0.903 ## 6 1.55 ## 7 1.10 ## 8 -0.400 ## 9 -2.47 ## 10 -0.374 通过类型 df %&gt;% select(where(is.character)) ## # A tibble: 10 x 1 ## grp ## &lt;chr&gt; ## 1 a ## 2 a ## 3 a ## 4 a ## 5 a ## 6 b ## 7 b ## 8 b ## 9 b ## 10 b df %&gt;% select(where(is.numeric)) ## # A tibble: 10 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.665 -0.387 ## 2 -0.270 -0.839 ## 3 0.791 0.0371 ## 4 -1.38 -0.144 ## 5 0.903 0.148 ## 6 1.55 0.143 ## 7 1.10 0.0986 ## 8 -0.400 -1.11 ## 9 -2.47 -0.670 ## 10 -0.374 -0.440 通过各种组合 df %&gt;% select(!where(is.character)) ## # A tibble: 10 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.665 -0.387 ## 2 -0.270 -0.839 ## 3 0.791 0.0371 ## 4 -1.38 -0.144 ## 5 0.903 0.148 ## 6 1.55 0.143 ## 7 1.10 0.0986 ## 8 -0.400 -1.11 ## 9 -2.47 -0.670 ## 10 -0.374 -0.440 df %&gt;% select(where(is.numeric) &amp; starts_with(&quot;x&quot;)) ## # A tibble: 10 x 1 ## x ## &lt;dbl&gt; ## 1 -0.665 ## 2 -0.270 ## 3 0.791 ## 4 -1.38 ## 5 0.903 ## 6 1.55 ## 7 1.10 ## 8 -0.400 ## 9 -2.47 ## 10 -0.374 df %&gt;% select(starts_with(&quot;g&quot;) | ends_with(&quot;y&quot;)) ## # A tibble: 10 x 2 ## grp y ## &lt;chr&gt; &lt;dbl&gt; ## 1 a -0.387 ## 2 a -0.839 ## 3 a 0.0371 ## 4 a -0.144 ## 5 a 0.148 ## 6 b 0.143 ## 7 b 0.0986 ## 8 b -1.11 ## 9 b -0.670 ## 10 b -0.440 # 注意any_of和all_of的区别 vars &lt;- c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;) df %&gt;% select(all_of(vars)) df %&gt;% select(any_of(vars)) 22.6 重命名某列 df %&gt;% rename(group = grp) ## # A tibble: 10 x 3 ## group x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a -0.665 -0.387 ## 2 a -0.270 -0.839 ## 3 a 0.791 0.0371 ## 4 a -1.38 -0.144 ## 5 a 0.903 0.148 ## 6 b 1.55 0.143 ## 7 b 1.10 0.0986 ## 8 b -0.400 -1.11 ## 9 b -2.47 -0.670 ## 10 b -0.374 -0.440 df %&gt;% rename_with(toupper) ## # A tibble: 10 x 3 ## GRP X Y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a -0.665 -0.387 ## 2 a -0.270 -0.839 ## 3 a 0.791 0.0371 ## 4 a -1.38 -0.144 ## 5 a 0.903 0.148 ## 6 b 1.55 0.143 ## 7 b 1.10 0.0986 ## 8 b -0.400 -1.11 ## 9 b -2.47 -0.670 ## 10 b -0.374 -0.440 df %&gt;% rename_with(toupper, is.numeric) ## # A tibble: 10 x 3 ## grp X Y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a -0.665 -0.387 ## 2 a -0.270 -0.839 ## 3 a 0.791 0.0371 ## 4 a -1.38 -0.144 ## 5 a 0.903 0.148 ## 6 b 1.55 0.143 ## 7 b 1.10 0.0986 ## 8 b -0.400 -1.11 ## 9 b -2.47 -0.670 ## 10 b -0.374 -0.440 df %&gt;% rename_with(toupper, starts_with(&quot;x&quot;)) ## # A tibble: 10 x 3 ## grp X y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a -0.665 -0.387 ## 2 a -0.270 -0.839 ## 3 a 0.791 0.0371 ## 4 a -1.38 -0.144 ## 5 a 0.903 0.148 ## 6 b 1.55 0.143 ## 7 b 1.10 0.0986 ## 8 b -0.400 -1.11 ## 9 b -2.47 -0.670 ## 10 b -0.374 -0.440 22.7 调整列的位置 我们前面一章讲过arrange()排序，这是行方向的排序， 比如按照x变量绝对值的大小从高到低排序。 df %&gt;% arrange(desc(abs(x))) ## # A tibble: 10 x 3 ## grp x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b -2.47 -0.670 ## 2 b 1.55 0.143 ## 3 a -1.38 -0.144 ## 4 b 1.10 0.0986 ## 5 a 0.903 0.148 ## 6 a 0.791 0.0371 ## 7 a -0.665 -0.387 ## 8 b -0.400 -1.11 ## 9 b -0.374 -0.440 ## 10 a -0.270 -0.839 我们现在想调整列的位置，比如，这里调整数据框三列的位置，让grp列放在x列的后面 df %&gt;% select(x, grp, y) ## # A tibble: 10 x 3 ## x grp y ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 -0.665 a -0.387 ## 2 -0.270 a -0.839 ## 3 0.791 a 0.0371 ## 4 -1.38 a -0.144 ## 5 0.903 a 0.148 ## 6 1.55 b 0.143 ## 7 1.10 b 0.0986 ## 8 -0.400 b -1.11 ## 9 -2.47 b -0.670 ## 10 -0.374 b -0.440 如果列变量很多的时候，上面的方法就不太好用，因此推荐大家使用relocate() df %&gt;% relocate(grp, .after = y) ## # A tibble: 10 x 3 ## x y grp ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 -0.665 -0.387 a ## 2 -0.270 -0.839 a ## 3 0.791 0.0371 a ## 4 -1.38 -0.144 a ## 5 0.903 0.148 a ## 6 1.55 0.143 b ## 7 1.10 0.0986 b ## 8 -0.400 -1.11 b ## 9 -2.47 -0.670 b ## 10 -0.374 -0.440 b df %&gt;% relocate(x, .before = grp) ## # A tibble: 10 x 3 ## x grp y ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 -0.665 a -0.387 ## 2 -0.270 a -0.839 ## 3 0.791 a 0.0371 ## 4 -1.38 a -0.144 ## 5 0.903 a 0.148 ## 6 1.55 b 0.143 ## 7 1.10 b 0.0986 ## 8 -0.400 b -1.11 ## 9 -2.47 b -0.670 ## 10 -0.374 b -0.440 还有 df %&gt;% relocate(grp, .after = last_col()) ## # A tibble: 10 x 3 ## x y grp ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 -0.665 -0.387 a ## 2 -0.270 -0.839 a ## 3 0.791 0.0371 a ## 4 -1.38 -0.144 a ## 5 0.903 0.148 a ## 6 1.55 0.143 b ## 7 1.10 0.0986 b ## 8 -0.400 -1.11 b ## 9 -2.47 -0.670 b ## 10 -0.374 -0.440 b 22.8 强大的across函数 我们必须为这个函数点赞。大爱Hadley Wickham !!! 我们经常需要对数据框的多列执行相同的操作。比如 iris &lt;- iris %&gt;% as_tibble() iris ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # ... with 140 more rows, and 1 more variable: ## # Species &lt;fct&gt; iris %&gt;% group_by(Species) %&gt;% summarise( mean_Sepal_Length = mean(Sepal.Length), mean_Sepal_Width = mean(Sepal.Width), mean_Petal_Length = mean(Petal.Length), mean_Petal_Width = mean(Petal.Width) ) ## # A tibble: 3 x 5 ## Species mean_Sepal_Leng~ mean_Sepal_Width ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 5.01 3.43 ## 2 versic~ 5.94 2.77 ## 3 virgin~ 6.59 2.97 ## # ... with 2 more variables: mean_Petal_Length &lt;dbl&gt;, ## # mean_Petal_Width &lt;dbl&gt; dplyr 1.0之后，使用across()函数异常简练 iris %&gt;% group_by(Species) %&gt;% summarise( across(everything(), mean) ) ## # A tibble: 3 x 5 ## Species Sepal.Length Sepal.Width Petal.Length ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 5.01 3.43 1.46 ## 2 versic~ 5.94 2.77 4.26 ## 3 virgin~ 6.59 2.97 5.55 ## # ... with 1 more variable: Petal.Width &lt;dbl&gt; 或者更科学的 iris %&gt;% group_by(Species) %&gt;% summarise( across(is.numeric, mean) ) ## # A tibble: 3 x 5 ## Species Sepal.Length Sepal.Width Petal.Length ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 5.01 3.43 1.46 ## 2 versic~ 5.94 2.77 4.26 ## 3 virgin~ 6.59 2.97 5.55 ## # ... with 1 more variable: Petal.Width &lt;dbl&gt; 可以看到，以往是一列一列的处理，现在对多列同时操作，这主要得益于across()函数，它有两个主要的参数： across(.cols = , .fns = ) 第一个参数.cols，选取我们要需要的若干列，选取多列的语法与select()的语法一致 第二个参数.fns，我们要执行的函数（或者多个函数），函数的语法有三种形式可选： A function, e.g. mean. A purrr-style lambda, e.g. ~ mean(.x, na.rm = TRUE) A list of functions/lambdas, e.g. list(mean = mean, n_miss = ~ sum(is.na(.x)) 再看看这个案例 std &lt;- function(x) { (x - mean(x)) / sd(x) } iris %&gt;% group_by(Species) %&gt;% summarise( across(starts_with(&quot;Sepal&quot;), std) ) ## # A tibble: 150 x 3 ## # Groups: Species [3] ## Species Sepal.Length Sepal.Width ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 0.267 0.190 ## 2 setosa -0.301 -1.13 ## 3 setosa -0.868 -0.601 ## 4 setosa -1.15 -0.865 ## 5 setosa -0.0170 0.454 ## 6 setosa 1.12 1.25 ## 7 setosa -1.15 -0.0739 ## 8 setosa -0.0170 -0.0739 ## 9 setosa -1.72 -1.39 ## 10 setosa -0.301 -0.865 ## # ... with 140 more rows # purrr style iris %&gt;% group_by(Species) %&gt;% summarise( across(starts_with(&quot;Sepal&quot;), ~ (.x - mean(.x)) / sd(.x)) ) ## # A tibble: 150 x 3 ## # Groups: Species [3] ## Species Sepal.Length Sepal.Width ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 0.267 0.190 ## 2 setosa -0.301 -1.13 ## 3 setosa -0.868 -0.601 ## 4 setosa -1.15 -0.865 ## 5 setosa -0.0170 0.454 ## 6 setosa 1.12 1.25 ## 7 setosa -1.15 -0.0739 ## 8 setosa -0.0170 -0.0739 ## 9 setosa -1.72 -1.39 ## 10 setosa -0.301 -0.865 ## # ... with 140 more rows iris %&gt;% group_by(Species) %&gt;% summarise( across(starts_with(&quot;Petal&quot;), list(min = min, max = max)) # across(starts_with(&quot;Petal&quot;), list(min = min, max = max), .names = &quot;{fn}_{col}&quot;) ) ## # A tibble: 3 x 5 ## Species Petal.Length_min Petal.Length_max ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 1 1.9 ## 2 versic~ 3 5.1 ## 3 virgin~ 4.5 6.9 ## # ... with 2 more variables: Petal.Width_min &lt;dbl&gt;, ## # Petal.Width_max &lt;dbl&gt; iris %&gt;% group_by(Species) %&gt;% summarise( across(starts_with(&quot;Sepal&quot;), mean), Area = mean(Petal.Length * Petal.Width), across(c(Petal.Width), min), n = n() ) ## # A tibble: 3 x 6 ## Species Sepal.Length Sepal.Width Area Petal.Width ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 5.01 3.43 0.366 0.1 ## 2 versic~ 5.94 2.77 5.72 1 ## 3 virgin~ 6.59 2.97 11.3 1.4 ## # ... with 1 more variable: n &lt;int&gt; 除了在summarise()里可以使用外，在其它函数也是可以使用的 iris %&gt;% mutate(across(is.numeric, mean)) ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.84 3.06 3.76 1.20 ## 2 5.84 3.06 3.76 1.20 ## 3 5.84 3.06 3.76 1.20 ## 4 5.84 3.06 3.76 1.20 ## 5 5.84 3.06 3.76 1.20 ## 6 5.84 3.06 3.76 1.20 ## 7 5.84 3.06 3.76 1.20 ## 8 5.84 3.06 3.76 1.20 ## 9 5.84 3.06 3.76 1.20 ## 10 5.84 3.06 3.76 1.20 ## # ... with 140 more rows, and 1 more variable: ## # Species &lt;fct&gt; iris %&gt;% mutate(across(starts_with(&quot;Sepal&quot;), mean)) ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.84 3.06 1.4 0.2 ## 2 5.84 3.06 1.4 0.2 ## 3 5.84 3.06 1.3 0.2 ## 4 5.84 3.06 1.5 0.2 ## 5 5.84 3.06 1.4 0.2 ## 6 5.84 3.06 1.7 0.4 ## 7 5.84 3.06 1.4 0.3 ## 8 5.84 3.06 1.5 0.2 ## 9 5.84 3.06 1.4 0.2 ## 10 5.84 3.06 1.5 0.1 ## # ... with 140 more rows, and 1 more variable: ## # Species &lt;fct&gt; iris %&gt;% mutate(across(is.numeric, std)) # std function has defined before ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.898 1.02 -1.34 -1.31 ## 2 -1.14 -0.132 -1.34 -1.31 ## 3 -1.38 0.327 -1.39 -1.31 ## 4 -1.50 0.0979 -1.28 -1.31 ## 5 -1.02 1.25 -1.34 -1.31 ## 6 -0.535 1.93 -1.17 -1.05 ## 7 -1.50 0.786 -1.34 -1.18 ## 8 -1.02 0.786 -1.28 -1.31 ## 9 -1.74 -0.361 -1.34 -1.31 ## 10 -1.14 0.0979 -1.28 -1.44 ## # ... with 140 more rows, and 1 more variable: ## # Species &lt;fct&gt; iris %&gt;% mutate( across(is.numeric, ~ .x / 2), across(is.factor, stringr::str_to_upper) ) ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2.55 1.75 0.7 0.1 ## 2 2.45 1.5 0.7 0.1 ## 3 2.35 1.6 0.65 0.1 ## 4 2.3 1.55 0.75 0.1 ## 5 2.5 1.8 0.7 0.1 ## 6 2.7 1.95 0.85 0.2 ## 7 2.3 1.7 0.7 0.15 ## 8 2.5 1.7 0.75 0.1 ## 9 2.2 1.45 0.7 0.1 ## 10 2.45 1.55 0.75 0.05 ## # ... with 140 more rows, and 1 more variable: ## # Species &lt;chr&gt; 22.9 “current” group or “current” variable n(), 返回当前分组的多少行 cur_data(), 返回当前分组的数据内容（不包含分组变量） cur_group(), 返回当前分组的分组变量（一行一列的数据框） across(cur_column()), 返回当前列的列名 这些函数返回当前分组的信息，因此只能在特定函数内部使用，比如summarise() and mutate() df &lt;- tibble( g = sample(rep(letters[1:3], 1:3)), x = runif(6), y = runif(6) ) df ## # A tibble: 6 x 3 ## g x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b 0.603 0.415 ## 2 b 0.443 0.936 ## 3 c 0.0727 0.301 ## 4 c 0.749 0.888 ## 5 c 0.591 0.273 ## 6 a 0.278 0.259 df %&gt;% group_by(g) %&gt;% summarise( n = n() ) ## # A tibble: 3 x 2 ## g n ## &lt;chr&gt; &lt;int&gt; ## 1 a 1 ## 2 b 2 ## 3 c 3 df %&gt;% group_by(g) %&gt;% summarise( data = list(cur_group()) ) ## # A tibble: 3 x 2 ## g data ## &lt;chr&gt; &lt;list&gt; ## 1 a &lt;tibble [1 x 1]&gt; ## 2 b &lt;tibble [1 x 1]&gt; ## 3 c &lt;tibble [1 x 1]&gt; df %&gt;% group_by(g) %&gt;% summarise( data = list(cur_data()) ) ## # A tibble: 3 x 2 ## g data ## &lt;chr&gt; &lt;list&gt; ## 1 a &lt;tibble [1 x 2]&gt; ## 2 b &lt;tibble [2 x 2]&gt; ## 3 c &lt;tibble [3 x 2]&gt; mtcars %&gt;% group_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt, data = cur_data())) ) ## # A tibble: 6 x 6 ## # Groups: cyl [3] ## cyl term estimate std.error statistic p.value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 (Interce~ 39.6 4.35 9.10 7.77e-6 ## 2 4 wt -5.65 1.85 -3.05 1.37e-2 ## 3 6 (Interce~ 28.4 4.18 6.79 1.05e-3 ## 4 6 wt -2.78 1.33 -2.08 9.18e-2 ## 5 8 (Interce~ 23.9 3.01 7.94 4.05e-6 ## 6 8 wt -2.19 0.739 -2.97 1.18e-2 df %&gt;% group_by(g) %&gt;% mutate(across(everything(), ~ paste(cur_column(), round(.x, 2)))) ## # A tibble: 6 x 3 ## # Groups: g [3] ## g x y ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 b x 0.6 y 0.42 ## 2 b x 0.44 y 0.94 ## 3 c x 0.07 y 0.3 ## 4 c x 0.75 y 0.89 ## 5 c x 0.59 y 0.27 ## 6 a x 0.28 y 0.26 wt &lt;- c(x = 0.2, y = 0.8) df %&gt;% mutate( across(c(x, y), ~ .x * wt[cur_column()]) ) ## # A tibble: 6 x 3 ## g x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b 0.121 0.332 ## 2 b 0.0885 0.749 ## 3 c 0.0145 0.241 ## 4 c 0.150 0.711 ## 5 c 0.118 0.219 ## 6 a 0.0555 0.207 22.10 行方向操作 数据框中向量de方向，事实上可以看做有两个方向，横着看是row-vector，竖着看是col-vector。 tidyverse遵循的tidy原则，一列表示一个变量，一行表示一次观察。 这种数据的存储格式，对ggplot2很方便，但对行方向的操作或者运算不同友好。比如 22.10.1 行方向上的统计 df &lt;- tibble(id = letters[1:6], w = 10:15, x = 20:25, y = 30:35, z = 40:45) df ## # A tibble: 6 x 5 ## id w x y z ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 a 10 20 30 40 ## 2 b 11 21 31 41 ## 3 c 12 22 32 42 ## 4 d 13 23 33 43 ## 5 e 14 24 34 44 ## 6 f 15 25 35 45 计算每行的均值， df %&gt;% mutate(avg = mean(c(w, x, y, z))) ## # A tibble: 6 x 6 ## id w x y z avg ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 10 20 30 40 27.5 ## 2 b 11 21 31 41 27.5 ## 3 c 12 22 32 42 27.5 ## 4 d 13 23 33 43 27.5 ## 5 e 14 24 34 44 27.5 ## 6 f 15 25 35 45 27.5 好像不对？为什么呢？ 按照tidy的方法 df %&gt;% pivot_longer( cols = -id, names_to = &quot;variable&quot;, values_to = &quot;value&quot; ) %&gt;% group_by(id) %&gt;% summarize( r_mean = mean(value) ) ## # A tibble: 6 x 2 ## id r_mean ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 25 ## 2 b 26 ## 3 c 27 ## 4 d 28 ## 5 e 29 ## 6 f 30 如果保留原始数据，就还需要再left_join()一次，虽然思路清晰，但还是挺周转的。 按照Jenny Bryan的方案，使用purrr宏包的pmap_dbl函数 library(purrr) df %&gt;% mutate(r_mean = pmap_dbl(select_if(., is.numeric), lift_vd(mean))) ## # A tibble: 6 x 6 ## id w x y z r_mean ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 10 20 30 40 25 ## 2 b 11 21 31 41 26 ## 3 c 12 22 32 42 27 ## 4 d 13 23 33 43 28 ## 5 e 14 24 34 44 29 ## 6 f 15 25 35 45 30 但需要学习新的语法，代价也很高。 rowwise() df %&gt;% rowwise() %&gt;% mutate(avg = mean(c(w, x, y, z))) ## # A tibble: 6 x 6 ## # Rowwise: ## id w x y z avg ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 10 20 30 40 25 ## 2 b 11 21 31 41 26 ## 3 c 12 22 32 42 27 ## 4 d 13 23 33 43 28 ## 5 e 14 24 34 44 29 ## 6 f 15 25 35 45 30 变量名要是很多的话，又变了体力活了，怎么才能变的轻巧一点呢？ rowwise() + c_across()，现在dplyr 1.0终于给出了一个很好的解决方案 df %&gt;% rowwise() %&gt;% mutate( avg = mean(c_across(w:z)) ) ## # A tibble: 6 x 6 ## # Rowwise: ## id w x y z avg ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 10 20 30 40 25 ## 2 b 11 21 31 41 26 ## 3 c 12 22 32 42 27 ## 4 d 13 23 33 43 28 ## 5 e 14 24 34 44 29 ## 6 f 15 25 35 45 30 这个很好的解决方案中，rowwise()工作原理类似与group_by()，是按每一行进行分组，然后按行（行方向）统计 df %&gt;% rowwise(id) %&gt;% mutate(total = mean(c_across(w:z))) ## # A tibble: 6 x 6 ## # Rowwise: id ## id w x y z total ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 10 20 30 40 25 ## 2 b 11 21 31 41 26 ## 3 c 12 22 32 42 27 ## 4 d 13 23 33 43 28 ## 5 e 14 24 34 44 29 ## 6 f 15 25 35 45 30 df %&gt;% rowwise(id) %&gt;% mutate(mean = mean(c_across(is.numeric))) ## # A tibble: 6 x 6 ## # Rowwise: id ## id w x y z mean ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 10 20 30 40 25 ## 2 b 11 21 31 41 26 ## 3 c 12 22 32 42 27 ## 4 d 13 23 33 43 28 ## 5 e 14 24 34 44 29 ## 6 f 15 25 35 45 30 df %&gt;% rowwise(id) %&gt;% summarise( m = mean(c_across(is.numeric)) ) ## # A tibble: 6 x 2 ## # Groups: id [6] ## id m ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 25 ## 2 b 26 ## 3 c 27 ## 4 d 28 ## 5 e 29 ## 6 f 30 因此，我们可以总结成下面这张图 22.10.2 行方向处理与列表列是天然一对 rowwise()不仅仅用于计算行方向均值这样的简单统计，而是当处理列表列时，方才显示出rowwise()与purrr::map一样的强大。那么，什么是列表列？ 列表列指的是数据框的一列是一个列表， 比如 tb &lt;- tibble( x = list(1, 2:3, 4:6) ) 如果想显示列表中每个元素的长度，用purrr包，可以这样写 tb %&gt;% mutate(l = purrr::map_int(x, length)) ## # A tibble: 3 x 2 ## x l ## &lt;list&gt; &lt;int&gt; ## 1 &lt;dbl [1]&gt; 1 ## 2 &lt;int [2]&gt; 2 ## 3 &lt;int [3]&gt; 3 如果从行方向的角度理解，其实很简练 tb %&gt;% rowwise() %&gt;% mutate(l = length(x)) ## # A tibble: 3 x 2 ## # Rowwise: ## x l ## &lt;list&gt; &lt;int&gt; ## 1 &lt;dbl [1]&gt; 1 ## 2 &lt;int [2]&gt; 2 ## 3 &lt;int [3]&gt; 3 22.10.3 行方向上的建模 mtcars &lt;- mtcars %&gt;% as_tibble() mtcars ## # A tibble: 32 x 11 ## mpg cyl disp hp drat wt qsec vs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 ## 2 21 6 160 110 3.9 2.88 17.0 0 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 ## 8 24.4 4 147. 62 3.69 3.19 20 1 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 ## # ... with 22 more rows, and 3 more variables: ## # am &lt;dbl&gt;, gear &lt;dbl&gt;, carb &lt;dbl&gt; 以cyl分组，计算每组中mpg ~ wt的线性模型的系数. mtcars %&gt;% group_by(cyl) %&gt;% nest() ## # A tibble: 3 x 2 ## # Groups: cyl [3] ## cyl data ## &lt;dbl&gt; &lt;list&gt; ## 1 6 &lt;tibble [7 x 10]&gt; ## 2 4 &lt;tibble [11 x 10]&gt; ## 3 8 &lt;tibble [14 x 10]&gt; 22.10.3.1 列方向的做法 分组建模后，形成列表列，此时列表中的每个元素对应一个模型，我们需要依次提取每次模型的系数，列方向的做法是，借用purrr::map完成列表中每个模型的迭代， mtcars %&gt;% group_by(cyl) %&gt;% nest() %&gt;% mutate(model = purrr::map(data, ~ lm(mpg ~ wt, data = .))) %&gt;% mutate(result = purrr::map(model, ~ broom::tidy(.))) %&gt;% unnest(result) ## # A tibble: 6 x 8 ## # Groups: cyl [3] ## cyl data model term estimate std.error statistic ## &lt;dbl&gt; &lt;lis&gt; &lt;lis&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6 &lt;tib~ &lt;lm&gt; (Int~ 28.4 4.18 6.79 ## 2 6 &lt;tib~ &lt;lm&gt; wt -2.78 1.33 -2.08 ## 3 4 &lt;tib~ &lt;lm&gt; (Int~ 39.6 4.35 9.10 ## 4 4 &lt;tib~ &lt;lm&gt; wt -5.65 1.85 -3.05 ## 5 8 &lt;tib~ &lt;lm&gt; (Int~ 23.9 3.01 7.94 ## 6 8 &lt;tib~ &lt;lm&gt; wt -2.19 0.739 -2.97 ## # ... with 1 more variable: p.value &lt;dbl&gt; 用purrr::map实现列表元素一个一个的依次迭代，从数据框的角度来看（数据框是列表的一种特殊形式），因此实质上就是一行一行的处理。所以，尽管purrr很强大，但需要一定学习成本，从解决问题的路径上也比较周折。 22.10.3.2 行方向的做法 事实上，分组建模后，形成列表列，这种存储格式，天然地符合行处理的范式，因此一开始就使用行方向分组（这里nest_by() 类似于 group_by()） mtcars %&gt;% nest_by(cyl) %&gt;% mutate(model = list(lm(mpg ~ wt, data = data))) %&gt;% summarise(broom::tidy(model)) ## # A tibble: 6 x 6 ## # Groups: cyl [3] ## cyl term estimate std.error statistic p.value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 (Interce~ 39.6 4.35 9.10 7.77e-6 ## 2 4 wt -5.65 1.85 -3.05 1.37e-2 ## 3 6 (Interce~ 28.4 4.18 6.79 1.05e-3 ## 4 6 wt -2.78 1.33 -2.08 9.18e-2 ## 5 8 (Interce~ 23.9 3.01 7.94 4.05e-6 ## 6 8 wt -2.19 0.739 -2.97 1.18e-2 # or mtcars %&gt;% nest_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt, data = data)) ) ## # A tibble: 6 x 6 ## # Groups: cyl [3] ## cyl term estimate std.error statistic p.value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 (Interce~ 39.6 4.35 9.10 7.77e-6 ## 2 4 wt -5.65 1.85 -3.05 1.37e-2 ## 3 6 (Interce~ 28.4 4.18 6.79 1.05e-3 ## 4 6 wt -2.78 1.33 -2.08 9.18e-2 ## 5 8 (Interce~ 23.9 3.01 7.94 4.05e-6 ## 6 8 wt -2.19 0.739 -2.97 1.18e-2 至此，tidyverse框架下，实现分组统计中的数据框进，数据框输出， 现在有四种方法了 mtcars %&gt;% group_nest(cyl) %&gt;% mutate(model = purrr::map(data, ~ lm(mpg ~ wt, data = .))) %&gt;% mutate(result = purrr::map(model, ~ broom::tidy(.))) %&gt;% tidyr::unnest(result) mtcars %&gt;% group_by(cyl) %&gt;% group_modify( ~ broom::tidy(lm(mpg ~ wt, data = .)) ) mtcars %&gt;% nest_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt, data = data)) ) mtcars %&gt;% group_by(cyl) %&gt;% summarise( broom::tidy(lm(mpg ~ wt, data = cur_data())) ) # or mtcars %&gt;% group_by(cyl) %&gt;% summarise(broom::tidy(lm(mpg ~ wt))) 22.11 参考资料 https://dplyr.tidyverse.org/dev/articles/rowwise.html https://dplyr.tidyverse.org/dev/articles/colwise.html "],["beauty-of-across.html", "第 23 章 tidyverse中的across()之美 23.1 across()横空出世 23.2 across()函数形式 23.3 across()应用举例 23.4 across()总结", " 第 23 章 tidyverse中的across()之美 dplyr 1.0版本增加了across()函数，这个函数集中体现了dplyr宏包的强大和简约，今天我用企鹅数据，来领略它的美。 library(tidyverse) library(palmerpenguins) penguins ## # A tibble: 344 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ NA NA ## 5 Adelie Torge~ 36.7 19.3 ## 6 Adelie Torge~ 39.3 20.6 ## 7 Adelie Torge~ 38.9 17.8 ## 8 Adelie Torge~ 39.2 19.6 ## 9 Adelie Torge~ 34.1 18.1 ## 10 Adelie Torge~ 42 20.2 ## # ... with 334 more rows, and 4 more variables: ## # flipper_length_mm &lt;int&gt;, body_mass_g &lt;int&gt;, ## # sex &lt;fct&gt;, year &lt;int&gt; 看到数据框里有很多缺失值，需要统计每一列缺失值的数量，按照常规的写法 penguins %&gt;% summarise( na_in_species = sum(is.na(species)), na_in_island = sum(is.na(island)), na_in_length = sum(is.na(bill_length_mm)), na_in_depth = sum(is.na(bill_depth_mm)), na_in_flipper = sum(is.na(flipper_length_mm)), na_in_body = sum(is.na(body_mass_g)), na_in_sex = sum(is.na(sex)), na_in_year = sum(is.na(year)) ) ## # A tibble: 1 x 8 ## na_in_species na_in_island na_in_length na_in_depth ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 2 2 ## # ... with 4 more variables: na_in_flipper &lt;int&gt;, ## # na_in_body &lt;int&gt;, na_in_sex &lt;int&gt;, ## # na_in_year &lt;int&gt; 幸亏数据框的列数不够多，只有8列，如果数据框有几百列，那就成体力活了，同时代码复制粘贴也容易出错。想偷懒，我们自然想到用summarise_all()， penguins %&gt;% summarise_all( ~ sum(is.na(.)) ) ## # A tibble: 1 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 2 2 ## # ... with 4 more variables: flipper_length_mm &lt;int&gt;, ## # body_mass_g &lt;int&gt;, sex &lt;int&gt;, year &lt;int&gt; 挺好。接着探索，我们想先按企鹅类型分组，然后统计出各体征数据的均值，这个好说，直接写代码 penguins %&gt;% group_by(species) %&gt;% summarise( mean_length = mean(bill_length_mm, na.rm = TRUE), mean_depth = mean(bill_depth_mm, na.rm = TRUE), mean_flipper = mean(flipper_length_mm, na.rm = TRUE), mean_body = mean(body_mass_g, na.rm = TRUE) ) ## # A tibble: 3 x 5 ## species mean_length mean_depth mean_flipper mean_body ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 38.8 18.3 190. 3701. ## 2 Chinst~ 48.8 18.4 196. 3733. ## 3 Gentoo 47.5 15.0 217. 5076. 或者用summarise_if()偷懒 d1 &lt;- penguins %&gt;% group_by(species) %&gt;% summarise_if(is.numeric, mean, na.rm = TRUE) d1 ## # A tibble: 3 x 6 ## species bill_length_mm bill_depth_mm flipper_length_~ ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 38.8 18.3 190. ## 2 Chinst~ 48.8 18.4 196. ## 3 Gentoo 47.5 15.0 217. ## # ... with 2 more variables: body_mass_g &lt;dbl&gt;, ## # year &lt;dbl&gt; 方法不错，从语义上还算很好理解。 但多了一列year, 我想在summarise_if()中用 is.numeric &amp; !year去掉year，却没成功。人类的欲望是无穷的，我们还需要统计每组下企鹅的个数，然后合并到一起。因此，我们再接再厉 d2 &lt;- penguins %&gt;% group_by(species) %&gt;% summarise( n = n() ) d2 ## # A tibble: 3 x 2 ## species n ## &lt;fct&gt; &lt;int&gt; ## 1 Adelie 152 ## 2 Chinstrap 68 ## 3 Gentoo 124 最后合并 d1 %&gt;% left_join(d2, by = &quot;species&quot;) ## # A tibble: 3 x 7 ## species bill_length_mm bill_depth_mm flipper_length_~ ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 38.8 18.3 190. ## 2 Chinst~ 48.8 18.4 196. ## 3 Gentoo 47.5 15.0 217. ## # ... with 3 more variables: body_mass_g &lt;dbl&gt;, ## # year &lt;dbl&gt;, n &lt;int&gt; 结果应该没问题，然鹅，总让人感觉怪怪的，过程有点折腾，希望不这么麻烦。 23.1 across()横空出世 across()的出现，让这一切变得简单和清晰，上面三步完成的动作，一步搞定 penguins %&gt;% group_by(species) %&gt;% summarise( across(where(is.numeric) &amp; !year, mean, na.rm = TRUE), n = n() ) ## # A tibble: 3 x 6 ## species bill_length_mm bill_depth_mm flipper_length_~ ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 38.8 18.3 190. ## 2 Chinst~ 48.8 18.4 196. ## 3 Gentoo 47.5 15.0 217. ## # ... with 2 more variables: body_mass_g &lt;dbl&gt;, ## # n &lt;int&gt; 是不是很强大。大爱Hadley Wickham !!! 23.2 across()函数形式 across()函数，它有三个主要的参数： across(.cols = , .fns = , .names = ) 第一个参数.cols = ，选取我们要需要的若干列，选取多列的语法与select()的语法一致，选择方法非常丰富和人性化 基本语法 :，变量在位置上是连续的，可以使用类似 1:3 或者species:island !，变量名前加!，意思是求这个变量的补集，等价于去掉这个变量，比如!species &amp; 与 |，两组变量集的交集和并集，比如 is.numeric &amp; !year, 就是选取数值类型变量，但不包括year; 再比如 is.numeric | is.factor就是选取数值型变量和因子型变量 c()，选取变量的组合，比如c(a, b, x) 通过人性化的语句 everything(): 选取所有的变量 last_col(): 选取最后一列，也就说倒数第一列，也可以last_col(offset = 1L) 就是倒数第二列 通过变量名的特征 starts_with(): 指定一组变量名的前缀，也就把选取具有这一前缀的变量，starts_with(\"bill_\") ends_with(): 指定一组变量名的后缀，也就选取具有这一后缀的变量，ends_with(\"_mm\") contains(): 指定变量名含有特定的字符串，也就是选取含有指定字符串的变量，ends_with(\"length\") matches(): 同上，字符串可以是正则表达式 通过字符串向量 all_of(): 选取字符串向量对应的变量名，比如all_of(c(\"species\", \"sex\", \"year\"))，当然前提是，数据框中要有这些变量，否则会报错。 any_of(): 同all_of()，只不过数据框中没有字符串向量对应的变量，也不会报错，比如数据框中没有people这一列，代码any_of(c(\"species\", \"sex\", \"year\", \"people\"))也正常运行，挺人性化的 通过函数 常见的有数据类型函数 where(is.numeric), where(is.factor), where(is.character), where(is.date) 第二个参数.fns =，我们要执行的函数（或者多个函数），函数的语法有三种形式可选： A function, e.g. mean. A purrr-style lambda, e.g. ~ mean(.x, na.rm = TRUE) A list of functions/lambdas, e.g. list(mean = mean, n_miss = ~ sum(is.na(.x)) 第三个参数.names =, 如果.fns是单个函数就默认保留原来数据列的名称，即\"{.col}\" ；如果.fns是多个函数，就在数据列的列名后面跟上函数名，比如\"{.col}_{.fn}\"；当然，我们也可以简单调整列名和函数之间的顺序或者增加一个标识的字符串，比如弄成\"{.fn}_{.col}\"，\"{.col}_{.fn}_aa\" 23.3 across()应用举例 下面通过一些小案例，继续呈现across()函数的功能 23.3.1 求每一列的缺失值数量 就是本章开始的需求 penguins %&gt;% summarise( na_in_species = sum(is.na(species)), na_in_island = sum(is.na(island)), na_in_length = sum(is.na(bill_length_mm)), na_in_depth = sum(is.na(bill_depth_mm)), na_in_flipper = sum(is.na(flipper_length_mm)), na_in_body = sum(is.na(body_mass_g)), na_in_sex = sum(is.na(sex)), na_in_year = sum(is.na(year)) ) # using across() penguins %&gt;% summarise( across(everything(), function(x) sum(is.na(x))) ) ## # A tibble: 1 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 2 2 ## # ... with 4 more variables: flipper_length_mm &lt;int&gt;, ## # body_mass_g &lt;int&gt;, sex &lt;int&gt;, year &lt;int&gt; # or penguins %&gt;% summarise( across(everything(), ~ sum(is.na(.))) ) ## # A tibble: 1 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 2 2 ## # ... with 4 more variables: flipper_length_mm &lt;int&gt;, ## # body_mass_g &lt;int&gt;, sex &lt;int&gt;, year &lt;int&gt; 23.3.2 每个类型变量下有多少组？ penguins %&gt;% summarise( distinct_species = n_distinct(species), distinct_island = n_distinct(island), distinct_sex = n_distinct(sex) ) ## # A tibble: 1 x 3 ## distinct_species distinct_island distinct_sex ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 3 3 3 # using across() penguins %&gt;% summarise( across(c(species, island, sex), n_distinct) ) ## # A tibble: 1 x 3 ## species island sex ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 3 3 3 23.3.3 多列多个统计函数 penguins %&gt;% group_by(species) %&gt;% summarise( length_mean = mean(bill_length_mm, na.rm = TRUE), length_sd = sd(bill_length_mm, na.rm = TRUE), depth_mean = mean(bill_depth_mm, na.rm = TRUE), depth_sd = sd(bill_depth_mm, na.rm = TRUE), flipper_mean = mean(flipper_length_mm, na.rm = TRUE), flipper_sd = sd(flipper_length_mm, na.rm = TRUE), n = n() ) ## # A tibble: 3 x 8 ## species length_mean length_sd depth_mean depth_sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 38.8 2.66 18.3 1.22 ## 2 Chinst~ 48.8 3.34 18.4 1.14 ## 3 Gentoo 47.5 3.08 15.0 0.981 ## # ... with 3 more variables: flipper_mean &lt;dbl&gt;, ## # flipper_sd &lt;dbl&gt;, n &lt;int&gt; # using across() penguins %&gt;% group_by(species) %&gt;% summarise( across(ends_with(&quot;_mm&quot;), list(mean = mean, sd = sd), na.rm = TRUE), n = n() ) ## # A tibble: 3 x 8 ## species bill_length_mm_~ bill_length_mm_~ ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 38.8 2.66 ## 2 Chinst~ 48.8 3.34 ## 3 Gentoo 47.5 3.08 ## # ... with 5 more variables: bill_depth_mm_mean &lt;dbl&gt;, ## # bill_depth_mm_sd &lt;dbl&gt;, ## # flipper_length_mm_mean &lt;dbl&gt;, ## # flipper_length_mm_sd &lt;dbl&gt;, n &lt;int&gt; 23.3.4 不同分组下数据变量的多个分位数 事实上，这里是across()与summarise()的强大结合起来 penguins %&gt;% group_by(species, island) %&gt;% summarise( prob = c(.25, .75), length = quantile(bill_length_mm, prob, na.rm = TRUE), depth = quantile(bill_depth_mm, prob, na.rm = TRUE), flipper = quantile(flipper_length_mm, prob, na.rm = TRUE) ) ## # A tibble: 10 x 6 ## # Groups: species, island [5] ## species island prob length depth flipper ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Biscoe 0.25 37.7 17.6 185. ## 2 Adelie Biscoe 0.75 40.7 19.0 193 ## 3 Adelie Dream 0.25 36.8 17.5 185 ## 4 Adelie Dream 0.75 40.4 18.8 193 ## 5 Adelie Torgersen 0.25 36.7 17.4 187 ## 6 Adelie Torgersen 0.75 41.1 19.2 195 ## 7 Chinstrap Dream 0.25 46.3 17.5 191 ## 8 Chinstrap Dream 0.75 51.1 19.4 201 ## 9 Gentoo Biscoe 0.25 45.3 14.2 212 ## 10 Gentoo Biscoe 0.75 49.6 15.7 221 # using across() penguins %&gt;% group_by(species, island) %&gt;% summarise( prob = c(.25, .75), across( c(bill_length_mm, bill_depth_mm, flipper_length_mm), ~ quantile(., prob, na.rm = TRUE) ) ) ## # A tibble: 10 x 6 ## # Groups: species, island [5] ## species island prob bill_length_mm bill_depth_mm ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Biscoe 0.25 37.7 17.6 ## 2 Adelie Biscoe 0.75 40.7 19.0 ## 3 Adelie Dream 0.25 36.8 17.5 ## 4 Adelie Dream 0.75 40.4 18.8 ## 5 Adelie Torge~ 0.25 36.7 17.4 ## 6 Adelie Torge~ 0.75 41.1 19.2 ## 7 Chinst~ Dream 0.25 46.3 17.5 ## 8 Chinst~ Dream 0.75 51.1 19.4 ## 9 Gentoo Biscoe 0.25 45.3 14.2 ## 10 Gentoo Biscoe 0.75 49.6 15.7 ## # ... with 1 more variable: flipper_length_mm &lt;dbl&gt; # or penguins %&gt;% group_by(species, island) %&gt;% summarise( prob = c(.25, .75), across(where(is.numeric) &amp; !year, ~ quantile(., prob, na.rm = TRUE)) ) ## # A tibble: 10 x 7 ## # Groups: species, island [5] ## species island prob bill_length_mm bill_depth_mm ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Biscoe 0.375 37.7 17.6 ## 2 Adelie Biscoe 0.625 40.7 19.0 ## 3 Adelie Dream 0.375 36.8 17.5 ## 4 Adelie Dream 0.625 40.4 18.8 ## 5 Adelie Torge~ 0.375 36.7 17.4 ## 6 Adelie Torge~ 0.625 41.1 19.2 ## 7 Chinst~ Dream 0.375 46.3 17.5 ## 8 Chinst~ Dream 0.625 51.1 19.4 ## 9 Gentoo Biscoe 0.375 45.3 14.2 ## 10 Gentoo Biscoe 0.625 49.6 15.7 ## # ... with 2 more variables: flipper_length_mm &lt;dbl&gt;, ## # body_mass_g &lt;dbl&gt; 23.3.5 不同分组下更复杂的统计 # using across() penguins %&gt;% group_by(species) %&gt;% summarise( n = n(), across(starts_with(&quot;bill_&quot;), mean, na.rm = TRUE), Area = mean(bill_length_mm * bill_depth_mm, na.rm = TRUE), across(ends_with(&quot;_g&quot;), mean, na.rm = TRUE), ) ## # A tibble: 3 x 6 ## species n bill_length_mm bill_depth_mm Area ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 152 38.8 18.3 712. ## 2 Chinst~ 68 48.8 18.4 900. ## 3 Gentoo 124 47.5 15.0 712. ## # ... with 1 more variable: body_mass_g &lt;dbl&gt; 23.3.6 数据标准化处理 std &lt;- function(x) { (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE) } # using across() penguins %&gt;% summarise( across(where(is.numeric), std), across(where(is.character), as.factor) ) ## # A tibble: 344 x 5 ## bill_length_mm bill_depth_mm flipper_length_~ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.883 0.784 -1.42 ## 2 -0.810 0.126 -1.06 ## 3 -0.663 0.430 -0.421 ## 4 NA NA NA ## 5 -1.32 1.09 -0.563 ## 6 -0.847 1.75 -0.776 ## 7 -0.920 0.329 -1.42 ## 8 -0.865 1.24 -0.421 ## 9 -1.80 0.480 -0.563 ## 10 -0.352 1.54 -0.776 ## # ... with 334 more rows, and 2 more variables: ## # body_mass_g &lt;dbl&gt;, year &lt;dbl&gt; # using across() and purrr style penguins %&gt;% drop_na() %&gt;% summarise( across(starts_with(&quot;bill_&quot;), ~ (.x - mean(.x)) / sd(.x)) ) ## # A tibble: 333 x 2 ## bill_length_mm bill_depth_mm ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.895 0.780 ## 2 -0.822 0.119 ## 3 -0.675 0.424 ## 4 -1.33 1.08 ## 5 -0.858 1.74 ## 6 -0.931 0.323 ## 7 -0.876 1.24 ## 8 -0.529 0.221 ## 9 -0.986 2.05 ## 10 -1.72 2.00 ## # ... with 323 more rows 23.3.7 数据对数化处理 # using across() penguins %&gt;% drop_na() %&gt;% mutate( across(where(is.numeric), log), across(where(is.character), as.factor) ) ## # A tibble: 333 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 3.67 2.93 ## 2 Adelie Torge~ 3.68 2.86 ## 3 Adelie Torge~ 3.70 2.89 ## 4 Adelie Torge~ 3.60 2.96 ## 5 Adelie Torge~ 3.67 3.03 ## 6 Adelie Torge~ 3.66 2.88 ## 7 Adelie Torge~ 3.67 2.98 ## 8 Adelie Torge~ 3.72 2.87 ## 9 Adelie Torge~ 3.65 3.05 ## 10 Adelie Torge~ 3.54 3.05 ## # ... with 323 more rows, and 4 more variables: ## # flipper_length_mm &lt;dbl&gt;, body_mass_g &lt;dbl&gt;, ## # sex &lt;fct&gt;, year &lt;dbl&gt; # using across() penguins %&gt;% drop_na() %&gt;% mutate( across(where(is.numeric), .fns = list(log = log), .names = &quot;{.fn}_{.col}&quot;), across(where(is.character), as.factor) ) ## # A tibble: 333 x 13 ## species island bill_length_mm bill_depth_mm ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ 36.7 19.3 ## 5 Adelie Torge~ 39.3 20.6 ## 6 Adelie Torge~ 38.9 17.8 ## 7 Adelie Torge~ 39.2 19.6 ## 8 Adelie Torge~ 41.1 17.6 ## 9 Adelie Torge~ 38.6 21.2 ## 10 Adelie Torge~ 34.6 21.1 ## # ... with 323 more rows, and 9 more variables: ## # flipper_length_mm &lt;int&gt;, body_mass_g &lt;int&gt;, ## # sex &lt;fct&gt;, year &lt;int&gt;, log_bill_length_mm &lt;dbl&gt;, ## # log_bill_depth_mm &lt;dbl&gt;, ## # log_flipper_length_mm &lt;dbl&gt;, ## # log_body_mass_g &lt;dbl&gt;, log_year &lt;dbl&gt; 23.3.8 在分组建模中与cur_data()配合使用 penguins %&gt;% group_by(species) %&gt;% summarise( broom::tidy(lm(bill_length_mm ~ bill_depth_mm, data = cur_data())) ) ## # A tibble: 6 x 6 ## # Groups: species [3] ## species term estimate std.error statistic p.value ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie (Inte~ 23.1 3.03 7.60 3.01e-12 ## 2 Adelie bill_~ 0.857 0.165 5.19 6.67e- 7 ## 3 Chinstr~ (Inte~ 13.4 5.06 2.66 9.92e- 3 ## 4 Chinstr~ bill_~ 1.92 0.274 7.01 1.53e- 9 ## 5 Gentoo (Inte~ 17.2 3.28 5.25 6.60e- 7 ## 6 Gentoo bill_~ 2.02 0.219 9.24 1.02e-15 penguins %&gt;% group_by(species) %&gt;% summarise( broom::tidy(lm(bill_length_mm ~ ., data = cur_data() %&gt;% select(is.numeric))) ) ## # A tibble: 15 x 6 ## # Groups: species [3] ## species term estimate std.error statistic p.value ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie (Inte~ -2.75e+2 5.09e+2 -0.539 5.90e-1 ## 2 Adelie bill_~ 2.70e-1 1.92e-1 1.40 1.63e-1 ## 3 Adelie flipp~ 2.51e-2 3.50e-2 0.717 4.74e-1 ## 4 Adelie body_~ 2.62e-3 5.25e-4 4.98 1.74e-6 ## 5 Adelie year 1.47e-1 2.55e-1 0.576 5.66e-1 ## 6 Chinstr~ (Inte~ -4.20e+2 8.24e+2 -0.509 6.12e-1 ## 7 Chinstr~ bill_~ 1.58e+0 3.76e-1 4.20 8.62e-5 ## 8 Chinstr~ flipp~ 1.67e-2 6.82e-2 0.244 8.08e-1 ## 9 Chinstr~ body_~ 1.43e-3 1.15e-3 1.24 2.19e-1 ## 10 Chinstr~ year 2.15e-1 4.12e-1 0.520 6.05e-1 ## 11 Gentoo (Inte~ -6.25e+2 5.10e+2 -1.23 2.23e-1 ## 12 Gentoo bill_~ 5.89e-1 3.15e-1 1.87 6.40e-2 ## 13 Gentoo flipp~ 1.32e-1 4.58e-2 2.89 4.59e-3 ## 14 Gentoo body_~ 2.04e-3 6.07e-4 3.36 1.05e-3 ## 15 Gentoo year 3.11e-1 2.55e-1 1.22 2.24e-1 penguins %&gt;% group_by(species) %&gt;% summarise( broom::tidy(lm(bill_length_mm ~ ., data = cur_data() %&gt;% transmute(across(is.numeric)) )) ) ## # A tibble: 15 x 6 ## # Groups: species [3] ## species term estimate std.error statistic p.value ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie (Inte~ -2.75e+2 5.09e+2 -0.539 5.90e-1 ## 2 Adelie bill_~ 2.70e-1 1.92e-1 1.40 1.63e-1 ## 3 Adelie flipp~ 2.51e-2 3.50e-2 0.717 4.74e-1 ## 4 Adelie body_~ 2.62e-3 5.25e-4 4.98 1.74e-6 ## 5 Adelie year 1.47e-1 2.55e-1 0.576 5.66e-1 ## 6 Chinstr~ (Inte~ -4.20e+2 8.24e+2 -0.509 6.12e-1 ## 7 Chinstr~ bill_~ 1.58e+0 3.76e-1 4.20 8.62e-5 ## 8 Chinstr~ flipp~ 1.67e-2 6.82e-2 0.244 8.08e-1 ## 9 Chinstr~ body_~ 1.43e-3 1.15e-3 1.24 2.19e-1 ## 10 Chinstr~ year 2.15e-1 4.12e-1 0.520 6.05e-1 ## 11 Gentoo (Inte~ -6.25e+2 5.10e+2 -1.23 2.23e-1 ## 12 Gentoo bill_~ 5.89e-1 3.15e-1 1.87 6.40e-2 ## 13 Gentoo flipp~ 1.32e-1 4.58e-2 2.89 4.59e-3 ## 14 Gentoo body_~ 2.04e-3 6.07e-4 3.36 1.05e-3 ## 15 Gentoo year 3.11e-1 2.55e-1 1.22 2.24e-1 penguins %&gt;% group_by(species) %&gt;% summarise( broom::tidy(lm(bill_length_mm ~ ., data = across(is.numeric))) ) ## # A tibble: 15 x 6 ## # Groups: species [3] ## species term estimate std.error statistic p.value ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie (Inte~ -2.75e+2 5.09e+2 -0.539 5.90e-1 ## 2 Adelie bill_~ 2.70e-1 1.92e-1 1.40 1.63e-1 ## 3 Adelie flipp~ 2.51e-2 3.50e-2 0.717 4.74e-1 ## 4 Adelie body_~ 2.62e-3 5.25e-4 4.98 1.74e-6 ## 5 Adelie year 1.47e-1 2.55e-1 0.576 5.66e-1 ## 6 Chinstr~ (Inte~ -4.20e+2 8.24e+2 -0.509 6.12e-1 ## 7 Chinstr~ bill_~ 1.58e+0 3.76e-1 4.20 8.62e-5 ## 8 Chinstr~ flipp~ 1.67e-2 6.82e-2 0.244 8.08e-1 ## 9 Chinstr~ body_~ 1.43e-3 1.15e-3 1.24 2.19e-1 ## 10 Chinstr~ year 2.15e-1 4.12e-1 0.520 6.05e-1 ## 11 Gentoo (Inte~ -6.25e+2 5.10e+2 -1.23 2.23e-1 ## 12 Gentoo bill_~ 5.89e-1 3.15e-1 1.87 6.40e-2 ## 13 Gentoo flipp~ 1.32e-1 4.58e-2 2.89 4.59e-3 ## 14 Gentoo body_~ 2.04e-3 6.07e-4 3.36 1.05e-3 ## 15 Gentoo year 3.11e-1 2.55e-1 1.22 2.24e-1 23.3.9 与cur_column()配合使用 # 每一列乘以各自的系数 df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) mult &lt;- list(x = 1, y = 10, z = 100) df %&gt;% mutate(across(all_of(names(mult)), ~ .x * mult[[cur_column()]])) ## # A tibble: 3 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 30 500 ## 2 2 40 600 ## 3 3 50 700 # 每一列乘以各自的权重 df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) weights &lt;- list(x = 0.2, y = 0.3, z = 0.5) df %&gt;% mutate( across(all_of(names(weights)), list(wt = ~ .x * weights[[cur_column()]]), .names = &quot;{col}.{fn}&quot; ) ) ## # A tibble: 3 x 6 ## x y z x.wt y.wt z.wt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3 5 0.2 0.900 2.5 ## 2 2 4 6 0.4 1.2 3 ## 3 3 5 7 0.6 1.5 3.5 # 每一列有各自的阈值，如果在阈值之上为1，否则为 0 df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) cutoffs &lt;- list(x = 2, y = 3, z = 7) df %&gt;% mutate( across(all_of(names(cutoffs)), ~ if_else(.x &gt; cutoffs[[cur_column()]], 1, 0)) ) ## # A tibble: 3 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 ## 2 0 1 0 ## 3 1 1 0 23.3.10 与c_across()配合也挺默契 在一行中的占比 df &lt;- tibble(x = 1:3, y = 3:5, z = 5:7) df %&gt;% rowwise() %&gt;% mutate(total = sum(c_across(x:z))) %&gt;% ungroup() %&gt;% mutate(across(x:z, ~ . / total)) ## # A tibble: 3 x 4 ## x y z total ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 0.111 0.333 0.556 9 ## 2 0.167 0.333 0.5 12 ## 3 0.2 0.333 0.467 15 看一行中哪个最大，最大的变为1，其余的变为0 replace_col_max &lt;- function(vec) { if (!is.vector(vec)) { stop(&quot;input of replace_col_max must be vector.&quot;) } if_else(vec == max(vec), 1L, 0L) } df %&gt;% rowwise() %&gt;% mutate( new = list(replace_col_max(c_across(everything()))) ) %&gt;% unnest_wider(new, names_sep = &quot;_&quot;) ## # A tibble: 3 x 6 ## x y z new_1 new_2 new_3 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 3 5 0 0 1 ## 2 2 4 6 0 0 1 ## 3 3 5 7 0 0 1 23.4 across()总结 我们看到了，across()函数在summarise()/mutate()/transmute()/condense()中使用，它能实现以下几个功能： 数据框中的多列执行相同操作 不同性质的操作，有时可以一起写出，不用再left_join() 图 23.1: across()函数总结图 "],["tidyverse-NA.html", "第 24 章 tidyverse中的缺失值 24.1 什么是缺失值? 24.2 有关NA的计算 24.3 如何判断NA? 24.4 强制转换 24.5 如果统计有多少NA? 24.6 应用到tidyverse中 24.7 思考 24.8 更多", " 第 24 章 tidyverse中的缺失值 今天我们聊聊数据处理中的缺失值。 24.1 什么是缺失值? 我们先导入企鹅数据 library(tidyverse) penguins &lt;- read_csv(here::here(&quot;demo_data&quot;, &quot;penguins.csv&quot;)) penguins ## # A tibble: 344 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ NA NA ## 5 Adelie Torge~ 36.7 19.3 ## 6 Adelie Torge~ 39.3 20.6 ## 7 Adelie Torge~ 38.9 17.8 ## 8 Adelie Torge~ 39.2 19.6 ## 9 Adelie Torge~ 34.1 18.1 ## 10 Adelie Torge~ 42 20.2 ## # ... with 334 more rows, and 4 more variables: ## # flipper_length_mm &lt;dbl&gt;, body_mass_g &lt;dbl&gt;, ## # sex &lt;chr&gt;, year &lt;dbl&gt; 我们看到第4行第3列开始，出现若干NA，这里的NA就是缺失值，NA的意思就是 not available. 注意区分 “NA” 和 NA “NA” 有引号的是字符串 NA 是R里的特殊标记 在R console中执行 ?\"NA\"，我们看到第一行 NA is a logical constant of length 1 which contains a missing value indicator. 也就说，NA代表了数据缺失的一种逻辑状态（另外两个逻辑值是TRUE， FALSE），NA有两层含义： 它是逻辑值 代表着缺失值 24.2 有关NA的计算 数值运算时 一般情况下，与 NA 的数值计算结果也是 NA， c(NA, 1) + 2 ## [1] NA 3 逻辑运算时 逻辑运算中TRUE为真，FALSE为假，而NA会被认为未知（即真假难辨）2。 isTRUE(NA) ## [1] FALSE isFALSE(NA) ## [1] FALSE 既不是真，也不是假，真假难辨。因此，在逻辑运算时，可以按下表指引 TRUE NA FALSE 真 不能确定真假 假 # Some logical operations do not return NA c(TRUE, FALSE) &amp; NA ## [1] NA FALSE c(TRUE, FALSE) | NA ## [1] TRUE NA 可以看到，TRUE &amp; NA 的结果为 NA（而不是FALSE），是因为NA的意思是“不能确定真假”，即有可能真也有可能假，介于真和假之间。因此TRUE 与 NA的逻辑和(即TRUE &amp; NA)返回NA；而FALSE 与 NA的逻辑和(即FALSE &amp; NA) 则返回FALSE。逻辑或的情形也是类似的。 24.3 如何判断NA? 找出数据中的缺失值，可以用is.na()函数 c(1, 2, NA, 4) %&gt;% is.na() ## [1] FALSE FALSE TRUE FALSE 24.4 强制转换 前面提到 NA 是一个与TRUE和FALSE并列的逻辑值，比如 c(TRUE, FALSE, NA) %&gt;% class() ## [1] &quot;logical&quot; 它的结果变成了“logical.” 但如果 NA 放在数值型的向量中， c(1, 2, NA, 4) %&gt;% class() ## [1] &quot;numeric&quot; 它的结果却变成了“numeric” 如果 NA 放在字符串的向量中， c(&quot;1&quot;, &quot;2&quot;, NA, &quot;4&quot;) %&gt;% class() ## [1] &quot;character&quot; 它的结果却变成了“character” 为什么会出现这种诡异的现象？究其原因，还在于NA的属性上，代表数据缺失的逻辑值，即数据类型是逻辑型。 c(TRUE, NA, FALSE) ## [1] TRUE NA FALSE c(TRUE, NA, FALSE) %&gt;% class() ## [1] &quot;logical&quot; 在第 2 章中，我们提到，把不同类型的数据用c()组合成向量时，因为c() 函数要求数据类型必须一致，因此就会发生强制转换。比如当逻辑型变量和数值型变量组合在一起时，逻辑型会强制转换成数值型。 c(1, 2, TRUE, 4) ## [1] 1 2 1 4 c(1, 2, TRUE, 4) %&gt;% class() ## [1] &quot;numeric&quot; TRUE会转换成1，FALSE会转换成0. 那么此时逻辑型的 NA 会转换成数值型的 NA_real_ 逻辑型 转换成数值型 TRUE 1 NA NA_real_ FALSE 0 c(1, 2, NA, 4) ## [1] 1 2 NA 4 c(1, 2, NA, 4) %&gt;% class() ## [1] &quot;numeric&quot; c(1, 2, NA_real_, 4) ## [1] 1 2 NA 4 c(1, 2, NA_real_, 4) %&gt;% class() ## [1] &quot;numeric&quot; 当逻辑型变量和字符串型变量组合在一起时，逻辑型会强制转换成字符串型。 逻辑型 转换成字符串型 TRUE “TRUE” NA NA_character_ FALSE “FALSE” c(&quot;1&quot;, &quot;2&quot;, TRUE, &quot;4&quot;) ## [1] &quot;1&quot; &quot;2&quot; &quot;TRUE&quot; &quot;4&quot; c(&quot;1&quot;, &quot;2&quot;, NA, &quot;4&quot;) ## [1] &quot;1&quot; &quot;2&quot; NA &quot;4&quot; c(&quot;1&quot;, &quot;2&quot;, NA_character_, &quot;4&quot;) ## [1] &quot;1&quot; &quot;2&quot; NA &quot;4&quot; 除了逻辑型NA, 数值型NA_real_, 字符串型NA_character_外, 还有整数型NA_integer_, 和复数型NA_complex. 我们再看下面的例子 c(TRUE, NA) %&gt;% purrr::map(., ~is.logical(.)) ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE c(&quot;a&quot;, NA, NA_character_) %&gt;% purrr::map(., ~is.character(.)) ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE c(123, NA, NA_real_) %&gt;% purrr::map(., ~is.numeric(.)) ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE c(NA_real_, NA_complex_, NA_character_, NA_integer_, NA) %&gt;% #被强制转换成character类型 purrr::map(., ~is.character(.)) ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE ## ## [[4]] ## [1] TRUE ## ## [[5]] ## [1] TRUE 24.5 如果统计有多少NA? 在实际的数据处理中，没有人愿意把问题搞复杂，一般情况下会先预处理，比如，剔除掉或者用其他值替换掉。不管是一删了之，还是采用插值替换，都有必要了解下数据中多少NA，这样才决定采用什么样的预处理办法。 常用的方法： 先用is.na()判断出是否为缺失值，缺失值是TRUE，不是缺失值为FALSE；然后TRUE/FALSE转换成数值，即TRUE -&gt; 1; FALSE -&gt; 0；最后把所有的1加起来，就知道数据中有多少个缺失值。 具体代码为 c(1, 2, NA, 4) %&gt;% is.na() %&gt;% as.integer() %&gt;% sum() ## [1] 1 偷懒可以这样写 c(1, 2, NA, 4) %&gt;% is.na() %&gt;% sum() ## [1] 1 当然也可以自定义一个函数， sum_of_na &lt;- function(x){ sum(is.na(x)) } c(1, 2, NA, 4) %&gt;% sum_of_na() ## [1] 1 24.6 应用到tidyverse中 回到本章开始的企鹅数据 penguins$bill_length_mm %&gt;% sum_of_na() ## [1] 2 用到dplyr函数中 penguins %&gt;% summarise( N1 = sum_of_na(bill_length_mm), N2 = sum_of_na(bill_depth_mm) ) ## # A tibble: 1 x 2 ## N1 N2 ## &lt;int&gt; &lt;int&gt; ## 1 2 2 一次性统计所有列 penguins %&gt;% summarise( across(everything(), sum_of_na) ) ## # A tibble: 1 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 2 2 ## # ... with 4 more variables: flipper_length_mm &lt;int&gt;, ## # body_mass_g &lt;int&gt;, sex &lt;int&gt;, year &lt;int&gt; 更偷懒的办法，也更直观（再次感受到R的美！） penguins %&gt;% summarise( across(everything(), ~sum(is.na(.x))) ) ## # A tibble: 1 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 2 2 ## # ... with 4 more variables: flipper_length_mm &lt;int&gt;, ## # body_mass_g &lt;int&gt;, sex &lt;int&gt;, year &lt;int&gt; 数据框的一列中每个元素的数据类型是要求相同的，这是构建数据框的基本要求。因此，在dplyr中mutate()函数创建数据框的新列时， 这一列的元素必须是同一种类型，如果遇到新列中包含NA，也要确保NA的类型与其它元素的类型要一致，比如其它元素是字符串，那么就应该使用字符串类型的缺失值，即NA_character_. 我来看下面这个例子： d &lt;- tibble(x = c(1, 3, 6, NA, 8, NA)) d ## # A tibble: 6 x 1 ## x ## &lt;dbl&gt; ## 1 1 ## 2 3 ## 3 6 ## 4 NA ## 5 8 ## 6 NA d %&gt;% mutate( is_even = case_when( x %% 2 == 0 ~ &quot;even&quot;, x %% 2 == 1 ~ &quot;not even&quot;, TRUE ~ NA # wrong ) ) 上面这个代码中，本意是希望构建一个新列存储(“even,” “not even”)字符串；而NA是逻辑型的，类型不一致，因此会报错。 正确的写法是使用NA_character_ d %&gt;% mutate( is_even = case_when( x %% 2 == 0 ~ &quot;even&quot;, x %% 2 == 1 ~ &quot;not even&quot;, TRUE ~ NA_character_ ) ) ## # A tibble: 6 x 2 ## x is_even ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 not even ## 2 3 not even ## 3 6 even ## 4 NA &lt;NA&gt; ## 5 8 even ## 6 NA &lt;NA&gt; 24.7 思考 上面例子中的dplyr::case_when()换做dplyr::if_else()函数，应该怎么写? 企鹅数据中，找出有缺失值的行，有一个NA也算。 24.8 更多 注意区分NA 和 Inf, NaN, NULL Inf = 无穷大，比如 pi / 0 %&gt;% is.infinite() NaN = 不是一个数（Not a Number）, 比如 0 / 0 %&gt;% is.nan(), sqrt(-1) %&gt;% is.nan() NULL = 空值，比如 c() %&gt;% is.null() https://tianyishi2001.github.io/r-and-tidyverse-book/logical-operation.html "],["dot.html", "第 25 章 tidyverse中的dot 25.1 每一行的 . 各自代表什么意思呢? 25.2 占位符 25.3 Lambda函数 25.4 正则表达式 25.5 Unary funciton (只带一个参数的函数) 25.6 more placeholder 25.7 当mutate遇到map 25.8 Dot dot dot 25.9 Don’t confuse 25.10 小结 25.11 回答问题", " 第 25 章 tidyverse中的dot 本章介绍tidyverse的语法中经常遇到.， 不同的场景，含义不同。因此很有必要弄清楚各自的含义。 library(tidyverse) 25.1 每一行的 . 各自代表什么意思呢? read_csv(&quot;./data/wages.csv&quot;) %&gt;% mutate(letter = str_extract(race, &quot;(?&lt;=h)(.)&quot;)) %&gt;% select(., -letter) %&gt;% mutate_at(vars(race), ~ as.factor(.)) %&gt;% mutate_at(vars(sex), ~ if_else(. == &quot;male&quot;, 1, 0)) %&gt;% filter_if(~ is.numeric(.), all_vars(. != 0)) %&gt;% split(.$sex) %&gt;% map(~ lm(earn ~ ., data = .)) %&gt;% map_dfr(~ broom::tidy(.), .id = &quot;sex&quot;) 回答之前，我们先介绍一些相关知识点 25.2 占位符 管道符号%&gt;% 主要功能是传递参数。 y %&gt;% f() is equivalent to f(y) y %&gt;% f(x, .) is equivalent to f(x, y) z %&gt;% f(x, y, arg = .) is equivalent to f(x, y, arg = z) 我们经常这样写 mtcars %&gt;% select(cyl, disp, hp) %&gt;% head(2) ## # A tibble: 2 x 3 ## cyl disp hp ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6 160 110 ## 2 6 160 110 实际上，这里是有占位符的 mtcars %&gt;% select(., cyl, disp, hp) %&gt;% head(., 2) ## # A tibble: 2 x 3 ## cyl disp hp ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6 160 110 ## 2 6 160 110 25.3 Lambda函数 .出现在函数.f的位置上， 就是 purrr 风格的Lambda函数~ fun(.)， mtcars %&gt;% select_at(vars(contains(&quot;ar&quot;)), ~ toupper(.)) %&gt;% head(3) ## # A tibble: 3 x 2 ## GEAR CARB ## &lt;dbl&gt; &lt;dbl&gt; ## 1 4 4 ## 2 4 4 ## 3 4 1 有时候程序员会将~toupper(.)简写成 toupper mtcars %&gt;% select_at(vars(contains(&quot;ar&quot;)), toupper) %&gt;% head(3) ## # A tibble: 3 x 2 ## GEAR CARB ## &lt;dbl&gt; &lt;dbl&gt; ## 1 4 4 ## 2 4 4 ## 3 4 1 25.4 正则表达式 words &lt;- &quot;the fattest cat.&quot; words %&gt;% str_replace_all(&quot;t.&quot;, &quot;-&quot;) ## [1] &quot;-e fa-es-ca-&quot; words %&gt;% str_replace_all(&quot;t\\\\.&quot;, &quot;-&quot;) ## [1] &quot;the fattest ca-&quot; 25.5 Unary funciton (只带一个参数的函数) mean_rm &lt;- . %&gt;% mean(na.rm = T) c(1, 2, 3, NA) %&gt;% mean_rm() ## [1] 2 等价于 # is equivalent to c(1, 2, 3, NA) %&gt;% mean(., na.rm = T) ## [1] 2 25.6 more placeholder iris %&gt;% subset(1:nrow(.) %% 30 == 0) ## # A tibble: 5 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.7 3.2 1.6 0.2 ## 2 5.2 2.7 3.9 1.4 ## 3 5.5 2.5 4 1.3 ## 4 6 2.2 5 1.5 ## 5 5.9 3 5.1 1.8 ## # ... with 1 more variable: Species &lt;fct&gt; 1:10 %&gt;% { c(min(.), max(.)) } ## [1] 1 10 25.7 当mutate遇到map 当dplyr::mutate遇到purrr::map，情况就复杂很多了。然而，这种情况，tidyverse比比皆是。我就多说几句吧 iris %&gt;% head(3) %&gt;% mutate(., r_sum = pmap_dbl(select_if(., is.numeric), sum)) ## # A tibble: 3 x 6 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## # ... with 2 more variables: Species &lt;fct&gt;, ## # r_sum &lt;dbl&gt; 这里mutate()行，有两个., 实际这两个.都是等待iris %&gt;% head(3)传来的data.frame df &lt;- tibble( mean = c(1, 2), sd = c(2, 4) ) df ## # A tibble: 2 x 2 ## mean sd ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 ## 2 2 4 df %&gt;% dplyr::mutate(., rand = map(mean, ~ rnorm(5, .))) %&gt;% tidyr::unnest_wider(rand) ## # A tibble: 2 x 7 ## mean sd ...1 ...2 ...3 ...4 ...5 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 0.238 -0.0633 0.651 2.24 0.941 ## 2 2 4 2.63 2.59 1.68 2.00 0.196 第一个 .， 是df 第二个 .， 是df中的mean df %&gt;% dplyr::mutate(rand = map2(mean, sd, ~ rnorm(5, .x, .y))) %&gt;% tidyr::unnest_wider(rand) ## # A tibble: 2 x 7 ## mean sd ...1 ...2 ...3 ...4 ...5 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 -0.141 -1.16 1.68 2.26 -0.419 ## 2 2 4 -1.28 1.07 -1.49 6.01 -2.63 mean传给 .x sd传给 .y 再来一个变态的。（我们不一定要这样写，但我们尽可能的要明白它的意思。） df &lt;- tribble( ~a, ~b, 1, 10, 2, 11 ) df %&gt;% dplyr::mutate(., sum = purrr::pmap_dbl(., ~ sum(...))) ## # A tibble: 2 x 3 ## a b sum ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 10 11 ## 2 2 11 13 25.8 Dot dot dot commas &lt;- function(...) { stringr::str_c(..., collapse = &quot;, &quot;) } commas(letters[1:10]) ## [1] &quot;a, b, c, d, e, f, g, h, i, j&quot; 25.9 Don’t confuse 注意：有些函数的参数前缀是 . mutate_all(.tbl, .funs, ...) mutate_if(.tbl, .predicate, .funs, ...) mutate_at(.tbl, .vars, .funs, ..., .cols = NULL) select_all(.tbl, .funs = list(), ...) rename_all(.tbl, .funs = list(), ...) 25.10 小结 tidyvere中 占位符(时常经常和 %&gt;% 一起) Lambda函数 一元函数（LHS） 其他情形 回归公式 正则表达式 注意 有些函数参数以 . 前缀(不要混淆喔! ) 25.11 回答问题 现在回答本章开始的问题 read_csv(&quot;./demo_data/wages.csv&quot;) %&gt;% dplyr::mutate(letter = str_extract(race, &quot;(?&lt;=h)(.)&quot;)) %&gt;% dplyr::select(., -letter) %&gt;% dplyr::mutate_at(vars(race), ~ as.factor(.)) %&gt;% dplyr::mutate_at(vars(sex), ~ if_else(. == &quot;male&quot;, 1, 0)) %&gt;% dplyr::filter_if(~ is.numeric(.), all_vars(. != 0)) %&gt;% split(.$sex) %&gt;% purrr::map(~ lm(earn ~ ., data = .)) %&gt;% purrr::map_dfr(., ~ broom::tidy(.), .id = &quot;sex&quot;) ## # A tibble: 8 x 6 ## sex term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 (Interc~ -121846. 37449. -3.25 1.21e- 3 ## 2 1 height 977. 515. 1.90 5.84e- 2 ## 3 1 sex NA NA NA NA ## 4 1 racehis~ 578. 7934. 0.0728 9.42e- 1 ## 5 1 raceoth~ -2035. 11514. -0.177 8.60e- 1 ## 6 1 racewhi~ 12823. 5284. 2.43 1.56e- 2 ## 7 1 ed 5234. 601. 8.71 4.30e-17 ## 8 1 age 406. 95.5 4.25 2.52e- 5 第1行：路径中.代表当前位置，如果是..表示上一级目录 第2行：正则表达式，代表任何字符 第3行：占位符，等待数据框的传入，也可以简写select(-letter) 第4行: lambda函数，~ as.factor(.)也可以简写as.factor，~和(.)要么都写，要么都不写 第5行：同上,lambda函数 第6行：第一个.代表lambda函数; 第二个.也是lambda函数，但这里它是all_vars(expr)中expr的一种特有写法，代表所有数值型变量，*行方向构成的向量, all_vars(. != 0)函数返回TRUE或FALSE，从而帮助filter()是否筛选该行 第7行：占位符，代表上面传来的数据框 第8行：回归模型lm中，第一个.代表除因变量earn之外所有的变量，第二个.占位符，留给上面的数据框 第9行：第一个.是占位符，代表上面传来的list，第二个.lambda函数，依次对list的元素迭代处理，第二个.是参数名，.id是特有的一个符号。 "],["tidyeval.html", "第 26 章 非标准性评估 26.1 编写函数 26.2 看看发生了什么 26.3 处理多个参数 26.4 调整输入的表达式 26.5 案例 26.6 可能会用到的函数 26.7 Resources", " 第 26 章 非标准性评估 Tidy Evaluation (Tidy Eval)，不是一个宏包，而是一个非标准评估的框架，也叫延迟评估。主要目的是更方便地与tidyverse里的函数配合使用，事实上，很多时候我们不一定需要用到它。我这里尽可能规避较专业的词汇，用通俗的语言介绍一些简单用法，表述可能不准确。如果想了解背后复杂的机制请阅读advance R。 26.1 编写函数 library(tidyverse) library(rlang) 写代码的过程中，我们会遇到对不同的数据框，执行相同的操作。比如 df1 %&gt;% group_by(x1) %&gt;% summarise(mean = mean(y1)) df2 %&gt;% group_by(x2) %&gt;% summarise(mean = mean(y2)) df3 %&gt;% group_by(x3) %&gt;% summarise(mean = mean(y3)) df4 %&gt;% group_by(x4) %&gt;% summarise(mean = mean(y4)) 为了减少代码的重复，我们考虑将共同的部分保留，变化的部分用参数名提取出来 data %&gt;% group_by(group_var) %&gt;% summarise(mean = mean(summary_var)) 很自然地，我们想到写一个子函数的形式，比如 grouped_mean &lt;- function(data, group_var, summary_var) { data %&gt;% group_by(group_var) %&gt;% summarise(mean = mean(summary_var)) } 当我们试图运行这段代码的时候，却发现报错了 grouped_mean(mtcars, cyl, mpg) ## Error: Must group by variables found in `.data`. ## * Column `group_var` is not found. Hadley Wickham告诉我们，正确的写法应该是， grouped_mean &lt;- function(data, group_var, summary_var) { group_var &lt;- enquo(group_var) summary_var &lt;- enquo(summary_var) data %&gt;% group_by(!!group_var) %&gt;% summarise(mean = mean(!!summary_var)) } 然后再运行 grouped_mean(mtcars, cyl, mpg) ## # A tibble: 3 x 2 ## cyl mean ## &lt;dbl&gt; &lt;dbl&gt; ## 1 4 26.7 ## 2 6 19.7 ## 3 8 15.1 或者更简便的 grouped_mean &lt;- function(data, group_var, summary_var) { data %&gt;% group_by({{group_var}}) %&gt;% summarise(mean = mean({{summary_var}})) } grouped_mean(mtcars, cyl, mpg) ## # A tibble: 3 x 2 ## cyl mean ## &lt;dbl&gt; &lt;dbl&gt; ## 1 4 26.7 ## 2 6 19.7 ## 3 8 15.1 dplyr1.0之后，可以这样写 sum_group_vars &lt;- function(df, group_vars, sum_vars){ df %&gt;% group_by(across({{ group_vars }})) %&gt;% summarise(n = n(), across({{ sum_vars }}, list(mean = mean, sd = sd)) ) } sum_group_vars(mpg, c(model, year), c(hwy, cty)) 下面我们讲讲为什么要这样写。 26.2 看看发生了什么 弄清楚之前，这里需要明白两个概念： 环境变量(env-variables) ，一般你在Rstuido右上角的Environment中发现它。比如n &lt;- 10这里的n 数据变量(data-variables)，一般指数据框的某个变量。比如data &lt;- data.frame(x = 1, n = 2)中的data$n 那么，对于我们这里编写的函数中 grouped_mean(mtcars, cyl, mpg) cyl和mpg是打算传递的参数，是环境变量，但我们期望他们在函数中当作mtcars中的数据变量，即当做mtcars的一个列的名字来使用， 那么要完成这个角色转换，就需要引用(quote)和解引用(unquote)两个工序： 第一步，用 enquo()把用户传递过来的参数引用起来（引用可以理解为冷冻起来） 第二步，用 !! 解开这个引用（解引用可以理解为解冷），然后使用参数的内容 这个quote-unquote的过程让环境变量名变成了数据变量，也可以理解为在函数评估过程中，数据变量（data-variable）遮盖了环境变量（env-variable），即数据遮盖（data masking），看到cyl，正常情况下，本来应该是到环境变量里去找这个cyl对应的值，然而，数据遮盖机制，插队了，让代码去数据变量中去找cyl以及对应的值。 我们通过rlang::qq_show()看看这个quote-unquote机制是怎么工作的 先看看qq_show() var &lt;- quote(height) qq_show(!!var) ## height 再看看grouped_mean()的代码 group_var &lt;- quote(cyl) summary_var &lt;- quote(mpg) rlang::qq_show( data %&gt;% group_by(!!group_var) %&gt;% summarise(mean = mean(!!summary_var)) ) ## data %&gt;% group_by(cyl) %&gt;% summarise(mean = mean(mpg)) 关于数据遮盖更多细节请看Quote and unquote。 26.3 处理多个参数 前面讲了如何传递分组参数和统计参数到子函数。如果传递更多的参数，可以用...代替group_var ，然后传递到group_by()，比如 grouped_mean &lt;- function(data, summary_var, ...) { summary_var &lt;- enquo(summary_var) group_var &lt;- enquos(...) data %&gt;% group_by(!!!group_var) %&gt;% summarise(mean = mean(!!summary_var)) } 指定统计参数disp，分组参数(cyl am)，然后运行代码, grouped_mean(mtcars, disp, cyl, am) ## # A tibble: 6 x 3 ## # Groups: cyl [3] ## cyl am mean ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 0 136. ## 2 4 1 93.6 ## 3 6 0 205. ## 4 6 1 155 ## 5 8 0 358. ## 6 8 1 326 或者指定统计参数disp，更多的分组参数(cyl, am, vs) grouped_mean(mtcars, disp, cyl, am, vs) ## # A tibble: 7 x 4 ## # Groups: cyl, am [6] ## cyl am vs mean ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 0 1 136. ## 2 4 1 0 120. ## 3 4 1 1 89.8 ## 4 6 0 1 205. ## 5 6 1 0 155 ## 6 8 0 0 358. ## 7 8 1 0 326 注意到...代表的是多个参数，因此在引用的时候用的是enquos()，在解引用的时候 用的是group_by(!!!group_var). 事实上, ...是一个特殊的符号，我们可以省略引用后再解引用的过程，直接传给给group_by()， 比如 grouped_mean &lt;- function(data, summary_var, ...) { summary_var &lt;- enquo(summary_var) data %&gt;% group_by(...) %&gt;% summarise(mean = mean(!!summary_var)) } grouped_mean(mtcars, disp, cyl, am, vs) ## # A tibble: 7 x 4 ## # Groups: cyl, am [6] ## cyl am vs mean ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 0 1 136. ## 2 4 1 0 120. ## 3 4 1 1 89.8 ## 4 6 0 1 205. ## 5 6 1 0 155 ## 6 8 0 0 358. ## 7 8 1 0 326 26.4 调整输入的表达式 26.4.1 修改引用参数的默认名 我们希望输出的统计结果中，统计参数名加一个前缀 “avg_”， 可以分三步完成 获取引用参数的默认名 修改参数的默认名，比如加前缀或者后缀 !! 解引用并放在 := 左边 grouped_mean2 &lt;- function(.data, .summary_var, ...) { summary_var &lt;- enquo(.summary_var) group_vars &lt;- enquos(...) # Get and modify the default name summary_nm &lt;- as_label(summary_var) summary_nm &lt;- paste0(&quot;avg_&quot;, summary_nm) .data %&gt;% group_by(!!!group_vars) %&gt;% summarise(!!summary_nm := mean(!!summary_var)) # Unquote the name } grouped_mean2(mtcars, disp, cyl, am) ## # A tibble: 6 x 3 ## # Groups: cyl [3] ## cyl am avg_disp ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 0 136. ## 2 4 1 93.6 ## 3 6 0 205. ## 4 6 1 155 ## 5 8 0 358. ## 6 8 1 326 或者更简洁的办法 my_summarise &lt;- function(data, group_var, summarise_var) { data %&gt;% group_by(across({{ group_var }})) %&gt;% summarise(across({{ summarise_var }}, mean, .names = &quot;mean_{col}&quot;)) } my_summarise(starwars, species, height) 如果想调整多个分组变量的默认名，比如加个前缀“groups_”，方法和上面的步骤类似 引用传递过来的参数名，.enquos(..., .named = TRUE), 增加了控制语句.named = TRUE 修改在每个参数的默认名，比如加前缀或者后缀 !! 解引用并放在 := 左边 grouped_mean3 &lt;- function(.data, .summary_var, ...) { summary_var &lt;- enquo(.summary_var) # Quote the dots with default names group_vars &lt;- enquos(..., .named = TRUE) summary_nm &lt;- as_label(summary_var) summary_nm &lt;- paste0(&quot;avg_&quot;, summary_nm) # Modify the names of the list of quoted dots names(group_vars) &lt;- paste0(&quot;groups_&quot;, names(group_vars)) .data %&gt;% group_by(!!!group_vars) %&gt;% # Unquote-splice as usual summarise(!!summary_nm := mean(!!summary_var)) } grouped_mean3(mtcars, disp, cyl, am) ## # A tibble: 6 x 3 ## # Groups: groups_cyl [3] ## groups_cyl groups_am avg_disp ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 0 136. ## 2 4 1 93.6 ## 3 6 0 205. ## 4 6 1 155 ## 5 8 0 358. ## 6 8 1 326 26.4.2 修改引用的表达式 有时候，我们不想“按多个变量分组，对一个变量统计”。而是“按一个变量分组，对多个变量统计”。这种情况，我们就需要调整引用的表达式 .group_var放分组的变量species ... 放需要统计的多个变量height, mass，期望完成 mean(height), mean(mass) 需要用purrr:map()配合调整表达式， 如 vars &lt;- list(quote(mass), quote(height)) purrr::map(vars, function(var) expr(mean(!!var, na.rm = TRUE))) ## [[1]] ## mean(mass, na.rm = TRUE) ## ## [[2]] ## mean(height, na.rm = TRUE) 完整代码可以这样写 grouped_mean4 &lt;- function(.data, .group_var, ...) { group_var &lt;- enquo(.group_var) summary_vars &lt;- enquos(..., .named = TRUE) # Wrap the summary variables with mean() summary_vars &lt;- purrr::map(summary_vars, function(var) { expr(mean(!!var, na.rm = TRUE)) }) # Prefix the names with `avg_` names(summary_vars) &lt;- paste0(&quot;avg_&quot;, names(summary_vars)) .data %&gt;% group_by(!!group_var) %&gt;% summarise(!!!summary_vars) } grouped_mean4(starwars, species, height, mass) ## # A tibble: 38 x 3 ## species avg_height avg_mass ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Aleena 79 15 ## 2 Besalisk 198 102 ## 3 Cerean 198 82 ## 4 Chagrian 196 NaN ## 5 Clawdite 168 55 ## 6 Droid 131. 69.8 ## 7 Dug 112 40 ## 8 Ewok 88 20 ## 9 Geonosian 183 80 ## 10 Gungan 209. 74 ## # ... with 28 more rows 26.5 案例 26.5.1 统计并过滤 df &lt;- tibble(index = sample(letters[1:4], size = 100, replace = TRUE) ) df ## # A tibble: 100 x 1 ## index ## &lt;chr&gt; ## 1 c ## 2 a ## 3 c ## 4 c ## 5 d ## 6 c ## 7 b ## 8 a ## 9 c ## 10 b ## # ... with 90 more rows filter_which &lt;- function(df, var, val) { which_var &lt;- enquo(var) which_val &lt;- as_name(enquo(val)) df %&gt;% count(!!which_var) %&gt;% filter(!!which_var == which_val) } df %&gt;% filter_which(index, a) ## # A tibble: 1 x 2 ## index n ## &lt;chr&gt; &lt;int&gt; ## 1 a 23 26.5.2 自定义统计输出 my_summarise &lt;- function(data, expr) { data %&gt;% summarise( &quot;mean_{{expr}}&quot; := mean({{ expr }}), &quot;sum_{{expr}}&quot; := sum({{ expr }}), &quot;n_{{expr}}&quot; := n() ) } mtcars %&gt;% my_summarise(mpg) ## # A tibble: 1 x 3 ## mean_mpg sum_mpg n_mpg ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 20.1 643. 32 26.5.3 形成依次下滑的列 d &lt;- tibble(x = seq_len(10)) jetlag &lt;- function(data, variable, n = 10){ variable &lt;- enquo(variable) indices &lt;- seq_len(n) quosures &lt;- purrr::map( indices, ~quo(lag(!!variable, !!.x)) ) %&gt;% purrr::set_names(nm = purrr::map_chr(indices, ~paste0(&quot;lag_&quot;, .x))) dplyr::mutate(data, !!!quosures) } d %&gt;% jetlag(x, 3) ## # A tibble: 10 x 4 ## x lag_1 lag_2 lag_3 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 NA NA NA ## 2 2 1 NA NA ## 3 3 2 1 NA ## 4 4 3 2 1 ## 5 5 4 3 2 ## 6 6 5 4 3 ## 7 7 6 5 4 ## 8 8 7 6 5 ## 9 9 8 7 6 ## 10 10 9 8 7 26.6 可能会用到的函数 enquo() vs quo() vs expr() vs as_name() vs as_label() vs sym() a &lt;- 1 b &lt;- 1 var &lt;- quote(a + b) # returns a single quoted expression for the delayed computation var ## a + b qq_show(!!var) ## a + b # quotes a new expression locally expr(mean(!!var, na.rm = TRUE)) ## mean(a + b, na.rm = TRUE) var &lt;- quo(height) # transforms a quoted variable name into a string. as_name(var) ## [1] &quot;height&quot; # also returns a single string but supports any kind of R object as input, including quoted function calls and vectors. Its purpose is to summarise that object into a single label. That label is often suitable as a default name. as_label(var) ## [1] &quot;height&quot; # creates a symbol from a string sym(&quot;height&quot;) ## height 26.7 Resources tidyeval book - https://tidyeval.tidyverse.org/ or tidyeval post - https://rpubs.com/lionel-/tidyeval-introduction tidyeval webinar - https://www.rstudio.com/resources/webinars/tidy-eval/ “Tidy evaluation in 5 minutes” by Hadley Wickham - https://www.youtube.com/watch?v=nERXS3ssntw Metaprogramming chapters in “Advanced R” - https://adv-r.hadley.nz/meta.html tidyeval cheatsheet - https://www.rstudio.com/resources/cheatsheets/ https://github.com/tidyverse/dplyr/blob/master/vignettes/programming.Rmd https://github.com/romatik/touring_the_tidyverse https://tidyeval.tidyverse.org/dplyr.html "],["sampling.html", "第 27 章 模拟与抽样 27.1 模拟 27.2 MASS::mvrnorm 27.3 蒙特卡洛 27.4 抽样与样本 27.5 扩展阅读", " 第 27 章 模拟与抽样 library(tidyverse) 本章目的是在tidyverse的架构下，介绍一些模拟和抽样的知识。先回顾下Hadley Wickham提出的数据科学tidy原则，tidy思想体现在: 任何数据都可以规整为数据框 数据框的一列代表一个变量，数据框的一行代表一次观察 函数处理数据时，数据框进、数据框出 27.1 模拟 27.1.1 生成随机数 比如生成5个高斯分布的随机数，高斯分布就是正态分布，R语言里我们用rnorm()函数产生正态分布的随机数 rnorm(n = 5, mean = 0, sd = 1) ## [1] 0.41316 0.06703 -0.07219 0.41416 0.98988 事实上，R内置了很多随机数产生的函数 Distrution Notation R Uniform \\(\\text{U}(a, b)\\) runif Normal \\(\\text{N}(\\mu, \\sigma)\\) rnorm Binormal \\(\\text{Bin}(n, p)\\) rbinorm Piosson \\(\\text{pois}(\\lambda)\\) rpois Beta \\(\\text{Beta}(\\alpha, \\beta)\\) rbeta 如果大家查看帮助文档?runif，会发现每种分布都有对应的四个函数 d:density p:cumulative probability q:quantile r:random dnorm(seq(0.1, 0.5, length.out = 10), mean = 0, sd = 1) ## [1] 0.3970 0.3948 0.3919 0.3882 0.3838 0.3788 0.3730 ## [8] 0.3666 0.3596 0.3521 在tidyverse的框架下，我们喜欢在数据框(data.frame)下运用这些函数，因为这样我们可以方便使用ggplot2来可视化， 例子1，我们生成100个正态分布的点，然后看看其分布 tibble( x = rnorm(n = 100, mean = 0, sd = 1) ) %&gt;% ggplot(aes(x = x)) + geom_density() 我们将模拟的正态分布和理论上正态分布画在一起 tibble( x = rnorm(n = 100, mean = 0, sd = 1) ) %&gt;% ggplot(aes(x = x)) + geom_density() + stat_function( fun = dnorm, args = list(mean = 0, sd = 1), color = &quot;red&quot; ) 如果我们模拟点再增加点，会越来越逼近理论上的分布。 例子2，在数据框(data.frame)下，建立模拟\\(x\\)和\\(y\\)的线性关系 \\[ y_i = 4 + 3.2\\, x_i\\] 现实中，观察值往往会带入误差，假定误差服从正态分布，那么\\(x\\)和\\(y\\)的线性关系重新表述为 \\[ y_i = \\beta_0 + \\beta_1\\, x_i + \\epsilon_i, \\quad \\epsilon \\in \\text{Normal}(\\mu =0, \\sigma =1) \\] beta_0 &lt;- 4 beta_1 &lt;- 3.2 epsilon &lt;- rnorm(n = 1000, mean = 0, sd = 1) sim_normal &lt;- tibble( # x_vals = runif(1000, 0, 10) x_vals = seq(from = 0, to = 5, length.out = 1000), y_vals = beta_0 + beta_1 * x_vals + epsilon, ) sim_normal %&gt;% head() ## # A tibble: 6 x 2 ## x_vals y_vals ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0 5.93 ## 2 0.00501 5.73 ## 3 0.0100 4.47 ## 4 0.0150 5.26 ## 5 0.0200 6.80 ## 6 0.0250 4.30 sim_normal %&gt;% ggplot(aes(x = x_vals, y = y_vals)) + geom_point() 有时候为了方便，可以写简练点 tibble( a = runif(1000, 0, 5), b = 4 + rnorm(1000, mean = 3.2 * a, sd = 1) ) %&gt;% ggplot(aes(x = a, y = b)) + geom_point() 27.2 MASS::mvrnorm MASS::mvrnorm(n = 1, mu, Sigma)产生多元高斯分布的随机数，每组随机变量高度相关。 比如人的身高服从正态分布，人的体重也服从正态分布，同时身高和体重又存在强烈的关联。 n: 随机样本的大小 mu: 多元高斯分布的均值向量 Sigma: 协方差矩阵，主要这里是大写的S (Sigma)，提醒我们它是一个矩阵，不是一个数值 a &lt;- 3.5 b &lt;- -1 sigma_a &lt;- 1 sigma_b &lt;- 0.5 rho &lt;- -0.7 mu &lt;- c(a, b) cov_ab &lt;- sigma_a * sigma_b * rho # 协方差 # 构建协方差矩阵 sigma &lt;- matrix(c( sigma_a^2, cov_ab, cov_ab, sigma_b^2 ), ncol = 2) d &lt;- MASS::mvrnorm(1000, mu = mu, Sigma = sigma) %&gt;% data.frame() %&gt;% set_names(&quot;group_a&quot;, &quot;group_b&quot;) head(d) ## group_a group_b ## 1 4.099 -1.3813 ## 2 3.103 0.0307 ## 3 5.762 -2.1944 ## 4 2.458 -0.5788 ## 5 3.240 -0.6353 ## 6 5.423 -1.5914 d %&gt;% ggplot(aes(x = group_a)) + geom_density( color = &quot;transparent&quot;, fill = &quot;dodgerblue3&quot;, alpha = 1 / 2 ) + stat_function( fun = dnorm, args = list(mean = 3.5, sd = 1), linetype = 2 ) d %&gt;% ggplot(aes(x = group_b)) + geom_density( color = &quot;transparent&quot;, fill = &quot;dodgerblue3&quot;, alpha = 1 / 2 ) + stat_function( fun = dnorm, args = list(mean = -1, sd = 0.5), linetype = 2 ) d %&gt;% ggplot(aes(x = group_a, y = group_b)) + geom_point() + stat_ellipse(type = &quot;norm&quot;, level = 0.95) 我们回头验算一下 d %&gt;% summarise( a_mean = mean(group_a), b_mean = mean(group_b), a_sd = sd(group_a), b_sd = sd(group_b), cor = cor(group_a, group_b), cov = cov(group_a, group_b) ) ## a_mean b_mean a_sd b_sd cor cov ## 1 3.529 -1.002 0.9984 0.4962 -0.6976 -0.3456 27.3 蒙特卡洛 这是我研究生时候老师布置的一个的题目，当时我用的是C语言代码，现在我们有强大的tidyverse set.seed(2019) n &lt;- 50000 points &lt;- tibble(&quot;x&quot; = runif(n), &quot;y&quot; = runif(n)) points &lt;- points %&gt;% mutate(inside = map2_dbl(.x = x, .y = y, ~ if_else(.x**2 + .y**2 &lt; 1, 1, 0))) %&gt;% rowid_to_column(&quot;N&quot;) 正方形的面积是1，圆的面积是\\(\\pi r^2 = \\frac{1}{4} \\pi\\)，如果知道两者的比例，就可以估算\\(\\pi\\) points &lt;- points %&gt;% mutate(estimate = 4 * cumsum(inside) / N) points %&gt;% tail() ## # A tibble: 6 x 5 ## N x y inside estimate ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 49995 0.591 0.0411 1 3.15 ## 2 49996 0.945 0.127 1 3.15 ## 3 49997 0.654 0.159 1 3.15 ## 4 49998 0.521 0.491 1 3.15 ## 5 49999 0.812 0.203 1 3.15 ## 6 50000 0.00935 0.657 1 3.15 points %&gt;% ggplot() + geom_line(aes(y = estimate, x = N), colour = &quot;#82518c&quot;) + geom_hline(yintercept = pi) 27.4 抽样与样本 27.4.1 总体分布 假定一个事实，川师男生总体的平均身高和身高的标准差分别为 true.mean &lt;- 175.7 true.sd &lt;- 15.19 那么我们可以模拟分布情况如下 pop.distn &lt;- tibble( height = seq(100, 250, 0.5), density = dnorm(height, mean = true.mean, sd = true.sd) ) ggplot(pop.distn) + geom_line(aes(height, density)) + geom_vline( xintercept = true.mean, color = &quot;red&quot;, linetype = &quot;dashed&quot; ) + geom_vline( xintercept = true.mean + true.sd, color = &quot;blue&quot;, linetype = &quot;dashed&quot; ) + geom_vline( xintercept = true.mean - true.sd, color = &quot;blue&quot;, linetype = &quot;dashed&quot; ) + labs( x = &quot;Height (cm)&quot;, y = &quot;Density&quot;, title = &quot;川师男生身高分布&quot; ) 27.4.2 样本 假定我们从中抽取30个男生身高样本 sample.a &lt;- tibble(height = rnorm(n = 30, mean = true.mean, sd = true.sd)) 然后看看样本的直方图 sample.a %&gt;% ggplot(aes(x = height)) + geom_histogram(aes(y = stat(density)), fill = &quot;steelblue&quot;, alpha = 0.75, bins = 10 ) + geom_line( data = pop.distn, aes(x = height, y = density), alpha = 0.25, size = 1.5 ) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_vline(xintercept = mean(sample.a$height), linetype = &quot;solid&quot;) 红色的虚线代表分布的总体的均值，黑色实线代表30个样本的均值， sample.a %&gt;% summarize( sample.mean = mean(height), sample.sd = sd(height) ) ## # A tibble: 1 x 2 ## sample.mean sample.sd ## &lt;dbl&gt; &lt;dbl&gt; ## 1 176. 17.3 也就是说，基于这30个观察值的样本，我们认为川师男生的身高均值为175.743cm，方差为17.3027 可能有同学说，这个样本太少了，计算的均值还不够科学，会以偏概全。于是又重新找了30个男生，和上次类似，用rnorm函数模拟，我们记为样本b sample.b &lt;- tibble(height = rnorm(30, mean = true.mean, sd = true.sd)) 再来看看这次样本的分布 sample.b %&gt;% ggplot(aes(x = height)) + geom_histogram(aes(y = stat(density)), fill = &quot;steelblue&quot;, alpha = 0.75, bins = 10 ) + geom_line( data = pop.distn, aes(x = height, y = density), alpha = 0.25, size = 1.5 ) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_vline(xintercept = mean(sample.a$height), linetype = &quot;solid&quot;) 同样，我们计算样本b的均值和方差 sample.b %&gt;% summarize( sample.mean = mean(height), sample.sd = sd(height) ) ## # A tibble: 1 x 2 ## sample.mean sample.sd ## &lt;dbl&gt; &lt;dbl&gt; ## 1 174. 14.9 这次抽样的结果，均值为173.711cm，方差为14.8641 和样本a比，有一点点变化。不经想问，我能否继续抽样呢？结果会有变化吗？为了避免重复写代码 ，我把上面的过程整合到一起，写一个子函数，专门模拟抽样过程 rnorm.stats &lt;- function(n, mu, sigma) { the.sample &lt;- rnorm(n, mu, sigma) tibble( sample.size = n, sample.mean = mean(the.sample), sample.sd = sd(the.sample) ) } 于是，我们又可以继续模拟了。注意我们之前设定的总体分布的均值和方差 true.mean &lt;- 175.7 true.sd &lt;- 15.19 rnorm.stats(30, true.mean, true.sd) ## # A tibble: 1 x 3 ## sample.size sample.mean sample.sd ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 30 175. 16.2 yes，代码工作的很好，但不过只是代码减少了一点点，仍然只是一次抽样（这里30个样本为一次抽样），我们的目的是反复抽样， 抽很多次的那种喔。 那我们用purrr包的rerun函数偷个懒， df.samples.of.30 &lt;- purrr::rerun(2500, rnorm.stats(30, true.mean, true.sd)) %&gt;% dplyr::bind_rows() 哇，一下子抽了2500个样本,全部装进了df.sample.of.30这个数据框， 偷偷看一眼呢 df.samples.of.30 %&gt;% head() ## # A tibble: 6 x 3 ## sample.size sample.mean sample.sd ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 30 173. 16.1 ## 2 30 178. 15.8 ## 3 30 175. 14.2 ## 4 30 179. 17.9 ## 5 30 178. 15.4 ## 6 30 180. 12.6 回过头看看df.samples.of.30是什么： 从川师的男生中随机抽取30个，计算这30个人身高的均值和方差，这叫一次抽样 把上面的工作，重复2500次，得到2500个均值和方差 2500个均值和方差，组成了一个数据框 我们发现每次抽样的均值都不一样，感觉又像一个分布(抽样的均值分布)，我们画出来看看吧 df.samples.of.30 %&gt;% ggplot(aes(x = sample.mean, y = stat(density))) + geom_histogram(bins = 25, fill = &quot;firebrick&quot;, alpha = 0.5) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs( title = &quot;抽样2500次（每次30个男生）身高均值的分布&quot;, subtitle = &quot;Distribution of mean heights for 2500 samples of size 30&quot; ) 注意到，这不是男生身高的分布，而是每次抽样计算的均值构成的分布. 为了更清楚的说明，我们把整体的分布(灰色曲线)、样本a（蓝色直方图）、抽样的均值分布（红色直方图）三者画在一起。 df.samples.of.30 %&gt;% ggplot(aes(x = sample.mean, y = stat(density))) + geom_histogram(bins = 50, fill = &quot;firebrick&quot;, alpha = 0.5) + geom_histogram( data = sample.a, aes(x = height, y = stat(density)), bins = 11, fill = &quot;steelblue&quot;, alpha = 0.25 ) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_line(data = pop.distn, aes(x = height, y = density), alpha = 0.25, size = 1.5) + xlim(125, 225) 样本的均值分布，是个很有意思的结果，比如，我们再选30个男生再抽样一次，我们可以断定，这次抽样的均值会落在了红色的区间之内。 然而，注意到，必须限定再次抽样的大小仍然是30个男生，以上这句话才成立。 df.samples.of.30 %&gt;% summarize( mean.of.means = mean(sample.mean), sd.of.means = sd(sample.mean) ) ## # A tibble: 1 x 2 ## mean.of.means sd.of.means ## &lt;dbl&gt; &lt;dbl&gt; ## 1 176. 2.77 这里计算的是抽样(样本大小为30)均值分布，而不是整体的均值分布。言外之意，样本大小可以是其它的呗， 那就把样本调整为50、100、250、500分别试试看 df.samples.of.50 &lt;- rerun(2500, rnorm.stats(50, true.mean, true.sd)) %&gt;% bind_rows() df.samples.of.100 &lt;- rerun(2500, rnorm.stats(100, true.mean, true.sd)) %&gt;% bind_rows() df.samples.of.250 &lt;- rerun(2500, rnorm.stats(250, true.mean, true.sd)) %&gt;% bind_rows() df.samples.of.500 &lt;- rerun(2500, rnorm.stats(500, true.mean, true.sd)) %&gt;% bind_rows() 忍不住想画图看看，每次抽取的男生数量不同，均值的分布会有不同？ df.combined &lt;- bind_rows( df.samples.of.30, df.samples.of.50, df.samples.of.100, df.samples.of.250, df.samples.of.500 ) %&gt;% mutate(sample.sz = as.factor(sample.size)) df.combined %&gt;% ggplot(aes(x = sample.mean, y = stat(density), fill = sample.sz)) + geom_histogram(bins = 25, alpha = 0.5) + geom_vline(xintercept = true.mean, linetype = &quot;dashed&quot;) + facet_wrap(vars(sample.sz), nrow = 1) + scale_fill_brewer(palette = &quot;Set1&quot;) + labs( x = &quot;Sample means&quot;, y = &quot;Density&quot;, title = &quot;Distribution of mean heights for samples of varying size&quot; ) 随着样本大小由30增加到500，抽样的均值分布围绕着越来越聚合到实际的均值，或者说随着样本大小的增多，对均值估计的不确定性越小。 sampling.distn.mean.table &lt;- df.combined %&gt;% group_by(sample.size) %&gt;% summarize( mean.of.means = mean(sample.mean), sd.of.means = sd(sample.mean) ) sampling.distn.mean.table ## # A tibble: 5 x 3 ## sample.size mean.of.means sd.of.means ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 30 176. 2.77 ## 2 50 176. 2.11 ## 3 100 176. 1.51 ## 4 250 176. 0.948 ## 5 500 176. 0.672 有个统计学上的概念需要明确。 输出结果的第三列sd.of.means 是不同样本大小(30,50,100,250,500)下，反复抽样后平均数分布的标准差。 数学上，如果已知总体的标准差(\\(\\sigma\\))，那么抽取无限多份大小为 \\(n\\) 的样本，每个样本各有一个平均值，所有这个大小的样本之平均值的标准差可证明为 \\[ \\frac{\\sigma}{\\sqrt{n}} \\] 即，平均值的标准误差。 下面我们画图看看，模拟出来的\\(sd.of.means\\)和理论值\\(\\frac{\\sigma}{\\sqrt{n}}\\)是否一致。 注意到这里的\\(\\sigma\\)是总体的标准差，即最开始我们设定的川师男生身高的标准差true.sd. 也就说，理论上 df.se.mean.theory &lt;- tibble( sample.size = seq(10, 500, 10) ) %&gt;% mutate(std.error = true.sd / sqrt(sample.size)) df.se.mean.theory ## # A tibble: 50 x 2 ## sample.size std.error ## &lt;dbl&gt; &lt;dbl&gt; ## 1 10 4.80 ## 2 20 3.40 ## 3 30 2.77 ## 4 40 2.40 ## 5 50 2.15 ## 6 60 1.96 ## 7 70 1.82 ## 8 80 1.70 ## 9 90 1.60 ## 10 100 1.52 ## # ... with 40 more rows sampling.distn.mean.table %&gt;% ggplot(aes(x = sample.size, y = sd.of.means)) + geom_point() + geom_line(aes(x = sample.size, y = std.error), data = df.se.mean.theory, color = &quot;red&quot; ) + labs( x = &quot;Sample size&quot;, y = &quot;Std Error of Mean&quot;, title = &quot;平均值标准误差随样本大小变化（理论值和模拟值对比）&quot; ) 两者吻合的很好。 刚刚我们看到的，抽样均值分布随着样本大小变化而变化。可以试想下，抽样的其他统计量分布（方差，中位数），是不是也随着样本大小变化而变化呢？ sampling.distn.sd.table &lt;- df.combined %&gt;% group_by(sample.size) %&gt;% summarize( mean.of.sds = mean(sample.sd), sd.of.sds = sd(sample.sd) ) sampling.distn.sd.table ## # A tibble: 5 x 3 ## sample.size mean.of.sds sd.of.sds ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 30 15.1 1.99 ## 2 50 15.1 1.56 ## 3 100 15.2 1.07 ## 4 250 15.2 0.681 ## 5 500 15.2 0.486 答案是肯定的，样本量的增多，抽样方差的不确定性减少。 27.5 扩展阅读 https://learningstatisticswithr.com/book/ "],["lm.html", "第 28 章 线性回归 28.1 从一个案例开始 28.2 线性回归模型 28.3 使用lm() 函数 28.4 模型的解释 28.5 多元线性回归 28.6 更多模型 28.7 变量重要性 28.8 可能遇到的情形 28.9 延伸阅读 28.10 线性模型的物理解释", " 第 28 章 线性回归 线性模型是数据分析中最常用的一种分析方法。最基础的往往最深刻。 library(tidyverse) 28.1 从一个案例开始 这是一份1994年收集1379个对象关于收入、身高、教育水平等信息的数据集。数据在课件首页提供了下载链接。 首先，我们下载后导入数据 wages &lt;- read_csv(&quot;./demo_data/wages.csv&quot;) wages %&gt;% head() ## # A tibble: 6 x 6 ## earn height sex race ed age ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 79571. 73.9 male white 16 49 ## 2 96397. 66.2 female white 16 62 ## 3 48711. 63.8 female white 16 33 ## 4 80478. 63.2 female other 16 95 ## 5 82089. 63.1 female white 17 43 ## 6 15313. 64.5 female white 15 30 28.1.1 缺失值检查 一般情况下，拿到一份数据，首先要了解数据，知道每个变量的含义， wages %&gt;% colnames() ## [1] &quot;earn&quot; &quot;height&quot; &quot;sex&quot; &quot;race&quot; &quot;ed&quot; ## [6] &quot;age&quot; 同时检查数据是否有缺失值，这点很重要。在R中 NA（not available，不可用）表示缺失值, 比如可以这样检查是否有缺失值。 # 如何检查数据是否有缺失值？ wages %&gt;% summarise( earn_na = sum(is.na(earn)), height_na = sum(is.na(height)), sex_na = sum(is.na(sex)), race_na = sum(is.na(race)), ed_na = sum(is.na(ed)), age_na = sum(is.na(age)) ) ## # A tibble: 1 x 6 ## earn_na height_na sex_na race_na ed_na age_na ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 0 程序员都是偷懒的，所以也可以写的简便一点。大家在学习的过程中，也会慢慢的发现tidyverse的函数很贴心，很周到。 wages %&gt;% summarise_all( ~ sum(is.na(.)) ) ## # A tibble: 1 x 6 ## earn height sex race ed age ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 0 当然，也可以用purrr::map()的方法。这部分我会在后面的章节中逐步介绍。 wages %&gt;% map_df(~ sum(is.na(.))) ## # A tibble: 1 x 6 ## earn height sex race ed age ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 0 28.1.2 变量简单统计 然后探索下每个变量的分布。比如调研数据中男女的数量分别是多少？ wages %&gt;% count(sex) ## # A tibble: 2 x 2 ## sex n ## &lt;chr&gt; &lt;int&gt; ## 1 female 859 ## 2 male 520 男女这两组的身高均值分别是多少？收入的均值分别是多少？ wages %&gt;% group_by(sex) %&gt;% summarise( n = n(), mean_height = mean(height), mean_earn = mean(earn) ) ## # A tibble: 2 x 4 ## sex n mean_height mean_earn ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 859 64.5 24246. ## 2 male 520 70.0 45993. 也有可以用可视化的方法，呈现男女收入的分布情况 wages %&gt;% ggplot(aes(x = earn, color = sex)) + geom_density() 大家可以自行探索其他变量的情况。现在提出几个问题，希望大家带着这些问题去探索： 长的越高的人挣钱越多？ 是否男性就比女性挣的多？ 影响收入最大的变量是哪个？ 怎么判定我们建立的模型是不是很好？ 28.2 线性回归模型 长的越高的人挣钱越多？ 要回答这个问题，我们先介绍线性模型。顾名思义，就是认为\\(x\\)和\\(y\\)之间有线性关系，数学上可以写为 \\[ \\begin{aligned} y &amp;= \\alpha + \\beta x + \\epsilon \\\\ \\epsilon &amp;\\in \\text{Normal}(\\mu, \\sigma) \\end{aligned} \\] \\(\\epsilon\\) 代表误差项，它与\\(x\\) 无关，且服从正态分布。 建立线性模型，就是要估计这里的系数\\(\\hat\\alpha\\)和\\(\\hat\\beta\\)，即截距项和斜率项。常用的方法是最小二乘法（ordinary least squares (OLS) regression）： 就是我们估算的\\(\\hat\\alpha\\)和\\(\\hat\\beta\\), 要使得残差的平方和最小，即\\(\\sum_i(y_i - \\hat y_i)^2\\)或者叫\\(\\sum_i \\epsilon_i^2\\)最小。 当然，数据量很大，手算是不现实的，我们借助R语言代码吧 28.3 使用lm() 函数 用R语言代码(建议大家先?lm看看帮助文档)， lm参数很多, 但很多我们都用不上，所以我们只关注其中重要的两个参数 lm(formula = y ~ x, data) lm(y ~ x, data) 是最常用的线性模型函数(lm是linear model的缩写)。参数解释说明 formula：指定回归模型的公式，对于简单的线性回归模型y ~ x. ~ 符号：代表“预测”，可以读做“y由x预测”。有些学科不同的表述，比如下面都是可以的 response ~ explanatory dependent ~ independent outcome ~ predictors data：代表数据框，数据框包含了响应变量和独立变量 在运行lm()之前，先画出身高和收入的散点图(记在我们想干什么，寻找身高和收入的关系) wages %&gt;% ggplot(aes(x = height, y = earn)) + geom_point() 等不及了，就运行代码吧 mod1 &lt;- lm( formula = earn ~ height, data = wages ) 这里我们将earn作为响应变量，height为预测变量。lm()返回赋值给mod1. mod1现在是个什么东东呢？ mod1是一个叫lm object或者叫类的东西， names(mod1) ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; ## [4] &quot;rank&quot; &quot;fitted.values&quot; &quot;assign&quot; ## [7] &quot;qr&quot; &quot;df.residual&quot; &quot;xlevels&quot; ## [10] &quot;call&quot; &quot;terms&quot; &quot;model&quot; 我们打印看看，会发生什么 print(mod1) ## ## Call: ## lm(formula = earn ~ height, data = wages) ## ## Coefficients: ## (Intercept) height ## -126523 2387 这里有两部分信息。首先第一部分是我们建立的模型；第二部分是R给出了截距（\\(\\alpha = -126532\\)）和斜率（\\(\\beta = 2387\\)）. 也就是说我们建立的线性回归模型是 \\[ \\hat y = -126532 + 2387 \\; x \\] 查看详细信息 summary(mod1) ## ## Call: ## lm(formula = earn ~ height, data = wages) ## ## Residuals: ## Min 1Q Median 3Q Max ## -47903 -19744 -5184 11642 276796 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -126523 14076 -8.99 &lt;2e-16 *** ## height 2387 211 11.31 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29900 on 1377 degrees of freedom ## Multiple R-squared: 0.085, Adjusted R-squared: 0.0844 ## F-statistic: 128 on 1 and 1377 DF, p-value: &lt;2e-16 查看拟合值 # predict(mod1) # predictions at original x values wages %&gt;% modelr::add_predictions(mod1) ## # A tibble: 1,379 x 7 ## earn height sex race ed age pred ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 79571. 73.9 male white 16 49 49867. ## 2 96397. 66.2 female white 16 62 31581. ## 3 48711. 63.8 female white 16 33 25708. ## 4 80478. 63.2 female other 16 95 24395. ## 5 82089. 63.1 female white 17 43 24061. ## 6 15313. 64.5 female white 15 30 27522. ## 7 47104. 61.5 female white 12 53 20385. ## 8 50960. 73.3 male white 17 50 48434. ## 9 3213. 72.2 male hispanic 15 25 45928. ## 10 42997. 72.4 male white 12 30 46310. ## # ... with 1,369 more rows 查看残差值 # resid(mod1) wages %&gt;% modelr::add_predictions(mod1) %&gt;% modelr::add_residuals(mod1) ## # A tibble: 1,379 x 8 ## earn height sex race ed age pred resid ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 79571. 73.9 male white 16 49 49867. 29705. ## 2 96397. 66.2 fema~ white 16 62 31581. 64816. ## 3 48711. 63.8 fema~ white 16 33 25708. 23003. ## 4 80478. 63.2 fema~ other 16 95 24395. 56083. ## 5 82089. 63.1 fema~ white 17 43 24061. 58028. ## 6 15313. 64.5 fema~ white 15 30 27522. -12209. ## 7 47104. 61.5 fema~ white 12 53 20385. 26720. ## 8 50960. 73.3 male white 17 50 48434. 2526. ## 9 3213. 72.2 male hisp~ 15 25 45928. -42715. ## 10 42997. 72.4 male white 12 30 46310. -3313. ## # ... with 1,369 more rows 28.4 模型的解释 建立一个lm模型是简单的，然而最重要的是，我们能解释这个模型。 mod1的解释： 对于斜率\\(\\beta = 2387\\)意味着，当一个人的身高是68英寸时，他的预期收入\\(earn = -126532 + 2387 \\times 68= 35806\\) 美元， 换个方式说，身高\\(height\\)每增加一个1英寸, 收入\\(earn\\)会增加2387美元。 对于截距\\(\\alpha = -126532\\)，即当身高为0时，期望的收入值-126532。呵呵，人的身高不可能为0，所以这是一种极端的理论情况，现实不可能发生。 wages %&gt;% ggplot(aes(x = height, y = earn)) + geom_point(alpha = 0.25) + geom_smooth(method = &quot;lm&quot;, se = FALSE) 28.5 多元线性回归 刚才讨论的单个预测变量height，现在我们增加一个预测变量ed，稍微扩展一下我们的一元线性模型，就是多元回归模型 \\[ \\begin{aligned} earn &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 \\text{ed} +\\epsilon \\\\ \\end{aligned} \\] R语言代码实现也很简单，只需要把变量ed增加在公式的右边 mod2 &lt;- lm(earn ~ height + ed, data = wages) 同样，我们打印mod2看看 mod2 ## ## Call: ## lm(formula = earn ~ height + ed, data = wages) ## ## Coefficients: ## (Intercept) height ed ## -161541 2087 4118 大家试着解释下mod2.  28.6 更多模型 lm(earn ~ sex, data = wages) lm(earn ~ ed, data = wages) lm(earn ~ age, data = wages) lm(earn ~ height + sex, data = wages) lm(earn ~ height + ed, data = wages) lm(earn ~ height + age, data = wages) lm(earn ~ height + race, data = wages) lm(earn ~ height + sex + ed, data = wages) lm(earn ~ height + sex + age, data = wages) lm(earn ~ height + sex + race, data = wages) lm(earn ~ height + ed + age, data = wages) lm(earn ~ height + ed + race, data = wages) lm(earn ~ height + age + race, data = wages) lm(earn ~ height + sex + ed + age, data = wages) lm(earn ~ height + sex + ed + race, data = wages) lm(earn ~ height + sex + age + race, data = wages) lm(earn ~ height + ed + age + race, data = wages) lm(earn ~ sex + ed + age + race, data = wages) lm(earn ~ height + sex + ed + age + race, data = wages) 28.7 变量重要性 哪个变量对收入的影响最大？ lm(earn ~ height + ed + age, data = wages) 方法一，变量都做标准化处理后，再放到模型中计算，然后对比系数的绝对值 fit &lt;- wages %&gt;% mutate_at(vars(earn, height, ed, age), scale) %&gt;% lm(earn ~ 1 + height + ed + age, data = .) summary(fit) ## ## Call: ## lm(formula = earn ~ 1 + height + ed + age, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.921 -0.536 -0.121 0.353 8.298 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.77e-16 2.40e-02 0.00 1 ## height 2.74e-01 2.43e-02 11.26 &lt; 2e-16 *** ## ed 3.39e-01 2.43e-02 13.97 &lt; 2e-16 *** ## age 1.55e-01 2.44e-02 6.35 2.9e-10 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.89 on 1375 degrees of freedom ## Multiple R-squared: 0.21, Adjusted R-squared: 0.208 ## F-statistic: 122 on 3 and 1375 DF, p-value: &lt;2e-16 方法二，通过比较模型参数的t-statistic的绝对值，可以考察参数的重要程度 caret::varImp(fit) ## Overall ## height 11.26 ## ed 13.97 ## age 6.35 28.8 可能遇到的情形 根据同学们的建议，模型中涉及统计知识，留给统计老师讲，我们这里是R语言课，应该讲代码。 因此，这里再介绍几种线性回归中遇到的几种特殊情况 28.8.1 截距项 # 包含截距，以下两者是等价的 lm(earn ~ 1 + height, data = wages) lm(earn ~ height, data = wages) # 去掉截距，以下两者是等价的 lm(earn ~ height - 1, data = wages) lm(earn ~ 0 + height, data = wages) 不包含截距项，实际上就是强制通过原点(0,0)，这样做很大程度上影响了斜率。 28.8.2 只有截距项 lm(earn ~ 1, data = wages) ## ## Call: ## lm(formula = earn ~ 1, data = wages) ## ## Coefficients: ## (Intercept) ## 32446 只有截距项，实质上就是计算y变量的均值 wages %&gt;% summarise( mean_wages = mean(earn) ) ## # A tibble: 1 x 1 ## mean_wages ## &lt;dbl&gt; ## 1 32446. 28.8.3 分类变量 race变量就是数据框wages的一个分类变量，代表四个不同的种族。用分类变量做回归，本质上是各组之间的进行比较。 wages %&gt;% distinct(race) ## # A tibble: 4 x 1 ## race ## &lt;chr&gt; ## 1 white ## 2 other ## 3 hispanic ## 4 black wages %&gt;% ggplot(aes(x = race, y = earn, fill = race)) + geom_boxplot(position = position_dodge()) + scale_y_continuous(limits = c(0, 20000)) 以分类变量作为解释变量，做线性回归 mod3 &lt;- lm(earn ~ race, data = wages) mod3 ## ## Call: ## lm(formula = earn ~ race, data = wages) ## ## Coefficients: ## (Intercept) racehispanic raceother ## 28372 -2887 3905 ## racewhite ## 4993 tidyverse框架下，喜欢数据框的统计结果，因此，可用broom的tidy()函数将模型输出转换为数据框的形式 broom::tidy(mod3) ## # A tibble: 4 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 28372. 2781. 10.2 1.29e-23 ## 2 racehispanic -2887. 4515. -0.639 5.23e- 1 ## 3 raceother 3905. 6428. 0.608 5.44e- 1 ## 4 racewhite 4993. 2929. 1.70 8.85e- 2 我们看到输出结果，只有race_hispanic、 race_other和race_white三个系数和Intercept截距，race_black去哪里了呢？ 事实上，race变量里有4组，回归时，选择black为基线，hispanic的系数，可以理解为由black切换到hispanic，引起earn收入的变化（效应） 对 black 组的估计，earn = 28372.09 = 28372.09 对 hispanic组的估计，earn = 28372.09 + -2886.79 = 25485.30 对 other 组的估计，earn = 28372.09 + 3905.32 = 32277.41 对 white 组的估计，earn = 28372.09 + 4993.33 = 33365.42 分类变量的线性回归本质上就是方差分析 第 30 章专题讨论方差分析 28.8.4 因子变量 hispanic组的估计最低，适合做基线，因此可以将race转换为因子变量，这样方便调整因子先后顺序 wages_fct &lt;- wages %&gt;% mutate(race = factor(race, levels = c(&quot;hispanic&quot;, &quot;white&quot;, &quot;black&quot;, &quot;other&quot;))) %&gt;% select(earn, race) head(wages_fct) ## # A tibble: 6 x 2 ## earn race ## &lt;dbl&gt; &lt;fct&gt; ## 1 79571. white ## 2 96397. white ## 3 48711. white ## 4 80478. other ## 5 82089. white ## 6 15313. white wages_fct替换wages，然后建立线性模型 mod4 &lt;- lm(earn ~ race, data = wages_fct) broom::tidy(mod4) ## # A tibble: 4 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 25485. 3557. 7.16 1.26e-12 ## 2 racewhite 7880. 3674. 2.14 3.22e- 2 ## 3 raceblack 2887. 4515. 0.639 5.23e- 1 ## 4 raceother 6792. 6800. 0.999 3.18e- 1 以hispanic组作为基线，各组系数也调整了，但加上截距后，实际值是没有变的。 大家可以用sex变量试试看 lm(earn ~ sex, data = wages) 28.8.5 一个分类变量和一个连续变量 如果预测变量是一个分类变量和一个连续变量 mod5 &lt;- lm(earn ~ height + sex, data = wages) coef(mod5) ## (Intercept) height sexmale ## -32479.9 879.4 16874.2 height = 879.424 当sex保持不变时，height变化引起的earn变化 sexmale = 16874.158 当height保持不变时，sex变化(female变为male)引起的earn变化 p1 &lt;- wages %&gt;% ggplot(aes(x = height, y = earn, color = sex)) + geom_point(alpha = 0.1) + geom_line(aes(y = predict(mod5))) + scale_y_continuous(limits = c(0, 100000)) p1 28.8.6 偷懒的写法 . is shorthand for “everything else.” lm(earn ~ height + sex + race + ed + age, data = wages) lm(earn ~ ., data = wages) lm(earn ~ height + sex + race + ed, data = wages) lm(earn ~ . - age, data = wages) R 语言很多时候都出现了.，不同的场景，含义是不一样的。我会在后面第 25 章专门讨论这个问题， 这是一个非常重要的问题 28.8.7 交互项 lm(earn ~ height + sex + height:sex, data = wages) lm(earn ~ height * sex, data = wages) lm(earn ~ (height + sex)^2, data = wages) lm(earn ~ height:sex, data = wages) lm(earn ~ height:sex:race, data = wages) mod6 &lt;- lm(earn ~ height + sex + height:sex, data = wages) coef(mod6) ## (Intercept) height sexmale ## -12167.0 564.5 -30510.4 ## height:sexmale ## 701.4 对于女性，height增长1个单位，引起earn的增长564.5102 对于男性，height增长1个单位，引起earn的增长564.5102 + 701.4065 = 1265.92 p2 &lt;- wages %&gt;% ggplot(aes(x = height, y = earn, color = sex)) + geom_point(alpha = 0.1) + geom_line(aes(y = predict(mod6))) + scale_y_continuous(limits = c(0, 100000)) p2 注意，没有相互项和有相互项的区别 library(patchwork) combined &lt;- p1 + p2 &amp; theme(legend.position = &quot;bottom&quot;) combined + plot_layout(guides = &quot;collect&quot;) 28.8.8 虚拟变量 交互项，有点不好理解？我们再细致说一遍 earn ~ height + sex + height:sex 对应的数学表达式 \\[ \\begin{aligned} \\text{earn} &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 \\text{sex} +\\beta_3 \\text{(height*sex)}+ \\epsilon \\\\ \\end{aligned} \\] 我们要求出其中的\\(\\alpha, \\beta_1, \\beta_2, \\beta_3\\)，事实上，分类变量在R语言代码里，会转换成0和1这种虚拟变量，然后再计算。类似 wages %&gt;% mutate(sexmale = if_else(sex == &quot;female&quot;, 0, 1)) ## # A tibble: 1,379 x 7 ## earn height sex race ed age sexmale ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 79571. 73.9 male white 16 49 1 ## 2 96397. 66.2 female white 16 62 0 ## 3 48711. 63.8 female white 16 33 0 ## 4 80478. 63.2 female other 16 95 0 ## 5 82089. 63.1 female white 17 43 0 ## 6 15313. 64.5 female white 15 30 0 ## 7 47104. 61.5 female white 12 53 0 ## 8 50960. 73.3 male white 17 50 1 ## 9 3213. 72.2 male hispanic 15 25 1 ## 10 42997. 72.4 male white 12 30 1 ## # ... with 1,369 more rows 那么上面的公式变为 \\[ \\begin{aligned} \\text{earn} &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 \\text{sexmale} +\\beta_3 \\text{(height*sexmale)}+ \\epsilon \\\\ \\end{aligned} \\] 于是，可以将上面的公式里男性(sexmale = 1)和女性(sexmale = 0)分别表示 \\[ \\begin{aligned} \\text{female}\\qquad earn &amp;= \\alpha + \\beta_1 \\text{height} +\\epsilon \\\\ \\text{male}\\qquad earn &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 *1 +\\beta_3 \\text{(height*1)}+ \\epsilon \\\\ &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_2 +\\beta_3 \\text{height}+ \\epsilon \\\\ &amp; = (\\alpha + \\beta_2) + (\\beta_1 + \\beta_3)\\text{height} + \\epsilon \\\\ \\end{aligned} \\] 我们再对比mod6结果中的系数\\(\\alpha, \\beta_1, \\beta_2, \\beta_3\\) mod6 ## ## Call: ## lm(formula = earn ~ height + sex + height:sex, data = wages) ## ## Coefficients: ## (Intercept) height sexmale ## -12167 565 -30510 ## height:sexmale ## 701 是不是更容易理解呢？ 对于女性，(截距\\(\\alpha\\)，系数\\(\\beta_1\\))，height增长1个单位，引起earn的增长564.5102 对于男性，(截距\\(\\alpha + \\beta_2\\)，系数\\(\\beta_1 + \\beta_3\\))，height增长1个单位，引起earn的增长564.5102 + 701.4065 = 1265.92 事实上，对于男性和女性，截距和系数都不同，因此这种情形等价于，按照sex分成两组，男性算男性的斜率，女性算女性的斜率 wages %&gt;% group_by(sex) %&gt;% group_modify( ~ broom::tidy(lm(earn ~ height, data = .)) ) ## # A tibble: 4 x 6 ## # Groups: sex [2] ## sex term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female (Interce~ -12167. 20160. -0.604 0.546 ## 2 female height 565. 312. 1.81 0.0710 ## 3 male (Interce~ -42677. 38653. -1.10 0.270 ## 4 male height 1266. 551. 2.30 0.0221 wages %&gt;% ggplot(aes(x = height, y = earn, color = sex)) + geom_smooth(method = lm, se = F) wages %&gt;% ggplot(aes(x = height, y = earn, color = sex)) + geom_line(aes(y = predict(mod6))) 如果再特殊一点的模型（有点过分了） mod7 &lt;- lm(earn ~ height + height:sex, data = wages) coef(mod7) ## (Intercept) height height:sexmale ## -24632.7 757.5 251.3 这又怎么理解呢？ 我们还是按照数学模型来理解，这里对应的数学表达式 \\[ \\begin{aligned} \\text{earn} &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_4 \\text{(height*sex)}+ \\epsilon \\\\ \\end{aligned} \\] 引入虚拟变量 \\[ \\begin{aligned} \\text{earn} &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_4 \\text{(height*sexmale)}+ \\epsilon \\\\ \\end{aligned} \\] 同样假定男性(sexmale = 1)和女性(sexmale = 0)，那么 \\[ \\begin{aligned} \\text{female}\\qquad earn &amp;= \\alpha + \\beta_1 \\text{height} +\\epsilon \\\\ \\text{male}\\qquad earn &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_4 \\text{(height*1)}+ \\epsilon \\\\ &amp;= \\alpha + \\beta_1 \\text{height} + \\beta_4 \\text{height}+ \\epsilon \\\\ &amp; = \\alpha + (\\beta_1 + \\beta_4)\\text{height} + \\epsilon \\\\ \\end{aligned} \\] 对照模型mod7的结果，我们可以理解： 对于女性(截距\\(\\alpha\\)，系数\\(\\beta_1\\))，height增长1个单位，引起earn的增长757.4661 对于男性(截距\\(\\alpha\\)，系数$_1 + _4 $)，height增长1个单位，引起earn的增长757.4661 + 251.2915 = 1008.758 注意到，mod6和mod7是两个不同的模型, mod7中男女拟合曲线在y轴的截距是相同的，而mod6在y轴的截距是不同的 28.8.9 predict vs fit fitted() , 模型一旦建立，可以使用拟合函数fitted()返回拟合值，建模和拟合使用的是同一数据 predict()， 模型建立后，可以用新的数据进行预测，predict()要求数据框包含新的预测变量，如果没有提供，那么就使用建模时的预测变量进行预测，这种情况下，得出的结果和fitted()就时一回事了。 predict()函数和fitted()函数不同的地方，还在于predict()函数往往带有返回何种类型的选项，可以是具体数值，也可以是分类变量。具体会在第 37 章介绍。 28.8.10 回归和相关的关系 相关，比如求两个变量的相关系数cor(x, y) 回归，也是探寻自变量和因变量的关系，一般用来预测 回归分析中，如果自变量只有一个\\(x\\)，也就是模型lm(y~x)，那么回归和相关就有关联了。 比如：计算身高和收入两者的Pearson相关系数的平方 r &lt;- cor(wages$height, wages$earn) print(r^2) ## [1] 0.08503 然后看看，身高和收入的线性模型 lm(formula = earn ~ height, data = wages) %&gt;% broom::glance() %&gt;% pull(r.squared) ## [1] 0.08503 相关系数的平方 和 线性模型的\\(R^2\\)是相等的 28.9 延伸阅读 一篇极富思考性和启发性的文章《常见统计检验的本质是线性模型》 28.10 线性模型的物理解释 图中，中间蓝色点是这些数据点的均值点，线性模型可以类比为，这里有一根通过这个均值点的刚体，而每个数据点都是一个弹簧，竖直连接到刚体，很显然越远的点，对刚体的拉力越大，越近越小，最后刚体达到平衡状态，此时刚体的状态就是线性回归的直线。 可参考Least squares as springs "],["broom.html", "第 29 章 模型输出结果的规整 29.1 案例 29.2 broom 29.3 应用 29.4 练习", " 第 29 章 模型输出结果的规整 29.1 案例 还是用第 13 章的gapminder案例 library(tidyverse) library(gapminder) gapminder ## # A tibble: 1,704 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanist~ Asia 1952 28.8 8.43e6 779. ## 2 Afghanist~ Asia 1957 30.3 9.24e6 821. ## 3 Afghanist~ Asia 1962 32.0 1.03e7 853. ## 4 Afghanist~ Asia 1967 34.0 1.15e7 836. ## 5 Afghanist~ Asia 1972 36.1 1.31e7 740. ## 6 Afghanist~ Asia 1977 38.4 1.49e7 786. ## 7 Afghanist~ Asia 1982 39.9 1.29e7 978. ## 8 Afghanist~ Asia 1987 40.8 1.39e7 852. ## 9 Afghanist~ Asia 1992 41.7 1.63e7 649. ## 10 Afghanist~ Asia 1997 41.8 2.22e7 635. ## # ... with 1,694 more rows 29.1.1 可视化探索 画个简单的图 gapminder %&gt;% ggplot(aes(x = log(gdpPercap), y = lifeExp)) + geom_point(alpha = 0.2) 我们想用不同的模型拟合log(gdpPercap)与lifeExp的关联 library(colorspace) model_colors &lt;- colorspace::qualitative_hcl(4, palette = &quot;dark 2&quot;) # model_colors &lt;- c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;) ggplot( data = gapminder, mapping = aes(x = log(gdpPercap), y = lifeExp) ) + geom_point(alpha = 0.2) + geom_smooth( method = &quot;lm&quot;, aes(color = &quot;OLS&quot;, fill = &quot;OLS&quot;) # one ) + geom_smooth( method = &quot;lm&quot;, formula = y ~ splines::bs(x, df = 3), aes(color = &quot;Cubic Spline&quot;, fill = &quot;Cubic Spline&quot;) # two ) + geom_smooth( method = &quot;loess&quot;, aes(color = &quot;LOESS&quot;, fill = &quot;LOESS&quot;) # three ) + scale_color_manual(name = &quot;Models&quot;, values = model_colors) + scale_fill_manual(name = &quot;Models&quot;, values = model_colors) + theme(legend.position = &quot;top&quot;) 29.1.2 简单模型 还是回到我们今天的主题。我们建立一个简单的线性模型 out &lt;- lm( formula = lifeExp ~ gdpPercap + pop + continent, data = gapminder ) out ## ## Call: ## lm(formula = lifeExp ~ gdpPercap + pop + continent, data = gapminder) ## ## Coefficients: ## (Intercept) gdpPercap ## 4.78e+01 4.50e-04 ## pop continentAmericas ## 6.57e-09 1.35e+01 ## continentAsia continentEurope ## 8.19e+00 1.75e+01 ## continentOceania ## 1.81e+01 str(out) summary(out) ## ## Call: ## lm(formula = lifeExp ~ gdpPercap + pop + continent, data = gapminder) ## ## Residuals: ## Min 1Q Median 3Q Max ## -49.16 -4.49 0.30 5.11 25.17 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.78e+01 3.40e-01 140.82 &lt;2e-16 ## gdpPercap 4.50e-04 2.35e-05 19.16 &lt;2e-16 ## pop 6.57e-09 1.98e-09 3.33 9e-04 ## continentAmericas 1.35e+01 6.00e-01 22.46 &lt;2e-16 ## continentAsia 8.19e+00 5.71e-01 14.34 &lt;2e-16 ## continentEurope 1.75e+01 6.25e-01 27.97 &lt;2e-16 ## continentOceania 1.81e+01 1.78e+00 10.15 &lt;2e-16 ## ## (Intercept) *** ## gdpPercap *** ## pop *** ## continentAmericas *** ## continentAsia *** ## continentEurope *** ## continentOceania *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.37 on 1697 degrees of freedom ## Multiple R-squared: 0.582, Adjusted R-squared: 0.581 ## F-statistic: 394 on 6 and 1697 DF, p-value: &lt;2e-16 模型的输出结果是一个复杂的list，图 29.1给出了out的结构 图 29.1: 线性模型结果的示意图 我们发现out对象包含了很多元素，比如系数、残差、模型残差自由度等等，用读取列表的方法可以直接读取 out$coefficients out$residuals out$fitted.values 事实上，前面使用的suammary()函数只是选取和打印了out对象的一小部分信息，同时这些信息的结构不适合用dplyr操作和ggplot2画图。 29.2 broom 为规整模型结果，这里我们推荐用David Robinson 开发的broom宏包。 library(broom) broom 宏包将常用的100多种模型的输出结果规整成数据框 tibble()的格式，在模型比较和可视化中就可以方便使用dplyr函数了。 broom 提供了三个主要的函数: tidy() 提取模型输出结果的主要信息，比如 coefficients 和 t-statistics glance() 把模型视为一个整体，提取如 F-statistic，model deviance 或者 r-squared等信息 augment() 模型输出的信息添加到建模用的数据集中，比如fitted values 和 residuals 29.2.1 tidy tidy(out) ## # A tibble: 7 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 4.78e+1 3.40e-1 141. 0. ## 2 gdpPercap 4.50e-4 2.35e-5 19.2 3.24e- 74 ## 3 pop 6.57e-9 1.98e-9 3.33 9.01e- 4 ## 4 continentAm~ 1.35e+1 6.00e-1 22.5 5.19e- 98 ## 5 continentAs~ 8.19e+0 5.71e-1 14.3 4.06e- 44 ## 6 continentEu~ 1.75e+1 6.25e-1 28.0 6.34e-142 ## 7 continentOc~ 1.81e+1 1.78e+0 10.1 1.59e- 23 out %&gt;% tidy() %&gt;% ggplot(mapping = aes( x = term, y = estimate )) + geom_point() + coord_flip() 可以很方便的获取系数的置信区间 out %&gt;% tidy(conf.int = TRUE) ## # A tibble: 7 x 7 ## term estimate std.error statistic p.value conf.low ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Int~ 4.78e+1 3.40e-1 141. 0. 4.71e+1 ## 2 gdpP~ 4.50e-4 2.35e-5 19.2 3.24e- 74 4.03e-4 ## 3 pop 6.57e-9 1.98e-9 3.33 9.01e- 4 2.70e-9 ## 4 cont~ 1.35e+1 6.00e-1 22.5 5.19e- 98 1.23e+1 ## 5 cont~ 8.19e+0 5.71e-1 14.3 4.06e- 44 7.07e+0 ## 6 cont~ 1.75e+1 6.25e-1 28.0 6.34e-142 1.62e+1 ## 7 cont~ 1.81e+1 1.78e+0 10.1 1.59e- 23 1.46e+1 ## # ... with 1 more variable: conf.high &lt;dbl&gt; out %&gt;% tidy(conf.int = TRUE) %&gt;% filter(!term %in% c(&quot;(Intercept)&quot;)) %&gt;% ggplot(aes( x = reorder(term, estimate), y = estimate, ymin = conf.low, ymax = conf.high )) + geom_pointrange() + coord_flip() + labs(x = &quot;&quot;, y = &quot;OLS Estimate&quot;) 29.2.2 augment augment()会返回一个数据框，这个数据框是在原始数据框的基础上，增加了模型的拟合值（.fitted）, 拟合值的标准误（.se.fit）, 残差（.resid）等列。 augment(out) ## # A tibble: 1,704 x 10 ## lifeExp gdpPercap pop continent .fitted .resid ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 28.8 779. 8.43e6 Asia 56.4 -27.6 ## 2 30.3 821. 9.24e6 Asia 56.4 -26.1 ## 3 32.0 853. 1.03e7 Asia 56.5 -24.5 ## 4 34.0 836. 1.15e7 Asia 56.5 -22.4 ## 5 36.1 740. 1.31e7 Asia 56.4 -20.3 ## 6 38.4 786. 1.49e7 Asia 56.5 -18.0 ## 7 39.9 978. 1.29e7 Asia 56.5 -16.7 ## 8 40.8 852. 1.39e7 Asia 56.5 -15.7 ## 9 41.7 649. 1.63e7 Asia 56.4 -14.7 ## 10 41.8 635. 2.22e7 Asia 56.4 -14.7 ## # ... with 1,694 more rows, and 4 more variables: ## # .std.resid &lt;dbl&gt;, .hat &lt;dbl&gt;, .sigma &lt;dbl&gt;, ## # .cooksd &lt;dbl&gt; out %&gt;% augment() %&gt;% ggplot(mapping = aes(x = lifeExp, y = .fitted)) + geom_point() 29.2.3 glance glance() 函数也会返回数据框，但这个数据框只有一行，内容实际上是summary()输出结果的最底下一行。 glance(out) ## # A tibble: 1 x 12 ## r.squared adj.r.squared sigma statistic p.value ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.582 0.581 8.37 394. 3.94e-317 ## # ... with 7 more variables: df &lt;dbl&gt;, logLik &lt;dbl&gt;, ## # AIC &lt;dbl&gt;, BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, ## # df.residual &lt;int&gt;, nobs &lt;int&gt; 29.3 应用 broom的三个主要函数在分组统计建模时，格外方便。 penguins &lt;- palmerpenguins::penguins %&gt;% drop_na() penguins %&gt;% group_nest(species) %&gt;% mutate(model = purrr::map(data, ~ lm(bill_depth_mm ~ bill_length_mm, data = .))) %&gt;% mutate(glance = purrr::map(model, ~ broom::glance(.))) %&gt;% tidyr::unnest(glance) ## # A tibble: 3 x 15 ## species data model r.squared adj.r.squared sigma ## &lt;fct&gt; &lt;list&lt;tb&gt; &lt;lis&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie [146 x 7] &lt;lm&gt; 0.149 0.143 1.13 ## 2 Chinst~ [68 x 7] &lt;lm&gt; 0.427 0.418 0.866 ## 3 Gentoo [119 x 7] &lt;lm&gt; 0.428 0.423 0.749 ## # ... with 9 more variables: statistic &lt;dbl&gt;, ## # p.value &lt;dbl&gt;, df &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, ## # BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt;, ## # nobs &lt;int&gt; fit_ols &lt;- function(df) { lm(body_mass_g ~ bill_depth_mm + bill_length_mm, data = df) } out_tidy &lt;- penguins %&gt;% group_nest(species) %&gt;% mutate(model = purrr::map(data, fit_ols)) %&gt;% mutate(tidy = purrr::map(model, ~ broom::tidy(.))) %&gt;% tidyr::unnest(tidy) %&gt;% dplyr::filter(!term %in% &quot;(Intercept)&quot;) out_tidy ## # A tibble: 6 x 8 ## species data model term estimate std.error ## &lt;fct&gt; &lt;list&lt;tb&gt; &lt;lis&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie [146 x 7] &lt;lm&gt; bill~ 164. 25.1 ## 2 Adelie [146 x 7] &lt;lm&gt; bill~ 64.8 11.5 ## 3 Chinst~ [68 x 7] &lt;lm&gt; bill~ 159. 43.3 ## 4 Chinst~ [68 x 7] &lt;lm&gt; bill~ 23.8 14.7 ## 5 Gentoo [119 x 7] &lt;lm&gt; bill~ 255. 40.0 ## 6 Gentoo [119 x 7] &lt;lm&gt; bill~ 54.7 12.7 ## # ... with 2 more variables: statistic &lt;dbl&gt;, ## # p.value &lt;dbl&gt; out_tidy %&gt;% ggplot(aes( x = species, y = estimate, ymin = estimate - 2 * std.error, ymax = estimate + 2 * std.error, color = term )) + geom_pointrange(position = position_dodge(width = 0.25)) + theme(legend.position = &quot;top&quot;) + labs(x = NULL, y = &quot;Estimate&quot;, color = &quot;系数&quot;) 29.4 练习 假定数据是 df &lt;- tibble( x = runif(30, 2, 10), y = -2*x + rnorm(30, 0, 5) ) df ## # A tibble: 30 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 8.59 -19.3 ## 2 7.95 -8.92 ## 3 8.06 -16.3 ## 4 2.82 -3.84 ## 5 2.17 -4.88 ## 6 5.19 -5.14 ## 7 7.94 -16.1 ## 8 8.01 -28.1 ## 9 4.10 -3.55 ## 10 9.62 -12.2 ## # ... with 20 more rows 用broom::augment()和ggplot2做出类似的残差图 "],["tidystats.html", "第 30 章 Tidy Statistics 30.1 方法的区分 30.2 从一个案例开始 30.3 单因素方差分析 30.4 双因素方差分析 30.5 在tidyverse中的应用", " 第 30 章 Tidy Statistics 一个事实是，用统计的，往往不是学统计的。 对非统计专业的初学者（比如我）感觉 t-test， ANOVAs， Chi-Square test等太不友好了，每次用的时候，我都要去翻书看我用对了没有，还要担心p-value是否徘徊在0.05附近。或许，从t-test等统计检验方法开始学统计是个错误的开始。我有时候在想，我们是不是应该更关心模型的理解，或者模型背后的理论呢。（如果和我的想法一样，就跳过本章吧） 想归想，但同学们对这方面的需求很大，所以还是打算介绍基本的方差分析内容。 30.1 方法的区分 比较几组数据之间是否有显著性差异，最常用的方法有以下几种 X变量类型 X组别数量 Y变量类型 分析方法 R语法 定类 2组或者多组 定量 方差 aov() 定类 仅仅2组 定量 t检验 t.test() 定类 2组或者多组 定类 卡方 chisq.test() 根据X变量的个数，方差分析又分为单因素方差分析和多因素方差分析，当X的个数（不是组别数量）为1个时，我们称之为单因素方差；X的个数为2个时，则为双因素方差。 30.2 从一个案例开始 从这是一份1994年收集1379个对象关于收入、身高、教育水平等信息的数据集，数据在课件首页下载。 首先，我们下载后导入数据 library(tidyverse) wages &lt;- read_csv(&quot;./demo_data/wages.csv&quot;) wages %&gt;% head() %&gt;% knitr::kable() earn height sex race ed age 79571 73.89 male white 16 49 96397 66.23 female white 16 62 48711 63.77 female white 16 33 80478 63.22 female other 16 95 82089 63.08 female white 17 43 15313 64.53 female white 15 30 我们的问题：男性是否就比女性挣的多？ 30.3 单因素方差分析 t.test(earn ~ sex, data = wages) ## ## Welch Two Sample t-test ## ## data: earn by sex ## t = -12, df = 768, p-value &lt;2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -25324 -18171 ## sample estimates: ## mean in group female mean in group male ## 24246 45993 lm(earn ~ sex, data = wages) %&gt;% summary() ## ## Call: ## lm(formula = earn ~ sex, data = wages) ## ## Residuals: ## Min 1Q Median 3Q Max ## -46092 -20516 -4639 11722 271956 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 24246 1004 24.1 &lt;2e-16 *** ## sexmale 21748 1636 13.3 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29400 on 1377 degrees of freedom ## Multiple R-squared: 0.114, Adjusted R-squared: 0.113 ## F-statistic: 177 on 1 and 1377 DF, p-value: &lt;2e-16 aov(earn ~ sex, data = wages) %&gt;% summary() ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## sex 1 1.53e+11 1.53e+11 177 &lt;2e-16 *** ## Residuals 1377 1.19e+12 8.66e+08 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 30.4 双因素方差分析 我们采用ggpubr宏包下的ToothGrowth来说明，这个数据集包含60个样本，记录着每10只豚鼠在不同的喂食方法和不同的药物剂量下，牙齿的生长情况. len : 牙齿长度 supp : 两种喂食方法 (橙汁和维生素C) dose : 抗坏血酸剂量 (0.5, 1, and 2 mg) library(&quot;ggpubr&quot;) my_data &lt;- ToothGrowth %&gt;% mutate_at(vars(supp, dose), ~ as_factor(.)) my_data %&gt;% head() ## len supp dose ## 1 4.2 VC 0.5 ## 2 11.5 VC 0.5 ## 3 7.3 VC 0.5 ## 4 5.8 VC 0.5 ## 5 6.4 VC 0.5 ## 6 10.0 VC 0.5 my_data %&gt;% ggplot(aes(x = supp, y = len, fill = supp)) + geom_boxplot(position = position_dodge()) + facet_wrap(vars(dose)) + labs(title = &quot;VC剂量和摄入方式对豚鼠牙齿的影响&quot;) 问题：豚鼠牙齿的长度是否与药物的食用方法和剂量有关？ 线性回归时，我们是通过独立变量来预测响应变量，但现在我们关注的重点会从预测转向不同组别差异之间的分析，这即为方差分析（ANOVA）。 这里是两个解释变量，所以问题需要双因素方差分析 (ANOVA) aov(len ~ supp + dose, data = my_data) %&gt;% broom::tidy() ## # A tibble: 3 x 6 ## term df sumsq meansq statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 supp 1 205. 205. 14.0 4.29e- 4 ## 2 dose 2 2426. 1213. 82.8 1.87e-17 ## 3 Residuals 56 820. 14.7 NA NA 检验表明不同类型之间存在显著差异，但是并没有告诉我们具体谁与谁之间的不同。需要多重比较帮助我们解决这个问题。使用TurkeyHSD函数 aov(len ~ supp + dose, data = my_data) %&gt;% TukeyHSD(which = &quot;dose&quot;) %&gt;% broom::tidy() ## # A tibble: 3 x 7 ## term contrast null.value estimate conf.low conf.high ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 dose 1-0.5 0 9.13 6.22 12.0 ## 2 dose 2-0.5 0 15.5 12.6 18.4 ## 3 dose 2-1 0 6.37 3.45 9.28 ## # ... with 1 more variable: adj.p.value &lt;dbl&gt; aov(len ~ supp + dose, data = my_data) %&gt;% TukeyHSD(which = &quot;supp&quot;) %&gt;% broom::tidy() ## # A tibble: 1 x 7 ## term contrast null.value estimate conf.low conf.high ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 supp VC-OJ 0 -3.7 -5.68 -1.72 ## # ... with 1 more variable: adj.p.value &lt;dbl&gt; 思考：交互效应是否显著？ aov(len ~ supp * dose, data = my_data) %&gt;% broom::tidy() ## # A tibble: 4 x 6 ## term df sumsq meansq statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 supp 1 205. 205. 15.6 2.31e- 4 ## 2 dose 2 2426. 1213. 92.0 4.05e-18 ## 3 supp:dose 2 108. 54.2 4.11 2.19e- 2 ## 4 Residuals 54 712. 13.2 NA NA 30.5 在tidyverse中的应用 我们也可以配合强大的tidyverse函数，完成不同分组下的方差分析，比如 mtcars %&gt;% group_by(cyl) %&gt;% summarise( broom::tidy(aov(mpg ~ gear, data = cur_data())), .groups = &quot;keep&quot; ) %&gt;% select(term, statistic, p.value) %&gt;% filter(term != &quot;Residuals&quot;) %&gt;% arrange(p.value) ## # A tibble: 3 x 4 ## # Groups: cyl [3] ## cyl term statistic p.value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 gear 1.17 0.308 ## 2 8 gear 0.0297 0.866 ## 3 6 gear 0.000451 0.984 更多使用可参考第 22 章。 "],["tests-as-linear.html", "第 31 章 统计检验与线性模型的等价性 31.1 t检验 31.2 关联 31.3 单因素方差分析 31.4 单因素协变量分析 31.5 双因素方差分析", " 第 31 章 统计检验与线性模型的等价性 心理学专业的同学最喜欢的统计方法，估计是方差分析(ANOVA) 和它的堂兄协变量分析 (ANCOVA)，事实上常用的统计检验本质上都是线性模型，所以你学了线性模型，就可以不用学统计检验了，是不是很开心？ 本章，我们将通过几个案例展示统计检验与线性模型的等价性，因此我们这里只关注代码本身，不关注模型的好坏以及模型的解释。部分代码和思想来自 Jonas Kristoffer Lindeløv experim是一个模拟的数据集，这个虚拟的研究目的是，考察两种不同类型的干预措施对帮助学生应对即将到来的统计学课程的焦虑的影响。实验方案如下： 首先，学生完成一定数量的量表(量表1)，包括对统计学课程的害怕(fost)，自信(confid)，抑郁(depress)指标 然后，学生被等分成两组，组1 进行技能提升训练；组2进行信心提升训练。训练结束后，完成相同的量表(量表2) 三个月后，他们再次完成相同的量表(量表3) 也就说，相同的指标在不同的时期测了三次，目的是考察期间的干预措施对若干指标的影响。 library(tidyverse) library(knitr) library(kableExtra) edata &lt;- read_csv(&quot;./demo_data/Experim.csv&quot;) %&gt;% mutate(group = if_else(group == &quot;maths skills&quot;, 1, 2)) %&gt;% mutate( across(c(sex, id, group), as.factor) ) edata ## # A tibble: 30 x 18 ## id sex age group fost1 confid1 depress1 fost2 ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 male 23 2 50 15 44 48 ## 2 10 male 21 2 47 14 42 45 ## 3 9 male 25 1 44 12 40 39 ## 4 3 male 30 1 47 11 43 42 ## 5 12 male 45 2 46 16 44 45 ## 6 11 male 22 1 39 13 43 40 ## 7 6 male 22 2 32 21 37 33 ## 8 5 male 26 1 44 17 46 37 ## 9 8 male 23 2 40 22 37 40 ## 10 13 male 21 1 47 20 50 45 ## # ... with 20 more rows, and 10 more variables: ## # confid2 &lt;dbl&gt;, depress2 &lt;dbl&gt;, fost3 &lt;dbl&gt;, ## # confid3 &lt;dbl&gt;, depress3 &lt;dbl&gt;, exam &lt;dbl&gt;, ## # mah_1 &lt;dbl&gt;, DepT1gp2 &lt;chr&gt;, DepT2Gp2 &lt;chr&gt;, ## # DepT3gp2 &lt;chr&gt; glimpse(edata) ## Rows: 30 ## Columns: 18 ## $ id &lt;fct&gt; 4, 10, 9, 3, 12, 11, 6, 5, 8, 13,... ## $ sex &lt;fct&gt; male, male, male, male, male, mal... ## $ age &lt;dbl&gt; 23, 21, 25, 30, 45, 22, 22, 26, 2... ## $ group &lt;fct&gt; 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, ... ## $ fost1 &lt;dbl&gt; 50, 47, 44, 47, 46, 39, 32, 44, 4... ## $ confid1 &lt;dbl&gt; 15, 14, 12, 11, 16, 13, 21, 17, 2... ## $ depress1 &lt;dbl&gt; 44, 42, 40, 43, 44, 43, 37, 46, 3... ## $ fost2 &lt;dbl&gt; 48, 45, 39, 42, 45, 40, 33, 37, 4... ## $ confid2 &lt;dbl&gt; 16, 15, 18, 16, 16, 20, 22, 20, 2... ## $ depress2 &lt;dbl&gt; 44, 42, 40, 43, 45, 42, 36, 47, 3... ## $ fost3 &lt;dbl&gt; 45, 44, 36, 41, 43, 39, 32, 32, 4... ## $ confid3 &lt;dbl&gt; 14, 18, 19, 20, 20, 22, 23, 26, 2... ## $ depress3 &lt;dbl&gt; 40, 40, 38, 43, 43, 38, 35, 42, 3... ## $ exam &lt;dbl&gt; 52, 55, 58, 60, 58, 62, 59, 70, 6... ## $ mah_1 &lt;dbl&gt; 0.5700, 1.6594, 3.5405, 2.4542, 0... ## $ DepT1gp2 &lt;chr&gt; &quot;not depressed&quot;, &quot;not depressed&quot;,... ## $ DepT2Gp2 &lt;chr&gt; &quot;not depressed&quot;, &quot;not depressed&quot;,... ## $ DepT3gp2 &lt;chr&gt; &quot;not depressed&quot;, &quot;not depressed&quot;,... 31.1 t检验 首先，我们想检验第一次测量的抑郁得分（depress1）的分布，是否明显偏离正态分布（均值为0），这里的零假设就是正态分布且均值为0； 备选假设就是均值不为0 # Run t-test model_1_t &lt;- t.test(edata$depress1, mu = 0) model_1_t ## ## One Sample t-test ## ## data: edata$depress1 ## t = 51, df = 29, p-value &lt;2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 40.82 44.25 ## sample estimates: ## mean of x ## 42.53 输出结果显示，p-value很小接近0，拒绝零假设，也就说均值不大可能为0。事实上，通过密度图可以看到depress1的分布均值在42附近，与0相距很远。 edata %&gt;% ggplot(aes(x = depress1)) + geom_density() 先不管做这个假设有没有意义，我们用线性回归的方法做一遍， t.test(depress1 ~ 1, data = edata) ## ## One Sample t-test ## ## data: depress1 ## t = 51, df = 29, p-value &lt;2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 40.82 44.25 ## sample estimates: ## mean of x ## 42.53 # Run equivalent linear model model_1_lm &lt;- lm(depress1 ~ 1, data = edata) summary(model_1_lm) ## ## Call: ## lm(formula = depress1 ~ 1, data = edata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.533 -3.533 0.467 2.467 7.467 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 42.533 0.838 50.7 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.59 on 29 degrees of freedom 这个语法lm(y ~ 1)是不是感觉有点点怪怪的呢？左边是响应变量y，右边只有一个1，没有其他预测变量，这里的意思就是用截距预测响应变量y。事实上，也可以看作是检验y变量的均值是否显著偏离0. 为了方便比较两个模型，我们通过broom宏包将两个结果规整在一起，发现两个模型的t-value, estimate 和p.value都是一样的，这与和Jonas Kristoffer Lindeløv表中期望的一样。 library(broom) # tidy() gets model outputs we usually use to report our results model_1_t_tidy &lt;- tidy(model_1_t) %&gt;% mutate(model = &quot;t.test(y)&quot;) model_1_lm_tidy &lt;- tidy(model_1_lm) %&gt;% mutate(model = &quot;lm(y ~ 1)&quot;) results &lt;- bind_rows(model_1_t_tidy, model_1_lm_tidy) %&gt;% select(model, estimate, statistic, p.value) model estimate statistic p.value t.test(y) 42.53 50.73 0 lm(y ~ 1) 42.53 50.73 0 上面例子，我们用不同的方法完成了相同的检验。事实上，在R语言t.test()内部会直接调用lm()函数，其函数语句和我们的这里代码也是一样的。 绝大部分时候，我们想考察实验中的干预是否有效，换句话说，基线得分 depress1 和 干预后得分 depress3 是否存在显著差异？这就需要进行配对样本t检验。 # run paired t-test testing depression from g1 against g2 model_2_t &lt;- t.test(edata$depress1, edata$depress3, paired = TRUE) model_2_t_tidy &lt;- tidy(model_2_t) %&gt;% mutate(model = &quot;t.test(x, y, paired = TRUE&quot;) model_2_t ## ## Paired t-test ## ## data: edata$depress1 and edata$depress3 ## t = 7.2, df = 29, p-value = 6e-08 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 2.386 4.281 ## sample estimates: ## mean of the differences ## 3.333 写成线性模型为lm(depress1 - depress3 ~ 1)，即先让两个变量相减，然后去做回归 # run linear model model_2_lm &lt;- lm(depress1 - depress3 ~ 1, data = edata) model_2_lm_tidy &lt;- tidy(model_2_lm) %&gt;% mutate(model = &quot;lm(y-x ~ 1)&quot;) summary(model_2_lm) ## ## Call: ## lm(formula = depress1 - depress3 ~ 1, data = edata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.333 -1.333 -0.333 1.667 5.667 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.333 0.463 7.2 6.4e-08 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.54 on 29 degrees of freedom # we combine the two model outputs, rowwise results &lt;- bind_rows(model_2_t_tidy, model_2_lm_tidy) %&gt;% select(model, estimate, statistic, p.value) model estimate statistic p.value t.test(x, y, paired = TRUE 3.333 7.196 0 lm(y-x ~ 1) 3.333 7.196 0 haha，通过这个等价的线性模型，我们似乎可以窥探到配对样本t检验是怎么样工作的。 它depress1 和 depress3一一对应相减后得到新的一列，用新的一列做单样本t检验 # run paired t-test testing depression from g1 against g2 model_2_t2 &lt;- t.test(edata$depress1- edata$depress3) model_2_t2_tidy &lt;- tidy(model_2_t2) %&gt;% mutate(model = &quot;t.test(x - y&quot;) model_2_t2 ## ## One Sample t-test ## ## data: edata$depress1 - edata$depress3 ## t = 7.2, df = 29, p-value = 6e-08 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 2.386 4.281 ## sample estimates: ## mean of x ## 3.333 既然是原理这样，那么在回归模型之前，可以在数据框中用depress1 - depress3构建新的一列 # calculate the difference between baseline and tp3 depression edata &lt;- edata %&gt;% mutate( dep_slope = depress1 - depress3 ) model_2_lm2 &lt;- lm(dep_slope ~ 1, data = edata) model_2_lm2_tidy &lt;- tidy(model_2_lm2) %&gt;% mutate(model = &quot;lm(delta ~ 1)&quot;) 最后，把四个模型放在一起 # we combine the three model outputs, rowwise results &lt;- bind_rows(model_2_t_tidy, model_2_t2_tidy) %&gt;% bind_rows(model_2_lm_tidy) %&gt;% bind_rows(model_2_lm2_tidy) %&gt;% select(model, estimate, statistic, p.value) model estimate statistic p.value t.test(x, y, paired = TRUE 3.333 7.196 0 t.test(x - y 3.333 7.196 0 lm(y-x ~ 1) 3.333 7.196 0 lm(delta ~ 1) 3.333 7.196 0 我们看到，四个模型给出了相同的结果。 31.2 关联 两个变量的关联检验，用的也比较常见。比如两个连续型变量，我们可能想知道它们之间的关联，以及这种关联是否显著。 # Run correlation test model_3_cor &lt;- cor.test(edata$depress3, edata$depress1, method = &quot;pearson&quot;) model_3_cor_tidy &lt;- tidy(model_3_cor) %&gt;% mutate(model = &quot;cor.test(x, y)&quot;) model_3_cor ## ## Pearson&#39;s product-moment correlation ## ## data: edata$depress3 and edata$depress1 ## t = 9.2, df = 28, p-value = 5e-10 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7379 0.9354 ## sample estimates: ## cor ## 0.8675 # Run equivalent linear model model_3_lm &lt;- lm(depress3 ~ depress1, data = edata) model_3_lm_tidy &lt;- tidy(model_3_lm) %&gt;% mutate(model = &quot;lm(y ~ x)&quot;) summary(model_3_lm) ## ## Call: ## lm(formula = depress3 ~ depress1, data = edata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.842 -1.474 0.177 1.293 4.197 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.687 4.455 -0.38 0.71 ## depress1 0.961 0.104 9.23 5.5e-10 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.58 on 28 degrees of freedom ## Multiple R-squared: 0.753, Adjusted R-squared: 0.744 ## F-statistic: 85.2 on 1 and 28 DF, p-value: 5.49e-10 # we combine the two model outputs, rowwise results &lt;- bind_rows(model_3_cor_tidy, model_3_lm_tidy) %&gt;% select(model, term, estimate, statistic, p.value) model term estimate statistic p.value cor.test(x, y) NA 0.8675 9.2291 0.0000 lm(y ~ x) (Intercept) -1.6871 -0.3787 0.7078 depress1 0.9613 9.2291 0.0000 喔袄，这次的表格有点不一样了。那是因为，线性模型会不仅输出系数，而且还输出了模型的截距，因此两个模型的系数会不一样，但在 t-statistic 和 p.value 是一样的。 31.3 单因素方差分析 我们现在想看看两组（组1=技能提升组；组2=信心提升组）在第一次量表中depress1得分是否有显著区别？ # Run one-way anova model_4_anova &lt;- aov(depress1 ~ group, data = edata) model_4_anova_tidy &lt;- tidy(model_4_anova) %&gt;% mutate(model = &quot;aov(y ~ factor(x))&quot;) summary(model_4_anova) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## group 1 2 2.13 0.1 0.76 ## Residuals 28 609 21.76 # Run equivalent linear model model_4_lm &lt;- lm(depress1 ~ group, data = edata) model_4_lm_tidy &lt;- tidy(model_4_lm) %&gt;% mutate(model = &quot;lm(y ~ factor(x))&quot;) summary(model_4_lm) ## ## Call: ## lm(formula = depress1 ~ group, data = edata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.800 -3.667 0.467 2.733 7.733 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 42.800 1.204 35.53 &lt;2e-16 *** ## group2 -0.533 1.703 -0.31 0.76 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.66 on 28 degrees of freedom ## Multiple R-squared: 0.00349, Adjusted R-squared: -0.0321 ## F-statistic: 0.098 on 1 and 28 DF, p-value: 0.757 # we combine the two model outputs, rowwise results &lt;- bind_rows(model_4_anova_tidy, model_4_lm_tidy) %&gt;% select(model, term, estimate, statistic, p.value) model term estimate statistic p.value aov(y ~ factor(x)) group NA 0.0980 0.7565 Residuals NA NA NA lm(y ~ factor(x)) (Intercept) 42.8000 35.5337 0.0000 group2 -0.5333 -0.3131 0.7565 这两个模型输出结果不一样了，且模型的区别似乎有点不好理解。aov评估group变量整体是否有效应， 如果group中的任何一个水平都显著偏离基线水平，那么说明group变量是显著的。 在lm()中，是将group1视为基线, 依次比较其它因子水平（比如group2）与基线group1的之间的偏离，并评估每次这种偏离的显著性； 而aov评估group变量整体是否有效应，即如果group中的任何一个因子水平都显著偏离基线水平，那么说明group变量是显著的。 也就说，aov给出了整体的评估；而lm给出了因子水平之间的评估。 在本案例中，由于group的因子水平只有两个，因此，我们看到两个模型的结论是一致的，p.value = 0.756, 即group分组之间没有显著差异。 同时，我们看到aov没有返回beta系数的估计值，F-value (statistic)值也高于lm线性模型给出的t-statistic。那是因为统计值的计算方法是不一样的造成的，如果 将aov给出F-statustic值的开方，那么就等于lm给出的t-statistic值（限定分组变量只有因子水平时） # take the square root of the anova stat sqrt(model_4_anova_tidy$statistic[1]) ## [1] 0.3131 # same as stat from lm model_4_lm_tidy$statistic[2] ## [1] -0.3131 # or, square the lm stat model_4_lm_tidy$statistic[2]^2 ## [1] 0.09803 # same as anova stat model_4_anova_tidy$statistic[1] ## [1] 0.09803 31.4 单因素协变量分析 在上面的模型中增加confid1这个指标，考察信心得分是否会影响干预的成功？此时，模型有一个离散变量group，和一个连续变量confid1，这就需要用到协变量分析。 # Run one-way anova model_5_ancova &lt;- aov(dep_slope ~ group + confid1, data = edata) model_5_ancova_tidy &lt;- tidy(model_5_ancova) %&gt;% mutate(model = &quot;aov(y ~ x + z)&quot;) summary(model_5_ancova) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## group 1 19.2 19.20 3.13 0.088 . ## confid1 1 2.0 2.03 0.33 0.569 ## Residuals 27 165.4 6.13 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Run equivalent linear model model_5_lm &lt;- lm(dep_slope ~ group + confid1, data = edata) model_5_lm_tidy &lt;- tidy(model_5_lm) %&gt;% mutate(model = &quot;lm(y ~ x + z)&quot;) summary(model_5_lm) ## ## Call: ## lm(formula = dep_slope ~ group + confid1, data = edata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.485 -2.041 0.424 1.523 4.909 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.4637 1.7375 1.99 0.056 . ## group2 1.6132 0.9041 1.78 0.086 . ## confid1 -0.0493 0.0856 -0.58 0.569 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.48 on 27 degrees of freedom ## Multiple R-squared: 0.114, Adjusted R-squared: 0.0481 ## F-statistic: 1.73 on 2 and 27 DF, p-value: 0.196 # we combine the two model outputs, rowwise results &lt;- bind_rows(model_5_ancova_tidy, model_5_lm_tidy) %&gt;% select(model, term, estimate, statistic, p.value) model term estimate statistic p.value aov(y ~ x + z) group NA 3.1336 0.0880 confid1 NA 0.3316 0.5695 Residuals NA NA NA lm(y ~ x + z) (Intercept) 3.4637 1.9935 0.0564 group2 1.6132 1.7842 0.0856 confid1 -0.0493 -0.5758 0.5695 和单因素方差分析一样，输出结果有一点点不同，但模型输出告诉我们，两个结果是相同的。 aov模型中，group整体的p-value是 ~0.088， lm模型中检验group2偏离group1的p.value是0.086. confidence 这个变量p.value都是0.56993。 唯一不同的地方是aov模型中confidence有一个正的statistic值0.3315 但lm是负的0.5758. 究其原因，可能是它们都很接近0，那么即使数学上很小的差别都会导致结果从0的一边跳到0的另一边。事实上，和单因素方差分析一样，我们将lm模型的confidence的统计值做平方计算，发现与aov的结果是一样样的 # or, square the lm stat model_5_lm_tidy$statistic[-1]^2 ## [1] 3.1832 0.3316 # same as anova stat model_5_ancova_tidy$statistic ## [1] 3.1336 0.3316 NA 31.5 双因素方差分析 如果我们考察组内性别差异是否会导致depression的变化，那么就需要双因素方差分析，而且两个预测子之间还有相互作用项。 # Run anova model_6_anova &lt;- aov(dep_slope ~ group * sex, data = edata) model_6_anova_tidy &lt;- tidy(model_6_anova) %&gt;% mutate(model = &quot;aov(y ~ x * z)&quot;) summary(model_6_anova) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## group 1 19.2 19.20 3.33 0.079 . ## sex 1 5.1 5.15 0.89 0.353 ## group:sex 1 12.5 12.51 2.17 0.153 ## Residuals 26 149.8 5.76 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Run equivalent linear model model_6_lm &lt;- lm(dep_slope ~ group * sex, data = edata) model_6_lm_tidy &lt;- tidy(model_6_lm) %&gt;% mutate(model = &quot;lm(y ~ x * z)&quot;) summary(model_6_lm) ## ## Call: ## lm(formula = dep_slope ~ group * sex, data = edata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.125 -1.821 0.482 1.719 3.875 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.286 0.907 2.52 0.018 * ## group2 2.839 1.242 2.29 0.031 * ## sexmale 0.464 1.242 0.37 0.712 ## group2:sexmale -2.589 1.757 -1.47 0.153 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.4 on 26 degrees of freedom ## Multiple R-squared: 0.197, Adjusted R-squared: 0.105 ## F-statistic: 2.13 on 3 and 26 DF, p-value: 0.12 # we combine the two model outputs, rowwise results &lt;- bind_rows(model_6_anova_tidy, model_6_lm_tidy) %&gt;% select(model, term, estimate, statistic, p.value) model term estimate statistic p.value aov(y ~ x * z) group NA 3.3324 0.0794 sex NA 0.8935 0.3532 group:sex NA 2.1721 0.1525 Residuals NA NA NA lm(y ~ x * z) (Intercept) 2.2857 2.5194 0.0182 group2 2.8393 2.2855 0.0307 sexmale 0.4643 0.3737 0.7116 group2:sexmale -2.5893 -1.4738 0.1525 aov()和lm() 公式写法是一样，输出结果又一次不一样，但结论是相同的（尤其是分组变量只有两个水平时候） aov评估的是 （这些变量作为整体），是否对Y产生差异；而lm 模型，我们评估的是分类变量中的某个因子水平是否与基线水平之间是否有著差异。 最后，为了更好地演示aov与lm之间的等价性，给group弄成一个有多个水平（&gt;2）的因子, 具体过程如下 edata_mock &lt;- edata %&gt;% # Add 2 to numeric version of groups mutate(group = as.numeric(group) + 2) %&gt;% # bind this by row to the origincal eData (with group as numeric) bind_rows(edata %&gt;% mutate(group = as.numeric(group))) %&gt;% # make group a factor again so the correct test is applied mutate(group = as.factor(group)) 数据没有改，只是复制了一遍，复制出来的数据，因子水平改为3和4， 那么新的数据edata_mock中，group就有四个因子水平（1，2，3，4） # Run anova model_7_anova &lt;- aov(dep_slope ~ group * sex, data = edata_mock) model_7_anova_tidy &lt;- tidy(model_7_anova) %&gt;% mutate(model = &quot;aov(y ~ x * z)&quot;) summary(model_7_anova) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## group 3 38.4 12.80 2.22 0.097 . ## sex 1 10.3 10.30 1.79 0.187 ## group:sex 3 25.0 8.34 1.45 0.239 ## Residuals 52 299.6 5.76 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Run equivalent linear model model_7_lm &lt;- lm(dep_slope ~ group * sex, data = edata_mock) model_7_lm_tidy &lt;- tidy(model_7_lm) %&gt;% mutate(model = &quot;lm(y ~ x * z)&quot;) summary(model_7_lm) ## ## Call: ## lm(formula = dep_slope ~ group * sex, data = edata_mock) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.125 -2.000 0.482 1.875 3.875 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.29e+00 9.07e-01 2.52 0.015 * ## group2 2.84e+00 1.24e+00 2.29 0.026 * ## group3 -2.81e-15 1.28e+00 0.00 1.000 ## group4 2.84e+00 1.24e+00 2.29 0.026 * ## sexmale 4.64e-01 1.24e+00 0.37 0.710 ## group2:sexmale -2.59e+00 1.76e+00 -1.47 0.147 ## group3:sexmale 1.69e-15 1.76e+00 0.00 1.000 ## group4:sexmale -2.59e+00 1.76e+00 -1.47 0.147 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.4 on 52 degrees of freedom ## Multiple R-squared: 0.197, Adjusted R-squared: 0.0894 ## F-statistic: 1.83 on 7 and 52 DF, p-value: 0.101 # we combine the two model outputs, rowwise results &lt;- bind_rows(model_7_anova_tidy, model_7_lm_tidy) %&gt;% select(model, term, estimate, statistic, p.value) model term estimate statistic p.value aov(y ~ x * z) group NA 2.2216 0.0966 sex NA 1.7871 0.1871 group:sex NA 1.4481 0.2395 Residuals NA NA NA lm(y ~ x * z) (Intercept) 2.2857 2.5194 0.0149 group2 2.8393 2.2855 0.0264 group3 0.0000 0.0000 1.0000 group4 2.8393 2.2855 0.0264 sexmale 0.4643 0.3737 0.7101 group2:sexmale -2.5893 -1.4738 0.1466 group3:sexmale 0.0000 0.0000 1.0000 group4:sexmale -2.5893 -1.4738 0.1466 样本大小翻倍，因此统计值和p-values不一样了。 注意到lm模型，这里现在又两个多余的分组。 因为group3和基线group1完全一样，因此统计为0，p-value 为1；而group 2和group4也是一样的，因此相对基线group1而言，结果是一样的。 所以，相比于做统计检验，我倾向于线性模型，因为lm()除了给出变量作为整体是否对响应变量产生影响外，还提供了更多的因子之间的信息。 edata %&gt;% mutate(`sex:group` = interaction(sex, group, sep = &quot;:&quot;)) %&gt;% ggplot(aes( x = sex:group, y = dep_slope, colour = sex:group )) + geom_jitter(width = .2) + geom_boxplot(width = .3, alpha = .2) + labs( y = &quot;Depression difference&quot;, title = &quot;Depression difference between baseline and EOS&quot;, subtitle = &quot;Divided by intervention group and sex&quot; ) "],["infer.html", "第 32 章 统计推断 32.1 案例1:你会给爱情片还是动作片高分？ 32.2 案例2: 航天事业的预算有党派门户之见？ 32.3 案例3:原住民中的女学生多？ 32.4 宏包infer 32.5 更多", " 第 32 章 统计推断 Statistical Inference: A Tidy Approach 32.1 案例1:你会给爱情片还是动作片高分？ 这是一个关于电影评分的数据集3， library(tidyverse) d &lt;- ggplot2movies::movies d ## # A tibble: 58,788 x 24 ## title year length budget rating votes r1 r2 ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 $ 1971 121 NA 6.4 348 4.5 4.5 ## 2 $1000 ~ 1939 71 NA 6 20 0 14.5 ## 3 $21 a ~ 1941 7 NA 8.2 5 0 0 ## 4 $40,000 1996 70 NA 8.2 6 14.5 0 ## 5 $50,00~ 1975 71 NA 3.4 17 24.5 4.5 ## 6 $pent 2000 91 NA 4.3 45 4.5 4.5 ## 7 $windle 2002 93 NA 5.3 200 4.5 0 ## 8 &#39;15&#39; 2002 25 NA 6.7 24 4.5 4.5 ## 9 &#39;38 1987 97 NA 6.6 18 4.5 4.5 ## 10 &#39;49-&#39;17 1917 61 NA 6 51 4.5 0 ## # ... with 58,778 more rows, and 16 more variables: ## # r3 &lt;dbl&gt;, r4 &lt;dbl&gt;, r5 &lt;dbl&gt;, r6 &lt;dbl&gt;, r7 &lt;dbl&gt;, ## # r8 &lt;dbl&gt;, r9 &lt;dbl&gt;, r10 &lt;dbl&gt;, mpaa &lt;chr&gt;, ## # Action &lt;int&gt;, Animation &lt;int&gt;, Comedy &lt;int&gt;, ## # Drama &lt;int&gt;, Documentary &lt;int&gt;, Romance &lt;int&gt;, ## # Short &lt;int&gt; 数据集包含58788 行 和 24 变量 variable description title 电影名 year 发行年份 budget 预算金额 length 电影时长 rating 平均得分 votes 投票人数 r1-10 各分段投票人占比 mpaa MPAA 分级 action 动作片 animation 动画片 comedy 喜剧片 drama 戏剧 documentary 纪录片 romance 爱情片 short 短片 我们想看下爱情片与动作片（不是爱情动作片）的平均得分是否显著不同。 首先我们简单的整理下数据，主要是剔除既是爱情片又是动作片的电影 movies_genre_sample &lt;- d %&gt;% select(title, year, rating, Action, Romance) %&gt;% filter(!(Action == 1 &amp; Romance == 1)) %&gt;% # 既是爱情片又是动作片的，删去 mutate(genre = case_when( Action == 1 ~ &quot;Action&quot;, Romance == 1 ~ &quot;Romance&quot;, TRUE ~ &quot;Neither&quot; )) %&gt;% filter(genre != &quot;Neither&quot;) %&gt;% select(-Action, -Romance) %&gt;% group_by(genre) %&gt;% slice_sample(n = 34) %&gt;% # 每种题材的电影只选取了34个 ungroup() movies_genre_sample ## # A tibble: 68 x 4 ## title year rating genre ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Alley Cat 1982 6.1 Acti~ ## 2 Purple Plain, The 1954 6.3 Acti~ ## 3 Martial Law 1990 4 Acti~ ## 4 Vodkaa, komisario Palmu 1969 5.7 Acti~ ## 5 Vendetta 1986 5.1 Acti~ ## 6 Confessione di un commissario di~ 1971 7 Acti~ ## 7 Full Clip 2004 4.1 Acti~ ## 8 Tailspin Tommy in The Great Air ~ 1935 9.6 Acti~ ## 9 Cyclone 1978 3.1 Acti~ ## 10 Gharaana Mogudu 1992 9 Acti~ ## # ... with 58 more rows 先看下图形 movies_genre_sample %&gt;% ggplot(aes(x = genre, y = rating)) + geom_boxplot() + geom_jitter() 看下两种题材电影评分的分布 movies_genre_sample %&gt;% ggplot(mapping = aes(x = rating)) + geom_histogram(binwidth = 1, color = &quot;white&quot;) + facet_grid(vars(genre)) 统计两种题材电影评分的均值 summary_ratings &lt;- movies_genre_sample %&gt;% group_by(genre) %&gt;% summarize( mean = mean(rating), std_dev = sd(rating), n = n() ) summary_ratings ## # A tibble: 2 x 4 ## genre mean std_dev n ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Action 5.54 1.72 34 ## 2 Romance 6.08 1.41 34 32.1.1 传统的基于频率方法的t检验 假设： 零假设: \\(H_0: \\mu_{1} - \\mu_{2} = 0\\) 备选假设: \\(H_A: \\mu_{1} - \\mu_{2} \\neq 0\\) 两种可能的结论: 拒绝 \\(H_0\\) 不能拒绝 \\(H_0\\) t_test_eq &lt;- t.test(rating ~ genre, data = movies_genre_sample, var.equal = TRUE ) %&gt;% broom::tidy() t_test_eq ## # A tibble: 1 x 10 ## estimate estimate1 estimate2 statistic p.value ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.541 5.54 6.08 -1.42 0.161 ## # ... with 5 more variables: parameter &lt;dbl&gt;, ## # conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, method &lt;chr&gt;, ## # alternative &lt;chr&gt; t_test_uneq &lt;- t.test(rating ~ genre, data = movies_genre_sample, var.equal = FALSE ) %&gt;% broom::tidy() t_test_uneq ## # A tibble: 1 x 10 ## estimate estimate1 estimate2 statistic p.value ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.541 5.54 6.08 -1.42 0.161 ## # ... with 5 more variables: parameter &lt;dbl&gt;, ## # conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, method &lt;chr&gt;, ## # alternative &lt;chr&gt; 32.1.2 infer:基于模拟的检验 所有的假设检验都符合这个框架4: 图 32.1: Hypothesis Testing Framework 实际观察的差别 library(infer) obs_diff &lt;- movies_genre_sample %&gt;% specify(formula = rating ~ genre) %&gt;% calculate( stat = &quot;diff in means&quot;, order = c(&quot;Romance&quot;, &quot;Action&quot;) ) obs_diff ## # A tibble: 1 x 1 ## stat ## &lt;dbl&gt; ## 1 0.541 模拟 null_dist &lt;- movies_genre_sample %&gt;% specify(formula = rating ~ genre) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 5000, type = &quot;permute&quot;) %&gt;% calculate( stat = &quot;diff in means&quot;, order = c(&quot;Romance&quot;, &quot;Action&quot;) ) head(null_dist) ## # A tibble: 6 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.135 ## 2 2 0.0353 ## 3 3 -0.7 ## 4 4 0.294 ## 5 5 -0.141 ## 6 6 0.247 可视化 null_dist %&gt;% visualize() null_dist %&gt;% visualize() + shade_p_value(obs_stat = obs_diff, direction = &quot;both&quot;) # shade_p_value(bins = 100, obs_stat = obs_diff, direction = &quot;both&quot;) 计算p值 pvalue &lt;- null_dist %&gt;% get_pvalue(obs_stat = obs_diff, direction = &quot;two_sided&quot;) pvalue ## # A tibble: 1 x 1 ## p_value ## &lt;dbl&gt; ## 1 0.164 结论 在构建的虚拟(\\(\\Delta = 0\\))的平行世界里，出现实际观察值（0.5412）的概率很小，这里是（0.1644）。 如果以(p&lt; 0.05)为标准，那我们有足够的证据证明，H0不成立，即爱情电影和动作电影的评分均值存在显著差异，具体来说，动作电影的平均评分要比爱情电影低些。 32.2 案例2: 航天事业的预算有党派门户之见？ 美国国家航空航天局的预算是否存在党派门户之见？ gss &lt;- read_rds(&quot;./demo_data/gss.rds&quot;) gss %&gt;% select(NASA, party) %&gt;% count(NASA, party) %&gt;% head(8) ## # A tibble: 8 x 3 ## NASA party n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 TOO LITTLE Dem 8 ## 2 TOO LITTLE Ind 13 ## 3 TOO LITTLE Rep 9 ## 4 ABOUT RIGHT Dem 22 ## 5 ABOUT RIGHT Ind 37 ## 6 ABOUT RIGHT Rep 17 ## 7 TOO MUCH Dem 13 ## 8 TOO MUCH Ind 22 gss %&gt;% ggplot(aes(x = party, fill = NASA)) + geom_bar() 假设： 零假设 \\(H_0\\): 不同党派对预算的态度的构成比(TOO LITTLE, ABOUT RIGHT, TOO MUCH) 没有区别 备选假设 \\(H_a\\): 不同党派对预算的态度的构成比(TOO LITTLE, ABOUT RIGHT, TOO MUCH) 存在区别 两种可能的结论: 拒绝 \\(H_0\\) 不能拒绝 \\(H_0\\) 32.2.1 传统的方法 chisq.test(gss$party, gss$NASA) ## ## Pearson&#39;s Chi-squared test ## ## data: gss$party and gss$NASA ## X-squared = 1.3, df = 4, p-value = 0.9 或者 gss %&gt;% chisq_test(NASA ~ party) %&gt;% dplyr::select(p_value) %&gt;% dplyr::pull() ## [1] 0.8569 32.2.2 infer:Simulation-based tests obs_stat &lt;- gss %&gt;% specify(NASA ~ party) %&gt;% calculate(stat = &quot;Chisq&quot;) obs_stat ## # A tibble: 1 x 1 ## stat ## &lt;dbl&gt; ## 1 1.33 null_dist &lt;- gss %&gt;% specify(NASA ~ party) %&gt;% # (1) hypothesize(null = &quot;independence&quot;) %&gt;% # (2) generate(reps = 5000, type = &quot;permute&quot;) %&gt;% # (3) calculate(stat = &quot;Chisq&quot;) # (4) null_dist ## # A tibble: 5,000 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 4.85 ## 2 2 1.01 ## 3 3 6.20 ## 4 4 4.08 ## 5 5 2.46 ## 6 6 2.72 ## 7 7 2.63 ## 8 8 1.27 ## 9 9 3.96 ## 10 10 3.24 ## # ... with 4,990 more rows null_dist %&gt;% visualize() + shade_p_value(obs_stat = obs_stat, method = &quot;both&quot;, direction = &quot;right&quot;) null_dist %&gt;% get_pvalue(obs_stat = obs_stat, direction = &quot;greater&quot;) ## # A tibble: 1 x 1 ## p_value ## &lt;dbl&gt; ## 1 0.851 看到 p_value &gt; 0.05，不能拒绝 \\(H_0\\)，我们没有足够的证据证明党派之间有显著差异 32.3 案例3:原住民中的女学生多？ 案例 quine 数据集有 146 行 5 列，包含学生的生源、文化、性别和学习成效，具体说明如下 Eth: 民族背景：原住民与否 (是“A”; 否 “N”) Sex: 性别 Age: 年龄组 (“F0,” “F1,” “F2” or “F3”) Lrn: 学习者状态(平均水平 “AL”， 学习缓慢 “SL”) Days：一年中缺勤天数 td &lt;- MASS::quine %&gt;% as_tibble() %&gt;% mutate( across(c(Sex, Eth), as_factor) ) td ## # A tibble: 146 x 5 ## Eth Sex Age Lrn Days ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 A M F0 SL 2 ## 2 A M F0 SL 11 ## 3 A M F0 SL 14 ## 4 A M F0 AL 5 ## 5 A M F0 AL 5 ## 6 A M F0 AL 13 ## 7 A M F0 AL 20 ## 8 A M F0 AL 22 ## 9 A M F1 SL 6 ## 10 A M F1 SL 6 ## # ... with 136 more rows 从民族背景有两组（A， N）来看，性别为 F 的占比 是否有区别？ td %&gt;% count(Eth, Sex) ## # A tibble: 4 x 3 ## Eth Sex n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 A F 38 ## 2 A M 31 ## 3 N F 42 ## 4 N M 35 32.3.1 传统方法 prop.test(table(td$Eth, td$Sex), correct = FALSE) ## ## 2-sample test for equality of proportions ## without continuity correction ## ## data: table(td$Eth, td$Sex) ## X-squared = 0.0041, df = 1, p-value = 0.9 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1564 0.1670 ## sample estimates: ## prop 1 prop 2 ## 0.5507 0.5455 32.3.2 基于模拟的方法 obs_diff &lt;- td %&gt;% specify(Sex ~ Eth, success = &quot;F&quot;) %&gt;% # #被解释变量 sex中F的占比 calculate( stat = &quot;diff in props&quot;, order = c(&quot;A&quot;, &quot;N&quot;) # 解释变量中两组A，N ) obs_diff ## # A tibble: 1 x 1 ## stat ## &lt;dbl&gt; ## 1 0.00527 null_distribution &lt;- td %&gt;% specify(Sex ~ Eth, success = &quot;F&quot;) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 5000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in props&quot;, order = c(&quot;A&quot;, &quot;N&quot;)) null_distribution %&gt;% visualize() pvalue &lt;- null_distribution %&gt;% get_pvalue(obs_stat = obs_diff, direction = &quot;both&quot;) pvalue ## # A tibble: 1 x 1 ## p_value ## &lt;dbl&gt; ## 1 1 null_distribution %&gt;% get_ci(level = 0.95, type = &quot;percentile&quot;) ## # A tibble: 1 x 2 ## lower_ci upper_ci ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.160 0.170 32.4 宏包infer 我比较喜欢infer宏包的设计思想，它把统计推断分成了四个步骤 下图可以更好的帮助我们理解infer的工作流程 specify() 指定解释变量和被解释变量 (y ~ x) hypothesize() 指定零假设 (比如, independence= y 和 x 彼此独立) generate() 从基于零假设的平行世界中抽样: 指定每次重抽样的类型，通俗点讲就是数据洗牌，重抽样type = \"bootstrap\" (有放回的)，对应的零假设往往是null = “point” ； 重抽样type = \"permuting\" (无放回的)，对应的零假设往往是null = “independence,” 指的是y和x之间彼此独立的，因此抽样后会重新排列，也就说原先 value1-group1 可能变成了value1-group2，(因为我们假定他们是独立的啊，这种操作，也不会影响y和x的关系) 指定多少组 (reps = 1000) calculate() 计算每组(reps)的统计值 (stat = \"diff in props\") visualize() 可视化，对比零假设的分布与实际观察值. 下面是我自己对重抽样的理解 32.5 更多 更多统计推断的内容可参考 http://infer.netlify.com https://moderndive.netlify.com/index.html https://moderndive.com/index.html https://github.com/tidymodels/infer https://github.com/hadley/ggplot2movies/blob/master/R/movies.R http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html "],["lmm.html", "第 33 章 多层线性模型 33.1 分组数据 33.2 案例 33.3 线性模型 33.4 变化的截距 33.5 变化的斜率 33.6 变化的斜率 + 变化的截距 33.7 信息池 33.8 更多", " 第 33 章 多层线性模型 33.1 分组数据 在实验设计和数据分析中，我们可能经常会遇到分组的数据结构。所谓的分组，就是每一次观察，属于某个特定的组，比如考察学生的成绩，这些学生属于某个班级，班级又属于某个学校。有时候发现这种分组的数据，会给数据分析带来很多有意思的内容。 33.2 案例 我们从一个有意思的案例开始。 不同院系教职员工的收入 一般情况下，不同的院系，制定教师收入的依据和标准可能是不同的。我们假定有一份大学教职员的收入清单，这个学校包括信息学院、外国语学院、社会政治学、生物学院、统计学院共五个机构，我们通过数据建模，探索这个学校的薪酬制定规则。 create_data &lt;- function() { df &lt;- tibble( ids = 1:100, department = rep(c(&quot;sociology&quot;, &quot;biology&quot;, &quot;english&quot;, &quot;informatics&quot;, &quot;statistics&quot;), 20), bases = rep(c(40000, 50000, 60000, 70000, 80000), 20) * runif(100, .9, 1.1), experience = floor(runif(100, 0, 10)), raises = rep(c(2000, 500, 500, 1700, 500), 20) * runif(100, .9, 1.1) ) df &lt;- df %&gt;% mutate( salary = bases + experience * raises ) df } library(tidyverse) library(lme4) library(modelr) library(broom) library(broom.mixed) df &lt;- create_data() df ## # A tibble: 100 x 6 ## ids department bases experience raises salary ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 sociology 39001. 3 2111. 45335. ## 2 2 biology 48825. 8 540. 53148. ## 3 3 english 55582. 5 483. 57996. ## 4 4 informatics 69586. 1 1569. 71155. ## 5 5 statistics 77592. 4 474. 79488. ## 6 6 sociology 36927. 0 1894. 36927. ## 7 7 biology 45655. 9 549. 50594. ## 8 8 english 63026. 8 533. 67291. ## 9 9 informatics 65205. 4 1848. 72597. ## 10 10 statistics 74944. 5 452. 77203. ## # ... with 90 more rows 33.3 线性模型 薪酬制定规则一：假定教师收入主要取决于他从事工作的时间，也就说说工作时间越长收入越高。意味着，每个院系的起始薪酬（起薪）是一样的，并有相同的年度增长率。那么，这个收入问题就是一个简单线性模型： \\[\\hat{y} = \\alpha + \\beta_1x_1 + ... + \\beta_nx_n\\] 具体到我们的案例中，薪酬模型可以写为 \\[ \\hat{salary_i} = \\alpha + \\beta * experience_i \\] 通过这个等式，可以计算出各个系数，即截距\\(\\alpha\\)就是起薪，斜率\\(\\beta\\)就是年度增长率。确定了斜率和截距，也就确定了每个教职员工的收入曲线。 # Model without respect to grouping m1 &lt;- lm(salary ~ experience, data = df) m1 ## ## Call: ## lm(formula = salary ~ experience, data = df) ## ## Coefficients: ## (Intercept) experience ## 59009 1162 broom::tidy(m1) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 59009. 2476. 23.8 1.44e-42 ## 2 experience 1162. 436. 2.67 8.99e- 3 df %&gt;% modelr::add_predictions(m1) ## # A tibble: 100 x 7 ## ids department bases experience raises salary ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 sociology 39001. 3 2111. 45335. ## 2 2 biology 48825. 8 540. 53148. ## 3 3 english 55582. 5 483. 57996. ## 4 4 informati~ 69586. 1 1569. 71155. ## 5 5 statistics 77592. 4 474. 79488. ## 6 6 sociology 36927. 0 1894. 36927. ## 7 7 biology 45655. 9 549. 50594. ## 8 8 english 63026. 8 533. 67291. ## 9 9 informati~ 65205. 4 1848. 72597. ## 10 10 statistics 74944. 5 452. 77203. ## # ... with 90 more rows, and 1 more variable: ## # pred &lt;dbl&gt; # Model without respect to grouping df %&gt;% add_predictions(m1) %&gt;% ggplot(aes(x = experience, y = salary)) + geom_point() + geom_line(aes(x = experience, y = pred)) + labs(x = &quot;Experience&quot;, y = &quot;Predicted Salary&quot;) + ggtitle(&quot;linear model Salary Prediction&quot;) + scale_colour_discrete(&quot;Department&quot;) 注意到，对每个教师来说，不管来自哪个学院的，系数\\(\\alpha\\)和\\(\\beta\\)是一样的，是固定的，因此这种简单线性模型也称之为固定效应模型。 事实上，这种线性模型的方法太过于粗狂，构建的线性直线不能反映收入随院系的变化。 33.4 变化的截距 薪酬制定规则二，假定不同的院系起薪不同，但年度增长率是相同的。 这种统计模型，相比于之前的固定效应模型（简单线性模型）而言，加入了截距会随所在学院不同而变化的思想，统计模型写为 \\[\\hat{y_i} = \\alpha_{j[i]} + \\beta x_i\\] 这个等式中，斜率\\(\\beta\\)代表着年度增长率，是一个固定值，也就前面说的固定效应项，而截距\\(\\alpha\\)代表着起薪，随学院变化，是五个值，因为一个学院对应一个，称之为变化效应项（也叫随机效应项）。这里模型中既有固定效应项又有变化效应项，因此称之为混合效应模型。 教师\\(i\\)，他所在的学院\\(j\\)，记为\\(j[i]\\)，那么教师\\(i\\)所在学院\\(j\\)对应的\\(\\alpha\\)，很自然的记为\\(\\alpha_{j[i]}\\) # Model with varying intercept m2 &lt;- lmer(salary ~ experience + (1 | department), data = df) m2 ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: salary ~ experience + (1 | department) ## Data: df ## REML criterion at convergence: 1933 ## Random effects: ## Groups Name Std.Dev. ## department (Intercept) 13528 ## Residual 3922 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) experience ## 59896 979 broom.mixed::tidy(m2, effects = &quot;fixed&quot;) ## # A tibble: 2 x 5 ## effect term estimate std.error statistic ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 fixed (Intercept) 59896. 6099. 9.82 ## 2 fixed experience 979. 137. 7.16 broom.mixed::tidy(m2, effects = &quot;ran_vals&quot;) ## # A tibble: 5 x 6 ## effect group level term estimate std.error ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ran_vals depart~ biology (Interc~ -10886. 875. ## 2 ran_vals depart~ english (Interc~ -2042. 875. ## 3 ran_vals depart~ informa~ (Interc~ 12111. 875. ## 4 ran_vals depart~ sociolo~ (Interc~ -14744. 875. ## 5 ran_vals depart~ statist~ (Interc~ 15562. 875. df %&gt;% add_predictions(m2) %&gt;% ggplot(aes( x = experience, y = salary, group = department, colour = department )) + geom_point() + geom_line(aes(x = experience, y = pred)) + labs(x = &quot;Experience&quot;, y = &quot;Predicted Salary&quot;) + ggtitle(&quot;Varying Intercept Salary Prediction&quot;) + scale_colour_discrete(&quot;Department&quot;) 这种模型，我们就能看到院系不同 带来的员工收入的差别。 33.5 变化的斜率 薪酬制定规则三，不同的院系起始薪酬是相同的，但年度增长率不同。 与薪酬模型规则二的统计模型比较，我们只需要把变化的截距变成变化的斜率，那么统计模型可写为 \\[\\hat{y_i} = \\alpha + \\beta_{j[i]}x_i\\] 这里，截距(\\(\\alpha\\))对所有教师而言是固定不变的，而斜率(\\(\\beta\\))会随学院不同而变化，5个学院对应着5个斜率。 # Model with varying slope m3 &lt;- lmer(salary ~ experience + (0 + experience | department), data = df) m3 ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## salary ~ experience + (0 + experience | department) ## Data: df ## REML criterion at convergence: 2055 ## Random effects: ## Groups Name Std.Dev. ## department experience 2057 ## Residual 7550 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) experience ## 58320 1229 broom.mixed::tidy(m3, effects = &quot;fixed&quot;) ## # A tibble: 2 x 5 ## effect term estimate std.error statistic ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 fixed (Intercept) 58320. 1466. 39.8 ## 2 fixed experience 1229. 957. 1.29 broom.mixed::tidy(m3, effects = &quot;ran_vals&quot;) ## # A tibble: 5 x 6 ## effect group level term estimate std.error ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ran_vals departm~ biology experi~ -2022. 357. ## 2 ran_vals departm~ english experi~ -363. 280. ## 3 ran_vals departm~ informa~ experi~ 2106. 305. ## 4 ran_vals departm~ sociolo~ experi~ -1845. 266. ## 5 ran_vals departm~ statist~ experi~ 2123. 286. df %&gt;% add_predictions(m3) %&gt;% ggplot(aes( x = experience, y = salary, group = department, colour = department )) + geom_point() + geom_line(aes(x = experience, y = pred)) + labs(x = &quot;Experience&quot;, y = &quot;Predicted Salary&quot;) + ggtitle(&quot;Varying slope Salary Prediction&quot;) + scale_colour_discrete(&quot;Department&quot;) 33.6 变化的斜率 + 变化的截距 薪酬制定规则四，不同的学院起始薪酬和年度增长率也不同。 这可能是最现实的一种情形了，它实际上是规则二和规则三的一种组合，要求截距和斜率都会随学院的不同变化，数学上记为 \\[\\hat{y_i} = \\alpha_{j[i]} + \\beta_{j[i]}x_i\\] 具体来说，教师\\(i\\)，所在的学院\\(j\\), 他的入职的起始收入表示为 (\\(\\alpha_{j[i]}\\))，年度增长率表示为(\\(\\beta_{j[i]}\\)). # Model with varying slope and intercept m4 &lt;- lmer(salary ~ experience + (1 + experience | department), data = df) m4 ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## salary ~ experience + (1 + experience | department) ## Data: df ## REML criterion at convergence: 1915 ## Random effects: ## Groups Name Std.Dev. Corr ## department (Intercept) 14667 ## experience 734 -0.34 ## Residual 3403 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) experience ## 59776 969 broom.mixed::tidy(m4, effects = &quot;fixed&quot;) ## # A tibble: 2 x 5 ## effect term estimate std.error statistic ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 fixed (Intercept) 59776. 6594. 9.06 ## 2 fixed experience 969. 349. 2.77 broom.mixed::tidy(m4, effects = &quot;ran_vals&quot;) ## # A tibble: 10 x 6 ## effect group level term estimate std.error ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ran_va~ departm~ biology (Inter~ -8566. 1159. ## 2 ran_va~ departm~ english (Inter~ -873. 1566. ## 3 ran_va~ departm~ informa~ (Inter~ 8598. 1497. ## 4 ran_va~ departm~ sociolo~ (Inter~ -18337. 1458. ## 5 ran_va~ departm~ statist~ (Inter~ 19178. 1524. ## 6 ran_va~ departm~ biology experi~ -603. 243. ## 7 ran_va~ departm~ english experi~ -188. 258. ## 8 ran_va~ departm~ informa~ experi~ 769. 268. ## 9 ran_va~ departm~ sociolo~ experi~ 687. 228. ## 10 ran_va~ departm~ statist~ experi~ -665. 256. df %&gt;% add_predictions(m4) %&gt;% ggplot(aes( x = experience, y = salary, group = department, colour = department )) + geom_point() + geom_line(aes(x = experience, y = pred)) + labs(x = &quot;Experience&quot;, y = &quot;Predicted Salary&quot;) + ggtitle(&quot;Varying Intercept and Slopes Salary Prediction&quot;) + scale_colour_discrete(&quot;Department&quot;) 33.7 信息池 33.7.1 提问 问题：薪酬制定规则四中，不同的院系起薪不同，年度增长率也不同，我们得出了5组不同的截距和斜率，那么是不是可以等价为，先按照院系分5组，然后各算各的截距和斜率? 比如 df %&gt;% group_by(department) %&gt;% group_modify( ~ broom::tidy(lm(salary ~ 1 + experience, data = .)) ) ## # A tibble: 10 x 6 ## # Groups: department [5] ## department term estimate std.error statistic ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 biology (Int~ 51489. 1054. 48.9 ## 2 biology expe~ 278. 226. 1.23 ## 3 english (Int~ 59045. 1666. 35.4 ## 4 english expe~ 753. 279. 2.70 ## 5 informati~ (Int~ 67790. 1580. 42.9 ## 6 informati~ expe~ 1868. 289. 6.47 ## 7 sociology (Int~ 41028. 1169. 35.1 ## 8 sociology expe~ 1724. 185. 9.30 ## 9 statistics (Int~ 79426. 2031. 39.1 ## 10 statistics expe~ 221. 347. 0.637 ## # ... with 1 more variable: p.value &lt;dbl&gt; 分组各自回归，与这里的（变化的截距+变化的斜率）模型，不是一回事。 33.7.2 信息共享 完全共享 broom::tidy(m1) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 59009. 2476. 23.8 1.44e-42 ## 2 experience 1162. 436. 2.67 8.99e- 3 complete_pooling &lt;- broom::tidy(m1) %&gt;% dplyr::select(term, estimate) %&gt;% tidyr::pivot_wider( names_from = term, values_from = estimate ) %&gt;% dplyr::rename(Intercept = `(Intercept)`, slope = experience) %&gt;% dplyr::mutate(pooled = &quot;complete_pool&quot;) %&gt;% dplyr::select(pooled, Intercept, slope) complete_pooling ## # A tibble: 1 x 3 ## pooled Intercept slope ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 complete_pool 59009. 1162. 部分共享 fix_effect &lt;- broom.mixed::tidy(m4, effects = &quot;fixed&quot;) fix_effect fix_effect$estimate[1] fix_effect$estimate[2] var_effect &lt;- broom.mixed::tidy(m4, effects = &quot;ran_vals&quot;) var_effect # random effects plus fixed effect parameters partial_pooling &lt;- var_effect %&gt;% dplyr::select(level, term, estimate) %&gt;% tidyr::pivot_wider( names_from = term, values_from = estimate ) %&gt;% dplyr::rename(Intercept = `(Intercept)`, estimate = experience) %&gt;% dplyr::mutate( Intercept = Intercept + fix_effect$estimate[1], estimate = estimate + fix_effect$estimate[2] ) %&gt;% dplyr::mutate(pool = &quot;partial_pool&quot;) %&gt;% dplyr::select(pool, level, Intercept, estimate) partial_pooling partial_pooling &lt;- coef(m4)$department %&gt;% tibble::rownames_to_column() %&gt;% dplyr::rename(level = rowname, Intercept = `(Intercept)`, slope = experience) %&gt;% dplyr::mutate(pooled = &quot;partial_pool&quot;) %&gt;% dplyr::select(pooled, level, Intercept, slope) partial_pooling ## pooled level Intercept slope ## 1 partial_pool biology 51210 365.9 ## 2 partial_pool english 58904 780.5 ## 3 partial_pool informatics 68374 1737.5 ## 4 partial_pool sociology 41440 1656.3 ## 5 partial_pool statistics 78955 304.0 不共享 no_pool &lt;- df %&gt;% dplyr::group_by(department) %&gt;% dplyr::group_modify( ~ broom::tidy(lm(salary ~ 1 + experience, data = .)) ) no_pool ## # A tibble: 10 x 6 ## # Groups: department [5] ## department term estimate std.error statistic ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 biology (Int~ 51489. 1054. 48.9 ## 2 biology expe~ 278. 226. 1.23 ## 3 english (Int~ 59045. 1666. 35.4 ## 4 english expe~ 753. 279. 2.70 ## 5 informati~ (Int~ 67790. 1580. 42.9 ## 6 informati~ expe~ 1868. 289. 6.47 ## 7 sociology (Int~ 41028. 1169. 35.1 ## 8 sociology expe~ 1724. 185. 9.30 ## 9 statistics (Int~ 79426. 2031. 39.1 ## 10 statistics expe~ 221. 347. 0.637 ## # ... with 1 more variable: p.value &lt;dbl&gt; un_pooling &lt;- no_pool %&gt;% dplyr::select(department, term, estimate) %&gt;% tidyr::pivot_wider( names_from = term, values_from = estimate ) %&gt;% dplyr::rename(Intercept = `(Intercept)`, slope = experience) %&gt;% dplyr::mutate(pooled = &quot;no_pool&quot;) %&gt;% dplyr::select(pooled, level = department, Intercept, slope) un_pooling ## # A tibble: 5 x 4 ## # Groups: level [5] ## pooled level Intercept slope ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 no_pool biology 51489. 278. ## 2 no_pool english 59045. 753. ## 3 no_pool informatics 67790. 1868. ## 4 no_pool sociology 41028. 1724. ## 5 no_pool statistics 79426. 221. 33.7.3 可视化 library(ggrepel) un_pooling %&gt;% dplyr::bind_rows(partial_pooling) %&gt;% ggplot(aes(x = Intercept, y = slope)) + purrr::map( c(seq(from = 0.1, to = 0.9, by = 0.1)), .f = function(level) { stat_ellipse( geom = &quot;polygon&quot;, type = &quot;norm&quot;, size = 0, alpha = 1 / 10, fill = &quot;gray10&quot;, level = level ) } ) + geom_point(aes(group = pooled, color = pooled)) + geom_line(aes(group = level), size = 1 / 4) + # geom_point(data = complete_pooling, size = 4, color = &quot;red&quot;) + geom_text_repel( data = . %&gt;% filter(pooled == &quot;no_pool&quot;), aes(label = level) ) + scale_color_manual( name = &quot;信息池&quot;, values = c( &quot;no_pool&quot; = &quot;black&quot;, &quot;partial_pool&quot; = &quot;red&quot; # , # &quot;complete_pool&quot; = &quot;#A65141&quot; ), labels = c( &quot;no_pool&quot; = &quot;不共享&quot;, &quot;partial_pool&quot; = &quot;部分共享&quot; # , # &quot;complete_pool&quot; = &quot;完全共享&quot; ) ) #+ # theme_classic() 33.8 更多 解释模型的含义 lmer(salary ~ 1 + (0 + experience | department), data = df) # vs lmer(salary ~ 1 + experience + (0 + experience | department), data = df) lmer(salary ~ 1 + (1 + experience | department), data = df) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: salary ~ 1 + (1 + experience | department) ## Data: df ## REML criterion at convergence: 1934 ## Random effects: ## Groups Name Std.Dev. Corr ## department (Intercept) 15864 ## experience 1164 -0.49 ## Residual 3403 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) ## 66154 # vs lmer(salary ~ 1 + (1 | department) + (0 + experience | department), data = df) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## salary ~ 1 + (1 | department) + (0 + experience | department) ## Data: df ## REML criterion at convergence: 1934 ## Random effects: ## Groups Name Std.Dev. ## department (Intercept) 14638 ## department.1 experience 1163 ## Residual 3403 ## Number of obs: 100, groups: department, 5 ## Fixed Effects: ## (Intercept) ## 59988 课后阅读文献，读完后大家一起分享 课后阅读 Understanding mixed effects models through data simulation， "],["poisson-regression.html", "第 34 章 广义线性模型 34.1 线性回归回顾 34.2 案例 34.3 泊松回归模型 34.4 模型解释 34.5 思考 34.6 小结", " 第 34 章 广义线性模型 34.1 线性回归回顾 从线性模型的数学记号 \\[ y_n = \\alpha + \\beta x_n + \\epsilon_n \\quad \\text{where}\\quad \\epsilon_n \\sim \\operatorname{normal}(0,\\sigma). \\] 等价于 \\[ y_n - (\\alpha + \\beta x_n) \\sim \\operatorname{normal}(0,\\sigma), \\] 又可以写为 \\[ y_n \\sim \\operatorname{normal}(\\alpha + \\beta x_n, \\, \\sigma). \\] 线性回归需要满足四个前提假设： Linearity 因变量和每个自变量都是线性关系 Indpendence 对于所有的观测值，它们的误差项相互之间是独立的 Normality 误差项服从正态分布 Equal-variance 所有的误差项具有同样方差 这四个假设的首字母，合起来就是LINE，这样很好记 把这四个前提画在一张图中 34.2 案例 我们从一个有意思的案例开始。 在受污染的岛屿附近，金枪鱼出现次数 library(tidyverse) df &lt;- read_rds(&quot;./demo_data/fish.rds&quot;) df ## # A tibble: 200 x 2 ## pollution_level number_of_fish ## &lt;dbl&gt; &lt;int&gt; ## 1 0 4 ## 2 0.00503 2 ## 3 0.0101 1 ## 4 0.0151 5 ## 5 0.0201 4 ## 6 0.0251 1 ## 7 0.0302 2 ## 8 0.0352 2 ## 9 0.0402 3 ## 10 0.0452 1 ## # ... with 190 more rows 我们的问题是，污染如何影响鱼类的数量？具体来说是想：建立不同位置金枪鱼的数量 与 这个位置的污染程度之间的线性关系。 34.2.1 线性模型的局限性 先看看变量之间的关系 df %&gt;% ggplot(aes(x = pollution_level, y = number_of_fish)) + geom_point() + geom_smooth(method = lm) + labs( title = &quot;Number of fish counted under different pollution level&quot;, x = &quot;Pollution level&quot;, y = &quot;Number of fish counted&quot; ) 线性关系不明显，而且被解释变量甚至出现了负值。 我们再看看线性模型的结果 m0 &lt;- lm(number_of_fish ~ pollution_level, data = df) summary(m0) ## ## Call: ## lm(formula = number_of_fish ~ pollution_level, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.499 -0.709 -0.024 0.578 4.635 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.900 0.152 19.1 &lt;2e-16 ## pollution_level -3.331 0.263 -12.6 &lt;2e-16 ## ## (Intercept) *** ## pollution_level *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.08 on 198 degrees of freedom ## Multiple R-squared: 0.447, Adjusted R-squared: 0.444 ## F-statistic: 160 on 1 and 198 DF, p-value: &lt;2e-16 线性模型的失灵！ 怎么办呢？ 34.2.2 泊松分布 我们再看看被解释变量的分布： 非负的整数0, 1, 2, 3, 4, … df %&gt;% ggplot(aes(x = number_of_fish)) + geom_histogram() + labs( title = &quot;number of fishes (Poisson distribution)&quot; ) 这是典型的泊松分布。 generate_pois &lt;- function(lambda_value) { tibble( lambda = as.character(lambda_value), x = seq(1, 10), d = dpois(x = x, lambda = lambda_value) ) } tb &lt;- seq(0.1, 1.8, by = 0.2) %&gt;% map_dfr(generate_pois) tb %&gt;% ggplot(aes(x = x, y = d, color = lambda)) + geom_point() + geom_line() + scale_x_continuous(breaks = seq(1, 10, 1)) + theme_bw() 事实上，生活中很多场合都会遇到计数、二进制、yes/no、等待时间等类型的数据，比如 医院每天急诊次数 每年摩托车死亡人数 城市发生火灾的次数 他们有个共同的特征 变量代表单位时间或者区域事件发生的次数，服从泊松分布。泊松分布有什么特点？ \\[ y_i \\sim \\text{Poisson}(\\lambda = \\lambda_i) \\] 34.2.3 正态分布换成泊松分布就行了？ 回到我们目的：建立不同位置 鱼的数量 与 这个位置的污染程度之间线性关系。 在之前线性模型中讲到，对每一次观测，被解释变量服从正态分布，那么，我们用解释变量的线性组合模拟正态分布的均值\\(\\mu_i\\)，即均值\\(\\mu_i\\)随\\(x_i\\)变化 \\[ \\begin{align*} y_i \\sim &amp; \\operatorname{normal}(\\mu_i, \\, \\sigma)\\\\ &amp;\\operatorname{normal}(\\mu_i = \\beta_0 + \\beta_1 x_i, \\, \\sigma) \\end{align*} \\] 我们也想如法炮制，正态分布换成泊松分布 \\[ \\begin{align*} y_i \\sim &amp; \\text{Poisson}(\\lambda_i)\\\\ &amp; \\text{Poisson}(\\lambda_i = \\beta_0 + \\beta_1 x_i) \\end{align*} \\] 但很遗憾，出现了问题 泊松分布的\\(\\lambda_i\\) 要求大于等于0，然而\\(\\beta_0 + \\beta_1 X_i\\)势必会出现负数 34.3 泊松回归模型 34.3.1 解决办法-连接函数之美 尽管不能使用直接线性模型，但可以间接使用，统计学家想到用log(\\(\\lambda_i\\)) 代替 \\(\\lambda_i\\)，然后让解释变量的线性组合模拟log(\\(\\lambda_i\\))，即 \\[ \\begin{align*} y_i \\sim &amp; \\text{Poisson}(\\lambda_i)\\\\ \\color{red}\\log(\\lambda_i) = &amp; \\beta_0 + \\beta_1 x_i \\end{align*} \\] 现在问题迎刃而解： - log(\\(\\lambda_i\\)) 值域范围是(\\(-\\infty\\) to \\(\\infty\\))，这样既保证了\\(\\lambda_i\\) 是正值，又保证了\\(\\beta_0 + \\beta_1 x_i\\) 可能出现的负值 这里的log()函数就是连接函数， 连接了\\(x_i\\)和\\(\\lambda_i\\) 所以泊松回归模型为 \\[ \\begin{align*} \\log(\\lambda_i) = &amp; \\beta_0 + \\beta_1 x_i \\end{align*} \\] 注意到，这里没有线性回归模型中的误差项。通过极大似然估计（Maximum Likelihood Estimation）计算系数\\((\\beta)\\) 什么叫最大相似性估计？通俗点讲，给定y的分布以及独立变量(x)的值，那么最有可能的\\(\\beta\\)系数多是多少？ step 1 \\(y\\) 服从泊松分布 \\[ \\operatorname{Pr}\\left(y_{i} | \\lambda\\right)=\\frac{\\lambda^{y_{i}} e^{-\\lambda}}{y_{i} !}, \\quad y=0,1,2, \\ldots \\quad ; \\quad \\lambda&amp;gt;0 \\] step 2 回归模型 \\[ E\\left[y_{i} | x_{i}\\right]=\\lambda_{i}=\\exp \\left(x_{i}^{\\prime} \\beta\\right) \\] step 3 \\(\\lambda_{i}\\) 代入上式，考虑观测值彼此独立，可以将所有\\(y_i\\)观测值相乘， \\[ \\operatorname{Pr}\\left(y_{1}, \\ldots, y_{N} | x_{1}, \\ldots, x_{N}\\right)=\\prod_{i=1}^{N} \\frac{e^{y_{i} x_{i}^{\\prime} \\beta} e^{-e^{x_{i}^{\\prime}} \\beta}}{y_{i} !} \\] step 4 然后取对数，得到(joint log-likelihood function) \\[ l\\left(\\beta | y_{i}, X_{i}\\right)=\\sum_{i=1}^{n} y_{i} X_{i}^{\\prime} \\beta-\\exp X_{i}^{\\prime} \\beta-\\log y_{i} ! \\] step 5 求偏导 \\[ \\frac{\\partial l}{\\partial \\beta}=\\sum_{i=1}^{n}\\left(y_{i}-\\exp X_{i}^{\\prime} \\beta\\right) X_{i} \\] step 6 令等式等于0，通过样本值，可以求出系数。 34.3.2 代码实现 使用glm()函数: glm(y ~ 1 + x, family = familytype(link = linkfunction), data = ) formula: 被解释变量 ~ 解释变量 family : 误差分布（和连接函数），family = poisson(link=\"log\") data : 数据框 m &lt;- glm(number_of_fish ~ pollution_level, family = poisson(link = &quot;log&quot;), data = df ) m ## ## Call: glm(formula = number_of_fish ~ pollution_level, family = poisson(link = &quot;log&quot;), ## data = df) ## ## Coefficients: ## (Intercept) pollution_level ## 1.39 -3.11 ## ## Degrees of Freedom: 199 Total (i.e. Null); 198 Residual ## Null Deviance: 363 ## Residual Deviance: 201 AIC: 492 summary(m) ## ## Call: ## glm(formula = number_of_fish ~ pollution_level, family = poisson(link = &quot;log&quot;), ## data = df) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.346 -0.923 -0.605 0.629 2.382 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.3872 0.0977 14.2 &lt;2e-16 ## pollution_level -3.1077 0.2716 -11.4 &lt;2e-16 ## ## (Intercept) *** ## pollution_level *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 363.03 on 199 degrees of freedom ## Residual deviance: 201.16 on 198 degrees of freedom ## AIC: 492.2 ## ## Number of Fisher Scoring iterations: 5 confint(m) ## 2.5 % 97.5 % ## (Intercept) 1.192 1.575 ## pollution_level -3.652 -2.586 broom::tidy(m) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 1.39 0.0977 14.2 9.33e-46 ## 2 pollution_level -3.11 0.272 -11.4 2.52e-30 34.4 模型解释 我们建立的模型是 \\[ \\begin{align*} y_i \\sim &amp; \\text{Poisson}(\\lambda_i)\\\\ \\log(\\lambda_i) = &amp; \\beta_0 + \\beta_1 x_i \\end{align*} \\] 我个人比较喜欢这样写 \\[ \\begin{align*} y_i \\sim &amp; \\;\\text{Poisson}(\\lambda_i = \\exp(\\beta_0 + \\beta_1 x_i)) \\end{align*} \\] 34.4.1 系数 \\[ \\begin{align*} \\frac{\\lambda_1}{\\lambda_0} &amp; = \\frac{\\exp(\\beta_1 + \\beta_1*x_1)}{\\exp(\\beta_0 + \\beta_1*x_0)} \\\\ &amp; = \\exp(\\beta_1(x_1 - x_0)) \\end{align*} \\] 计算当\\(x_i\\)增加一个单位时，事件平均发生次数将会是原来的\\(\\exp(\\beta_1)\\)倍。具体系数为： coef(m) ## (Intercept) pollution_level ## 1.387 -3.108 exp(coef(m)[2]) ## pollution_level ## 0.0447 exp(coef(m)) ## (Intercept) pollution_level ## 4.0036 0.0447 污染系数为0， 4.0036 污染系数从0变到0.5, 引起 (1/exp(-3.1077*0.5) = 4.7)倍数的鱼数量下降. 污染系数从0变到1, 引起 22.3704 倍数的鱼数量下降. 34.4.2 边际效应(Marginal effects) 即在其他条件不变的情况下，\\(x_i\\)增加一个单位，事件的平均发生次数会增加 \\(100\\beta_1 \\%\\)： 类似求偏导\\(\\frac{\\partial{\\lambda}}{\\partial{x}}\\) margins::margins(m, type = &quot;link&quot;) ## pollution_level ## -3.108 模型是非线性的，所以我们常用更直观的方式评估边际效应，即，自变量直接对因变量的贡献，可以令type = \"response\"，类似求偏导\\(\\frac{\\partial{y}}{\\partial{x}}\\) margins::marginal_effects(m, type = &quot;response&quot;, se = TRUE) %&gt;% as.data.frame() %&gt;% dplyr::mutate(pollution_level = df$pollution_level) %&gt;% ggplot(aes(x = pollution_level, y = dydx_pollution_level)) + geom_point() 纵坐标是事件的平均发生次数（增加）下降的比例，可以看到随着x变大，下降趋缓。更多边际效应的内容，可参考这里 34.4.3 拟合 fitted(m) %&gt;% head() ## 1 2 3 4 5 6 ## 4.004 3.942 3.880 3.820 3.761 3.703 实质上就是\\(exp(\\beta_0 + \\beta_1 * pollution_level)\\) intercept &lt;- coef(m)[1] beta &lt;- coef(m)[2] df %&gt;% dplyr::mutate(theory_pred = fitted(m)) %&gt;% dplyr::mutate( myguess_pred = exp(intercept + beta * pollution_level) ) ## # A tibble: 200 x 4 ## pollution_level number_of_fish theory_pred ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 0 4 4.00 ## 2 0.00503 2 3.94 ## 3 0.0101 1 3.88 ## 4 0.0151 5 3.82 ## 5 0.0201 4 3.76 ## 6 0.0251 1 3.70 ## 7 0.0302 2 3.65 ## 8 0.0352 2 3.59 ## 9 0.0402 3 3.53 ## 10 0.0452 1 3.48 ## # ... with 190 more rows, and 1 more variable: ## # myguess_pred &lt;dbl&gt; df %&gt;% dplyr::mutate(theory_pred = fitted(m)) %&gt;% ggplot(aes(x = pollution_level, y = theory_pred)) + geom_point() pred &lt;- predict(m, type = &quot;response&quot;, se = TRUE) %&gt;% as.data.frame() pred %&gt;% head() ## fit se.fit residual.scale ## 1 4.004 0.3911 1 ## 2 3.942 0.3810 1 ## 3 3.880 0.3711 1 ## 4 3.820 0.3615 1 ## 5 3.761 0.3521 1 ## 6 3.703 0.3430 1 df_pred &lt;- df %&gt;% dplyr::mutate( fit = pred$fit, se_fit = pred$se.fit ) df_pred ## # A tibble: 200 x 4 ## pollution_level number_of_fish fit se_fit ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 4 4.00 0.391 ## 2 0.00503 2 3.94 0.381 ## 3 0.0101 1 3.88 0.371 ## 4 0.0151 5 3.82 0.362 ## 5 0.0201 4 3.76 0.352 ## 6 0.0251 1 3.70 0.343 ## 7 0.0302 2 3.65 0.334 ## 8 0.0352 2 3.59 0.325 ## 9 0.0402 3 3.53 0.317 ## 10 0.0452 1 3.48 0.309 ## # ... with 190 more rows real_df &lt;- tibble( x = seq(0, 1, length.out = 100), y = 4 * exp(-3.2 * x) ) df_pred %&gt;% ggplot(aes(x = pollution_level, y = number_of_fish)) + geom_point() + geom_pointrange(aes( y = fit, ymax = fit + se_fit, ymin = fit - se_fit ), color = &quot;red&quot;) + # geom_point(aes(y = fit + se_fit), color = &quot;red&quot;) + # geom_point(aes(y = fit - se_fit), color = &quot;red&quot;) + geom_line(data = real_df, aes(x = x, y = y), color = &quot;black&quot;) + labs( title = &quot;Number of fish counted under different pollution level&quot;, x = &quot;Pollution level&quot;, y = &quot;Number of fish counted&quot; ) 34.4.4 模型评估 knitr::include_graphics(path = &quot;images/model_evaluation.png&quot;) 过度离散，负二项式分布模型 零膨胀 margins::margins(m) ggeffects::ggpredict(m) ggeffects::ggpredict(m, terms = c(&quot;pollution_level&quot;)) performance::model_performance(m) performance::check_model(m) performance::check_overdispersion(m) performance::check_zeroinflation(m) 34.5 思考 34.5.1 这两者为什么是相等的？ d &lt;- tibble( x = 1:100, y = 4 + 2 * x + rnorm(100) ) lm(y ~ x, data = d) ## ## Call: ## lm(formula = y ~ x, data = d) ## ## Coefficients: ## (Intercept) x ## 3.9 2.0 glm(y ~ x, family = gaussian(link = &quot;identity&quot;), data = d ) ## ## Call: glm(formula = y ~ x, family = gaussian(link = &quot;identity&quot;), data = d) ## ## Coefficients: ## (Intercept) x ## 3.9 2.0 ## ## Degrees of Freedom: 99 Total (i.e. Null); 98 Residual ## Null Deviance: 334000 ## Residual Deviance: 117 AIC: 306 lm 是 glm的一种特殊情形。 34.5.2 log link 与 log transforming 在案例中 log link glm(number_of_fish ~ pollution_level, family = gaussian(link = &quot;log&quot;), data = df ) 先对 number_of_fish 取对数后，然后线性回归 # lm(log(number_of_fish) ~ pollution_level, data = df) glm(log(number_of_fish) ~ pollution_level, family = gaussian(link = &quot;identity&quot;), data = df ) 这两者有什么区别？ 比较两者的结果，发现有很大的差别，尤其是斜率，为什么呢？ 因为这是两个不同的模型： 第一个模型中 link=\"log\"，模型并没有直接变换数据，只是使用了原始数据的均值，均值对数计算后，建立线性关系，即 \\[ \\begin{align*} \\log(\\lambda_i) &amp; = \\beta_0 + \\beta_1 x_i \\\\ \\lambda_i &amp; = \\exp(\\beta_0 + \\beta_1 x_i) \\end{align*} \\] 注意到这里family = gaussian, 因此，误差项满足高斯分布 \\[ \\begin{align*} y_i - \\lambda_i &amp;\\sim \\operatorname{normal}(0,\\sigma)\\\\ y_i - \\exp(\\beta_0 + \\beta_1 x_i) &amp;\\sim \\operatorname{normal}(0,\\sigma) \\\\ y_i &amp;\\sim \\operatorname{normal}(\\exp(\\beta_0 + \\beta_1 x_i), \\, \\sigma) \\end{align*} \\] \\[ y_i = \\exp(\\beta_0 + \\beta_1 x_i) + \\epsilon_i\\quad \\epsilon_i \\sim \\operatorname{normal}(0,\\sigma) \\] 因此对不同均值\\(\\lambda_i\\)，误差项的方差是一样的 第二个模型 log transforming，是直接转换原始数据，然后建立模型\\(\\log(y_i) = \\alpha + \\beta x_i\\)，原始数据y的均值和方差都改变了，一旦log(y) 变回 y时， \\[ \\log(y_i) =\\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad \\epsilon_i \\sim \\operatorname{normal}(0,\\sigma) \\] \\[ y_i = \\exp(\\beta_0 + \\beta_1 x_i) * \\exp(\\epsilon_i), \\quad \\epsilon_i \\sim \\operatorname{normal}(0,\\sigma) \\] 误差的方差也会随着均值变化。 34.5.3 更多分布 x &lt;- c(1, 2, 3, 4, 5) y &lt;- c(1, 2, 4, 2, 6) regNId &lt;- glm(y ~ x, family = gaussian(link = &quot;identity&quot;)) regNlog &lt;- glm(y ~ x, family = gaussian(link = &quot;log&quot;)) regPId &lt;- glm(y ~ x, family = poisson(link = &quot;identity&quot;)) regPlog &lt;- glm(y ~ x, family = poisson(link = &quot;log&quot;)) regGId &lt;- glm(y ~ x, family = Gamma(link = &quot;identity&quot;)) regGlog &lt;- glm(y ~ x, family = Gamma(link = &quot;log&quot;)) regIGId &lt;- glm(y ~ x, family = inverse.gaussian(link = &quot;identity&quot;)) regIGlog &lt;- glm(y ~ x, family = inverse.gaussian(link = &quot;log&quot;)) dx &lt;- tibble( x = c(1, 2, 3, 4, 5), y = c(1, 2, 4, 2, 6) ) dx %&gt;% ggplot(aes(x = x, y = y)) + geom_point() regNId &lt;- glm(y ~ x, family = gaussian(link = &quot;identity&quot;), data = dx) regNId dx %&gt;% mutate(pred = predict(regNId, type = &quot;response&quot;)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + geom_line(aes(y = pred, group = 1)) regPlog &lt;- glm(y ~ x, family = poisson(link = &quot;log&quot;), data = dx) regPlog dx %&gt;% mutate(pred = predict(regPlog, type = &quot;response&quot;)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + geom_line(aes(y = pred, group = 1)) regGId &lt;- glm(y ~ x, family = Gamma(link = &quot;identity&quot;), data = dx) regGId dx %&gt;% mutate(pred = predict(regGId, type = &quot;response&quot;)) %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + geom_line(aes(y = pred, group = 1)) 34.5.4 更复杂的模型 以后再说 glm(number_of_fish ~ 1 + (1 | pollution_level), family = poisson(link = &quot;log&quot;), data = df ) 34.6 小结 knitr::include_graphics(path = &quot;images/One_Picture.png&quot;) 第 35 章接着讲广义线性模型中的logistic回归模型。 "],["logistic-regression.html", "第 35 章 logistic回归模型 35.1 问题 35.2 模型的输出 35.3 预测", " 第 35 章 logistic回归模型 本章讲广义线性模型中的logistic回归模型。 35.1 问题 假定这里有一组数据，包含学生GRE成绩和被录取的状态(admit = 1，就是被录取；admit = 0，没有被录取) library(tidyverse) gredata &lt;- read_csv(&quot;demo_data/gredata.csv&quot;) gredata ## # A tibble: 400 x 4 ## admit gre gpa rank ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 380 3.61 3 ## 2 1 660 3.67 3 ## 3 1 800 4 1 ## 4 1 640 3.19 4 ## 5 0 520 2.93 4 ## 6 1 760 3 2 ## 7 1 560 2.98 1 ## 8 0 400 3.08 2 ## 9 1 540 3.39 3 ## 10 0 700 3.92 2 ## # ... with 390 more rows 我们能用学生GRE的成绩预测录取状态吗？回答这个问题需要用到logistic回归模型， \\[ \\begin{align*} \\text{admit}_{i} &amp;\\sim \\mathrm{Binomial}(1, p_{i}) \\\\ logit(p_{i}) &amp;= log\\Big(\\frac{p_{i}}{1 - p_{i}}\\Big) = \\alpha + \\beta \\cdot \\text{gre}_{i} \\end{align*} \\] 这里 \\(p_i\\) 就是被录取的概率。预测因子 \\(gre\\) 的线性组合模拟的是 \\(log\\Big(\\frac{p_{i}}{1 - p_{i}}\\Big)\\) ，即对数比率(log-odds). 按照上面表达式，用glm函数写代码， model_logit &lt;- glm(admit ~ gre, data = gredata, family = binomial(link = &quot;logit&quot;) ) summary(model_logit) ## ## Call: ## glm(formula = admit ~ gre, family = binomial(link = &quot;logit&quot;), ## data = gredata) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.162 -0.905 -0.755 1.349 1.988 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.901344 0.606038 -4.79 1.7e-06 *** ## gre 0.003582 0.000986 3.63 0.00028 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 499.98 on 399 degrees of freedom ## Residual deviance: 486.06 on 398 degrees of freedom ## AIC: 490.1 ## ## Number of Fisher Scoring iterations: 4 得到gre的系数是 coef(model_logit)[2] ## gre ## 0.003582 怎么理解这个0.003582呢？ 35.2 模型的输出 为了更好地理解模型的输出，这里用三种不同的度量方式(scales)来计算系数。 假定 \\(p\\) 为录取的概率 num scale formula 1 The log-odds scale \\(log \\frac{p}{1 - p}\\) 2 The odds scale \\(\\frac{p}{1 -p}\\) 3 The probability scale \\(p\\) 35.2.1 The log-odds scale 模型给出系数（0.003582）事实上就是log-odds度量方式的结果，具体来说， 这里系数（0.003582）代表着： GRE考试成绩每增加1个单位，那么log-odds(录取概率)就会增加0.003582. （注意，不是录取概率增加0.003582，而是log-odds(录取概率)增加0.003582） 为了更清楚的理解，我们把log-odds的结果与gre成绩画出来看看 logit_log_odds &lt;- broom::augment_columns( model_logit, data = gredata, type.predict = c(&quot;link&quot;) ) %&gt;% rename(log_odds = .fitted) library(latex2exp) logit_log_odds %&gt;% ggplot(aes(x = gre, y = log_odds)) + geom_path(color = &quot;#771C6D&quot;, size = 2) + labs(title = &quot;Log odds (β)&quot;, subtitle = &quot;This is linear!&quot;, x = NULL, y = TeX(&quot;$log \\\\frac{p}{1 - p}$&quot;)) + theme_minimal() + theme( plot.title = element_text(face = &quot;bold&quot;), axis.title.y = element_text(angle = 90) ) 由图看到，GRE成绩 与log-odds(录取概率)这个值的关系是线性的，斜率就是模型给出的系数0.003582 35.2.2 The odds scale 第二种odds scale度量方式可能要比第一种要好理解点，我们先求系数的指数，exp(0.003582) = 1.003588 exp(0.003582) ## [1] 1.004 1.003588的含义是: GRE考试成绩每增加1个单位，那么odds(录取概率)就会增大1.003588倍；若增加2个单位，那么odds(录取概率)就会增大(1.003588 * 1.003588)倍，也就说是个乘法关系。 有时候，大家喜欢用增长百分比表述，那么就是 (exp(0.003582) - 1) x 100% = (1.003588 - 1) x 100% = 0.36% 即，GRE考试成绩每增加1个点，那么odds(录取概率)就会增长百分之0.36. 同样，我们把odds(录取概率)的结果与GRE成绩画出来看看 logit_odds &lt;- broom::augment_columns( model_logit, data = gredata, type.predict = c(&quot;link&quot;) ) %&gt;% rename(log_odds = .fitted) %&gt;% mutate(odds_ratio = exp(log_odds)) logit_odds %&gt;% ggplot(aes(x = gre, y = odds_ratio)) + geom_line(color = &quot;#FB9E07&quot;, size = 2) + labs(title = &quot;Odds (exp(β))&quot;, subtitle = &quot;This is curvy, but it&#39;s a mathy transformation of a linear value&quot;, x = NULL, y = TeX(&quot;$\\\\frac{p}{1 - p}$&quot;)) + theme_minimal() + theme( plot.title = element_text(face = &quot;bold&quot;), axis.title.y = element_text(angle = 90) ) 35.2.3 The probability scale. 第三种度量方式是概率度量(probability scale)，因为模型假定的是，GRE的分数与log-odds(录取概率)呈线性关系，那么很显然GRE的分数与录取概率就不可能是线性关系了，而是呈非线性关系。我们先看下非线性关系长什么样。 logit_probs &lt;- broom::augment_columns( model_logit, data = gredata, type.predict = c(&quot;response&quot;) ) %&gt;% rename(pred_prob = .fitted) logit_probs %&gt;% ggplot(aes(x = gre, y = pred_prob)) + #geom_point(aes(x = gre, y = admit)) + geom_line(color = &quot;#CF4446&quot;, size = 2) + labs(title = &quot;Predicted probabilities&quot;, sutitle = &quot;Plug values of X into &quot;, x = &quot;X (value of explanatory variable)&quot;, y = TeX(&quot;\\\\hat{P(Y)} &quot;)) + theme_minimal() + theme(plot.title = element_text(face = &quot;bold&quot;)) 可以看到，GRE分数对录取的概率的影响是正的且非线性的，具体来说， GRE分数200分左右，录取概率约0.1； GRE分数500分左右，录取概率约0.25； GRE分数800分左右，录取概率接近0.5； 提请注意的是，以上三种度量的方式中： log_odds scale，预测因子与log_odds()的关系是一个固定值，具有可加性 odds scale， 预测因子与odds()的关系是一个固定值，具有乘法性 probability，预测因子与probability的关系不再是一个固定值了 用哪种度量方式来理解模型的输出，取决不同的场景。第一种方式容易计算但理解较为困难，第三种方式最容易理解，但不再是线性关系了。 35.3 预测 35.3.1 预测与拟合 先认识下两个常用的函数predict()和fitted(). gredata %&gt;% mutate( pred = predict(model_logit), fitted = fitted(model_logit) ) ## # A tibble: 400 x 6 ## admit gre gpa rank pred fitted ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 380 3.61 3 -1.54 0.177 ## 2 1 660 3.67 3 -0.537 0.369 ## 3 1 800 4 1 -0.0356 0.491 ## 4 1 640 3.19 4 -0.609 0.352 ## 5 0 520 2.93 4 -1.04 0.261 ## 6 1 760 3 2 -0.179 0.455 ## 7 1 560 2.98 1 -0.895 0.290 ## 8 0 400 3.08 2 -1.47 0.187 ## 9 1 540 3.39 3 -0.967 0.275 ## 10 0 700 3.92 2 -0.394 0.403 ## # ... with 390 more rows 线性模型中，predict()和fitted()这种写法的返回结果是一样的。但在glm模型中，两者的结果是不同的。predict()返回的是log_odds(录取概率)度量的结果；而fitted()返回的是录取概率。如果想保持一致，需要对predict()返回结果做反向的log_odds计算 \\[p = \\exp(\\alpha) / (1 + \\exp(\\alpha) )\\] 具体如下 gredata %&gt;% mutate( pred = predict(model_logit), fitted = fitted(model_logit), pred2 = exp(pred) / (1 + exp(pred) ) ) ## # A tibble: 400 x 7 ## admit gre gpa rank pred fitted pred2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 380 3.61 3 -1.54 0.177 0.177 ## 2 1 660 3.67 3 -0.537 0.369 0.369 ## 3 1 800 4 1 -0.0356 0.491 0.491 ## 4 1 640 3.19 4 -0.609 0.352 0.352 ## 5 0 520 2.93 4 -1.04 0.261 0.261 ## 6 1 760 3 2 -0.179 0.455 0.455 ## 7 1 560 2.98 1 -0.895 0.290 0.290 ## 8 0 400 3.08 2 -1.47 0.187 0.187 ## 9 1 540 3.39 3 -0.967 0.275 0.275 ## 10 0 700 3.92 2 -0.394 0.403 0.403 ## # ... with 390 more rows 我这样折腾无非是想让大家知道，在glm中predict()和fit()是不同的。 如果想让predict()也返回录取概率，也可以不用那么麻烦，事实上predict的type = \"response\") 选项已经为我们准备好了。 gredata %&gt;% mutate( pred = predict(model_logit, type = &quot;response&quot;), fitted = fitted(model_logit) ) ## # A tibble: 400 x 6 ## admit gre gpa rank pred fitted ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 380 3.61 3 0.177 0.177 ## 2 1 660 3.67 3 0.369 0.369 ## 3 1 800 4 1 0.491 0.491 ## 4 1 640 3.19 4 0.352 0.352 ## 5 0 520 2.93 4 0.261 0.261 ## 6 1 760 3 2 0.455 0.455 ## 7 1 560 2.98 1 0.290 0.290 ## 8 0 400 3.08 2 0.187 0.187 ## 9 1 540 3.39 3 0.275 0.275 ## 10 0 700 3.92 2 0.403 0.403 ## # ... with 390 more rows 35.3.2 预测 有时候，我们需要对给定的GRE分数，用建立的模型预测被录取的概率 newdata &lt;- tibble( gre = c(550, 660, 700, 780) ) newdata ## # A tibble: 4 x 1 ## gre ## &lt;dbl&gt; ## 1 550 ## 2 660 ## 3 700 ## 4 780 前面讲到predict()中type参数有若干选项type = c(\"link\", \"response\", \"terms\"), type = \"link\"，预测的是log_odds，实际上就是coef(model_logit)[1] + gre * coef(model_logit)[2] newdata %&gt;% mutate( pred_log_odds = predict(model_logit, newdata = newdata, type = &quot;link&quot;), # pred_log_odds2 = coef(model_logit)[1] + gre * coef(model_logit)[2] ) ## # A tibble: 4 x 3 ## gre pred_log_odds pred_log_odds2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 550 -0.931 -0.931 ## 2 660 -0.537 -0.537 ## 3 700 -0.394 -0.394 ## 4 780 -0.107 -0.107 type = \"response\"\"，预测的是probabilities， 实际上就是exp(pred_log_odds) / (1 + exp(pred_log_odds) ) newdata %&gt;% mutate( pred_log_odds = predict(model_logit, newdata = newdata, type = &quot;link&quot;) ) %&gt;% mutate( pred_prob = predict(model_logit, newdata = newdata, type = &quot;response&quot;), # pred_prob2 = exp(pred_log_odds) / (1 + exp(pred_log_odds) ) ) ## # A tibble: 4 x 4 ## gre pred_log_odds pred_prob pred_prob2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 550 -0.931 0.283 0.283 ## 2 660 -0.537 0.369 0.369 ## 3 700 -0.394 0.403 0.403 ## 4 780 -0.107 0.473 0.473 type = \"terms\"，返回一个矩阵，具体计算为：模型的设计矩阵中心化以后，与模型返回的系数相乘而得到的新矩阵5。 predict(model_logit, gredata, type = &#39;terms&#39;) %&gt;% as_tibble() %&gt;% head() ## # A tibble: 6 x 1 ## gre ## &lt;dbl&gt; ## 1 -0.744 ## 2 0.259 ## 3 0.761 ## 4 0.187 ## 5 -0.243 ## 6 0.617 我们复盘一次 X &lt;- model.matrix(admit ~ gre, data = gredata) X %&gt;% as.data.frame() %&gt;% mutate( across(everything(), ~ .x - mean(.x)) ) %&gt;% transmute( term = coef(model_logit)[2] * gre ) %&gt;% head() ## term ## 1 -0.7440 ## 2 0.2590 ## 3 0.7605 ## 4 0.1873 ## 5 -0.2425 ## 6 0.6172 https://stackoverflow.com/questions/37963904/what-does-predict-glm-type-terms-actually-do "],["ordinal.html", "第 36 章 有序logistic回归 36.1 logistic回归 36.2 生活中的有序logistic回归 36.3 案例 36.4 问题的提出 36.5 其他宏包", " 第 36 章 有序logistic回归 本节课，是广义线性模型的延续 library(tidyverse) 36.1 logistic回归 二元logistic回归：Y为定类且为2个，比如是否购买(1购买；0不购买) 多分类logistic回归：Y为定类且选项大于2个，比如总统候选人偏好(特朗普、希拉里、卢比奥) 有序logistic回归：Y为定类且有序，幸福感(不幸福、比较幸福和非常幸福) 36.2 生活中的有序logistic回归 人们在肯德基里点餐，一般都会买可乐，可乐有四种型号(small, medium, large or extra large)，选择何种型号的可乐会与哪些因素有关呢？是否购买了汉堡、是否购买了薯条，消费者的年龄等。我们这里考察的被解释变量，可乐的大小就是一个有序的值。 问卷调查。问大三的学生是否申请读研究生，有三个选项：1不愿意，2有点愿意，3非常愿意。那么这里的被解释变量是三个有序的类别，影响读研意愿的因素可能与父母的教育水平、本科阶段学习成绩、经济压力等有关。 36.3 案例 教育代际传递。通俗点说子女的教育程度是否受到父母教育程度的影响。我这个案例思路参考了南京大学池彪的《教育人力资本的代际传递研究》硕士论文，这篇文章思路很清晰，建议大家可以看看。根据文中提供的数据来源，我们下载2016年的中国家庭追踪调查数据CFPS，并整理了部分数据。 tb &lt;- readr::read_rds(&quot;./demo_data/cfps.rds&quot;) head(tb) ## # A tibble: 6 x 8 ## pid sex age edu edu_f edu_m urban ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.02e8 1 28 5 3 2 1 ## 2 1.04e8 1 34 6 4 4 1 ## 3 1.09e8 1 43 3 1 1 1 ## 4 1.09e8 1 31 4 4 4 1 ## 5 1.10e8 1 28 6 1 1 1 ## 6 1.10e8 1 42 4 2 2 1 ## # ... with 1 more variable: num_siblings &lt;int&gt; tb %&gt;% count(edu) ## # A tibble: 8 x 2 ## edu n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 399 ## 2 2 801 ## 3 3 1492 ## 4 4 706 ## 5 5 475 ## 6 6 374 ## 7 7 46 ## 8 8 2 tb %&gt;% count(edu_f) ## # A tibble: 6 x 2 ## edu_f n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 1345 ## 2 2 1090 ## 3 3 1125 ## 4 4 639 ## 5 5 72 ## 6 6 24 tb %&gt;% count(edu_m) ## # A tibble: 6 x 2 ## edu_m n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 2482 ## 2 2 768 ## 3 3 712 ## 4 4 310 ## 5 5 17 ## 6 6 6 为了方便处理，减少分类，我们将大专以及大专以上的都归为一类 df &lt;- tb %&gt;% dplyr::mutate( across( starts_with(&quot;edu&quot;), ~ case_when( . %in% c(5, 6, 7, 8) ~ 5, TRUE ~ . ) ) ) df ## # A tibble: 4,295 x 8 ## pid sex age edu edu_f edu_m urban ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.02e8 1 28 5 3 2 1 ## 2 1.04e8 1 34 5 4 4 1 ## 3 1.09e8 1 43 3 1 1 1 ## 4 1.09e8 1 31 4 4 4 1 ## 5 1.10e8 1 28 5 1 1 1 ## 6 1.10e8 1 42 4 2 2 1 ## 7 1.10e8 1 43 5 5 3 1 ## 8 1.10e8 1 31 4 4 4 1 ## 9 1.10e8 0 30 4 4 4 1 ## 10 1.10e8 1 30 5 4 4 1 ## # ... with 4,285 more rows, and 1 more variable: ## # num_siblings &lt;int&gt; 看起很复杂？那我写简单点 tb %&gt;% dplyr::mutate( across( starts_with(&quot;edu&quot;), ~ if_else(. %in% c(5, 6, 7, 8), 5, .) ) ) ## # A tibble: 4,295 x 8 ## pid sex age edu edu_f edu_m urban ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.02e8 1 28 5 3 2 1 ## 2 1.04e8 1 34 5 4 4 1 ## 3 1.09e8 1 43 3 1 1 1 ## 4 1.09e8 1 31 4 4 4 1 ## 5 1.10e8 1 28 5 1 1 1 ## 6 1.10e8 1 42 4 2 2 1 ## 7 1.10e8 1 43 5 5 3 1 ## 8 1.10e8 1 31 4 4 4 1 ## 9 1.10e8 0 30 4 4 4 1 ## 10 1.10e8 1 30 5 4 4 1 ## # ... with 4,285 more rows, and 1 more variable: ## # num_siblings &lt;int&gt; df %&gt;% count(edu) ## # A tibble: 5 x 2 ## edu n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 399 ## 2 2 801 ## 3 3 1492 ## 4 4 706 ## 5 5 897 df %&gt;% count(edu_f) ## # A tibble: 5 x 2 ## edu_f n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 1345 ## 2 2 1090 ## 3 3 1125 ## 4 4 639 ## 5 5 96 df %&gt;% count(edu_m) ## # A tibble: 5 x 2 ## edu_m n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 2482 ## 2 2 768 ## 3 3 712 ## 4 4 310 ## 5 5 23 36.4 问题的提出 问题的提出： 学历上父母是否门当户对？ 父母的受教育程度对子女的受教育水平是正向影响？ 父亲和母亲谁的影响大？ 对男孩影响大？还是对女孩影响大？ 以上情况城乡有无差异？ 36.4.1 父母门当户对？ 数据还是比较有意思的，我们来看看父母是否门当户对 多大比例选择门当户对? df ## # A tibble: 4,295 x 8 ## pid sex age edu edu_f edu_m urban ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.02e8 1 28 5 3 2 1 ## 2 1.04e8 1 34 5 4 4 1 ## 3 1.09e8 1 43 3 1 1 1 ## 4 1.09e8 1 31 4 4 4 1 ## 5 1.10e8 1 28 5 1 1 1 ## 6 1.10e8 1 42 4 2 2 1 ## 7 1.10e8 1 43 5 5 3 1 ## 8 1.10e8 1 31 4 4 4 1 ## 9 1.10e8 0 30 4 4 4 1 ## 10 1.10e8 1 30 5 4 4 1 ## # ... with 4,285 more rows, and 1 more variable: ## # num_siblings &lt;int&gt; df %&gt;% dplyr::summarise( eq_n = sum(edu_m == edu_f), n = n() ) %&gt;% dplyr::mutate(prop = eq_n / n) ## # A tibble: 1 x 3 ## eq_n n prop ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1829 4295 0.426 df %&gt;% dplyr::count(edu_m, edu_f) %&gt;% dplyr::group_by(edu_m) %&gt;% dplyr::mutate(prop = n / sum(n)) %&gt;% dplyr::ungroup() ## # A tibble: 24 x 4 ## edu_m edu_f n prop ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 1 1106 0.446 ## 2 1 2 635 0.256 ## 3 1 3 491 0.198 ## 4 1 4 230 0.0927 ## 5 1 5 20 0.00806 ## 6 2 1 147 0.191 ## 7 2 2 276 0.359 ## 8 2 3 224 0.292 ## 9 2 4 111 0.145 ## 10 2 5 10 0.0130 ## # ... with 14 more rows df %&gt;% dplyr::count(edu_m, edu_f) %&gt;% dplyr::group_by(edu_m) %&gt;% dplyr::mutate(percent = n / sum(n)) %&gt;% dplyr::select(-n) %&gt;% tidyr::pivot_wider( names_from = edu_f, values_from = percent ) ## # A tibble: 5 x 6 ## # Groups: edu_m [5] ## edu_m `1` `2` `3` `4` `5` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.446 0.256 0.198 0.0927 0.00806 ## 2 2 0.191 0.359 0.292 0.145 0.0130 ## 3 3 0.0927 0.191 0.438 0.233 0.0449 ## 4 4 0.0774 0.139 0.303 0.403 0.0774 ## 5 5 0.0870 NA 0.174 0.304 0.435 36.4.2 母亲的教育程度对子女的影响 library(ggridges) df %&gt;% dplyr::mutate( across(edu_m, as.factor) ) %&gt;% ggplot(aes(x = edu, y = edu_m)) + geom_density_ridges() + scale_x_continuous(limits = c(0, 6), breaks = c(1:5)) + labs( title = &quot;家庭中母亲的教育程度对子女的影响&quot;, subtitle = &quot;数字越大，教育程度越高&quot;, x = &quot;子女的教育程度&quot;, y = &quot;母亲的教育程度&quot; ) 36.4.3 父亲和母亲谁的影响大 这里需要用到有序logistic回归，我们使用MASS::polr函数。 为了理解模型的输出，我们需要先简单介绍下模型的含义。假定被解释变量\\(Y\\)有\\(J\\)类且有序，那么\\(Y\\) 小于等于某个具体类别\\(j\\)的累积概率，可以写为\\(P(Y \\le j)\\)，这里\\(j = 1, \\cdots, J-1\\). 从而，小于等于某个具体类别\\(j\\)的比率就可以定义为 \\[\\frac{P(Y \\le j)}{P(Y&gt;j)}\\] 对这个比率取对数，就是我们熟知的logit \\[log \\frac{P(Y \\le j)}{P(Y&gt;j)} = logit (P(Y \\le j)).\\] 在R语言中，有序logistic回归的数学模型就是 \\[logit (P(Y \\le j)) = \\alpha_{j} + \\beta_{1}x_1 + \\beta_{2}x_2 \\] \\(\\alpha\\) 是截距 \\(\\beta\\) 是回归系数，注意到有序分类 logistic 回归模型中就有 \\(J-1\\) 个 logit 模型。对于每个模型，系数是相同的，截距不同。下面我们通过代码来演示 library(MASS) df1 &lt;- df %&gt;% dplyr::mutate( across(c(edu, sex, urban), as.factor), across(edu, ~ fct_inseq(., ordered = TRUE)) ) mod_mass &lt;- polr(edu ~ edu_f + edu_m + sex + num_siblings + urban, data = df1, method = c(&quot;logistic&quot;) ) summary(mod_mass) ## Call: ## polr(formula = edu ~ edu_f + edu_m + sex + num_siblings + urban, ## data = df1, method = c(&quot;logistic&quot;)) ## ## Coefficients: ## Value Std. Error t value ## edu_f 0.461 0.0284 16.26 ## edu_m 0.507 0.0323 15.72 ## sex1 -0.461 0.0693 -6.65 ## num_siblings -0.154 0.0436 -3.53 ## urban1 0.957 0.0601 15.91 ## ## Intercepts: ## Value Std. Error t value ## 1|2 -0.838 0.122 -6.893 ## 2|3 0.674 0.117 5.742 ## 3|4 2.509 0.124 20.295 ## 4|5 3.545 0.129 27.430 ## ## Residual Deviance: 11680.22 ## AIC: 11698.22 输出结果得到有序分类 logistic 回归模型中截距和回归系数的最大似然估计值，确定出回归方程为： \\[ \\begin{aligned} \\text{logit}(\\hat{P}(Y \\le 1))&amp;= \\text{logit}\\left(p_{1}\\right) = \\ln \\left(\\frac{p_{1}}{1 - p_{1}}\\right) = -0.8385 + \\\\ \\text{logit}(\\hat{P}(Y \\le 2))&amp;= \\text{logit}\\left(p_{1} + p_{2}\\right) = \\ln \\left(\\frac{p_{1} + p_{2}}{1 - p_{1} - p_{2}}\\right) = 0.6742 + \\\\ \\text{logit}(\\hat{P}(Y \\le 3))&amp;= \\text{logit}\\left(p_{1} + p_{2} + p_{3}\\right) = \\ln \\left(\\frac{p_{1} + p_{2} + p_{3}}{1 - p_{1} - p_{2} - p_{3}}\\right) = 2.5093\\\\ \\text{logit}(\\hat{P}(Y \\le 4))&amp;= \\text{logit}\\left(p_{1} + p_{2} + p_{3} + p_{4}\\right) = \\ln \\left(\\frac{p_{1} + p_{2} + p_{3} + p_{4}}{1 - p_{1} - p_{2} - p_{3} - p_{4}}\\right) = 3.5454\\\\ \\end{aligned} \\] 写起很麻烦，偷个懒吧 library(equatiomatic) extract_eq(mod_mass, use_coefs = TRUE) ## $$ ## \\begin{aligned} ## \\log\\left[ \\frac { P( \\operatorname{1} \\geq \\operatorname{2} ) }{ 1 - P( \\operatorname{1} \\geq \\operatorname{2} ) } \\right] &amp;= -0.84 + 0.46(\\operatorname{edu\\_f}) + 0.51(\\operatorname{edu\\_m}) - 0.46(\\operatorname{sex}_{\\operatorname{1}}) - 0.15(\\operatorname{num\\_siblings}) + 0.96(\\operatorname{urban}_{\\operatorname{1}}) + \\epsilon \\\\ ## \\log\\left[ \\frac { P( \\operatorname{2} \\geq \\operatorname{3} ) }{ 1 - P( \\operatorname{2} \\geq \\operatorname{3} ) } \\right] &amp;= 0.67 + 0.46(\\operatorname{edu\\_f}) + 0.51(\\operatorname{edu\\_m}) - 0.46(\\operatorname{sex}_{\\operatorname{1}}) - 0.15(\\operatorname{num\\_siblings}) + 0.96(\\operatorname{urban}_{\\operatorname{1}}) + \\epsilon \\\\ ## \\log\\left[ \\frac { P( \\operatorname{3} \\geq \\operatorname{4} ) }{ 1 - P( \\operatorname{3} \\geq \\operatorname{4} ) } \\right] &amp;= 2.51 + 0.46(\\operatorname{edu\\_f}) + 0.51(\\operatorname{edu\\_m}) - 0.46(\\operatorname{sex}_{\\operatorname{1}}) - 0.15(\\operatorname{num\\_siblings}) + 0.96(\\operatorname{urban}_{\\operatorname{1}}) + \\epsilon \\\\ ## \\log\\left[ \\frac { P( \\operatorname{4} \\geq \\operatorname{5} ) }{ 1 - P( \\operatorname{4} \\geq \\operatorname{5} ) } \\right] &amp;= 3.55 + 0.46(\\operatorname{edu\\_f}) + 0.51(\\operatorname{edu\\_m}) - 0.46(\\operatorname{sex}_{\\operatorname{1}}) - 0.15(\\operatorname{num\\_siblings}) + 0.96(\\operatorname{urban}_{\\operatorname{1}}) + \\epsilon ## \\end{aligned} ## $$ 36.4.4 系数的解释 先将系数转换成odds ratios(OR) coef(mod_mass) %&gt;% exp() ## edu_f edu_m sex1 num_siblings ## 1.5859 1.6610 0.6307 0.8572 ## urban1 ## 2.6038 在其它因素不变的情况下，父亲教育程度每增加一个等级（比如，大专到本科）， 会增加子女教育程度向上提高一个级别的概率1.58倍，也就是增加了58%。 在其它因素不变的情况下，母亲教育程度每提高一个等级，会增加提升子女教育水平的概率1.66倍. 从子女的性别差异来看, 在其它因素不变的情况下，女性的受教育水平向上提高一个级别的概率更大，是男性的(1/0.630)倍，或者说，男性受教育水平向上提高一个级别的概率比女性减少37%(1 - 0.63). 从城乡差异来看，城镇子女提升教育水平的概率是农村的2.6倍 36.4.5 边际效应 library(margins) # me_mass &lt;- marginal_effects(mod_mass, variables = &quot;sex&quot;) me_mass &lt;- marginal_effects(mod_mass, variables = &quot;edu_m&quot;) me_mass %&gt;% head() ## dydx_edu_m ## 1 -0.013404 ## 2 -0.003196 ## 3 -0.047453 ## 4 -0.003196 ## 5 -0.047453 ## 6 -0.020597 从边际效应图可以看到，随着父母教育程度的增加，子女低学历的的概率减少，高学历的概率增加 36.5 其他宏包 36.5.1 ordinal 包 library(ordinal) mod_ordinal &lt;- clm(edu ~ edu_f + edu_m + sex + num_siblings + urban, data = df1, link = &quot;logit&quot;, thresholds = &quot;flexible&quot; ) broom::tidy(mod_ordinal) ## # A tibble: 9 x 6 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1|2 -0.838 0.122 -6.89 5.48e- 12 ## 2 2|3 0.674 0.117 5.74 9.34e- 9 ## 3 3|4 2.51 0.124 20.3 1.41e- 91 ## 4 4|5 3.55 0.129 27.4 1.21e-165 ## 5 edu_f 0.461 0.0284 16.3 1.98e- 59 ## 6 edu_m 0.507 0.0323 15.7 1.19e- 55 ## 7 sex1 -0.461 0.0693 -6.65 2.89e- 11 ## 8 num_~ -0.154 0.0436 -3.53 4.16e- 4 ## 9 urba~ 0.957 0.0601 15.9 5.30e- 57 ## # ... with 1 more variable: coef.type &lt;chr&gt; "],["tidymodels.html", "第 37 章 机器学习 37.1 数据 37.2 机器学习 37.3 model01 37.4 model02 37.5 model03 37.6 model04 37.7 workflow", " 第 37 章 机器学习 Rstudio工厂的 Max Kuhn 大神正主持机器学习的开发，日臻成熟了，感觉很强大啊。 library(tidyverse) library(tidymodels) 37.1 数据 penguins &lt;- read_csv(&quot;./demo_data/penguins.csv&quot;) %&gt;% janitor::clean_names() %&gt;% drop_na() penguins %&gt;% head() penguins %&gt;% ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species) ) + geom_point() 37.2 机器学习 split &lt;- penguins %&gt;% mutate(species = as_factor(species)) %&gt;% mutate(species = fct_lump(species, 1)) %&gt;% initial_split() split training_data &lt;- training(split) training_data testing_data &lt;- testing(split) testing_data 37.3 model01 model_logistic &lt;- parsnip::logistic_reg() %&gt;% set_engine(&quot;glm&quot;) %&gt;% set_mode(&quot;classification&quot;) %&gt;% fit(species ~ bill_length_mm + bill_depth_mm, data = training_data) bind_cols( predict(model_logistic, new_data = testing_data, type = &quot;class&quot;), predict(model_logistic, new_data = testing_data, type = &quot;prob&quot;), testing_data ) predict(model, new_data = testing_data) %&gt;% bind_cols(testing_data) %&gt;% count(.pred_class, species) 37.4 model02 model_neighbor &lt;- parsnip::nearest_neighbor(neighbors = 10) %&gt;% set_engine(&quot;kknn&quot;) %&gt;% set_mode(&quot;classification&quot;) %&gt;% fit(species ~ bill_length_mm, data = training_data) predict(model_neighbor, new_data = testing_data) %&gt;% bind_cols(testing_data) %&gt;% count(.pred_class, species) 37.5 model03 model_multinom &lt;- parsnip::multinom_reg() %&gt;% set_engine(&quot;nnet&quot;) %&gt;% set_mode(&quot;classification&quot;) %&gt;% fit(species ~ bill_length_mm, data = training_data) predict(model_multinom, new_data = testing_data) %&gt;% bind_cols(testing_data) %&gt;% count(.pred_class, species) 37.6 model04 model_decision &lt;- parsnip::decision_tree() %&gt;% set_engine(&quot;rpart&quot;) %&gt;% set_mode(&quot;classification&quot;) %&gt;% fit(species ~ bill_length_mm, data = training_data) predict(model_decision, new_data = testing_data) %&gt;% bind_cols(testing_data) %&gt;% count(.pred_class, species) 37.7 workflow 37.7.1 使用 recipes library(tidyverse) library(tidymodels) library(workflows) penguins &lt;- readr::read_csv(&quot;./demo_data/penguins.csv&quot;) %&gt;% janitor::clean_names() split &lt;- penguins %&gt;% tidyr::drop_na() %&gt;% rsample::initial_split(prop = 3/4) training_data &lt;- rsample::training(split) testing_data &lt;- rsample::testing(split) 参考tidy modeling in R, 被预测变量在分割前，应该先处理，比如标准化。 但这里的案例，我为了偷懒，被预测变量bill_length_mm，暂时保留不变。 预测变量做标准处理。 penguins_lm &lt;- parsnip::linear_reg() %&gt;% #parsnip::set_engine(&quot;lm&quot;) parsnip::set_engine(&quot;stan&quot;) penguins_recipe &lt;- recipes::recipe(bill_length_mm ~ bill_depth_mm + sex, data = training_data) %&gt;% recipes::step_normalize(all_numeric(), -all_outcomes()) %&gt;% recipes::step_dummy(all_nominal()) broom::tidy(penguins_recipe) ## # A tibble: 2 x 6 ## number operation type trained skip id ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 1 step normalize FALSE FALSE normalize_a~ ## 2 2 step dummy FALSE FALSE dummy_Gbbae penguins_recipe %&gt;% recipes::prep(data = training_data) %&gt;% #or prep(retain = TRUE) recipes::juice() penguins_recipe %&gt;% recipes::prep(data = training_data) %&gt;% recipes::bake(new_data = testing_data) # recipe used in new_data train_data &lt;- penguins_recipe %&gt;% recipes::prep(data = training_data) %&gt;% recipes::bake(new_data = NULL) test_data &lt;- penguins_recipe %&gt;% recipes::prep(data = training_data) %&gt;% recipes::bake(new_data = testing_data) 37.7.2 workflows的思路更清晰 workflows的思路让模型结构更清晰。 这样prep(), bake(), and juice() 就可以省略了，只需要recipe和model，他们往往是成对出现的 wflow &lt;- workflows::workflow() %&gt;% workflows::add_recipe(penguins_recipe) %&gt;% workflows::add_model(penguins_lm) wflow_fit &lt;- wflow %&gt;% parsnip::fit(data = training_data) wflow_fit %&gt;% workflows::pull_workflow_fit() %&gt;% broom.mixed::tidy() ## # A tibble: 3 x 3 ## term estimate std.error ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 41.5 0.410 ## 2 bill_depth_mm -2.17 0.300 ## 3 sex_male 5.08 0.614 wflow_fit %&gt;% workflows::pull_workflow_prepped_recipe() ## Data Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 2 ## ## Training data contained 250 data points and no missing data. ## ## Operations: ## ## Centering and scaling for bill_depth_mm [trained] ## Dummy variables from sex [trained] 先提取模型，用在 predict() 是可以的，但这样太麻烦了 wflow_fit %&gt;% workflows::pull_workflow_fit() %&gt;% stats::predict(new_data = test_data) # note: test_data not testing_data 因为，predict() 会自动的将recipes(对training_data的操作)，应用到testing_data 这个不错，参考这里 penguins_pred &lt;- predict( wflow_fit, new_data = testing_data %&gt;% dplyr::select(-bill_length_mm), type= &quot;numeric&quot; ) %&gt;% dplyr::bind_cols(testing_data %&gt;% dplyr::select(bill_length_mm)) penguins_pred ## # A tibble: 83 x 2 ## .pred bill_length_mm ## &lt;dbl&gt; &lt;dbl&gt; ## 1 42.2 34.6 ## 2 40.8 36.6 ## 3 41.8 46 ## 4 40.2 37.8 ## 5 44.9 37.7 ## 6 39.2 35.9 ## 7 41.9 39.5 ## 8 40.8 39.5 ## 9 39.1 37.6 ## 10 44.5 41.1 ## # ... with 73 more rows penguins_pred %&gt;% ggplot(aes(x = bill_length_mm, y = .pred)) + geom_abline(linetype = 2) + geom_point(alpha = 0.5) + labs(y = &quot;Predicted &quot;, x = &quot;bill_length_mm&quot;) 37.7.3 模型评估 参考https://www.tmwr.org/performance.html#regression-metrics penguins_pred %&gt;% yardstick::rmse(truth = bill_length_mm, estimate = .pred) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 5.29 # 自定义一个指标评价函数my_multi_metric，就是放一起，感觉不够tidyverse my_multi_metric &lt;- yardstick::metric_set(rmse, rsq, mae, ccc) penguins_pred %&gt;% my_multi_metric(truth = bill_length_mm, estimate = .pred) ## # A tibble: 4 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 5.29 ## 2 rsq standard 0.289 ## 3 mae standard 4.31 ## 4 ccc standard 0.384 "],["bayesian-models.html", "第 38 章 贝叶斯建模 38.1 生活中的贝叶斯 38.2 贝叶斯公式 38.3 三张图讲贝叶斯分析 38.4 线性模型", " 第 38 章 贝叶斯建模 library(tidyverse) library(tidybayes) library(rstan) library(brms) rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) 之前我们讲了线性模型和混合线性模型，今天我们往前一步，应该说是一大步。因为这一步迈向了贝叶斯分析，与频率学派的分析有本质的区别，这种区别类似经典物理和量子物理的区别。 频率学派，是从数据出发 贝叶斯。先假定参数有一个分布，看到数据后，再重新分配可能性。 38.1 生活中的贝叶斯 事实上，贝叶斯在生活中应用很广泛，我们自觉和不自觉中都在使用贝叶斯分析。 38.2 贝叶斯公式 参数是假设，数据是证据。对于参数 \\(\\theta\\) 和数据 \\(D\\)，贝叶斯公式可以写为 \\[ \\underbrace{p(\\theta|D)}_\\text{posterior} \\; = \\; \\underbrace{p(D|\\theta)}_\\text{likelihood} \\;\\; \\underbrace{p(\\theta)}_\\text{prior} \\;. \\] 38.3 三张图讲贝叶斯分析 第一张图: 在看到数据之前，我们预先认为参数，应该在某个范围且服从某种分布 第二张图: 曲线与数据匹配得怎么样? 相似性概率 第三张图: 看到数据之后，可能的曲线 观察到数据点后，我们认为服从线性模型，这个线性模型不是一条直线，而是很多条，有些线的可能性大，有些线的可能性低，但都是有可能的。那么，综合这些有可能的线，(截距和斜率)构成了一种分布，即后验概率分布。 因为我们是R语言课，我们跳过很多理论推导。事实上，我在学习贝叶斯数据分析的时候，也是先从代码操作人手，然后理解贝叶斯推断相关理论，有时候更直观更容易理解。当然，我不是说我的方法一定正确，只是供大家的一个选项。我会用到brms和stan，但我个人更喜欢stan. 38.4 线性模型 从最简单的线性模式开始 \\[ y_n = \\alpha + \\beta x_n + \\epsilon_n \\quad \\text{where}\\quad \\epsilon_n \\sim \\operatorname{normal}(0,\\sigma). \\] 等价于 \\[ y_n - (\\alpha + \\beta X_n) \\sim \\operatorname{normal}(0,\\sigma), \\] 进一步等价 \\[ y_n \\sim \\operatorname{normal}(\\alpha + \\beta X_n, \\, \\sigma). \\] stan_program &lt;- &quot; data { int&lt;lower=0&gt; N; vector[N] x; vector[N] y; } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; } model { y ~ normal(alpha + beta * x, sigma); } &quot; "],["eda-nobel.html", "第 39 章 探索性数据分析-诺奖获得者 39.1 探索性 39.2 数据集 39.3 导入数据 39.4 数据结构 39.5 我们想探索哪些问题？ 39.6 每个学科颁过多少次奖 39.7 看看我们伟大的祖国 39.8 哪些大神多次获得诺贝尔奖 39.9 大神在得奖的时候是多大年龄？ 39.10 性别比例 39.11 这些大神都是哪个年代出生的人？ 39.12 最年轻的诺奖获得者？ 39.13 平均年龄和获奖数量 39.14 出生地与工作地分布 39.15 迁移模式 39.16 地图 39.17 出生地和工作地不一样的占比 39.18 诺奖分享者 39.19 其它 39.20 延伸阅读", " 第 39 章 探索性数据分析-诺奖获得者 探索性数据分析（exporatory data analysis）是各种知识的综合运用。本章通过一个案例，讲解探索性数据分析的基本思路，也算是对前面几章内容的一次总结复习。 39.1 探索性 数据准备（对数据要做到心中有数） 描述变量 数据结构 缺失值及其处理 数据探索（围绕探索的目标） 数据规整 可视化 建模 39.2 数据集 这是一个诺贝尔奖获得者的数据集， 39.3 导入数据 library(tidyverse) library(lubridate) df &lt;- read_csv(&quot;./demo_data/nobel_winners.csv&quot;) df ## # A tibble: 969 x 18 ## prize_year category prize motivation prize_share ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1901 Chemist~ The ~ &quot;\\&quot;in rec~ 1/1 ## 2 1901 Literat~ The ~ &quot;\\&quot;in spe~ 1/1 ## 3 1901 Medicine The ~ &quot;\\&quot;for hi~ 1/1 ## 4 1901 Peace The ~ &lt;NA&gt; 1/2 ## 5 1901 Peace The ~ &lt;NA&gt; 1/2 ## 6 1901 Physics The ~ &quot;\\&quot;in rec~ 1/1 ## 7 1902 Chemist~ The ~ &quot;\\&quot;in rec~ 1/1 ## 8 1902 Literat~ The ~ &quot;\\&quot;the gr~ 1/1 ## 9 1902 Medicine The ~ &quot;\\&quot;for hi~ 1/1 ## 10 1902 Peace The ~ &lt;NA&gt; 1/2 ## # ... with 959 more rows, and 13 more variables: ## # laureate_id &lt;dbl&gt;, laureate_type &lt;chr&gt;, ## # full_name &lt;chr&gt;, birth_date &lt;date&gt;, ## # birth_city &lt;chr&gt;, birth_country &lt;chr&gt;, ## # gender &lt;chr&gt;, organization_name &lt;chr&gt;, ## # organization_city &lt;chr&gt;, ## # organization_country &lt;chr&gt;, death_date &lt;date&gt;, ## # death_city &lt;chr&gt;, death_country &lt;chr&gt; # 如果是xlsx格式 readxl::read_excel(&quot;myfile.xlsx&quot;) # 如果是csv格式 readr::read_csv(&quot;myfile.csv&quot;) 这里有个小小的提示： 路径（包括文件名）， 不要用中文和空格 数据框中变量，也不要有中文和空格（可用下划线代替空格） 39.4 数据结构 一行就是一个诺奖获得者的记录? 确定？ 缺失值及其处理 df %&gt;% map_df(~ sum(is.na(.))) ## # A tibble: 1 x 18 ## prize_year category prize motivation prize_share ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 88 0 ## # ... with 13 more variables: laureate_id &lt;int&gt;, ## # laureate_type &lt;int&gt;, full_name &lt;int&gt;, ## # birth_date &lt;int&gt;, birth_city &lt;int&gt;, ## # birth_country &lt;int&gt;, gender &lt;int&gt;, ## # organization_name &lt;int&gt;, organization_city &lt;int&gt;, ## # organization_country &lt;int&gt;, death_date &lt;int&gt;, ## # death_city &lt;int&gt;, death_country &lt;int&gt; 性别缺失怎么造成的？ df %&gt;% count(laureate_type) ## # A tibble: 2 x 2 ## laureate_type n ## &lt;chr&gt; &lt;int&gt; ## 1 Individual 939 ## 2 Organization 30 39.5 我们想探索哪些问题？ 你想关心哪些问题，可能是 每个学科颁过多少次奖？ 这些大神都是哪个年代的人？ 性别比例 平均年龄和获奖数量 最年轻的诺奖获得者是谁？ 中国诺奖获得者有哪些？ 得奖的时候多大年龄？ 获奖者所在国家的经济情况？ 有大神多次获得诺贝尔奖，而且在不同科学领域获奖？ 出生地分布？工作地分布？迁移模式？ GDP经济与诺奖模型？ 诺奖分享情况？ 39.6 每个学科颁过多少次奖 df %&gt;% count(category) ## # A tibble: 6 x 2 ## category n ## &lt;chr&gt; &lt;int&gt; ## 1 Chemistry 194 ## 2 Economics 83 ## 3 Literature 113 ## 4 Medicine 227 ## 5 Peace 130 ## 6 Physics 222 df %&gt;% count(category) %&gt;% ggplot(aes(x = category, y = n, fill = category)) + geom_col() + geom_text(aes(label = n), vjust = -0.25) + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) df %&gt;% count(category) %&gt;% ggplot(aes(x = fct_reorder(category, n), y = n, fill = category)) + geom_col() + geom_text(aes(label = n), vjust = -0.25) + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) 也可以使用别人定义好的配色方案 library(ggthemr) # install.packages(&quot;devtools&quot;) # devtools::install_github(&#39;cttobin/ggthemr&#39;) ggthemr(&quot;dust&quot;) df %&gt;% count(category) %&gt;% ggplot(aes(x = fct_reorder(category, n), y = n, fill = category)) + geom_col() + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) 这个配色方案感觉挺好看的呢，比较适合我这种又挑剔又懒惰的人。 当然，也可以自己DIY，或者使用配色网站的主题方案(https://learnui.design/tools/data-color-picker.html#palette) df %&gt;% count(category) %&gt;% ggplot(aes(x = fct_reorder(category, n), y = n)) + geom_col(fill = c(&quot;#003f5c&quot;, &quot;#444e86&quot;, &quot;#955196&quot;, &quot;#dd5182&quot;, &quot;#ff6e54&quot;, &quot;#ffa600&quot;)) + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) 让图骚动起来吧 library(gganimate) # install.packages(&quot;gganimate&quot;, dependencies = T) df %&gt;% count(category) %&gt;% mutate(category = fct_reorder(category, n)) %&gt;% ggplot(aes(x = category, y = n)) + geom_text(aes(label = n), vjust = -0.25) + geom_col(fill = c(&quot;#003f5c&quot;, &quot;#444e86&quot;, &quot;#955196&quot;, &quot;#dd5182&quot;, &quot;#ff6e54&quot;, &quot;#ffa600&quot;)) + labs(title = &quot;不同学科诺贝奖获奖次数对比&quot;, x = &quot;学科&quot;, y = &quot;数量&quot;) + theme(legend.position = &quot;none&quot;) + transition_states(category) + shadow_mark(past = TRUE) 和ggplot2的分面一样，动态图可以增加数据展示的维度。 39.7 看看我们伟大的祖国 df %&gt;% dplyr::filter(birth_country == &quot;China&quot;) %&gt;% dplyr::select(full_name, prize_year, category) ## # A tibble: 12 x 3 ## full_name prize_year category ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Walter Houser Brattain 1956 Physics ## 2 Chen Ning Yang 1957 Physics ## 3 Tsung-Dao (T.D.) Lee 1957 Physics ## 4 Edmond H. Fischer 1992 Medicine ## 5 Daniel C. Tsui 1998 Physics ## 6 Gao Xingjian 2000 Literature ## 7 Charles Kuen Kao 2009 Physics ## 8 Charles Kuen Kao 2009 Physics ## 9 Ei-ichi Negishi 2010 Chemistry ## 10 Liu Xiaobo 2010 Peace ## 11 Mo Yan 2012 Literature ## 12 Youyou Tu 2015 Medicine 我们发现获奖者有多个地址，就会有重复的情况，比如 Charles Kuen Kao在2009年Physics有两次，为什么重复计数了呢？ 下面我们去重吧， 去重可以用distinct()函数 dt &lt;- tibble::tribble( ~x, ~y, ~z, 1, 1, &quot;a&quot;, 1, 1, &quot;b&quot;, 1, 2, &quot;c&quot;, 1, 2, &quot;d&quot; ) dt ## # A tibble: 4 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 1 a ## 2 1 1 b ## 3 1 2 c ## 4 1 2 d dt %&gt;% distinct_at(vars(x), .keep_all = T) ## # A tibble: 1 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 1 a dt %&gt;% distinct_at(vars(x, y), .keep_all = T) ## # A tibble: 2 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 1 a ## 2 1 2 c nobel_winners &lt;- df %&gt;% mutate_if(is.character, tolower) %&gt;% distinct_at(vars(full_name, prize_year, category), .keep_all = TRUE) %&gt;% mutate( decade = 10 * (prize_year %/% 10), prize_age = prize_year - year(birth_date) ) nobel_winners ## # A tibble: 911 x 20 ## prize_year category prize motivation prize_share ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1901 chemist~ the ~ &quot;\\&quot;in rec~ 1/1 ## 2 1901 literat~ the ~ &quot;\\&quot;in spe~ 1/1 ## 3 1901 medicine the ~ &quot;\\&quot;for hi~ 1/1 ## 4 1901 peace the ~ &lt;NA&gt; 1/2 ## 5 1901 peace the ~ &lt;NA&gt; 1/2 ## 6 1901 physics the ~ &quot;\\&quot;in rec~ 1/1 ## 7 1902 chemist~ the ~ &quot;\\&quot;in rec~ 1/1 ## 8 1902 literat~ the ~ &quot;\\&quot;the gr~ 1/1 ## 9 1902 medicine the ~ &quot;\\&quot;for hi~ 1/1 ## 10 1902 peace the ~ &lt;NA&gt; 1/2 ## # ... with 901 more rows, and 15 more variables: ## # laureate_id &lt;dbl&gt;, laureate_type &lt;chr&gt;, ## # full_name &lt;chr&gt;, birth_date &lt;date&gt;, ## # birth_city &lt;chr&gt;, birth_country &lt;chr&gt;, ## # gender &lt;chr&gt;, organization_name &lt;chr&gt;, ## # organization_city &lt;chr&gt;, ## # organization_country &lt;chr&gt;, death_date &lt;date&gt;, ## # death_city &lt;chr&gt;, death_country &lt;chr&gt;, ## # decade &lt;dbl&gt;, prize_age &lt;dbl&gt; 这是时候，我们才对数据有了一个初步的了解 再来看看我的祖国 nobel_winners %&gt;% dplyr::filter(birth_country == &quot;china&quot;) %&gt;% dplyr::select(full_name, prize_year, category) ## # A tibble: 11 x 3 ## full_name prize_year category ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 walter houser brattain 1956 physics ## 2 chen ning yang 1957 physics ## 3 tsung-dao (t.d.) lee 1957 physics ## 4 edmond h. fischer 1992 medicine ## 5 daniel c. tsui 1998 physics ## 6 gao xingjian 2000 literature ## 7 charles kuen kao 2009 physics ## 8 ei-ichi negishi 2010 chemistry ## 9 liu xiaobo 2010 peace ## 10 mo yan 2012 literature ## 11 youyou tu 2015 medicine 39.8 哪些大神多次获得诺贝尔奖 nobel_winners %&gt;% count(full_name, sort = T) ## # A tibble: 904 x 2 ## full_name n ## &lt;chr&gt; &lt;int&gt; ## 1 &quot;comité international de la croix rouge (inte~ 3 ## 2 &quot;frederick sanger&quot; 2 ## 3 &quot;john bardeen&quot; 2 ## 4 &quot;linus carl pauling&quot; 2 ## 5 &quot;marie curie, née sklodowska&quot; 2 ## 6 &quot;office of the united nations high commission~ 2 ## 7 &quot; lie ducommun&quot; 1 ## 8 &quot;a. michael spence&quot; 1 ## 9 &quot;aage niels bohr&quot; 1 ## 10 &quot;aaron ciechanover&quot; 1 ## # ... with 894 more rows nobel_winners %&gt;% group_by(full_name) %&gt;% mutate( number_prize = n(), number_cateory = n_distinct(category) ) %&gt;% arrange(desc(number_prize), full_name) %&gt;% dplyr::filter(number_cateory == 2) ## # A tibble: 4 x 22 ## # Groups: full_name [2] ## prize_year category prize motivation prize_share ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1954 chemist~ the ~ &quot;\\&quot;for hi~ 1/1 ## 2 1962 peace the ~ &lt;NA&gt; 1/1 ## 3 1903 physics the ~ &quot;\\&quot;in rec~ 1/4 ## 4 1911 chemist~ the ~ &quot;\\&quot;in rec~ 1/1 ## # ... with 17 more variables: laureate_id &lt;dbl&gt;, ## # laureate_type &lt;chr&gt;, full_name &lt;chr&gt;, ## # birth_date &lt;date&gt;, birth_city &lt;chr&gt;, ## # birth_country &lt;chr&gt;, gender &lt;chr&gt;, ## # organization_name &lt;chr&gt;, organization_city &lt;chr&gt;, ## # organization_country &lt;chr&gt;, death_date &lt;date&gt;, ## # death_city &lt;chr&gt;, death_country &lt;chr&gt;, ## # decade &lt;dbl&gt;, prize_age &lt;dbl&gt;, number_prize &lt;int&gt;, ## # number_cateory &lt;int&gt; 39.9 大神在得奖的时候是多大年龄？ nobel_winners %&gt;% count(prize_age) %&gt;% ggplot(aes(x = prize_age, y = n)) + geom_col() nobel_winners %&gt;% group_by(category) %&gt;% summarise(mean_prize_age = mean(prize_age, na.rm = T)) ## # A tibble: 6 x 2 ## category mean_prize_age ## &lt;chr&gt; &lt;dbl&gt; ## 1 chemistry 58.0 ## 2 economics 67.2 ## 3 literature 64.7 ## 4 medicine 58.0 ## 5 peace 61.4 ## 6 physics 55.4 nobel_winners %&gt;% mutate(category = fct_reorder(category, prize_age, median, na.rm = TRUE)) %&gt;% ggplot(aes(category, prize_age)) + geom_point() + geom_boxplot() + coord_flip() nobel_winners %&gt;% dplyr::filter(!is.na(prize_age)) %&gt;% group_by(decade, category) %&gt;% summarize( average_age = mean(prize_age), median_age = median(prize_age) ) %&gt;% ggplot(aes(decade, average_age, color = category)) + geom_line() library(ggridges) nobel_winners %&gt;% ggplot(aes( x = prize_age, y = category, fill = category )) + geom_density_ridges() 他们60多少岁才得诺奖，大家才23或24岁，还年轻，不用焦虑喔。 nobel_winners %&gt;% ggplot(aes(x = prize_age, fill = category, color = category)) + geom_density() + facet_wrap(vars(category)) + theme(legend.position = &quot;none&quot;) 有同学说要一个个的画，至于group_split()函数，下次课在讲 nobel_winners %&gt;% group_split(category) %&gt;% map( ~ ggplot(data = .x, aes(x = prize_age)) + geom_density() + ggtitle(.x$category) ) ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] ## ## [[5]] ## ## [[6]] 也可以用强大的group_by() + group_map()组合，我们会在第 21 章讲到 nobel_winners %&gt;% group_by(category) %&gt;% group_map( ~ ggplot(data = .x, aes(x = prize_age)) + geom_density() + ggtitle(.y) ) 39.10 性别比例 nobel_winners %&gt;% dplyr::filter(laureate_type == &quot;individual&quot;) %&gt;% count(category, gender) %&gt;% group_by(category) %&gt;% mutate(prop = n / sum(n)) ## # A tibble: 12 x 4 ## # Groups: category [6] ## category gender n prop ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 chemistry female 4 0.0229 ## 2 chemistry male 171 0.977 ## 3 economics female 1 0.0128 ## 4 economics male 77 0.987 ## 5 literature female 14 0.124 ## 6 literature male 99 0.876 ## 7 medicine female 12 0.0569 ## 8 medicine male 199 0.943 ## 9 peace female 14 0.14 ## 10 peace male 86 0.86 ## 11 physics female 2 0.00980 ## 12 physics male 202 0.990 各年代性别比例 nobel_winners %&gt;% dplyr::filter(laureate_type == &quot;individual&quot;) %&gt;% # mutate(decade = glue::glue(&quot;{round(prize_year - 1, -1)}s&quot;)) %&gt;% count(decade, category, gender) %&gt;% group_by(decade, category) %&gt;% mutate(prop = n / sum(n)) %&gt;% ggplot(aes(decade, category, fill = prop)) + geom_tile(size = 0.7) + # geom_text(aes(label = scales::percent(prop, accuracy = .01))) + geom_text(aes(label = scales::number(prop, accuracy = .01))) + facet_grid(vars(gender)) + scale_fill_gradient(low = &quot;#FDF4E9&quot;, high = &quot;#834C0D&quot;) library(ggbeeswarm) # install.packages(&quot;ggbeeswarm&quot;) nobel_winners %&gt;% ggplot(aes( x = category, y = prize_age, colour = gender, alpha = gender )) + ggbeeswarm::geom_beeswarm() + coord_flip() + scale_color_manual(values = c(&quot;#BB1288&quot;, &quot;#5867A6&quot;)) + scale_alpha_manual(values = c(1, .4)) + theme_minimal() + theme(legend.position = &quot;top&quot;) + labs( title = &quot;诺奖获得者性别不平衡&quot;, subtitle = &quot;1901年-2016年数据&quot;, colour = &quot;Gender&quot;, alpha = &quot;Gender&quot;, x = &quot;学科&quot;, y = &quot;获奖年龄&quot; ) nobel_winners %&gt;% count(decade, category, gender = coalesce(gender, laureate_type) ) %&gt;% group_by(decade, category) %&gt;% mutate(percent = n / sum(n)) %&gt;% ggplot(aes(decade, n, fill = gender)) + geom_col() + facet_wrap(~category) + labs( x = &quot;Decade&quot;, y = &quot;# of nobel prize winners&quot;, fill = &quot;Gender&quot;, title = &quot;Nobel Prize gender distribution over time&quot; ) 39.11 这些大神都是哪个年代出生的人？ nobel_winners %&gt;% select(category, birth_date) %&gt;% mutate(year = floor(year(birth_date) / 10) * 10) %&gt;% count(category, year) %&gt;% dplyr::filter(!is.na(year)) %&gt;% ggplot(aes(x = year, y = n)) + geom_col() + scale_x_continuous(breaks = seq(1810, 1990, 20)) + geom_text(aes(label = n), vjust = -0.25) + facet_wrap(vars(category)) 课堂练习，哪位同学能把图弄得好看些？ 39.12 最年轻的诺奖获得者？ nobel_winners %&gt;% dplyr::filter(prize_age == min(prize_age, na.rm = T)) ## # A tibble: 1 x 20 ## prize_year category prize motivation prize_share ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2014 peace the ~ &quot;\\&quot;for th~ 1/2 ## # ... with 15 more variables: laureate_id &lt;dbl&gt;, ## # laureate_type &lt;chr&gt;, full_name &lt;chr&gt;, ## # birth_date &lt;date&gt;, birth_city &lt;chr&gt;, ## # birth_country &lt;chr&gt;, gender &lt;chr&gt;, ## # organization_name &lt;chr&gt;, organization_city &lt;chr&gt;, ## # organization_country &lt;chr&gt;, death_date &lt;date&gt;, ## # death_city &lt;chr&gt;, death_country &lt;chr&gt;, ## # decade &lt;dbl&gt;, prize_age &lt;dbl&gt; nobel_winners %&gt;% dplyr::filter( rank(prize_year - year(birth_date)) == 1 ) ## # A tibble: 1 x 20 ## prize_year category prize motivation prize_share ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2014 peace the ~ &quot;\\&quot;for th~ 1/2 ## # ... with 15 more variables: laureate_id &lt;dbl&gt;, ## # laureate_type &lt;chr&gt;, full_name &lt;chr&gt;, ## # birth_date &lt;date&gt;, birth_city &lt;chr&gt;, ## # birth_country &lt;chr&gt;, gender &lt;chr&gt;, ## # organization_name &lt;chr&gt;, organization_city &lt;chr&gt;, ## # organization_country &lt;chr&gt;, death_date &lt;date&gt;, ## # death_city &lt;chr&gt;, death_country &lt;chr&gt;, ## # decade &lt;dbl&gt;, prize_age &lt;dbl&gt; nobel_winners %&gt;% arrange( prize_year - year(birth_date) ) ## # A tibble: 911 x 20 ## prize_year category prize motivation prize_share ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2014 peace the ~ &quot;\\&quot;for th~ 1/2 ## 2 1915 physics the ~ &quot;\\&quot;for th~ 1/2 ## 3 1932 physics the ~ &quot;\\&quot;for th~ 1/1 ## 4 1933 physics the ~ &quot;\\&quot;for th~ 1/2 ## 5 1936 physics the ~ &quot;\\&quot;for hi~ 1/2 ## 6 1957 physics the ~ &quot;\\&quot;for th~ 1/2 ## 7 1923 medicine the ~ &quot;\\&quot;for th~ 1/2 ## 8 1961 physics the ~ &quot;\\&quot;for hi~ 1/2 ## 9 1976 peace the ~ &lt;NA&gt; 1/2 ## 10 2011 peace the ~ &quot;\\&quot;for th~ 1/3 ## # ... with 901 more rows, and 15 more variables: ## # laureate_id &lt;dbl&gt;, laureate_type &lt;chr&gt;, ## # full_name &lt;chr&gt;, birth_date &lt;date&gt;, ## # birth_city &lt;chr&gt;, birth_country &lt;chr&gt;, ## # gender &lt;chr&gt;, organization_name &lt;chr&gt;, ## # organization_city &lt;chr&gt;, ## # organization_country &lt;chr&gt;, death_date &lt;date&gt;, ## # death_city &lt;chr&gt;, death_country &lt;chr&gt;, ## # decade &lt;dbl&gt;, prize_age &lt;dbl&gt; nobel_winners %&gt;% top_n(1, year(birth_date) - prize_year) ## # A tibble: 1 x 20 ## prize_year category prize motivation prize_share ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2014 peace the ~ &quot;\\&quot;for th~ 1/2 ## # ... with 15 more variables: laureate_id &lt;dbl&gt;, ## # laureate_type &lt;chr&gt;, full_name &lt;chr&gt;, ## # birth_date &lt;date&gt;, birth_city &lt;chr&gt;, ## # birth_country &lt;chr&gt;, gender &lt;chr&gt;, ## # organization_name &lt;chr&gt;, organization_city &lt;chr&gt;, ## # organization_country &lt;chr&gt;, death_date &lt;date&gt;, ## # death_city &lt;chr&gt;, death_country &lt;chr&gt;, ## # decade &lt;dbl&gt;, prize_age &lt;dbl&gt; 39.13 平均年龄和获奖数量 df1 &lt;- nobel_winners %&gt;% group_by(category) %&gt;% summarise( mean_prise_age = mean(prize_age, na.rm = T), total_num = n() ) df1 ## # A tibble: 6 x 3 ## category mean_prise_age total_num ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 chemistry 58.0 175 ## 2 economics 67.2 78 ## 3 literature 64.7 113 ## 4 medicine 58.0 211 ## 5 peace 61.4 130 ## 6 physics 55.4 204 df1 %&gt;% ggplot(aes(mean_prise_age, total_num)) + geom_point(aes(color = category)) + geom_smooth(method = lm, se = FALSE) 39.14 出生地与工作地分布 nobel_winners_clean &lt;- nobel_winners %&gt;% mutate_at( vars(birth_country, death_country), ~ ifelse(str_detect(., &quot;\\\\(&quot;), str_extract(., &quot;(?&lt;=\\\\().*?(?=\\\\))&quot;), .) ) %&gt;% mutate_at( vars(birth_country, death_country), ~ case_when( . == &quot;scotland&quot; ~ &quot;united kingdom&quot;, . == &quot;northern ireland&quot; ~ &quot;united kingdom&quot;, str_detect(., &quot;czech&quot;) ~ &quot;czechia&quot;, str_detect(., &quot;germany&quot;) ~ &quot;germany&quot;, TRUE ~ . ) ) %&gt;% select(full_name, prize_year, category, birth_date, birth_country, gender, organization_name, organization_country, death_country) nobel_winners_clean %&gt;% count(death_country, sort = TRUE) ## # A tibble: 45 x 2 ## death_country n ## &lt;chr&gt; &lt;int&gt; ## 1 &lt;NA&gt; 329 ## 2 united states of america 203 ## 3 united kingdom 79 ## 4 germany 56 ## 5 france 51 ## 6 sweden 28 ## 7 switzerland 26 ## 8 italy 14 ## 9 russia 11 ## 10 spain 10 ## # ... with 35 more rows 39.15 迁移模式 nobel_winners_clean %&gt;% mutate( colour = case_when( death_country == &quot;united states of america&quot; ~ &quot;#FF2B4F&quot;, death_country == &quot;germany&quot; ~ &quot;#fcab27&quot;, death_country == &quot;united kingdom&quot; ~ &quot;#3686d3&quot;, death_country == &quot;france&quot; ~ &quot;#88398a&quot;, death_country == &quot;switzerland&quot; ~ &quot;#20d4bc&quot;, TRUE ~ &quot;gray60&quot; ) ) %&gt;% ggplot(aes( x = 0, y = fct_rev(factor(birth_country)), xend = death_country, yend = 1, colour = colour, alpha = (colour != &quot;gray60&quot;) )) + geom_curve( curvature = -0.5, arrow = arrow(length = unit(0.01, &quot;npc&quot;)) ) + scale_x_discrete() + scale_y_discrete() + scale_color_identity() + scale_alpha_manual(values = c(0.1, 0.2), guide = F) + scale_size_manual(values = c(0.1, 0.4), guide = F) + theme_minimal() + theme( panel.grid = element_blank(), plot.background = element_rect(fill = &quot;#F0EFF1&quot;, colour = &quot;#F0EFF1&quot;), legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 40, hjust = 1) ) 39.16 地图 library(here) library(sf) library(countrycode) # countrycode(&#39;Albania&#39;, &#39;country.name&#39;, &#39;iso3c&#39;) nobel_winners_birth_country &lt;- nobel_winners_clean %&gt;% count(birth_country) %&gt;% filter(!is.na(birth_country)) %&gt;% mutate(ISO3 = countrycode(birth_country, origin = &quot;country.name&quot;, destination = &quot;iso3c&quot; )) global &lt;- sf::st_read(&quot;./demo_data/worldmap/TM_WORLD_BORDERS_SIMPL-0.3.shp&quot;) %&gt;% st_transform(4326) ## Reading layer `TM_WORLD_BORDERS_SIMPL-0.3&#39; from data source `G:\\R_for_Data_Science\\demo_data\\worldmap\\TM_WORLD_BORDERS_SIMPL-0.3.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 246 features and 11 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -180 ymin: -90 xmax: 180 ymax: 83.57 ## geographic CRS: WGS 84 global %&gt;% full_join(nobel_winners_birth_country, by = &quot;ISO3&quot;) %&gt;% ggplot() + geom_sf(aes(fill = n), color = &quot;white&quot;, size = 0.1 ) + labs( x = NULL, y = NULL, title = &quot;Nobel Winners by country&quot;, subtitle = &quot;color of map indicates number of Nobel lauretes&quot;, fill = &quot;num of Nobel lauretes&quot;, caption = &quot;Made: wang_minjie&quot; ) + scale_fill_gradientn(colors = c(&quot;royalblue1&quot;, &quot;magenta&quot;, &quot;orange&quot;, &quot;gold&quot;), na.value = &quot;white&quot;) + # scale_fill_gradient(low = &quot;wheat1&quot;, high = &quot;red&quot;) + theme_void() + theme( legend.position = c(0.1, 0.3), plot.background = element_rect(fill = &quot;gray&quot;) ) # Determine to 10 Countries topCountries &lt;- nobel_winners_clean %&gt;% count(birth_country, sort = TRUE) %&gt;% na.omit() %&gt;% top_n(8) topCountries ## # A tibble: 8 x 2 ## birth_country n ## &lt;chr&gt; &lt;int&gt; ## 1 united states of america 259 ## 2 united kingdom 99 ## 3 germany 80 ## 4 france 54 ## 5 sweden 29 ## 6 poland 26 ## 7 russia 26 ## 8 japan 24 df4 &lt;- nobel_winners_clean %&gt;% filter(birth_country %in% topCountries$birth_country) %&gt;% group_by(birth_country, category, prize_year) %&gt;% summarise(prizes = n()) %&gt;% mutate(cumPrizes = cumsum(prizes)) df4 ## # A tibble: 489 x 5 ## # Groups: birth_country, category [47] ## birth_country category prize_year prizes cumPrizes ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 france chemistry 1906 1 1 ## 2 france chemistry 1912 2 3 ## 3 france chemistry 1913 1 4 ## 4 france chemistry 1935 2 6 ## 5 france chemistry 1970 1 7 ## 6 france chemistry 1987 1 8 ## 7 france chemistry 2016 1 9 ## 8 france economics 1983 1 1 ## 9 france economics 1988 1 2 ## 10 france economics 2014 1 3 ## # ... with 479 more rows library(gganimate) df4 %&gt;% mutate(prize_year = as.integer(prize_year)) %&gt;% ggplot(aes(x = birth_country, y = category, color = birth_country)) + geom_point(aes(size = cumPrizes), alpha = 0.6) + # geom_text(aes(label = cumPrizes)) + scale_size_continuous(range = c(2, 30)) + transition_reveal(prize_year) + labs( title = &quot;诺奖获得者最多的10个国家&quot;, subtitle = &quot;Year: {frame_along}&quot;, y = &quot;Category&quot; ) + theme_minimal() + theme( plot.title = element_text(size = 22), axis.title = element_blank() ) + scale_color_brewer(palette = &quot;RdYlBu&quot;) + theme(legend.position = &quot;none&quot;) + theme(plot.margin = margin(5.5, 5.5, 5.5, 5.5)) 39.17 出生地和工作地不一样的占比 nobel_winners_clean %&gt;% select(category, birth_country, death_country) %&gt;% mutate(immigration = if_else(birth_country == death_country, 0, 1)) ## # A tibble: 911 x 4 ## category birth_country death_country immigration ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 chemistry netherlands germany 1 ## 2 literature france france 0 ## 3 medicine poland germany 1 ## 4 peace switzerland switzerland 0 ## 5 peace france france 0 ## 6 physics germany germany 0 ## 7 chemistry germany germany 0 ## 8 literature germany germany 0 ## 9 medicine india united kingdom 1 ## 10 peace switzerland switzerland 0 ## # ... with 901 more rows 39.18 诺奖分享者 nobel_winners %&gt;% separate(prize_share, into = c(&quot;num&quot;, &quot;deno&quot;), sep = &quot;/&quot;, remove = FALSE) nobel_winners %&gt;% filter(category == &quot;medicine&quot;) %&gt;% mutate( num_a = as.numeric(str_sub(prize_share, 1, 1)), num_b = as.numeric(str_sub(prize_share, -1)), share = num_a / num_b, year = prize_year %% 10, decade = 10 * (prize_year %/% 10) ) %&gt;% group_by(prize_year) %&gt;% mutate(n = row_number()) %&gt;% ggplot() + geom_col(aes(x = &quot;&quot;, y = share, fill = as.factor(n)), show.legend = FALSE ) + coord_polar(&quot;y&quot;) + facet_grid(decade ~ year, switch = &quot;both&quot;) + labs(title = &quot;每年诺贝尔奖分享情况&quot;) + theme_void() + theme( plot.title = element_text(face = &quot;bold&quot;, vjust = 8), strip.text.x = element_text( size = 7, margin = margin(t = 5) ), strip.text.y = element_text( size = 7, angle = 180, hjust = 1, margin = margin(r = 10) ) ) 39.19 其它 没有回答的问题，大家自己花时间探索下。 39.20 延伸阅读 有些图可以再美化下 "],["eda-olympics.html", "第 40 章 探索性数据分析-奥林匹克 40.1 导入数据 40.2 可视化 40.3 回归分析 40.4 预测 40.5 再次可视化 40.6 list_column 40.7 课后作业", " 第 40 章 探索性数据分析-奥林匹克 这是Nature期刊上的一篇文章Nature. 2004 September 30; 431(7008)， 虽然觉得这个结论不太严谨，但我却无力反驳。 于是在文章补充材料里，我找到了文章使用的数据，现在的任务是，重复这张图和文章的分析过程。 40.1 导入数据 library(tidyverse) library(readxl) d &lt;- read_excel(&quot;./demo_data/olympics.xlsx&quot;) d ## # A tibble: 27 x 3 ## Olympic_year Men_score Women_score ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1900 11 NA ## 2 1904 11 NA ## 3 1908 10.8 NA ## 4 1912 10.8 NA ## 5 1916 NA NA ## 6 1920 10.8 NA ## 7 1924 10.6 NA ## 8 1928 10.8 12.2 ## 9 1932 10.3 11.9 ## 10 1936 10.3 11.5 ## # ... with 17 more rows 40.2 可视化 我们先画图看看 d %&gt;% ggplot() + geom_point(aes(x = Olympic_year, y = Men_score), color = &quot;blue&quot;) + geom_point(aes(x = Olympic_year, y = Women_score), color = &quot;red&quot;) 这样写也是可以的，只不过最好先tidy数据 d1 &lt;- d %&gt;% pivot_longer( cols = -Olympic_year, names_to = &quot;sex&quot;, values_to = &quot;winning_time&quot; ) d1 ## # A tibble: 54 x 3 ## Olympic_year sex winning_time ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1900 Men_score 11 ## 2 1900 Women_score NA ## 3 1904 Men_score 11 ## 4 1904 Women_score NA ## 5 1908 Men_score 10.8 ## 6 1908 Women_score NA ## 7 1912 Men_score 10.8 ## 8 1912 Women_score NA ## 9 1916 Men_score NA ## 10 1916 Women_score NA ## # ... with 44 more rows 然后在画图 d1 %&gt;% ggplot(aes(x = Olympic_year, y = winning_time, color = sex)) + geom_point() + # geom_smooth(method = &quot;lm&quot;) + scale_color_manual( values = c(&quot;Men_score&quot; = &quot;blue&quot;, &quot;Women_score&quot; = &quot;red&quot;) ) + scale_x_continuous( breaks = seq(1900, 2004, by = 4), labels = seq(1900, 2004, by = 4) ) + theme(axis.text.x = element_text( size = 10, angle = 45, colour = &quot;black&quot;, vjust = 1, hjust = 1 )) 40.3 回归分析 建立年份与成绩的线性关系 \\[ \\text{score}_i = \\alpha + \\beta \\times \\text{year}_i + \\epsilon_i; \\qquad \\epsilon_i\\in \\text{Normal}(\\mu, \\sigma) \\] 我们需要求出其中系数\\(\\alpha\\)和\\(\\beta\\)，写R语言代码如下 (lm(y ~ 1 + x,data = d), 要求得 \\(\\alpha\\)和\\(\\beta\\)，就是对应 1 和 x 前的系数) fit_1 &lt;- lm(Men_score ~ 1 + Olympic_year, data = d) summary(fit_1) ## ## Call: ## lm(formula = Men_score ~ 1 + Olympic_year, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.26371 -0.05270 0.00738 0.08005 0.21456 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 31.826453 1.679643 18.9 4.1e-15 *** ## Olympic_year -0.011006 0.000859 -12.8 1.1e-11 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.135 on 22 degrees of freedom ## (3 observations deleted due to missingness) ## Multiple R-squared: 0.882, Adjusted R-squared: 0.876 ## F-statistic: 164 on 1 and 22 DF, p-value: 1.13e-11 fit_2 &lt;- lm(Women_score ~ 1 + Olympic_year, data = d) summary(fit_2) ## ## Call: ## lm(formula = Women_score ~ 1 + Olympic_year, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.3758 -0.0846 0.0093 0.0829 0.3223 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 44.34705 4.28425 10.35 1.7e-08 *** ## Olympic_year -0.01682 0.00218 -7.73 8.6e-07 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.21 on 16 degrees of freedom ## (9 observations deleted due to missingness) ## Multiple R-squared: 0.789, Adjusted R-squared: 0.776 ## F-statistic: 59.8 on 1 and 16 DF, p-value: 8.63e-07 40.4 预测 使用predict()完成预测 df &lt;- data.frame(Olympic_year = 2020) predict(fit_1, newdata = df) ## 1 ## 9.595 为了图片中的一致，我们使用1900年到2252年(seq(1900, 2252, by = 4))建立预测项，并整理到数据框里 grid &lt;- tibble( Olympic_year = as.numeric(seq(1900, 2252, by = 4)) ) grid ## # A tibble: 89 x 1 ## Olympic_year ## &lt;dbl&gt; ## 1 1900 ## 2 1904 ## 3 1908 ## 4 1912 ## 5 1916 ## 6 1920 ## 7 1924 ## 8 1928 ## 9 1932 ## 10 1936 ## # ... with 79 more rows tb &lt;- grid %&gt;% mutate( Predict_Men = predict(fit_1, newdata = grid), Predict_Women = predict(fit_2, newdata = grid) ) tb ## # A tibble: 89 x 3 ## Olympic_year Predict_Men Predict_Women ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1900 10.9 12.4 ## 2 1904 10.9 12.3 ## 3 1908 10.8 12.3 ## 4 1912 10.8 12.2 ## 5 1916 10.7 12.1 ## 6 1920 10.7 12.0 ## 7 1924 10.7 12.0 ## 8 1928 10.6 11.9 ## 9 1932 10.6 11.8 ## 10 1936 10.5 11.8 ## # ... with 79 more rows 有时候我喜欢用modelr::add_predictions()函数实现相同的功能 library(modelr) grid %&gt;% add_predictions(fit_1, var = &quot;Predict_Men&quot;) %&gt;% add_predictions(fit_2, var = &quot;Predict_Women&quot;) ## # A tibble: 89 x 3 ## Olympic_year Predict_Men Predict_Women ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1900 10.9 12.4 ## 2 1904 10.9 12.3 ## 3 1908 10.8 12.3 ## 4 1912 10.8 12.2 ## 5 1916 10.7 12.1 ## 6 1920 10.7 12.0 ## 7 1924 10.7 12.0 ## 8 1928 10.6 11.9 ## 9 1932 10.6 11.8 ## 10 1936 10.5 11.8 ## # ... with 79 more rows 40.5 再次可视化 tb1 &lt;- tb %&gt;% pivot_longer( cols = -Olympic_year, names_to = &quot;sex&quot;, values_to = &quot;winning_time&quot; ) tb1 ## # A tibble: 178 x 3 ## Olympic_year sex winning_time ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1900 Predict_Men 10.9 ## 2 1900 Predict_Women 12.4 ## 3 1904 Predict_Men 10.9 ## 4 1904 Predict_Women 12.3 ## 5 1908 Predict_Men 10.8 ## 6 1908 Predict_Women 12.3 ## 7 1912 Predict_Men 10.8 ## 8 1912 Predict_Women 12.2 ## 9 1916 Predict_Men 10.7 ## 10 1916 Predict_Women 12.1 ## # ... with 168 more rows tb1 %&gt;% ggplot(aes( x = Olympic_year, y = winning_time, color = sex )) + geom_line(size = 2) + geom_point(data = d1) + scale_color_manual( name = &quot;标记&quot;, values = c( &quot;Men_score&quot; = &quot;blue&quot;, &quot;Women_score&quot; = &quot;red&quot;, &quot;Predict_Men&quot; = &quot;#588B8B&quot;, &quot;Predict_Women&quot; = &quot;#C8553D&quot; ), labels = c( &quot;Men_score&quot; = &quot;男性历史成绩&quot;, &quot;Women_score&quot; = &quot;女性历史成绩&quot;, &quot;Predict_Men&quot; = &quot;男性预测成绩&quot;, &quot;Predict_Women&quot; = &quot;女性预测成绩&quot; ) ) + scale_x_continuous( breaks = seq(1900, 2252, by = 16), labels = as.character(seq(1900, 2252, by = 16)) ) + theme(axis.text.x = element_text( size = 10, angle = 45, colour = &quot;black&quot;, vjust = 1, hjust = 1 )) 早知道nature文章这么简单，10年前我也可以写啊！ 40.6 list_column 这里是另外的一种方法 library(modelr) d1 &lt;- d %&gt;% pivot_longer( cols = -Olympic_year, names_to = &quot;sex&quot;, values_to = &quot;winning_time&quot; ) fit_model &lt;- function(df) lm(winning_time ~ Olympic_year, data = df) d2 &lt;- d1 %&gt;% group_nest(sex) %&gt;% mutate( mod = map(data, fit_model) ) d2 ## # A tibble: 2 x 3 ## sex data mod ## &lt;chr&gt; &lt;list&lt;tbl_df[,2]&gt;&gt; &lt;list&gt; ## 1 Men_score [27 x 2] &lt;lm&gt; ## 2 Women_score [27 x 2] &lt;lm&gt; # d2 %&gt;% mutate(p = list(grid, grid)) # d3 &lt;- d2 %&gt;% mutate(p = list(grid, grid)) # d3 # d3 %&gt;% # mutate( # predictions = map2(p, mod, add_predictions), # ) # or tb4 &lt;- d2 %&gt;% mutate( predictions = map(mod, ~ add_predictions(grid, .)) ) %&gt;% select(sex, predictions) %&gt;% unnest(predictions) tb4 %&gt;% ggplot(aes( x = Olympic_year, y = pred, group = sex, color = sex )) + geom_point() + geom_line(size = 2) + geom_point( data = d1, aes( x = Olympic_year, y = winning_time, group = sex, color = sex ) ) + scale_x_continuous( breaks = seq(1900, 2252, by = 16), labels = as.character(seq(1900, 2252, by = 16)) ) + theme(axis.text.x = element_text( size = 10, angle = 45, colour = &quot;black&quot;, vjust = 1, hjust = 1 )) 40.7 课后作业 探索数据，建立身高体重的线性模型 "],["eda-covid2019.html", "第 41 章 探索性数据分析-新冠疫情 41.1 数据来源 41.2 读取数据 41.3 数据集结构 41.4 数据清洗规整 41.5 可视化探索 41.6 每个国家的情况 41.7 地图 41.8 更多", " 第 41 章 探索性数据分析-新冠疫情 library(tidyverse) library(lubridate) library(maps) library(viridis) library(ggrepel) library(paletteer) library(shadowtext) library(showtext) showtext_auto() 新型冠状病毒（俗称武汉肺炎）疫情在多国蔓延，本章通过分析疫情数据，了解疫情发展，祝愿人类早日会战胜病毒！ 图 41.1: 电影《传染病》,《流感》海报 图 41.2: 电影《传染病》,《流感》海报 41.1 数据来源 我们打开链接https://github.com/CSSEGISandData/COVID-19， 找到疫情时间序列数据，你可以通过点击该网页Clone or download直接下载的方式获取数据。 41.2 读取数据 假定你已经下载了数据，比如time_series_covid19_confirmed_global.csv， 那么我们可以用readr::read_csv()函数直接读取, 关于在R语言里文件读取的方法可以参考第 5 章。 d &lt;- read_csv(&quot;./demo_data/time_series_covid19_confirmed_global.csv&quot;) d ## # A tibble: 256 x 74 ## `Province/State` `Country/Region` Lat Long ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 &lt;NA&gt; Afghanistan 33 65 ## 2 &lt;NA&gt; Albania 41.2 20.2 ## 3 &lt;NA&gt; Algeria 28.0 1.66 ## 4 &lt;NA&gt; Andorra 42.5 1.52 ## 5 &lt;NA&gt; Angola -11.2 17.9 ## 6 &lt;NA&gt; Antigua and Bar~ 17.1 -61.8 ## 7 &lt;NA&gt; Argentina -38.4 -63.6 ## 8 &lt;NA&gt; Armenia 40.1 45.0 ## 9 Australian Capi~ Australia -35.5 149. ## 10 New South Wales Australia -33.9 151. ## # ... with 246 more rows, and 70 more variables: ## # `1/22/20` &lt;dbl&gt;, `1/23/20` &lt;dbl&gt;, `1/24/20` &lt;dbl&gt;, ## # `1/25/20` &lt;dbl&gt;, `1/26/20` &lt;dbl&gt;, `1/27/20` &lt;dbl&gt;, ## # `1/28/20` &lt;dbl&gt;, `1/29/20` &lt;dbl&gt;, `1/30/20` &lt;dbl&gt;, ## # `1/31/20` &lt;dbl&gt;, `2/1/20` &lt;dbl&gt;, `2/2/20` &lt;dbl&gt;, ## # `2/3/20` &lt;dbl&gt;, `2/4/20` &lt;dbl&gt;, `2/5/20` &lt;dbl&gt;, ## # `2/6/20` &lt;dbl&gt;, `2/7/20` &lt;dbl&gt;, `2/8/20` &lt;dbl&gt;, ## # `2/9/20` &lt;dbl&gt;, `2/10/20` &lt;dbl&gt;, `2/11/20` &lt;dbl&gt;, ## # `2/12/20` &lt;dbl&gt;, `2/13/20` &lt;dbl&gt;, `2/14/20` &lt;dbl&gt;, ## # `2/15/20` &lt;dbl&gt;, `2/16/20` &lt;dbl&gt;, `2/17/20` &lt;dbl&gt;, ## # `2/18/20` &lt;dbl&gt;, `2/19/20` &lt;dbl&gt;, `2/20/20` &lt;dbl&gt;, ## # `2/21/20` &lt;dbl&gt;, `2/22/20` &lt;dbl&gt;, `2/23/20` &lt;dbl&gt;, ## # `2/24/20` &lt;dbl&gt;, `2/25/20` &lt;dbl&gt;, `2/26/20` &lt;dbl&gt;, ## # `2/27/20` &lt;dbl&gt;, `2/28/20` &lt;dbl&gt;, `2/29/20` &lt;dbl&gt;, ## # `3/1/20` &lt;dbl&gt;, `3/2/20` &lt;dbl&gt;, `3/3/20` &lt;dbl&gt;, ## # `3/4/20` &lt;dbl&gt;, `3/5/20` &lt;dbl&gt;, `3/6/20` &lt;dbl&gt;, ## # `3/7/20` &lt;dbl&gt;, `3/8/20` &lt;dbl&gt;, `3/9/20` &lt;dbl&gt;, ## # `3/10/20` &lt;dbl&gt;, `3/11/20` &lt;dbl&gt;, `3/12/20` &lt;dbl&gt;, ## # `3/13/20` &lt;dbl&gt;, `3/14/20` &lt;dbl&gt;, `3/15/20` &lt;dbl&gt;, ## # `3/16/20` &lt;dbl&gt;, `3/17/20` &lt;dbl&gt;, `3/18/20` &lt;dbl&gt;, ## # `3/19/20` &lt;dbl&gt;, `3/20/20` &lt;dbl&gt;, `3/21/20` &lt;dbl&gt;, ## # `3/22/20` &lt;dbl&gt;, `3/23/20` &lt;dbl&gt;, `3/24/20` &lt;dbl&gt;, ## # `3/25/20` &lt;dbl&gt;, `3/26/20` &lt;dbl&gt;, `3/27/20` &lt;dbl&gt;, ## # `3/28/20` &lt;dbl&gt;, `3/29/20` &lt;dbl&gt;, `3/30/20` &lt;dbl&gt;, ## # `3/31/20` &lt;dbl&gt; 41.3 数据集结构 探索数据之前，我们一定要对数据存储结构、数据变量名及其含义要非常清楚，重要的事情说三遍。 glimpse(d) ## Rows: 256 ## Columns: 74 ## $ `Province/State` &lt;chr&gt; NA, NA, NA, NA, NA, NA, N... ## $ `Country/Region` &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;,... ## $ Lat &lt;dbl&gt; 33.00, 41.15, 28.03, 42.5... ## $ Long &lt;dbl&gt; 65.000, 20.168, 1.660, 1.... ## $ `1/22/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/23/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/24/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/25/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/26/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/27/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/28/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/29/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/30/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `1/31/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/1/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/2/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/3/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/4/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/5/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/6/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/7/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/8/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/9/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/10/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/11/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/12/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/13/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/14/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/15/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/16/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/17/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/18/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/19/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/20/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/21/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/22/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/23/20` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/24/20` &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0... ## $ `2/25/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `2/26/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `2/27/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `2/28/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `2/29/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0... ## $ `3/1/20` &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0... ## $ `3/2/20` &lt;dbl&gt; 1, 0, 3, 1, 0, 0, 0, 1, 0... ## $ `3/3/20` &lt;dbl&gt; 1, 0, 5, 1, 0, 0, 1, 1, 0... ## $ `3/4/20` &lt;dbl&gt; 1, 0, 12, 1, 0, 0, 1, 1, ... ## $ `3/5/20` &lt;dbl&gt; 1, 0, 12, 1, 0, 0, 1, 1, ... ## $ `3/6/20` &lt;dbl&gt; 1, 0, 17, 1, 0, 0, 2, 1, ... ## $ `3/7/20` &lt;dbl&gt; 1, 0, 17, 1, 0, 0, 8, 1, ... ## $ `3/8/20` &lt;dbl&gt; 4, 0, 19, 1, 0, 0, 12, 1,... ## $ `3/9/20` &lt;dbl&gt; 4, 2, 20, 1, 0, 0, 12, 1,... ## $ `3/10/20` &lt;dbl&gt; 5, 10, 20, 1, 0, 0, 17, 1... ## $ `3/11/20` &lt;dbl&gt; 7, 12, 20, 1, 0, 0, 19, 1... ## $ `3/12/20` &lt;dbl&gt; 7, 23, 24, 1, 0, 0, 19, 4... ## $ `3/13/20` &lt;dbl&gt; 7, 33, 26, 1, 0, 1, 31, 8... ## $ `3/14/20` &lt;dbl&gt; 11, 38, 37, 1, 0, 1, 34, ... ## $ `3/15/20` &lt;dbl&gt; 16, 42, 48, 1, 0, 1, 45, ... ## $ `3/16/20` &lt;dbl&gt; 21, 51, 54, 2, 0, 1, 56, ... ## $ `3/17/20` &lt;dbl&gt; 22, 55, 60, 39, 0, 1, 68,... ## $ `3/18/20` &lt;dbl&gt; 22, 59, 74, 39, 0, 1, 79,... ## $ `3/19/20` &lt;dbl&gt; 22, 64, 87, 53, 0, 1, 97,... ## $ `3/20/20` &lt;dbl&gt; 24, 70, 90, 75, 1, 1, 128... ## $ `3/21/20` &lt;dbl&gt; 24, 76, 139, 88, 2, 1, 15... ## $ `3/22/20` &lt;dbl&gt; 40, 89, 201, 113, 2, 1, 2... ## $ `3/23/20` &lt;dbl&gt; 40, 104, 230, 133, 3, 3, ... ## $ `3/24/20` &lt;dbl&gt; 74, 123, 264, 164, 3, 3, ... ## $ `3/25/20` &lt;dbl&gt; 84, 146, 302, 188, 3, 3, ... ## $ `3/26/20` &lt;dbl&gt; 94, 174, 367, 224, 4, 7, ... ## $ `3/27/20` &lt;dbl&gt; 110, 186, 409, 267, 4, 7,... ## $ `3/28/20` &lt;dbl&gt; 110, 197, 454, 308, 5, 7,... ## $ `3/29/20` &lt;dbl&gt; 120, 212, 511, 334, 7, 7,... ## $ `3/30/20` &lt;dbl&gt; 170, 223, 584, 370, 7, 7,... ## $ `3/31/20` &lt;dbl&gt; 174, 243, 716, 376, 7, 7,... 41.4 数据清洗规整 41.4.1 必要的预备知识之select() d %&gt;% select(-c(1:4)) d %&gt;% select(5:ncol(.)) d %&gt;% select(matches(&quot;/20&quot;)) d %&gt;% select(ends_with(&quot;/20&quot;)) # 应该还有其他的方法 41.4.2 必要的预备知识之pivot_longer() 宽表格变长表格，需要用到pivot_longer() 和 pivot_wider()， 比如 table4a ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 longer &lt;- table4a %&gt;% pivot_longer( cols = `1999`:`2000`, names_to = &quot;year&quot;, values_to = &quot;cases&quot; ) longer ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 ## 2 Afghanistan 2000 2666 ## 3 Brazil 1999 37737 ## 4 Brazil 2000 80488 ## 5 China 1999 212258 ## 6 China 2000 213766 41.4.3 必要的预备知识之pivot_wider() 有时候我们想折腾下，比如把长表格再变回宽表格 longer %&gt;% pivot_wider( names_from = year, values_from = cases ) ## # A tibble: 3 x 3 ## country `1999` `2000` ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 41.4.4 必要的预备知识之日期格式 有时候，我会遇到日期date这种数据类型，我推荐使用lubridate包来处理，比如 c(&quot;2020-3-25&quot;, &quot;20200325&quot;, &quot;20-03-25&quot;, &quot;2020 03 25&quot;) %&gt;% lubridate::ymd() ## [1] &quot;2020-03-25&quot; &quot;2020-03-25&quot; &quot;2020-03-25&quot; &quot;2020-03-25&quot; c(&quot;3/25/20&quot;, &quot;03-25-20&quot;, &quot;3-25/2020&quot;) %&gt;% lubridate::mdy() ## [1] &quot;2020-03-25&quot; &quot;2020-03-25&quot; &quot;2020-03-25&quot; 遇到这种010210日期的，请把输入数据的人扁一顿，他会告诉你的 lubridate::dmy(010210) lubridate::dym(010210) lubridate::mdy(010210) lubridate::myd(010210) lubridate::ymd(010210) lubridate::ydm(010210) 41.4.5 必要的预备知识之时间差 difftime(ymd(&quot;2020-03-24&quot;), ymd(&quot;2020-03-23&quot;), units = &quot;days&quot; ) ## Time difference of 1 days 或者更直观的表述 ymd(&quot;2020-03-24&quot;) - ymd(&quot;2020-03-23&quot;) ## Time difference of 1 days 转换为天数 (ymd(&quot;2020-03-24&quot;) - ymd(&quot;2020-03-23&quot;)) %&gt;% as.numeric() ## [1] 1 41.4.6 有时候需要log10_scale tb &lt;- tibble( days_since_100 = 0:18, cases = 100 * 1.33^days_since_100 ) p1 &lt;- tb %&gt;% ggplot(aes(days_since_100, cases)) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) p2 &lt;- tb %&gt;% ggplot(aes(days_since_100, log10(cases))) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) p3 &lt;- tb %&gt;% ggplot(aes(days_since_100, cases)) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) + scale_y_log10() library(patchwork) p1 + p2 + p3 41.4.7 数据清洗规整 d1 &lt;- d %&gt;% pivot_longer( cols = 5:ncol(.), names_to = &quot;date&quot;, values_to = &quot;cases&quot; ) %&gt;% mutate(date = lubridate::mdy(date)) %&gt;% janitor::clean_names() %&gt;% group_by(country_region, date) %&gt;% summarise(cases = sum(cases)) %&gt;% ungroup() d1 ## # A tibble: 12,600 x 3 ## country_region date cases ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-01-22 0 ## 2 Afghanistan 2020-01-23 0 ## 3 Afghanistan 2020-01-24 0 ## 4 Afghanistan 2020-01-25 0 ## 5 Afghanistan 2020-01-26 0 ## 6 Afghanistan 2020-01-27 0 ## 7 Afghanistan 2020-01-28 0 ## 8 Afghanistan 2020-01-29 0 ## 9 Afghanistan 2020-01-30 0 ## 10 Afghanistan 2020-01-31 0 ## # ... with 12,590 more rows d1 %&gt;% group_by(date) %&gt;% summarise(confirmed = sum(cases)) ## # A tibble: 70 x 2 ## date confirmed ## &lt;date&gt; &lt;dbl&gt; ## 1 2020-01-22 555 ## 2 2020-01-23 654 ## 3 2020-01-24 941 ## 4 2020-01-25 1434 ## 5 2020-01-26 2118 ## 6 2020-01-27 2927 ## 7 2020-01-28 5578 ## 8 2020-01-29 6166 ## 9 2020-01-30 8234 ## 10 2020-01-31 9927 ## # ... with 60 more rows 【WHO：2019冠状病毒全球大流行正在“加速”】世界卫生组织（WHO）昨日发出警告，指2019冠状病毒全球感染者已超过30万人，全球大流行正在“加速”。世卫组织指，从首例病例报告到感染者达到10万人用了67天；感染人数增至20万用了11天；从20万到突破30万则只用了4天。 d1 %&gt;% group_by(date) %&gt;% summarise(confirmed = sum(cases)) %&gt;% ggplot(aes(x = date, y = confirmed)) + geom_point() + scale_x_date( date_labels = &quot;%m-%d&quot;, date_breaks = &quot;1 week&quot; ) + scale_y_continuous( breaks = c(0, 50000, 100000, 200000, 300000, 500000, 900000), labels = scales::comma ) # d1 %&gt;% distinct(country_region) %&gt;% pull(country_region) d1 %&gt;% distinct(country_region) ## # A tibble: 180 x 1 ## country_region ## &lt;chr&gt; ## 1 Afghanistan ## 2 Albania ## 3 Algeria ## 4 Andorra ## 5 Angola ## 6 Antigua and Barbuda ## 7 Argentina ## 8 Armenia ## 9 Australia ## 10 Austria ## # ... with 170 more rows d1 %&gt;% filter(country_region == &quot;China&quot;) ## # A tibble: 70 x 3 ## country_region date cases ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 China 2020-01-22 548 ## 2 China 2020-01-23 643 ## 3 China 2020-01-24 920 ## 4 China 2020-01-25 1406 ## 5 China 2020-01-26 2075 ## 6 China 2020-01-27 2877 ## 7 China 2020-01-28 5509 ## 8 China 2020-01-29 6087 ## 9 China 2020-01-30 8141 ## 10 China 2020-01-31 9802 ## # ... with 60 more rows d1 %&gt;% filter(country_region == &quot;China&quot;) %&gt;% ggplot(aes(x = date, y = cases)) + geom_point() + scale_x_date(date_breaks = &quot;1 week&quot;, date_labels = &quot;%m-%d&quot;) + scale_y_log10(labels = scales::comma) d1 %&gt;% group_by(country_region) %&gt;% filter(max(cases) &gt;= 20000) %&gt;% ungroup() %&gt;% ggplot(aes(x = date, y = cases, color = country_region)) + geom_point() + scale_x_date(date_breaks = &quot;1 week&quot;, date_labels = &quot;%m-%d&quot;) + scale_y_log10() + facet_wrap(vars(country_region), ncol = 2) + theme( axis.text.x = element_text(angle = 45, hjust = 1) ) + theme(legend.position = &quot;none&quot;) 41.5 可视化探索 网站https://www.ft.com/coronavirus-latest 这张图很受关注，于是打算重复 图 41.3: 图片来源www.ft.com 这张图想表达的是，出现100个案例后，各国确诊人数的爆发趋势 横坐标是天数，即在出现100个案例后的第几天 纵坐标是累积确诊人数 那么，我们需要对数据的时间轴做相应的变形 首先按照国家分组 筛选，累积确诊人数超过100的国家 找到所有case &gt;= 100的日期，date[cases &gt;= 100] 最早的日期，就说我们要找的第 0 day， min(date[cases &gt;= 100]) 构建新的一列mutate( days_since_100 = date - min(date[cases &gt;= 100]) 将days_since_100转换成数值型as.numeric() d2 &lt;- d1 %&gt;% group_by(country_region) %&gt;% filter(max(cases) &gt;= 100) %&gt;% mutate( days_since_100 = date - min(date[cases &gt;= 100]) ) %&gt;% mutate(days_since_100 = as.numeric(days_since_100)) %&gt;% filter(days_since_100 &gt;= 0) %&gt;% ungroup() d2 ## # A tibble: 1,710 x 4 ## country_region date cases days_since_100 ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-03-27 110 0 ## 2 Afghanistan 2020-03-28 110 1 ## 3 Afghanistan 2020-03-29 120 2 ## 4 Afghanistan 2020-03-30 170 3 ## 5 Afghanistan 2020-03-31 174 4 ## 6 Albania 2020-03-23 104 0 ## 7 Albania 2020-03-24 123 1 ## 8 Albania 2020-03-25 146 2 ## 9 Albania 2020-03-26 174 3 ## 10 Albania 2020-03-27 186 4 ## # ... with 1,700 more rows 大家都谈过恋爱，也有可能失恋。大家失恋时间是不同的，若把失恋的当天作为第 0 day, 就可以比较失恋若干天后每个人精神波动情况。参照《失恋33天》 d2_most &lt;- d2 %&gt;% group_by(country_region) %&gt;% top_n(1, days_since_100) %&gt;% filter(cases &gt;= 10000) %&gt;% ungroup() %&gt;% arrange(desc(cases)) d2_most ## # A tibble: 13 x 4 ## country_region date cases days_since_100 ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 US 2020-03-31 188172 28 ## 2 Italy 2020-03-31 105792 37 ## 3 Spain 2020-03-31 95923 29 ## 4 China 2020-03-31 82279 69 ## 5 Germany 2020-03-31 71808 30 ## 6 France 2020-03-31 52827 31 ## 7 Iran 2020-03-31 44605 34 ## 8 United Kingdom 2020-03-31 25481 26 ## 9 Switzerland 2020-03-31 16605 26 ## 10 Turkey 2020-03-31 13531 12 ## 11 Belgium 2020-03-31 12775 25 ## 12 Netherlands 2020-03-31 12667 25 ## 13 Austria 2020-03-31 10180 23 d2 %&gt;% bind_rows( tibble(country = &quot;33% daily rise&quot;, days_since_100 = 0:30) %&gt;% mutate(cases = 100 * 1.33^days_since_100) ) %&gt;% ggplot(aes(days_since_100, cases, color = country_region)) + geom_hline(yintercept = 100) + geom_vline(xintercept = 0) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) + # scale_colour_manual( # values = c( # &quot;US&quot; = &quot;#EB5E8D&quot;, # &quot;Italy&quot; = &quot;black&quot;, # &quot;Spain&quot; = &quot;#c2b7af&quot;, # &quot;China&quot; = &quot;red&quot;, # &quot;Germany&quot; = &quot;#c2b7af&quot;, # &quot;France&quot; = &quot;#c2b7af&quot;, # &quot;Iran&quot; = &quot;#9dbf57&quot;, # &quot;United Kingdom&quot; = &quot;#ce3140&quot;, # &quot;Korea, South&quot; = &quot;#208fce&quot;, # &quot;Japan&quot; = &quot;#208fce&quot;, # &quot;Singapore&quot; = &quot;#1E8FCC&quot;, # &quot;33% daily rise&quot; = &quot;#D9CCC3&quot;, # &quot;Switzerland&quot; = &quot;#c2b7af&quot;, # &quot;Turkey&quot; = &quot;#208fce&quot;, # &quot;Belgium&quot; = &quot;#c2b7af&quot;, # &quot;Netherlands&quot; = &quot;#c2b7af&quot;, # &quot;Austria&quot; = &quot;#c2b7af&quot;, # &quot;Hong Kong&quot; = &quot;#1E8FCC&quot;, # # gray # &quot;India&quot; = &quot;#c2b7af&quot;, # &quot;Switzerland&quot; = &quot;#c2b7af&quot;, # &quot;Belgium&quot; = &quot;#c2b7af&quot;, # &quot;Norway&quot; = &quot;#c2b7af&quot;, # &quot;Sweden&quot; = &quot;#c2b7af&quot;, # &quot;Austria&quot; = &quot;#c2b7af&quot;, # &quot;Australia&quot; = &quot;#c2b7af&quot;, # &quot;Denmark&quot; = &quot;#c2b7af&quot;, # &quot;Canada&quot; = &quot;#c2b7af&quot;, # &quot;Brazil&quot; = &quot;#c2b7af&quot;, # &quot;Portugal&quot; = &quot;#c2b7af&quot; # ) # ) + geom_shadowtext( data = d2_most, aes(label = paste0(&quot; &quot;, country_region)), bg.color = &quot;white&quot; ) + scale_y_log10( expand = expansion(mult = c(0, .1)), breaks = c(100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000), labels = scales::comma ) + scale_x_continuous( expand = expansion(mult = c(0, .1)), breaks = c(0, 5, 10, 15, 20, 25, 30) ) + theme_minimal() + theme( panel.grid.minor = element_blank(), plot.background = element_rect(fill = &quot;#FFF1E6&quot;), legend.position = &quot;none&quot;, panel.spacing = margin(3, 15, 3, 15, &quot;mm&quot;) ) + labs( x = &quot;Number of days since 100th case&quot;, y = &quot;&quot;, title = &quot;Country by country: how coronavirus case trajectories compare&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot; ) 有点乱，还有很多细节没有实现，后面再弄弄了 41.5.1 简便的方法 d2a &lt;- d1 %&gt;% group_by(country_region) %&gt;% filter(cases &gt;= 100) %&gt;% mutate(days_since_100 = 0:(n() - 1)) %&gt;% # same as # mutate(edate = as.numeric(date - min(date))) ungroup() d2a ## # A tibble: 1,710 x 4 ## country_region date cases days_since_100 ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Afghanistan 2020-03-27 110 0 ## 2 Afghanistan 2020-03-28 110 1 ## 3 Afghanistan 2020-03-29 120 2 ## 4 Afghanistan 2020-03-30 170 3 ## 5 Afghanistan 2020-03-31 174 4 ## 6 Albania 2020-03-23 104 0 ## 7 Albania 2020-03-24 123 1 ## 8 Albania 2020-03-25 146 2 ## 9 Albania 2020-03-26 174 3 ## 10 Albania 2020-03-27 186 4 ## # ... with 1,700 more rows 这里的d2a 和d2是一样的了，但方法简单很多。 41.5.2 疫情持续时间最久的国家 d3 &lt;- d2a %&gt;% group_by(country_region) %&gt;% filter(days_since_100 == max(days_since_100)) %&gt;% # same as # top_n(1, days_since_100) %&gt;% ungroup() %&gt;% arrange(desc(days_since_100)) d3 ## # A tibble: 110 x 4 ## country_region date cases days_since_100 ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;int&gt; ## 1 China 2020-03-31 82279 69 ## 2 Diamond Princess 2020-03-31 712 50 ## 3 Korea, South 2020-03-31 9786 40 ## 4 Japan 2020-03-31 1953 39 ## 5 Italy 2020-03-31 105792 37 ## 6 Iran 2020-03-31 44605 34 ## 7 France 2020-03-31 52827 31 ## 8 Singapore 2020-03-31 926 31 ## 9 Germany 2020-03-31 71808 30 ## 10 Spain 2020-03-31 95923 29 ## # ... with 100 more rows highlight &lt;- d3 %&gt;% top_n(10, days_since_100) %&gt;% pull(country_region) highlight ## [1] &quot;China&quot; &quot;Diamond Princess&quot; ## [3] &quot;Korea, South&quot; &quot;Japan&quot; ## [5] &quot;Italy&quot; &quot;Iran&quot; ## [7] &quot;France&quot; &quot;Singapore&quot; ## [9] &quot;Germany&quot; &quot;Spain&quot; d2a %&gt;% bind_rows( tibble(country = &quot;33% daily rise&quot;, days_since_100 = 0:30) %&gt;% mutate(cases = 100 * 1.33^days_since_100) ) %&gt;% ggplot(aes(days_since_100, cases, color = country_region)) + geom_hline(yintercept = 100) + geom_vline(xintercept = 0) + geom_line(size = 0.8) + geom_point(pch = 21, size = 1) + scale_y_log10( expand = expansion(mult = c(0, .1)), breaks = c(100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000), labels = scales::comma ) + scale_x_continuous( expand = expansion(mult = c(0, .1)), breaks = c(0, 5, 10, 15, 20, 25, 30, 40, 50, 60) ) + theme_minimal() + theme( panel.grid.minor = element_blank(), plot.background = element_rect(fill = &quot;#FFF1E6&quot;), legend.position = &quot;none&quot;, panel.spacing = margin(3, 15, 3, 15, &quot;mm&quot;) ) + labs( x = &quot;Number of days since 100th case&quot;, y = &quot;&quot;, title = &quot;Country by country: how coronavirus case trajectories compare&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot; ) + gghighlight::gghighlight(country_region %in% highlight, label_key = country_region, use_direct_label = TRUE, label_params = list(segment.color = NA, nudge_x = 1), use_group_by = FALSE ) 灰色线条的国家名，有点不好弄，在想办法 41.5.3 笨办法吧 笨办法，实际上是4张表共同完成 highlight &lt;- c( &quot;China&quot;, &quot;Spain&quot;, &quot;US&quot;, &quot;United Kingdom&quot;, &quot;Korea, South&quot;, &quot;Italy&quot;, &quot;Japan&quot;, &quot;Singapore&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Iran&quot; ) gray &lt;- c( &quot;India&quot;, &quot;Switzerland&quot;, &quot;Belgium&quot;, &quot;Netherlands&quot;, &quot;Sweden&quot;, &quot;Austria&quot;, &quot;Australia&quot;, &quot;Denmark&quot;, &quot;Canada&quot;, &quot;Brazil&quot;, &quot;Portugal&quot; ) d3_highlight &lt;- d2a %&gt;% filter(country_region %in% highlight) d3_gray &lt;- d2a %&gt;% filter(country_region %in% gray) d2a %&gt;% ggplot(aes(days_since_100, cases, group = country_region)) + geom_hline(yintercept = 100) + geom_vline(xintercept = 0) + geom_line(size = 0.8, color = &quot;gray70&quot;) + geom_point(pch = 21, size = 1, color = &quot;gray70&quot;) + # highlight country geom_line(data = d3_highlight, aes(color = country_region)) + geom_point(data = d3_highlight, aes(color = country_region)) + geom_text( data = d3_highlight %&gt;% group_by(country_region) %&gt;% top_n(1, days_since_100) %&gt;% ungroup(), aes(color = country_region, label = country_region), hjust = 0, vjust = 0, nudge_x = 0.5 ) + # gray country geom_text( data = d3_gray %&gt;% group_by(country_region) %&gt;% top_n(1, days_since_100) %&gt;% ungroup(), aes(label = country_region), color = &quot;gray50&quot;, hjust = 0, vjust = 0, nudge_x = 0.5 ) + geom_point( data = d3_gray %&gt;% group_by(country_region) %&gt;% top_n(1, days_since_100) %&gt;% ungroup(), size = 2, color = &quot;gray50&quot; ) + scale_y_log10( expand = expansion(mult = c(0, .1)), breaks = c(100, 200, 500, 2000, 5000, 10000, 20000, 50000, 100000, 150000), labels = scales::comma ) + scale_x_continuous( expand = expansion(mult = c(0, .1)), breaks = c(0, 5, 10, 15, 20, 25, 30, 40, 50, 60) ) + theme_minimal() + theme( panel.grid.minor = element_blank(), plot.background = element_rect(fill = &quot;#FFF1E6&quot;), legend.position = &quot;none&quot;, panel.spacing = margin(3, 15, 3, 15, &quot;mm&quot;) ) + labs( x = &quot;Number of days since 100th case&quot;, y = &quot;&quot;, title = &quot;Country by country: how coronavirus case trajectories compare&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot; ) 差强人意，再想想有没有好的办法 41.5.4 比较tidy的方法 对数据框d2a增加两列属性(有无标签，有无颜色)，然后手动改颜色 highlight_country &lt;- d2a %&gt;% group_by(country_region) %&gt;% filter(days_since_100 == max(days_since_100)) %&gt;% ungroup() %&gt;% arrange(desc(days_since_100)) %&gt;% top_n(10, days_since_100) %&gt;% pull(country_region) highlight_country ## [1] &quot;China&quot; &quot;Diamond Princess&quot; ## [3] &quot;Korea, South&quot; &quot;Japan&quot; ## [5] &quot;Italy&quot; &quot;Iran&quot; ## [7] &quot;France&quot; &quot;Singapore&quot; ## [9] &quot;Germany&quot; &quot;Spain&quot; 吸取了Kieran Healy大神的配色方案 ## Colors cgroup_cols &lt;- c(prismatic::clr_darken(paletteer_d(&quot;ggsci::category20_d3&quot;), 0.2)[1:length(highlight_country)], &quot;gray70&quot;) scales::show_col(cgroup_cols) d2a %&gt;% group_by(country_region) %&gt;% filter(max(days_since_100) &gt; 9) %&gt;% mutate( end_label = ifelse(days_since_100 == max(days_since_100), country_region, NA_character_) ) %&gt;% mutate(end_label = case_when(country_region %in% highlight_country ~ end_label, TRUE ~ NA_character_), cgroup = case_when(country_region %in% highlight_country ~ country_region, TRUE ~ &quot;ZZOTHER&quot;)) %&gt;% # length(highlight_country) + gray ggplot(aes(x = days_since_100, y = cases, color = cgroup, label = end_label, group = country_region)) + geom_line(size = 0.8) + geom_text_repel(nudge_x = 1.1, nudge_y = 0.1, segment.color = NA) + guides(color = FALSE) + scale_color_manual(values = cgroup_cols) + scale_y_continuous(labels = scales::comma_format(accuracy = 1), breaks = 10^seq(2, 8), trans = &quot;log10&quot; ) + labs(x = &quot;Days Since 100 Confirmed Death&quot;, y = &quot;Cumulative Number of Deaths (log10 scale)&quot;, title = &quot;Cumulative Number of Reported Deaths from COVID-19, Selected Countries&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot;) 感觉这样是最好的方案。 41.6 每个国家的情况 d2 %&gt;% group_by(country_region) %&gt;% filter(max(cases) &gt;= 1000) %&gt;% ungroup() ## # A tibble: 1,060 x 4 ## country_region date cases days_since_100 ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Argentina 2020-03-20 128 0 ## 2 Argentina 2020-03-21 158 1 ## 3 Argentina 2020-03-22 266 2 ## 4 Argentina 2020-03-23 301 3 ## 5 Argentina 2020-03-24 387 4 ## 6 Argentina 2020-03-25 387 5 ## 7 Argentina 2020-03-26 502 6 ## 8 Argentina 2020-03-27 589 7 ## 9 Argentina 2020-03-28 690 8 ## 10 Argentina 2020-03-29 745 9 ## # ... with 1,050 more rows d2 %&gt;% group_by(country_region) %&gt;% filter(max(cases) &gt;= 1000) %&gt;% ungroup() %&gt;% ggplot(aes(days_since_100, cases)) + geom_line(size = 0.8) + geom_line( data = d2 %&gt;% rename(country = country_region), aes(days_since_100, cases, group = country), color = &quot;grey&quot; ) + geom_point(pch = 21, size = 1, color = &quot;red&quot;) + scale_y_log10( expand = expansion(mult = c(0, .1)), breaks = c(100, 1000, 10000, 50000) ) + scale_x_continuous( expand = expansion(mult = c(0, 0)), breaks = c(0, 5, 10, 20, 30, 50) ) + facet_wrap(vars(country_region), scales = &quot;free_x&quot;) + theme( panel.background = element_rect(fill = &quot;#FFF1E6&quot;), plot.background = element_rect(fill = &quot;#FFF1E6&quot;) ) + labs( x = &quot;Number of days since 100th case&quot;, y = &quot;&quot;, title = &quot;Outbreak are now underway in dozens of other countries, with some on the same trajectory as Italy&quot;, subtitle = &quot;Cumulative number of cases, by Number of days since 100th case&quot;, caption = &quot;data source from @www.ft.com&quot; ) 41.7 地图 library(countrycode) # countrycode(&#39;Albania&#39;, &#39;country.name&#39;, &#39;iso3c&#39;) d2_newest %&gt;% mutate(ISO3 = countrycode(country_region, origin = &quot;country.name&quot;, destination = &quot;iso3c&quot; )) 我们选取最新的日期 d_newest &lt;- d %&gt;% select(Long, Lat, last_col()) %&gt;% set_names(&quot;Long&quot;, &quot;Lat&quot;, &quot;newest_date&quot;) d_newest ## # A tibble: 256 x 3 ## Long Lat newest_date ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 65 33 174 ## 2 20.2 41.2 243 ## 3 1.66 28.0 716 ## 4 1.52 42.5 376 ## 5 17.9 -11.2 7 ## 6 -61.8 17.1 7 ## 7 -63.6 -38.4 1054 ## 8 45.0 40.1 532 ## 9 149. -35.5 80 ## 10 151. -33.9 2032 ## # ... with 246 more rows world &lt;- map_data(&quot;world&quot;) ggplot() + geom_polygon( data = world, aes(x = long, y = lat, group = group), fill = &quot;grey&quot;, alpha = 0.3 ) + geom_point( data = d_newest, aes(x = Long, y = Lat, size = newest_date, color = newest_date), stroke = F, alpha = 0.7 ) + scale_size_continuous( name = &quot;Cases&quot;, trans = &quot;log&quot;, range = c(1, 7), breaks = c(1, 20, 100, 1000, 50000), labels = c(&quot;1-19&quot;, &quot;20-99&quot;, &quot;100-999&quot;, &quot;1,000-49,999&quot;, &quot;50,000+&quot;) ) + scale_color_viridis_c( option = &quot;inferno&quot;, name = &quot;Cases&quot;, trans = &quot;log&quot;, breaks = c(1, 20, 100, 1000, 50000), labels = c(&quot;1-19&quot;, &quot;20-99&quot;, &quot;100-999&quot;, &quot;1,000-49,999&quot;, &quot;50,000+&quot;) ) + theme_void() + guides(colour = guide_legend()) + labs( title = &quot;Mapping the coronavirus outbreak&quot;, subtitle = &quot;&quot;, caption = &quot;Source: JHU Unviersity, CSSE; FT research @www.FT.com&quot; ) + theme( legend.position = &quot;bottom&quot;, text = element_text(color = &quot;#22211d&quot;), plot.background = element_rect(fill = &quot;#ffffff&quot;, color = NA), panel.background = element_rect(fill = &quot;#ffffff&quot;, color = NA), legend.background = element_rect(fill = &quot;#ffffff&quot;, color = NA) ) 41.8 更多 参考 (https://www.ft.com/coronavirus-latest) (https://covid19datahub.io/) "],["eda-anscombe.html", "第 42 章 探索性数据分析-anscombe数据集 42.1 探索anscombe 42.2 规整数据 42.3 统计 42.4 建模 42.5 可视化看看", " 第 42 章 探索性数据分析-anscombe数据集 在可视化章节，我们提到 Anscombe’s quartet这个数据集， ?datasets::anscombe 在其官方文档，我们可看到它是这样描述的： Four x-y datasets which have the same traditional statistical properties (mean, variance, correlation, regression line, etc.), yet are quite different. d &lt;- datasets::anscombe head(d) ## x1 x2 x3 x4 y1 y2 y3 y4 ## 1 10 10 10 8 8.04 9.14 7.46 6.58 ## 2 8 8 8 8 6.95 8.14 6.77 5.76 ## 3 13 13 13 8 7.58 8.74 12.74 7.71 ## 4 9 9 9 8 8.81 8.77 7.11 8.84 ## 5 11 11 11 8 8.33 9.26 7.81 8.47 ## 6 14 14 14 8 9.96 8.10 8.84 7.04 42.1 探索anscombe library(tidyverse) 本节课的内容，就是用tidyverse的方法去探索下这个数据集： 规整数据 分组统计 建模 可视化 42.2 规整数据 我们再看看数据 head(d) ## x1 x2 x3 x4 y1 y2 y3 y4 ## 1 10 10 10 8 8.04 9.14 7.46 6.58 ## 2 8 8 8 8 6.95 8.14 6.77 5.76 ## 3 13 13 13 8 7.58 8.74 12.74 7.71 ## 4 9 9 9 8 8.81 8.77 7.11 8.84 ## 5 11 11 11 8 8.33 9.26 7.81 8.47 ## 6 14 14 14 8 9.96 8.10 8.84 7.04 实际上，这是四组(x1, y1), (x2, y2), (x3, y3), (x4, y4)。那要怎么样规整数据， 或者说怎么样把数据弄成tidy呢。这里有个技巧，你可以想象，数据能ggplot()可视化的基本上就是tidy的。 d %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + facet_wrap(~set) 那么，我们希望我们的数据是这样的格式 set x y 1 10 8.04 1 8 6.95 … 2 10 9.14 2 8 8.14 … 42.2.1 小小的回顾 我们之前讲过，数据变形中，宽表格变成长表格， 需要用到tidyr::pivot_longer()函数 比如 dt &lt;- tibble(id = c(&quot;a&quot;, &quot;b&quot;), x_1 = 1:2, x_2 = 3:4, y_1 = 5:6, y_2 = 8:9) dt ## # A tibble: 2 x 5 ## id x_1 x_2 y_1 y_2 ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 a 1 3 5 8 ## 2 b 2 4 6 9 dt %&gt;% pivot_longer(-id, names_to = &quot;name&quot;, values_to = &quot;vaules&quot; ) ## # A tibble: 8 x 3 ## id name vaules ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 a x_1 1 ## 2 a x_2 3 ## 3 a y_1 5 ## 4 a y_2 8 ## 5 b x_1 2 ## 6 b x_2 4 ## 7 b y_1 6 ## 8 b y_2 9 有时候，我们不想要下划线后面的编号，只想保留前面的第一个字母 dt %&gt;% pivot_longer( cols = -id, names_to = &quot;name&quot;, names_pattern = &quot;(.)_.&quot;, values_to = &quot;vaules&quot; ) ## # A tibble: 8 x 3 ## id name vaules ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 a x 1 ## 2 a x 3 ## 3 a y 5 ## 4 a y 8 ## 5 b x 2 ## 6 b x 4 ## 7 b y 6 ## 8 b y 9 有时候人的需求是多样的，比如不想要前面的第一个字母，只要下划线后面的编号 dt %&gt;% pivot_longer( cols = -id, names_to = &quot;name&quot;, names_pattern = &quot;._(.)&quot;, values_to = &quot;vaules&quot; ) ## # A tibble: 8 x 3 ## id name vaules ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 a 1 1 ## 2 a 2 3 ## 3 a 1 5 ## 4 a 2 8 ## 5 b 1 2 ## 6 b 2 4 ## 7 b 1 6 ## 8 b 2 9 有时候我们都想要呢？ dt %&gt;% pivot_longer( cols = -id, names_to = c(&quot;name&quot;, &quot;group&quot;), names_pattern = &quot;(.)_(.)&quot;, values_to = &quot;vaules&quot; ) ## # A tibble: 8 x 4 ## id name group vaules ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 a x 1 1 ## 2 a x 2 3 ## 3 a y 1 5 ## 4 a y 2 8 ## 5 b x 1 2 ## 6 b x 2 4 ## 7 b y 1 6 ## 8 b y 2 9 有时候，我们希望\"x\", \"y\"保留在列名，那么匹配出来的第一个字母，就不能给\"name\"，而是传给特殊的符号\".value\"，它会收集匹配出来的字符，然后放在列名中 dt %&gt;% pivot_longer( cols = -id, names_to = c(&quot;.value&quot;, &quot;group&quot;), names_pattern = &quot;(.)_(.)&quot;, values_to = &quot;vaules&quot; ) ## # A tibble: 4 x 4 ## id group x y ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 a 1 1 5 ## 2 a 2 3 8 ## 3 b 1 2 6 ## 4 b 2 4 9 是不是觉得很强大？ 42.2.2 回到案例 具体来说，我们希望 x1 按照指定的正则表达式分成了两个部分 x和 1，那么1放在set下，而 x 传给了.value 当作变型后的列名. knitr::include_graphics(&quot;images/pivot_longer_values.jpg&quot;) 那么和上面的情况一样，使用tidyr::pivot_longer()函数 tidy_d &lt;- d %&gt;% pivot_longer( cols = everything(), names_to = c(&quot;.value&quot;, &quot;set&quot;), names_pattern = &quot;(.)(.)&quot; ) tidy_d ## # A tibble: 44 x 3 ## set x y ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 10 8.04 ## 2 2 10 9.14 ## 3 3 10 7.46 ## 4 4 8 6.58 ## 5 1 8 6.95 ## 6 2 8 8.14 ## 7 3 8 6.77 ## 8 4 8 5.76 ## 9 1 13 7.58 ## 10 2 13 8.74 ## # ... with 34 more rows 再啰嗦下参数的含义： cols = everything() 表示选择所有列 names_to = c(\".value\", \"set\") 希望变型后的列名是c(\".value\", \"set\"), 这里 \".value\" 是个特殊的符号，代表着names_pattern匹配过来的值，一般情况下，是多个值，如果传给\".value\"的\"x, y, z\"，那么列名就会变成c(\"x\", \"y\", \"z\", \"set\") names_pattern = \"(.)(.)\" 将变换前的列名按照指定的正则表达式匹配，并且传递给names_to的对应的参数，比如这里第一个(.)传递给.value；第二个(.)传递给set. 42.3 统计 数据规整了，统计就很简单了 tidy_d_summary &lt;- tidy_d %&gt;% group_by(set) %&gt;% summarise(across( .cols = everything(), .fns = lst(mean, sd, var), .names = &quot;{col}_{fn}&quot; )) tidy_d_summary ## # A tibble: 4 x 7 ## set x_mean x_sd x_var y_mean y_sd y_var ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 9 3.32 11 7.50 2.03 4.13 ## 2 2 9 3.32 11 7.50 2.03 4.13 ## 3 3 9 3.32 11 7.5 2.03 4.12 ## 4 4 9 3.32 11 7.50 2.03 4.12 42.4 建模 具体参考第 22 章整理的四种方法 tidy_d %&gt;% group_nest(set) %&gt;% mutate( fit = map(data, ~ lm(y ~ x, data = .x)), tidy = map(fit, broom::tidy), glance = map(fit, broom::glance) ) %&gt;% unnest(tidy) 感觉大家更喜欢这种 tidy_d %&gt;% group_by(set) %&gt;% group_modify( ~ broom::tidy(lm(y ~ x, data = .)) ) ## # A tibble: 8 x 6 ## # Groups: set [4] ## set term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 (Intercep~ 3.00 1.12 2.67 0.0257 ## 2 1 x 0.500 0.118 4.24 0.00217 ## 3 2 (Intercep~ 3.00 1.13 2.67 0.0258 ## 4 2 x 0.5 0.118 4.24 0.00218 ## 5 3 (Intercep~ 3.00 1.12 2.67 0.0256 ## 6 3 x 0.500 0.118 4.24 0.00218 ## 7 4 (Intercep~ 3.00 1.12 2.67 0.0256 ## 8 4 x 0.500 0.118 4.24 0.00216 tidy_d %&gt;% group_by(set) %&gt;% summarise( broom::tidy(lm(y ~ x, data = cur_data())) ) ## # A tibble: 8 x 6 ## # Groups: set [4] ## set term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 (Intercep~ 3.00 1.12 2.67 0.0257 ## 2 1 x 0.500 0.118 4.24 0.00217 ## 3 2 (Intercep~ 3.00 1.13 2.67 0.0258 ## 4 2 x 0.5 0.118 4.24 0.00218 ## 5 3 (Intercep~ 3.00 1.12 2.67 0.0256 ## 6 3 x 0.500 0.118 4.24 0.00218 ## 7 4 (Intercep~ 3.00 1.12 2.67 0.0256 ## 8 4 x 0.500 0.118 4.24 0.00216 42.5 可视化看看 tidy_d %&gt;% ggplot(aes(x = x, y = y, colour = set)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + theme(legend.position = &quot;none&quot;) + facet_wrap(~set) "],["eda-height.html", "第 43 章 探索性数据分析-身高体重 43.1 案例分析 43.2 可视化 43.3 来点高级的 43.4 建模", " 第 43 章 探索性数据分析-身高体重 library(tidyverse) 43.1 案例分析 这是一份身高和体重的数据集 d &lt;- read_csv(&quot;./demo_data/weight-height.csv&quot;) d ## # A tibble: 10,000 x 3 ## Gender Height Weight ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Male 73.8 242. ## 2 Male 68.8 162. ## 3 Male 74.1 213. ## 4 Male 71.7 220. ## 5 Male 69.9 206. ## 6 Male 67.3 152. ## 7 Male 68.8 184. ## 8 Male 68.3 168. ## 9 Male 67.0 176. ## 10 Male 63.5 156. ## # ... with 9,990 more rows d %&gt;% summarise( across(everything(), ~ sum(is.na(.))) ) ## # A tibble: 1 x 3 ## Gender Height Weight ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 43.2 可视化 43.2.1 画出不同性别的身高分布 常规答案 d %&gt;% ggplot(aes(x = Height, fill = Gender)) + geom_density(alpha = 0.5) d %&gt;% ggplot(aes(x = Height, fill = Gender)) + geom_density(alpha = 0.5) + facet_wrap(vars(Gender)) 43.3 来点高级的 刚才我们看到了分面的操作，全局数据按照某个变量分组后，形成的若干个子集在不同的面板中分别展示出来。 这种方法很适合子集之间对比。事实上，我们看到每个子集的情况后，还很想知道全局的情况，以及子集在全局中的分布、状态或者位置。也就说，想对比子集和全局的情况。 所以我们期望（子集之间对比，子集与全局对比）。 具体方法：用分面的方法高亮展示子集，同时在每个分面上添加全局（灰色背景） 第一步，先把子集用分面的方法，分别画出来 d %&gt;% ggplot(aes(x = Height)) + geom_density() + facet_wrap(vars(Gender)) 第二步，添加整体的情况作为背景图层。因为第一步用到了分面，也就说会分组，但我们希望整体的背景图层不受分面信息影响，或者叫背景图层不需要分组，而是显示全部。也就说，要保证每个分面面板中的背景图都是一样的，因此，在这个geom_denstiy()图层中，构建不受facet_wrap()影响的数据，即删掉data的分组列。 d %&gt;% ggplot(aes(x = Height)) + geom_density( data = d %&gt;% select(-Gender) ) + geom_density() + facet_wrap(vars(Gender)) 第三步，y轴的调整，我们希望保持密度的形状，同时希望y轴不用比例值而是用具体的count个数，这样整体和局部能放在一个标度下， d %&gt;% ggplot(aes(x = Height, y = after_stat(count))) + geom_density( data = d %&gt;% select(-Gender) ) + geom_density() + facet_wrap(vars(Gender)) 第四步， 配色。 配色网站选颜色 “Male,” “Female” 是Gender已经存在的分组。另外，我们在背景图层，新增了一个组“all people”，这样，整个图就有三个分组（三个color组），那么，我们可以在scale_fill_manual中统一设置和指定。 density_colors &lt;- c( &quot;Male&quot; = &quot;#247BA0&quot;, &quot;Female&quot; = &quot;#F25F5C&quot;, &quot;all people&quot; = &quot;grey85&quot; ) d %&gt;% ggplot(aes(x = Height, y = after_stat(count))) + geom_density( data = df %&gt;% select(-Gender), aes(fill = &quot;all people&quot;, color = &quot;all people&quot;) ) + geom_density(aes(color = Gender, fill = Gender)) + facet_wrap(vars(Gender)) + scale_fill_manual(name = NULL, values = density_colors) + scale_color_manual(name = NULL, values = density_colors) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) 43.3.1 完整代码 density_colors &lt;- c( &quot;Male&quot; = &quot;#247BA0&quot;, &quot;Female&quot; = &quot;#F25F5C&quot;, &quot;all people&quot; = &quot;grey80&quot; ) scales::show_col(density_colors) d %&gt;% ggplot(aes(x = Height, y = after_stat(count))) + geom_density( data = d %&gt;% dplyr::select(-Gender), aes(fill = &quot;all people&quot;, color = &quot;all people&quot;) ) + geom_density(aes(color = Gender, fill = Gender)) + facet_wrap(vars(Gender)) + scale_fill_manual(name = NULL, values = density_colors) + scale_color_manual(name = NULL, values = density_colors) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) 或者，用不同的主题风格 density_colors &lt;- c( &quot;Male&quot; = &quot;#56B4E9&quot;, &quot;Female&quot; = &quot;#EF8A17&quot;, &quot;all participants&quot; = &quot;grey85&quot; ) d %&gt;% ggplot(aes(x = Height, y = after_stat(count))) + geom_density( data = function(x) dplyr::select(x, -Gender), aes(fill = &quot;all participants&quot;, color = &quot;all participants&quot;) ) + geom_density(aes(fill = Gender, color = Gender)) + facet_wrap(vars(Gender)) + scale_color_manual(name = NULL, values = density_colors) + scale_fill_manual(name = NULL, values = density_colors) + cowplot::theme_minimal_hgrid(16) + theme(legend.position = &quot;bottom&quot;, legend.justification = &quot;center&quot;) 43.3.2 画出不同性别的体重分布 d %&gt;% ggplot(aes(x = Weight, fill = Gender)) + geom_density(alpha = 0.5) 43.4 建模 43.4.1 身高与体重的散点图 d %&gt;% ggplot(aes(x = Height, y = Weight, color = Gender)) + geom_point() 43.4.2 建立身高与体重的线性模型 fit &lt;- lm(Weight ~ 1 + Height, data = d) summary(fit) ## ## Call: ## lm(formula = Weight ~ 1 + Height, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -51.93 -8.24 -0.12 8.26 46.84 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -350.7372 2.1115 -166 &lt;2e-16 *** ## Height 7.7173 0.0318 243 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 12.2 on 9998 degrees of freedom ## Multiple R-squared: 0.855, Adjusted R-squared: 0.855 ## F-statistic: 5.9e+04 on 1 and 9998 DF, p-value: &lt;2e-16 broom::tidy(fit) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -351. 2.11 -166. 0 ## 2 Height 7.72 0.0318 243. 0 43.4.3 建立不同性别下的身高与体重的线性模型 d %&gt;% group_by(Gender) %&gt;% group_modify( ~ broom::tidy(lm(Weight ~ 1 + Height, data = .)) ) ## # A tibble: 4 x 6 ## # Groups: Gender [2] ## Gender term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Female (Interce~ -246. 3.36 -73.3 0 ## 2 Female Height 5.99 0.0526 114. 0 ## 3 Male (Interce~ -224. 3.41 -65.8 0 ## 4 Male Height 5.96 0.0494 121. 0 d %&gt;% ggplot(aes(x = Height, y = Weight, group = Gender)) + geom_point(aes(color = Gender)) + geom_smooth(method = lm) "],["eda-caribou.html", "第 44 章 探索性数据分析-驯鹿迁移 44.1 驯鹿位置跟踪 44.2 驯鹿的身份信息 44.3 性别比例 44.4 每个站点运动最频繁的前10的驯鹿 44.5 驯鹿的活动信息 44.6 被追踪最多次的驯鹿的轨迹 44.7 某一只驯鹿的轨迹 44.8 选择某个驯鹿，查看他的活动轨迹 44.9 季节模式 44.10 迁移速度 44.11 动态展示 44.12 更多", " 第 44 章 探索性数据分析-驯鹿迁移 本章我们分析加拿大哥伦比亚林地驯鹿追踪数据，数据包含了从1988年到2016年期间260只驯鹿，近250000个位置标签。 44.1 驯鹿位置跟踪 大家可以在这里了解数据集的信息，它包含了两个数据集 # devtools::install_github(&quot;thebioengineer/tidytuesdayR&quot;) library(tidytuesdayR) tuesdata &lt;- tidytuesdayR::tt_load(&quot;2020-06-23&quot;) # or # tuesdata &lt;- tidytuesdayR::tt_load(2020, week = 26) library(tidyverse) library(lubridate) library(gganimate) individuals &lt;- readr::read_csv(&quot;./demo_data/caribou/individuals.csv&quot;) locations &lt;- readr::read_csv(&quot;./demo_data/caribou/locations.csv&quot;) 44.2 驯鹿的身份信息 individuals %&gt;% glimpse() ## Rows: 286 ## Columns: 14 ## $ animal_id &lt;chr&gt; &quot;HR_151.510&quot;, &quot;GR_C04... ## $ sex &lt;chr&gt; &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;... ## $ life_stage &lt;chr&gt; NA, NA, NA, NA, NA, N... ## $ pregnant &lt;lgl&gt; NA, NA, NA, NA, NA, N... ## $ with_calf &lt;lgl&gt; NA, NA, NA, NA, NA, N... ## $ death_cause &lt;chr&gt; NA, NA, NA, NA, NA, N... ## $ study_site &lt;chr&gt; &quot;Hart Ranges&quot;, &quot;Graha... ## $ deploy_on_longitude &lt;dbl&gt; NA, NA, NA, NA, NA, N... ## $ deploy_on_latitude &lt;dbl&gt; NA, NA, NA, NA, NA, N... ## $ deploy_on_comments &lt;chr&gt; NA, NA, NA, NA, NA, N... ## $ deploy_off_longitude &lt;dbl&gt; NA, NA, NA, NA, NA, N... ## $ deploy_off_latitude &lt;dbl&gt; NA, NA, NA, NA, NA, N... ## $ deploy_off_type &lt;chr&gt; &quot;unknown&quot;, &quot;unknown&quot;,... ## $ deploy_off_comments &lt;chr&gt; NA, NA, NA, NA, NA, N... individuals %&gt;% count(animal_id) ## # A tibble: 260 x 2 ## animal_id n ## &lt;chr&gt; &lt;int&gt; ## 1 BP_car022 1 ## 2 BP_car023 1 ## 3 BP_car032 1 ## 4 BP_car043 1 ## 5 BP_car100 1 ## 6 BP_car101 1 ## 7 BP_car115 1 ## 8 BP_car144 1 ## 9 BP_car145 1 ## 10 GR_C01 2 ## # ... with 250 more rows 我们发现有重复id的，怎么办？ individuals %&gt;% janitor::get_dupes(animal_id) ## # A tibble: 50 x 15 ## animal_id dupe_count sex life_stage pregnant ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 GR_C01 2 f &lt;NA&gt; NA ## 2 GR_C01 2 f &lt;NA&gt; NA ## 3 GR_C02 2 f &lt;NA&gt; NA ## 4 GR_C02 2 f &lt;NA&gt; NA ## 5 GR_C04 2 f &lt;NA&gt; NA ## 6 GR_C04 2 f &lt;NA&gt; NA ## 7 GR_C05 2 f &lt;NA&gt; NA ## 8 GR_C05 2 f &lt;NA&gt; NA ## 9 GR_C06 2 f &lt;NA&gt; NA ## 10 GR_C06 2 f &lt;NA&gt; NA ## # ... with 40 more rows, and 10 more variables: ## # with_calf &lt;lgl&gt;, death_cause &lt;chr&gt;, ## # study_site &lt;chr&gt;, deploy_on_longitude &lt;dbl&gt;, ## # deploy_on_latitude &lt;dbl&gt;, ## # deploy_on_comments &lt;chr&gt;, ## # deploy_off_longitude &lt;dbl&gt;, ## # deploy_off_latitude &lt;dbl&gt;, deploy_off_type &lt;chr&gt;, ## # deploy_off_comments &lt;chr&gt; individuals %&gt;% filter(deploy_on_latitude &gt; 50) %&gt;% ggplot(aes(x = deploy_on_longitude, y = deploy_on_latitude)) + geom_point(aes(color = study_site)) #+ # borders(&quot;world&quot;, regions = &quot;china&quot;) 44.3 性别比例 44.4 每个站点运动最频繁的前10的驯鹿 44.5 驯鹿的活动信息 简单点说，就是哪个驯鹿在什么时间出现在什么地方 locations %&gt;% ggplot(aes(x = longitude, y = latitude)) + geom_point(aes(color = study_site)) 44.6 被追踪最多次的驯鹿的轨迹 top_animal_ids &lt;- count(locations, animal_id, sort = TRUE) %&gt;% slice(1:10) %&gt;% pull(animal_id) locations %&gt;% filter(animal_id %in% top_animal_ids) %&gt;% arrange(animal_id, timestamp) %&gt;% group_by(animal_id) %&gt;% mutate(measurement_n = row_number()) %&gt;% ggplot(aes( x = longitude, y = latitude, color = animal_id, alpha = measurement_n )) + geom_point(show.legend = FALSE, size = 1) + geom_path(show.legend = FALSE, size = 1) + # scale_color_manual(values = ) + theme_minimal() + theme( plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 10), text = element_text(color = &quot;White&quot;), panel.grid.minor = element_blank(), panel.grid.major = element_line(color = &quot;gray60&quot;, size = 0.05), plot.background = element_rect(fill = &quot;gray10&quot;), axis.text = element_text(color = &quot;white&quot;) ) + labs( x = &quot;\\nLongitude&quot;, y = &quot;Latitude\\n&quot;, title = &quot;Caribou movement tracking&quot;, subtitle = &quot;Latitude and longitude locations of the animals with the highest number of measurements\\n&quot;, caption = &quot;Tidy Tuesday: Caribou Location Tracking&quot; ) 44.7 某一只驯鹿的轨迹 locations %&gt;% dplyr::filter(animal_id %in% c(&quot;QU_car143&quot;)) %&gt;% dplyr::arrange(animal_id, timestamp) %&gt;% dplyr::group_by(animal_id) %&gt;% dplyr::mutate(measurement_n = row_number()) %&gt;% ggplot(aes( x = longitude, y = latitude, color = measurement_n, alpha = measurement_n )) + geom_point(show.legend = FALSE, size = 1) + geom_path(show.legend = FALSE, size = 1) + scale_color_gradient(low = &quot;white&quot;, high = &quot;firebrick3&quot;) + theme_minimal() + theme( plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 10), text = element_text(color = &quot;White&quot;), panel.grid.minor = element_blank(), panel.grid.major = element_line(color = &quot;gray60&quot;, size = 0.05), plot.background = element_rect(fill = &quot;gray10&quot;), axis.text = element_text(color = &quot;white&quot;) ) + labs( x = &quot;\\nLongitude&quot;, y = &quot;Latitude\\n&quot;, title = &quot;QU_car143 movement tracking&quot;, subtitle = &quot;Latitude and longitude locations of the animals with the highest number of measurements\\n Ligher colors indicate earlier measurements&quot;, caption = &quot;Tidy Tuesday: Caribou Location Tracking&quot; ) 44.8 选择某个驯鹿，查看他的活动轨迹 example_animal &lt;- locations %&gt;% dplyr::filter(animal_id == sample(animal_id, 1)) %&gt;% dplyr::arrange(timestamp) example_animal ## # A tibble: 2,039 x 7 ## event_id animal_id study_site season ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2.27e9 QU_car110 Quintette Winter ## 2 2.27e9 QU_car110 Quintette Winter ## 3 2.27e9 QU_car110 Quintette Winter ## 4 2.27e9 QU_car110 Quintette Winter ## 5 2.27e9 QU_car110 Quintette Winter ## 6 2.27e9 QU_car110 Quintette Winter ## 7 2.27e9 QU_car110 Quintette Winter ## 8 2.27e9 QU_car110 Quintette Winter ## 9 2.27e9 QU_car110 Quintette Winter ## 10 2.27e9 QU_car110 Quintette Winter ## # ... with 2,029 more rows, and 3 more variables: ## # timestamp &lt;dttm&gt;, longitude &lt;dbl&gt;, latitude &lt;dbl&gt; &quot;2010-03-28 21:00:44&quot; %&gt;% lubridate::as_date() &quot;2010-03-28 21:00:44&quot; %&gt;% lubridate::as_datetime() &quot;2010-03-28 21:00:44&quot; %&gt;% lubridate::quarter() example_animal %&gt;% dplyr::mutate(date = lubridate::as_date(timestamp)) %&gt;% ggplot(aes(x = longitude, y = latitude, color = date)) + geom_path() example_animal %&gt;% dplyr::mutate(quarter = lubridate::quarter(timestamp) %&gt;% as.factor()) %&gt;% ggplot(aes(x = longitude, y = latitude, color = quarter)) + geom_path() + facet_wrap(vars(quarter)) + labs(title = &quot;一只小驯鹿到处啊跑&quot;) 44.9 季节模式 看看驯鹿夏季和冬季运动模式，这段代码来自gkaramanis movement &lt;- locations %&gt;% filter(study_site != &quot;Hart Ranges&quot;) %&gt;% mutate( season = fct_rev(season), longitude = round(longitude, 2), latitude = round(latitude, 2) ) %&gt;% distinct(season, study_site, longitude, latitude) ggplot(movement) + geom_point(aes(longitude, latitude, group = study_site, colour = study_site ), size = 0.1) + gghighlight::gghighlight( unhighlighted_params = list(colour = &quot;grey70&quot;), use_direct_label = FALSE ) + scale_colour_manual( values = c(&quot;#ffe119&quot;, &quot;#4363d8&quot;, &quot;#f58231&quot;, &quot;#e6194B&quot;, &quot;#800000&quot;, &quot;#000075&quot;, &quot;#f032e6&quot;, &quot;#3cb44b&quot;), breaks = c(&quot;Graham&quot;, &quot;Scott&quot;, &quot;Moberly&quot;, &quot;Burnt Pine&quot;, &quot;Kennedy&quot;, &quot;Quintette&quot;, &quot;Narraway&quot;) ) + guides(colour = guide_legend(title = &quot;Herd&quot;, override.aes = list(size = 3))) + coord_fixed(ratio = 1.5) + facet_wrap(vars(season), ncol = 2) + # labs( # title = &quot;Migration patterns of Northern Caribou\\nin the South Peace of British Columbia&quot;, # subtitle = str_wrap(&quot;In summer, most caribou migrate towards the central core of the Rocky Mountains where they use alpine and subalpine habitat. The result of this movement to the central core of the Rocky Mountains is that some of the east side herds can overlap with west side herds during the summer.&quot;, 100), # caption = str_wrap(&quot;Source: Seip DR, Price E (2019) Data from: Science update for the South Peace Northern Caribou (Rangifer tarandus caribou pop. 15) in British Columbia. Movebank Data Repository. https://doi.org/10.5441/001/1.p5bn656k | Graphic: Georgios Karamanis&quot;, 70) # ) + theme_void() + theme( legend.position = c(0.5, 0.6), legend.text = element_text(size = 11, colour = &quot;#F9EED9&quot;), legend.title = element_text(size = 16, hjust = 0.5, colour = &quot;#F9EED9&quot;), panel.spacing.x = unit(3, &quot;lines&quot;), plot.margin = margin(20, 20, 20, 20), plot.background = element_rect(fill = &quot;#7A6A4F&quot;, colour = NA), strip.text = element_text(colour = &quot;#F9EED9&quot;, size = 18), plot.title = element_text(colour = &quot;white&quot;, size = 20, hjust = 0, lineheight = 1), plot.subtitle = element_text(colour = &quot;white&quot;, size = 12, hjust = 0, lineheight = 1, margin = margin(10, 0, 50, 0)), plot.caption = element_text(colour = &quot;grey80&quot;, size = 7, hjust = 1, margin = margin(30, 0, 10, 0)) ) 44.10 迁移速度 location_with_speed &lt;- locations %&gt;% dplyr::group_by(animal_id) %&gt;% dplyr::mutate( last_longitude = lag(longitude), last_latitude = lag(latitude), hours = as.numeric(difftime(timestamp, lag(timestamp), units = &quot;hours&quot;)), km = geosphere::distHaversine( cbind(longitude, latitude), cbind(last_longitude, last_latitude) ) / 1000, speed = km / hours ) %&gt;% dplyr::ungroup() location_with_speed ## # A tibble: 249,450 x 12 ## event_id animal_id study_site season ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2.26e9 GR_C01 Graham Winter ## 2 2.26e9 GR_C01 Graham Winter ## 3 2.26e9 GR_C01 Graham Winter ## 4 2.26e9 GR_C01 Graham Winter ## 5 2.26e9 GR_C01 Graham Winter ## 6 2.26e9 GR_C01 Graham Winter ## 7 2.26e9 GR_C01 Graham Winter ## 8 2.26e9 GR_C01 Graham Winter ## 9 2.26e9 GR_C01 Graham Winter ## 10 2.26e9 GR_C01 Graham Winter ## # ... with 249,440 more rows, and 8 more variables: ## # timestamp &lt;dttm&gt;, longitude &lt;dbl&gt;, latitude &lt;dbl&gt;, ## # last_longitude &lt;dbl&gt;, last_latitude &lt;dbl&gt;, ## # hours &lt;dbl&gt;, km &lt;dbl&gt;, speed &lt;dbl&gt; location_with_speed %&gt;% ggplot(aes(x = speed)) + geom_histogram() + scale_x_log10() 44.11 动态展示 library(gganimate) example_animal %&gt;% ggplot(aes(x = longitude, y = latitude)) + geom_point() + transition_time(time = timestamp) + shadow_mark(past = TRUE) + labs(title = &quot;date is {frame_time}&quot;) 44.12 更多 df &lt;- locations %&gt;% dplyr::filter( study_site == &quot;Graham&quot;, year(timestamp) == 2002 ) %&gt;% dplyr::group_by(animal_id) %&gt;% dplyr::filter( as_date(min(timestamp)) == &quot;2002-01-01&quot;, as_date(max(timestamp)) == &quot;2002-12-31&quot; ) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(date = as_date(timestamp)) %&gt;% dplyr::group_by(animal_id, date) %&gt;% dplyr::summarise( longitude_centroid = mean(longitude), latitude_centroid = mean(latitude) ) %&gt;% dplyr::ungroup() %&gt;% tidyr::complete(animal_id, date) %&gt;% dplyr::arrange(animal_id, date) %&gt;% tidyr::fill(longitude_centroid, latitude_centroid, .direction = &quot;down&quot;) p &lt;- df %&gt;% ggplot(aes(longitude_centroid, latitude_centroid, colour = animal_id)) + geom_point(size = 2) + coord_map() + theme_void() + theme(legend.position = &quot;none&quot;) + transition_time(time = date) + shadow_mark(alpha = 0.2, size = 0.8) + ggtitle(&quot;Caribou location on {frame_time}&quot;) p "],["eda-penguins.html", "第 45 章 探索性数据分析-企鹅的故事 45.1 数据 45.2 探索性分析", " 第 45 章 探索性数据分析-企鹅的故事 今天讲一个关于企鹅的数据故事。这个故事来源于科考人员记录的大量企鹅体征数据，图片来源这里. 45.1 数据 45.1.1 导入数据 可通过宏包palmerpenguins::penguins获取数据，也可以读取本地penguins.csv文件， 我们采取后面一种方法： library(tidyverse) penguins &lt;- read_csv(&quot;./demo_data/penguins.csv&quot;) %&gt;% janitor::clean_names() penguins %&gt;% head() ## # A tibble: 6 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ NA NA ## 5 Adelie Torge~ 36.7 19.3 ## 6 Adelie Torge~ 39.3 20.6 ## # ... with 4 more variables: flipper_length_mm &lt;dbl&gt;, ## # body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt; 45.1.2 变量含义 variable class description species integer 企鹅种类 (Adelie, Gentoo, Chinstrap) island integer 所在岛屿 (Biscoe, Dream, Torgersen) bill_length_mm double 嘴峰长度 (单位毫米) bill_depth_mm double 嘴峰深度 (单位毫米) flipper_length_mm integer 鰭肢长度 (单位毫米) body_mass_g integer 体重 (单位克) sex integer 性别 year integer 记录年份 45.1.3 数据清洗 检查缺失值(NA)这个很重要！ penguins %&gt;% summarise( across(everything(), ~ sum(is.na(.))) ) ## # A tibble: 1 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 2 2 ## # ... with 4 more variables: flipper_length_mm &lt;int&gt;, ## # body_mass_g &lt;int&gt;, sex &lt;int&gt;, year &lt;int&gt; 有缺失值的地方找出来看看 penguins %&gt;% filter_all( any_vars(is.na(.)) ) ## # A tibble: 11 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ NA NA ## 2 Adelie Torge~ 34.1 18.1 ## 3 Adelie Torge~ 42 20.2 ## 4 Adelie Torge~ 37.8 17.1 ## 5 Adelie Torge~ 37.8 17.3 ## 6 Adelie Dream 37.5 18.9 ## 7 Gentoo Biscoe 44.5 14.3 ## 8 Gentoo Biscoe 46.2 14.4 ## 9 Gentoo Biscoe 47.3 13.8 ## 10 Gentoo Biscoe 44.5 15.7 ## 11 Gentoo Biscoe NA NA ## # ... with 4 more variables: flipper_length_mm &lt;dbl&gt;, ## # body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt; 发现共有11行至少有一处有缺失值，于是我们就删除这些行 penguins &lt;- penguins %&gt;% drop_na() penguins ## # A tibble: 333 x 8 ## species island bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie Torge~ 39.1 18.7 ## 2 Adelie Torge~ 39.5 17.4 ## 3 Adelie Torge~ 40.3 18 ## 4 Adelie Torge~ 36.7 19.3 ## 5 Adelie Torge~ 39.3 20.6 ## 6 Adelie Torge~ 38.9 17.8 ## 7 Adelie Torge~ 39.2 19.6 ## 8 Adelie Torge~ 41.1 17.6 ## 9 Adelie Torge~ 38.6 21.2 ## 10 Adelie Torge~ 34.6 21.1 ## # ... with 323 more rows, and 4 more variables: ## # flipper_length_mm &lt;dbl&gt;, body_mass_g &lt;dbl&gt;, ## # sex &lt;chr&gt;, year &lt;dbl&gt; 45.2 探索性分析 大家可以提出自己想探索的内容： 每种类型企鹅有多少只？ 每种类型企鹅各种属性的均值和分布？ 嘴峰长度和深度的关联？ 体重与翅膀长度的关联？ 嘴峰长度与嘴峰深度的比例？ 不同种类的宝宝，体重具有显著性差异？ 这体征中哪个因素对性别影响最大？ … 45.2.1 每种类型企鹅有多少只 penguins %&gt;% count(species, sort = T) ## # A tibble: 3 x 2 ## species n ## &lt;chr&gt; &lt;int&gt; ## 1 Adelie 146 ## 2 Gentoo 119 ## 3 Chinstrap 68 45.2.2 每个岛屿有多少企鹅？ penguins %&gt;% count(island, sort = T) ## # A tibble: 3 x 2 ## island n ## &lt;chr&gt; &lt;int&gt; ## 1 Biscoe 163 ## 2 Dream 123 ## 3 Torgersen 47 45.2.3 每种类型企鹅各种体征属性的均值和分布 penguins %&gt;% group_by(species) %&gt;% summarize(across(where(is.numeric), mean, na.rm = TRUE)) ## # A tibble: 3 x 6 ## species bill_length_mm bill_depth_mm flipper_length_~ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 38.8 18.3 190. ## 2 Chinst~ 48.8 18.4 196. ## 3 Gentoo 47.6 15.0 217. ## # ... with 2 more variables: body_mass_g &lt;dbl&gt;, ## # year &lt;dbl&gt; 45.2.4 每种类型企鹅的嘴峰长度的分布 penguins %&gt;% ggplot(aes(x = bill_length_mm)) + geom_density() + facet_wrap(vars(species), scales = &quot;free&quot;) 45.2.5 每种类型企鹅的嘴峰长度的分布（分性别） penguins %&gt;% ggplot(aes(x = bill_length_mm)) + geom_density(aes(fill = sex)) + facet_wrap(vars(species), scales = &quot;free&quot;) 男宝宝的嘴巴要长些，哈哈。 来张更好看点的 penguins %&gt;% ggplot(aes(x = bill_length_mm, fill = sex)) + geom_histogram( position = &quot;identity&quot;, alpha = 0.7, bins = 25 ) + scale_fill_manual(values = c(&quot;#66b3ff&quot;, &quot;#8c8c8c&quot;)) + ylab(&quot;number of penguins&quot;) + xlab(&quot;length (mm)&quot;) + theme_minimal() + theme( legend.position = &quot;bottom&quot;, legend.text = element_text(size = 11), legend.title = element_blank(), panel.grid.minor = element_blank(), axis.title = element_text(color = &quot;white&quot;, size = 10), plot.title = element_text(size = 20), plot.subtitle = element_text(size = 12, hjust = 1) ) + facet_wrap(vars(species), scales = &quot;free&quot;) 同理，可以画出其他属性的分布。当然，我更喜欢用山峦图来呈现不同分组的分布，因为竖直方向可以更方便比较 library(ggridges) penguins %&gt;% ggplot(aes(x = bill_length_mm, y = species, fill = species)) + ggridges::geom_density_ridges() 同样，我们也用颜色区分下性别，这样不同种类、不同性别企鹅的嘴峰长度分布一目了然 penguins %&gt;% ggplot(aes(x = bill_length_mm, y = species, fill = sex)) + geom_density_ridges(alpha = 0.5) 同样的代码，类似地画个其他体征的分布， penguins %&gt;% ggplot(aes(x = bill_depth_mm, fill = species)) + ggridges::geom_density_ridges(aes(y = species)) penguins %&gt;% ggplot(aes(x = bill_depth_mm, fill = sex)) + ggridges::geom_density_ridges(aes(y = species)) penguins %&gt;% ggplot(aes(x = body_mass_g, y = species, fill = sex)) + ggridges::geom_density_ridges(alpha = 0.5) 但这样一个特征一个特征的画，好麻烦。你知道程序员都是偷懒的，于是我们还有更骚的操作 penguins %&gt;% dplyr::select(species, bill_length_mm:body_mass_g) %&gt;% pivot_longer(-species, names_to = &quot;measurement&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = value)) + geom_density(aes(color = species, fill = species), size = 1.2, alpha = 0.2) + facet_wrap(vars(measurement), ncol = 2, scales = &quot;free&quot;) penguins %&gt;% dplyr::select(species, bill_length_mm:body_mass_g) %&gt;% pivot_longer(-species, names_to = &quot;measurement&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = species, y = value)) + geom_boxplot(aes(color = species, fill = species), size = 1.2, alpha = 0.2) + facet_wrap(vars(measurement), ncol = 2, scales = &quot;free&quot;) penguins %&gt;% dplyr::select(species, bill_length_mm:body_mass_g) %&gt;% pivot_longer(-species, names_to = &quot;measurement&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = value, y = species, fill = species)) + ggridges::geom_density_ridges() + facet_wrap(vars(measurement), scales = &quot;free&quot;) penguins %&gt;% dplyr::select(species,sex, bill_length_mm:body_mass_g) %&gt;% pivot_longer(-c(species, sex), names_to = &quot;measurement&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = value, y = species, fill = sex)) + ggridges::geom_density_ridges() + facet_wrap(vars(measurement), scales = &quot;free&quot;) 我若有所思的看着这张图，似乎看到了一些特征（pattern）了。 45.2.6 嘴峰长度和深度的关联 嘴巴越长，嘴巴也会越厚？ penguins %&gt;% ggplot(aes( x = bill_length_mm, y = bill_depth_mm, shape = species, color = species )) + geom_point() 我们把不同的种类，用不同的颜色区分看看 penguins %&gt;% ggplot(aes( x = bill_length_mm, y = bill_depth_mm, shape = species, color = species )) + geom_point(aes(size = body_mass_g)) 感觉这是一个辛普森佯谬， 我们画图看看 penguins %&gt;% ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(aes(color = species, shape = species)) + geom_smooth(method = lm) + geom_smooth(method = lm, aes(color = species)) 45.2.7 体重与翅膀长度的关联 翅膀越长，体重越大？ penguins %&gt;% group_by(species, island, sex) %&gt;% ggplot(aes( x = body_mass_g, y = reorder(species, -body_mass_g), color = species )) + geom_jitter(position = position_jitter(seed = 2020, width = 0.2), alpha = 0.4, size = 2) + stat_summary(fun = mean, geom = &quot;point&quot;, size = 5, alpha = 1) library(ggtext) penguins %&gt;% ggplot(aes(flipper_length_mm, body_mass_g, group = species)) + geom_point(aes(colour = species, shape = species), alpha = 0.7) + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + labs( title = &quot;Penguin Size, Palmer Station LTER&quot;, subtitle = &quot;Flipper length and body mass for &lt;span style = &#39;color:darkorange;&#39;&gt;Adelie&lt;/span&gt;, &lt;span style = &#39;color:purple;&#39;&gt;Chinstrap&lt;/span&gt; and &lt;span style = &#39;color:cyan4;&#39;&gt;Gentoo&lt;/span&gt; Penguins&quot;, x = &quot;flipper length (mm)&quot;, y = &quot;body mass (g)&quot; ) + theme_minimal() + theme( legend.position = &quot;none&quot;, # text = element_text(family = &quot;Futura&quot;), # (I only have &#39;Light&#39; ) plot.title = element_text(size = 16), plot.subtitle = element_markdown(), # element_markdown from `ggtext` to parse the css in the subtitle plot.title.position = &quot;plot&quot;, plot.caption = element_text(size = 8, colour = &quot;grey50&quot;), plot.caption.position = &quot;plot&quot; ) 45.2.8 不同种类的宝宝，体重具有显著性差异？ 先分组计算体重的均值和标准差 penguins %&gt;% group_by(species) %&gt;% summarise( count = n(), mean_body_mass = mean(body_mass_g), sd_body_mass = sd(body_mass_g) ) ## # A tibble: 3 x 4 ## species count mean_body_mass sd_body_mass ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 146 3706. 459. ## 2 Chinstrap 68 3733. 384. ## 3 Gentoo 119 5092. 501. penguins %&gt;% ggplot(aes(x = species, y = body_mass_g)) + geom_boxplot() + geom_jitter() 用统计方法验证下我们的猜测吧。记住，我们是有科学精神的的人！ 45.2.8.1 参数检验 one-way ANOVA(要求等方差) stats::aov(formula = body_mass_g ~ species, data = penguins) %&gt;% summary() ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## species 2 1.45e+08 72595110 342 &lt;2e-16 *** ## Residuals 330 7.01e+07 212332 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 p-value 很小，说明不同种类企鹅之间体重是有显著差异的，但aov只给出了species在整体上引起了体重差异（只要有任意两组之间有显著差异，aov给出的p-value都很小），如果想知道不同种类两两之间是否有显著差异，这就需要用到TukeyHSD(). one-way ANOVA(不要求等方差)，相关介绍看here oneway.test(body_mass_g ~ species, data = penguins) ## ## One-way analysis of means (not assuming equal ## variances) ## ## data: body_mass_g and species ## F = 317, num df = 2, denom df = 188, p-value ## &lt;2e-16 stats::aov(formula = body_mass_g ~ species, data = penguins) %&gt;% TukeyHSD(which = &quot;species&quot;) %&gt;% broom::tidy() ## # A tibble: 3 x 7 ## term contrast null.value estimate conf.low conf.high ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 spec~ Chinstr~ 0 26.9 -132. 186. ## 2 spec~ Gentoo-~ 0 1386. 1252. 1520. ## 3 spec~ Gentoo-~ 0 1359. 1194. 1524. ## # ... with 1 more variable: adj.p.value &lt;dbl&gt; 表格第一行instrap-Adelie 的 p-value = 0.916，没通过显著性检验；而Gentoo-Adelie 和 Gentoo-Chinstrap 他们的p-value都接近0，通过显著性检验，这和图中的结果是一致的。 作为统计出生的R语言，有很多宏包可以帮助我们验证我们的结论，我这里推荐可视化学统计的宏包ggstatsplot宏包将统计分析的结果写在图片里，统计结果和图形融合在一起，让统计结果更容易懂了。（使用这个宏包辅助我们学习统计） library(ggstatsplot) penguins %&gt;% ggstatsplot::ggbetweenstats( x = species, # &gt; 2 groups y = body_mass_g, type = &quot;parametric&quot;, pairwise.comparisons = TRUE, pairwise.display = &quot;all&quot;, messages = FALSE, var.equal = FALSE ) 45.2.8.2 非参数检验 相关介绍看here kruskal.test(body_mass_g ~ species, data = penguins) ## ## Kruskal-Wallis rank sum test ## ## data: body_mass_g by species ## Kruskal-Wallis chi-squared = 212, df = 2, ## p-value &lt;2e-16 penguins %&gt;% ggstatsplot::ggbetweenstats( x = species, y = body_mass_g, type = &quot;nonparametric&quot;, mean.ci = TRUE, pairwise.comparisons = TRUE, # &lt;&lt; pairwise.display = &quot;all&quot;, # ns = only non-significant p.adjust.method = &quot;fdr&quot;, # &lt;&lt; messages = FALSE ) 哇，原来统计可以这样学！ 45.2.9 嘴峰长度与嘴峰深度的比例 penguins %&gt;% mutate(ratio = bill_length_mm / bill_depth_mm) %&gt;% group_by(species) %&gt;% summarise(mean = mean(ratio)) ## # A tibble: 3 x 2 ## species mean ## &lt;chr&gt; &lt;dbl&gt; ## 1 Adelie 2.12 ## 2 Chinstrap 2.65 ## 3 Gentoo 3.18 penguins %&gt;% mutate(ratio = bill_length_mm / bill_depth_mm) %&gt;% ggplot(aes(x = ratio, fill = species)) + ggridges::geom_density_ridges(aes(y = species)) 男宝宝和女宝宝颜色区分下，代码只需要修改一个地方，留给大家自己实践下吧。 45.2.10 建立模型 建模需要标准化数据，并对分类变量（比如sex）编码为 1 和 0; （这是第二个好习惯） scale_fun &lt;- function(x) { # 标准化的子函数 (x - mean(x)) / sd(x) } d &lt;- penguins %&gt;% select(sex, species, bill_length_mm:body_mass_g) %&gt;% mutate( across(where(is.numeric), scale_fun) ) %&gt;% mutate(male = if_else(sex == &quot;male&quot;, 1, 0)) d ## # A tibble: 333 x 7 ## sex species bill_length_mm bill_depth_mm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 male Adelie -0.895 0.780 ## 2 fema~ Adelie -0.822 0.119 ## 3 fema~ Adelie -0.675 0.424 ## 4 fema~ Adelie -1.33 1.08 ## 5 male Adelie -0.858 1.74 ## 6 fema~ Adelie -0.931 0.323 ## 7 male Adelie -0.876 1.24 ## 8 fema~ Adelie -0.529 0.221 ## 9 male Adelie -0.986 2.05 ## 10 male Adelie -1.72 2.00 ## # ... with 323 more rows, and 3 more variables: ## # flipper_length_mm &lt;dbl&gt;, body_mass_g &lt;dbl&gt;, ## # male &lt;dbl&gt; 按照species分组后，对flipper_length_mm标准化？这样数据会聚拢到一起了喔, 还是不要了 penguins %&gt;% select(sex, species, bill_length_mm:body_mass_g) %&gt;% group_by(species) %&gt;% mutate( across(where(is.numeric), scale_fun) ) %&gt;% ungroup() 45.2.10.1 model_01 我们将性别sex视为响应变量，其他变量为预测变量。这里性别变量是二元的（0 或者 1），所以我们用logistic回归 logit_mod1 &lt;- glm( male ~ 1 + species + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, data = d, family = binomial(link = &quot;logit&quot;) ) summary(logit_mod1) ## ## Call: ## glm(formula = male ~ 1 + species + bill_length_mm + bill_depth_mm + ## flipper_length_mm + body_mass_g, family = binomial(link = &quot;logit&quot;), ## data = d) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -3.382 -0.215 0.002 0.155 2.809 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 4.684 1.187 3.95 7.9e-05 ## speciesChinstrap -6.980 1.574 -4.43 9.3e-06 ## speciesGentoo -8.354 2.524 -3.31 0.00093 ## bill_length_mm 3.357 0.716 4.69 2.8e-06 ## bill_depth_mm 3.196 0.655 4.88 1.0e-06 ## flipper_length_mm 0.291 0.670 0.43 0.66405 ## body_mass_g 4.723 0.872 5.41 6.2e-08 ## ## (Intercept) *** ## speciesChinstrap *** ## speciesGentoo *** ## bill_length_mm *** ## bill_depth_mm *** ## flipper_length_mm ## body_mass_g *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 461.61 on 332 degrees of freedom ## Residual deviance: 127.11 on 326 degrees of freedom ## AIC: 141.1 ## ## Number of Fisher Scoring iterations: 7 计算每个变量的平均边际效应 library(margins) logit_mod1_m &lt;- logit_mod1 %&gt;% margins() %&gt;% summary() %&gt;% as_tibble() logit_mod1_m ## # A tibble: 6 x 7 ## factor AME SE z p lower upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 bill_~ 0.185 0.0290 6.38 1.82e-10 0.128 0.242 ## 2 bill_~ 0.194 0.0339 5.72 1.04e- 8 0.128 0.261 ## 3 body_~ 0.273 0.0378 7.22 5.08e-13 0.199 0.347 ## 4 flipp~ 0.0169 0.0388 0.434 6.64e- 1 -0.0592 0.0929 ## 5 speci~ -0.373 0.0513 -7.27 3.67e-13 -0.473 -0.272 ## 6 speci~ -0.434 0.0740 -5.86 4.66e- 9 -0.579 -0.289 logit_mod1_m %&gt;% ggplot(aes( x = reorder(factor, AME), y = AME, ymin = lower, ymax = upper )) + geom_hline(yintercept = 0, color = &quot;gray80&quot;) + geom_pointrange() + coord_flip() + labs(x = NULL, y = &quot;Average Marginal Effect&quot;) library(ggeffects) ggpredict(logit_mod1, terms = &quot;bill_length_mm&quot;) 45.2.10.2 model_02 library(brms) brms_mod2 &lt;- brm( male ~ 1 + bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g + (1 | species), data = d, family = binomial(link = &quot;logit&quot;) ) summary(brms_mod2) library(ggeffects) ggpredict(brms_mod2, &quot;bill_depth_mm [all]&quot;) %&gt;% plot() 45.2.10.3 model_03 penguins %&gt;% ggplot(aes(x = flipper_length_mm, y = bill_length_mm, color = species)) + geom_point() brms_mod3 &lt;- brm(bill_length_mm ~ flipper_length_mm + (1|species), data = penguins ) penguins %&gt;% group_by(species) %&gt;% modelr::data_grid(flipper_length_mm) %&gt;% tidybayes::add_fitted_draws(brms_mod3, n = 100) %&gt;% ggplot() + geom_point( data = penguins, aes(flipper_length_mm, bill_length_mm, color = species, shape = species) ) + geom_line(aes(flipper_length_mm, .value, group = interaction(.draw, species), color = species), alpha = 0.1) "],["eda-career-decision.html", "第 46 章 探索性数据分析-大学生职业决策 46.1 预备知识 46.2 开始 46.3 探索", " 第 46 章 探索性数据分析-大学生职业决策 46.1 预备知识 library(tidyverse) example &lt;- tibble::tribble( ~name, ~english, ~chinese, ~math, ~sport, ~psy, ~edu, &quot;A&quot;, 133, 100, 102, 56, 89, 89, &quot;B&quot;, 120, 120, 86, 88, 45, 75, &quot;C&quot;, 98, 109, 114, 87, NA, 84, &quot;D&quot;, 120, 78, 106, 68, 86, 69, &quot;E&quot;, 110, 99, 134, 98, 75, 70, &quot;F&quot;, NA, 132, 130, NA, 68, 88 ) example ## # A tibble: 6 x 7 ## name english chinese math sport psy edu ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 133 100 102 56 89 89 ## 2 B 120 120 86 88 45 75 ## 3 C 98 109 114 87 NA 84 ## 4 D 120 78 106 68 86 69 ## 5 E 110 99 134 98 75 70 ## 6 F NA 132 130 NA 68 88 46.1.1 缺失值检查 我们需要判断每一列的缺失值 example %&gt;% summarise( na_in_english = sum(is.na(english)), na_in_chinese = sum(is.na(chinese)), na_in_math = sum(is.na(math)), na_in_sport = sum(is.na(sport)), na_in_psy = sum(is.na(math)), # tpyo here na_in_edu = sum(is.na(edu)) ) ## # A tibble: 1 x 6 ## na_in_english na_in_chinese na_in_math na_in_sport ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 0 0 1 ## # ... with 2 more variables: na_in_psy &lt;int&gt;, ## # na_in_edu &lt;int&gt; 我们发现，这种写法比较笨，而且容易出错，比如na_in_psy = sum(is.na(math)) 就写错了。那么有没有既偷懒又安全的方法呢？有的。但代价是需要学会across()函数，大家可以在Console中输入?dplyr::across查看帮助文档，或者看第 22 章。 example %&gt;% summarise( across(everything(), mean) ) ## # A tibble: 1 x 7 ## name english chinese math sport psy edu ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 NA NA 106. 112 NA NA 79.2 example %&gt;% summarise( across(everything(), function(x) sum(is.na(x)) ) ) ## # A tibble: 1 x 7 ## name english chinese math sport psy edu ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 1 0 0 1 1 0 46.1.2 数据预处理 直接丢弃缺失值所在的行 example %&gt;% drop_na() ## # A tibble: 4 x 7 ## name english chinese math sport psy edu ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 133 100 102 56 89 89 ## 2 B 120 120 86 88 45 75 ## 3 D 120 78 106 68 86 69 ## 4 E 110 99 134 98 75 70 用均值代替缺失值 d &lt;- example %&gt;% mutate( across(where(is.numeric), ~ if_else(is.na(.), mean(., na.rm = T), .)) ) d ## # A tibble: 6 x 7 ## name english chinese math sport psy edu ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 133 100 102 56 89 89 ## 2 B 120 120 86 88 45 75 ## 3 C 98 109 114 87 72.6 84 ## 4 D 120 78 106 68 86 69 ## 5 E 110 99 134 98 75 70 ## 6 F 116. 132 130 79.4 68 88 计算总分/均值 d %&gt;% rowwise() %&gt;% mutate( total = sum(c_across(-name)) ) ## # A tibble: 6 x 8 ## # Rowwise: ## name english chinese math sport psy edu total ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 133 100 102 56 89 89 569 ## 2 B 120 120 86 88 45 75 534 ## 3 C 98 109 114 87 72.6 84 565. ## 4 D 120 78 106 68 86 69 527 ## 5 E 110 99 134 98 75 70 586 ## 6 F 116. 132 130 79.4 68 88 614. d %&gt;% rowwise() %&gt;% mutate( mean = mean(c_across(-name)) ) ## # A tibble: 6 x 8 ## # Rowwise: ## name english chinese math sport psy edu mean ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 133 100 102 56 89 89 94.8 ## 2 B 120 120 86 88 45 75 89 ## 3 C 98 109 114 87 72.6 84 94.1 ## 4 D 120 78 106 68 86 69 87.8 ## 5 E 110 99 134 98 75 70 97.7 ## 6 F 116. 132 130 79.4 68 88 102. 数据标准化处理 standard &lt;- function(x) { (x - mean(x)) / sd(x) } d %&gt;% mutate( across(where(is.numeric), standard) ) ## # A tibble: 6 x 7 ## name english chinese math sport psy edu ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 1.44 -0.339 -0.555 -1.54 1.04 1.10 ## 2 B 0.326 0.731 -1.44 0.566 -1.75 -0.464 ## 3 C -1.56 0.143 0.111 0.500 0 0.538 ## 4 D 0.326 -1.51 -0.333 -0.75 0.852 -1.13 ## 5 E -0.531 -0.392 1.22 1.22 0.153 -1.02 ## 6 F 0 1.37 0.999 0 -0.292 0.984 46.2 开始 46.2.1 文件管理中需要注意的地方 感谢康钦虹同学提供的数据，但这里有几点需要注意的地方： 事项 问题 解决办法 文件名 excel的文件名是中文 用英文，比如 data.xlsx 列名 列名中有-号，大小写不统一 规范列名，或用janitor::clean_names()偷懒 预处理 直接在原始数据中新增 不要在原始数据上改动，统计工作可以在R里实现 文件管理 没有层级 新建data文件夹装数据，与code.Rmd并列 data &lt;- readxl::read_excel(&quot;demo_data/career-decision.xlsx&quot;, skip = 1) %&gt;% janitor::clean_names() #glimpse(data) d &lt;- data %&gt;% select(1:61) #glimpse(d) 46.2.2 缺失值检查 d %&gt;% summarise( across(everything(), ~sum(is.na(.))) ) ## # A tibble: 1 x 61 ## sex majoy grade from z1 z2 z3 z4 z5 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 0 0 0 0 ## # ... with 52 more variables: z6 &lt;int&gt;, z7 &lt;int&gt;, ## # z8 &lt;int&gt;, z9 &lt;int&gt;, z10 &lt;int&gt;, z11 &lt;int&gt;, ## # z12 &lt;int&gt;, z13 &lt;int&gt;, z14 &lt;int&gt;, z15 &lt;int&gt;, ## # z16 &lt;int&gt;, z17 &lt;int&gt;, z18 &lt;int&gt;, j1 &lt;int&gt;, ## # j2 &lt;int&gt;, j3 &lt;int&gt;, j4 &lt;int&gt;, j5 &lt;int&gt;, j6 &lt;int&gt;, ## # j7 &lt;int&gt;, j8 &lt;int&gt;, j9 &lt;int&gt;, j10 &lt;int&gt;, ## # j11 &lt;int&gt;, j12 &lt;int&gt;, j13 &lt;int&gt;, j14 &lt;int&gt;, ## # j15 &lt;int&gt;, j16 &lt;int&gt;, j17 &lt;int&gt;, j18 &lt;int&gt;, ## # j19 &lt;int&gt;, j20 &lt;int&gt;, j21 &lt;int&gt;, j22 &lt;int&gt;, ## # j23 &lt;int&gt;, j24 &lt;int&gt;, j25 &lt;int&gt;, j26 &lt;int&gt;, ## # j27 &lt;int&gt;, j28 &lt;int&gt;, j29 &lt;int&gt;, j30 &lt;int&gt;, ## # j31 &lt;int&gt;, j32 &lt;int&gt;, j33 &lt;int&gt;, j34 &lt;int&gt;, ## # j35 &lt;int&gt;, j36 &lt;int&gt;, j37 &lt;int&gt;, j38 &lt;int&gt;, ## # j39 &lt;int&gt; 没有缺失值，挺好 46.2.3 数据预处理 采用利克特式 5 点计分… (这方面你们懂得比我多) d &lt;- d %&gt;% rowwise() %&gt;% mutate( environment_exploration = sum(c_across(z1:z5)), self_exploration = sum(c_across(z6:z9)), objective_system_exploration = sum(c_across(z10:z15)), info_quantity_exploration = sum(c_across(z16:z18)), self_evaluation = sum(c_across(j1:j6)), information_collection = sum(c_across(j7:j15)), target_select = sum(c_across(j16:j24)), formulate = sum(c_across(j25:j32)), problem_solving = sum(c_across(j33:j39)), career_exploration = sum(c_across(z1:z18)), career_decision_making = sum(c_across(j1:j39)) ) %&gt;% select(-starts_with(&quot;z&quot;), -starts_with(&quot;j&quot;)) %&gt;% ungroup() %&gt;% mutate(pid = 1:n(), .before = sex) %&gt;% mutate( across(c(pid, sex, majoy, grade, from), as_factor) ) #glimpse(d) 46.2.4 标准化 standard &lt;- function(x) { (x - mean(x)) / sd(x) } d &lt;- d %&gt;% mutate( across(where(is.numeric), standard) ) d ## # A tibble: 304 x 16 ## pid sex majoy grade from environment_exp~ ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 1 1 4 4 2 -1.63 ## 2 2 1 4 4 1 -1.87 ## 3 3 2 4 4 2 0.0802 ## 4 4 2 4 4 1 -1.87 ## 5 5 2 4 4 1 -0.895 ## 6 6 1 1 4 3 -0.651 ## 7 7 1 4 4 3 -2.36 ## 8 8 1 4 4 1 -0.407 ## 9 9 1 4 4 3 -0.651 ## 10 10 1 4 4 2 0.324 ## # ... with 294 more rows, and 10 more variables: ## # self_exploration &lt;dbl&gt;, ## # objective_system_exploration &lt;dbl&gt;, ## # info_quantity_exploration &lt;dbl&gt;, ## # self_evaluation &lt;dbl&gt;, ## # information_collection &lt;dbl&gt;, target_select &lt;dbl&gt;, ## # formulate &lt;dbl&gt;, problem_solving &lt;dbl&gt;, ## # career_exploration &lt;dbl&gt;, ## # career_decision_making &lt;dbl&gt; 46.3 探索 46.3.1 想探索的问题 不同性别（或者年级，生源地，专业）下，各指标分值的差异性 两个变量的相关分析和回归分析 更多（欢迎大家提出了喔） 46.3.2 男生女生在职业探索上有所不同？ 以性别为例。因为性别变量是男女，仅仅2组，所以检查男女在各自指标上的均值差异，可以用T检验。 d %&gt;% group_by(sex) %&gt;% summarise( across(where(is.numeric), mean) ) ## # A tibble: 2 x 12 ## sex environment_exp~ self_exploration ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 -0.147 -0.0829 ## 2 2 0.165 0.0933 ## # ... with 9 more variables: ## # objective_system_exploration &lt;dbl&gt;, ## # info_quantity_exploration &lt;dbl&gt;, ## # self_evaluation &lt;dbl&gt;, ## # information_collection &lt;dbl&gt;, target_select &lt;dbl&gt;, ## # formulate &lt;dbl&gt;, problem_solving &lt;dbl&gt;, ## # career_exploration &lt;dbl&gt;, ## # career_decision_making &lt;dbl&gt; 你可以给这个图颜色弄得更好看点？ library(ggridges) d %&gt;% ggplot(aes(x = career_exploration, y = sex, fill = sex)) + geom_density_ridges() t_test_eq &lt;- t.test(career_exploration ~ sex, data = d, var.equal = TRUE) %&gt;% broom::tidy() t_test_eq ## # A tibble: 1 x 10 ## estimate estimate1 estimate2 statistic p.value ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.367 -0.173 0.194 -3.24 0.00132 ## # ... with 5 more variables: parameter &lt;dbl&gt;, ## # conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, method &lt;chr&gt;, ## # alternative &lt;chr&gt; t_test_uneq &lt;- t.test(career_exploration ~ sex, data = d, var.equal = FALSE) %&gt;% broom::tidy() t_test_uneq ## # A tibble: 1 x 10 ## estimate estimate1 estimate2 statistic p.value ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.367 -0.173 0.194 -3.27 0.00121 ## # ... with 5 more variables: parameter &lt;dbl&gt;, ## # conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, method &lt;chr&gt;, ## # alternative &lt;chr&gt; 当然，也可以用第 32 章介绍的统计推断的方法 library(infer) obs_diff &lt;- d %&gt;% specify(formula = career_exploration ~ sex) %&gt;% calculate(&quot;diff in means&quot;, order = c(&quot;1&quot;, &quot;2&quot;)) obs_diff ## # A tibble: 1 x 1 ## stat ## &lt;dbl&gt; ## 1 -0.367 null_dist &lt;- d %&gt;% specify(formula = career_exploration ~ sex) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 5000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;1&quot;, &quot;2&quot;)) null_dist ## # A tibble: 5,000 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 -0.0114 ## 2 2 0.0656 ## 3 3 0.00208 ## 4 4 -0.0663 ## 5 5 0.0155 ## 6 6 -0.0736 ## 7 7 -0.0798 ## 8 8 -0.0443 ## 9 9 0.0412 ## 10 10 0.105 ## # ... with 4,990 more rows null_dist %&gt;% visualize() + shade_p_value(obs_stat = obs_diff, direction = &quot;two_sided&quot;) null_dist %&gt;% get_p_value(obs_stat = obs_diff, direction = &quot;two_sided&quot;) %&gt;% #get_p_value(obs_stat = obs_diff, direction = &quot;less&quot;) %&gt;% mutate(p_value_clean = scales::pvalue(p_value)) ## # A tibble: 1 x 2 ## p_value p_value_clean ## &lt;dbl&gt; &lt;chr&gt; ## 1 0.00120 0.001 也可以用tidyverse的方法一次性的搞定所有指标 d %&gt;% pivot_longer( cols = -c(pid, sex, majoy, grade, from), names_to = &quot;index&quot;, values_to = &quot;value&quot; ) %&gt;% group_by(index) %&gt;% summarise( broom::tidy( t.test(value ~ sex, data = cur_data())) ) %&gt;% select(index, estimate, statistic, p.value) %&gt;% arrange(p.value) ## # A tibble: 11 x 4 ## index estimate statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 career_decision_making -0.494 -4.53 8.62e-6 ## 2 problem_solving -0.470 -4.26 2.70e-5 ## 3 target_select -0.449 -4.07 6.09e-5 ## 4 formulate -0.411 -3.72 2.35e-4 ## 5 information_collection -0.411 -3.70 2.53e-4 ## 6 self_evaluation -0.404 -3.65 3.15e-4 ## 7 objective_system_explo~ -0.382 -3.40 7.65e-4 ## 8 career_exploration -0.367 -3.27 1.21e-3 ## 9 environment_exploration -0.312 -2.75 6.29e-3 ## 10 info_quantity_explorat~ -0.274 -2.42 1.62e-2 ## 11 self_exploration -0.176 -1.54 1.26e-1 46.3.3 来自不同地方的学生在职业探索上有所不同？ 以生源地为例。因为生源地有3类，所以可以使用方差分析。 aov(career_exploration ~ from, data = d) %&gt;% TukeyHSD(which = &quot;from&quot;) %&gt;% broom::tidy() ## # A tibble: 3 x 7 ## term contrast null.value estimate conf.low conf.high ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 from 2-1 0 0.382 0.0623 0.701 ## 2 from 3-1 0 0.287 -0.0386 0.613 ## 3 from 3-2 0 -0.0943 -0.446 0.257 ## # ... with 1 more variable: adj.p.value &lt;dbl&gt; library(ggridges) d %&gt;% ggplot(aes(x = career_exploration, y = from, fill = from)) + geom_density_ridges() 也可以一次性的搞定所有指标 d %&gt;% pivot_longer( cols = -c(pid, sex, majoy, grade, from), names_to = &quot;index&quot;, values_to = &quot;value&quot; ) %&gt;% group_by(index) %&gt;% summarise( broom::tidy( aov(value ~ from, data = cur_data())) ) %&gt;% select(index, term, statistic, p.value) %&gt;% filter(term != &quot;Residuals&quot;) %&gt;% arrange(p.value) ## # A tibble: 11 x 4 ## # Groups: index [11] ## index term statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 problem_solving from 14.6 9.18e-7 ## 2 career_decision_making from 14.2 1.26e-6 ## 3 formulate from 12.2 7.81e-6 ## 4 information_collection from 10.2 5.27e-5 ## 5 self_evaluation from 8.91 1.74e-4 ## 6 target_select from 8.45 2.70e-4 ## 7 info_quantity_exploration from 5.78 3.44e-3 ## 8 career_exploration from 4.48 1.21e-2 ## 9 objective_system_explora~ from 4.06 1.81e-2 ## 10 environment_exploration from 3.69 2.60e-2 ## 11 self_exploration from 0.699 4.98e-1 46.3.4 职业探索和决策之间有关联？ 可以用第 28 章线性模型来探索 lm(career_decision_making ~ career_exploration, data = d) ## ## Call: ## lm(formula = career_decision_making ~ career_exploration, data = d) ## ## Coefficients: ## (Intercept) career_exploration ## 2.15e-15 7.83e-01 不要因为我讲课讲的很垃圾，就错过了R的美，瑕不掩瑜啦。要相信自己，你们是川师研究生中最聪明的。 "],["eda-ames-houseprice.html", "第 47 章 探索性数据分析-ames房屋价格 47.1 数据故事 47.2 探索设想 47.3 变量选取 47.4 缺失值处理 47.5 预处理 47.6 有趣的探索 47.7 建模", " 第 47 章 探索性数据分析-ames房屋价格 47.1 数据故事 图 47.1: 这是数据故事的地图 这是一份Ames房屋数据，您可以把它想象为房屋中介推出的成都市武侯区、锦江区以及高新区等各区县的房屋信息 library(tidyverse) ames &lt;- read_csv(&quot;./demo_data/ames_houseprice.csv&quot;) %&gt;% janitor::clean_names() glimpse(ames) ## Rows: 1,460 ## Columns: 81 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9,... ## $ ms_sub_class &lt;dbl&gt; 60, 20, 60, 70, 60, 50, 20... ## $ ms_zoning &lt;chr&gt; &quot;RL&quot;, &quot;RL&quot;, &quot;RL&quot;, &quot;RL&quot;, &quot;R... ## $ lot_frontage &lt;dbl&gt; 65, 80, 68, 60, 84, 85, 75... ## $ lot_area &lt;dbl&gt; 8450, 9600, 11250, 9550, 1... ## $ street &lt;chr&gt; &quot;Pave&quot;, &quot;Pave&quot;, &quot;Pave&quot;, &quot;P... ## $ alley &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA... ## $ lot_shape &lt;chr&gt; &quot;Reg&quot;, &quot;Reg&quot;, &quot;IR1&quot;, &quot;IR1&quot;... ## $ land_contour &lt;chr&gt; &quot;Lvl&quot;, &quot;Lvl&quot;, &quot;Lvl&quot;, &quot;Lvl&quot;... ## $ utilities &lt;chr&gt; &quot;AllPub&quot;, &quot;AllPub&quot;, &quot;AllPu... ## $ lot_config &lt;chr&gt; &quot;Inside&quot;, &quot;FR2&quot;, &quot;Inside&quot;,... ## $ land_slope &lt;chr&gt; &quot;Gtl&quot;, &quot;Gtl&quot;, &quot;Gtl&quot;, &quot;Gtl&quot;... ## $ neighborhood &lt;chr&gt; &quot;CollgCr&quot;, &quot;Veenker&quot;, &quot;Col... ## $ condition1 &lt;chr&gt; &quot;Norm&quot;, &quot;Feedr&quot;, &quot;Norm&quot;, &quot;... ## $ condition2 &lt;chr&gt; &quot;Norm&quot;, &quot;Norm&quot;, &quot;Norm&quot;, &quot;N... ## $ bldg_type &lt;chr&gt; &quot;1Fam&quot;, &quot;1Fam&quot;, &quot;1Fam&quot;, &quot;1... ## $ house_style &lt;chr&gt; &quot;2Story&quot;, &quot;1Story&quot;, &quot;2Stor... ## $ overall_qual &lt;dbl&gt; 7, 6, 7, 7, 8, 5, 8, 7, 7,... ## $ overall_cond &lt;dbl&gt; 5, 8, 5, 5, 5, 5, 5, 6, 5,... ## $ year_built &lt;dbl&gt; 2003, 1976, 2001, 1915, 20... ## $ year_remod_add &lt;dbl&gt; 2003, 1976, 2002, 1970, 20... ## $ roof_style &lt;chr&gt; &quot;Gable&quot;, &quot;Gable&quot;, &quot;Gable&quot;,... ## $ roof_matl &lt;chr&gt; &quot;CompShg&quot;, &quot;CompShg&quot;, &quot;Com... ## $ exterior1st &lt;chr&gt; &quot;VinylSd&quot;, &quot;MetalSd&quot;, &quot;Vin... ## $ exterior2nd &lt;chr&gt; &quot;VinylSd&quot;, &quot;MetalSd&quot;, &quot;Vin... ## $ mas_vnr_type &lt;chr&gt; &quot;BrkFace&quot;, &quot;None&quot;, &quot;BrkFac... ## $ mas_vnr_area &lt;dbl&gt; 196, 0, 162, 0, 350, 0, 18... ## $ exter_qual &lt;chr&gt; &quot;Gd&quot;, &quot;TA&quot;, &quot;Gd&quot;, &quot;TA&quot;, &quot;G... ## $ exter_cond &lt;chr&gt; &quot;TA&quot;, &quot;TA&quot;, &quot;TA&quot;, &quot;TA&quot;, &quot;T... ## $ foundation &lt;chr&gt; &quot;PConc&quot;, &quot;CBlock&quot;, &quot;PConc&quot;... ## $ bsmt_qual &lt;chr&gt; &quot;Gd&quot;, &quot;Gd&quot;, &quot;Gd&quot;, &quot;TA&quot;, &quot;G... ## $ bsmt_cond &lt;chr&gt; &quot;TA&quot;, &quot;TA&quot;, &quot;TA&quot;, &quot;Gd&quot;, &quot;T... ## $ bsmt_exposure &lt;chr&gt; &quot;No&quot;, &quot;Gd&quot;, &quot;Mn&quot;, &quot;No&quot;, &quot;A... ## $ bsmt_fin_type1 &lt;chr&gt; &quot;GLQ&quot;, &quot;ALQ&quot;, &quot;GLQ&quot;, &quot;ALQ&quot;... ## $ bsmt_fin_sf1 &lt;dbl&gt; 706, 978, 486, 216, 655, 7... ## $ bsmt_fin_type2 &lt;chr&gt; &quot;Unf&quot;, &quot;Unf&quot;, &quot;Unf&quot;, &quot;Unf&quot;... ## $ bsmt_fin_sf2 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 32, 0... ## $ bsmt_unf_sf &lt;dbl&gt; 150, 284, 434, 540, 490, 6... ## $ total_bsmt_sf &lt;dbl&gt; 856, 1262, 920, 756, 1145,... ## $ heating &lt;chr&gt; &quot;GasA&quot;, &quot;GasA&quot;, &quot;GasA&quot;, &quot;G... ## $ heating_qc &lt;chr&gt; &quot;Ex&quot;, &quot;Ex&quot;, &quot;Ex&quot;, &quot;Gd&quot;, &quot;E... ## $ central_air &lt;chr&gt; &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;... ## $ electrical &lt;chr&gt; &quot;SBrkr&quot;, &quot;SBrkr&quot;, &quot;SBrkr&quot;,... ## $ x1st_flr_sf &lt;dbl&gt; 856, 1262, 920, 961, 1145,... ## $ x2nd_flr_sf &lt;dbl&gt; 854, 0, 866, 756, 1053, 56... ## $ low_qual_fin_sf &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0,... ## $ gr_liv_area &lt;dbl&gt; 1710, 1262, 1786, 1717, 21... ## $ bsmt_full_bath &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 0,... ## $ bsmt_half_bath &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0,... ## $ full_bath &lt;dbl&gt; 2, 2, 2, 1, 2, 1, 2, 2, 2,... ## $ half_bath &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 0,... ## $ bedroom_abv_gr &lt;dbl&gt; 3, 3, 3, 3, 4, 1, 3, 3, 2,... ## $ kitchen_abv_gr &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2,... ## $ kitchen_qual &lt;chr&gt; &quot;Gd&quot;, &quot;TA&quot;, &quot;Gd&quot;, &quot;Gd&quot;, &quot;G... ## $ tot_rms_abv_grd &lt;dbl&gt; 8, 6, 6, 7, 9, 5, 7, 7, 8,... ## $ functional &lt;chr&gt; &quot;Typ&quot;, &quot;Typ&quot;, &quot;Typ&quot;, &quot;Typ&quot;... ## $ fireplaces &lt;dbl&gt; 0, 1, 1, 1, 1, 0, 1, 2, 2,... ## $ fireplace_qu &lt;chr&gt; NA, &quot;TA&quot;, &quot;TA&quot;, &quot;Gd&quot;, &quot;TA&quot;... ## $ garage_type &lt;chr&gt; &quot;Attchd&quot;, &quot;Attchd&quot;, &quot;Attch... ## $ garage_yr_blt &lt;dbl&gt; 2003, 1976, 2001, 1998, 20... ## $ garage_finish &lt;chr&gt; &quot;RFn&quot;, &quot;RFn&quot;, &quot;RFn&quot;, &quot;Unf&quot;... ## $ garage_cars &lt;dbl&gt; 2, 2, 2, 3, 3, 2, 2, 2, 2,... ## $ garage_area &lt;dbl&gt; 548, 460, 608, 642, 836, 4... ## $ garage_qual &lt;chr&gt; &quot;TA&quot;, &quot;TA&quot;, &quot;TA&quot;, &quot;TA&quot;, &quot;T... ## $ garage_cond &lt;chr&gt; &quot;TA&quot;, &quot;TA&quot;, &quot;TA&quot;, &quot;TA&quot;, &quot;T... ## $ paved_drive &lt;chr&gt; &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;... ## $ wood_deck_sf &lt;dbl&gt; 0, 298, 0, 0, 192, 40, 255... ## $ open_porch_sf &lt;dbl&gt; 61, 0, 42, 35, 84, 30, 57,... ## $ enclosed_porch &lt;dbl&gt; 0, 0, 0, 272, 0, 0, 0, 228... ## $ x3ssn_porch &lt;dbl&gt; 0, 0, 0, 0, 0, 320, 0, 0, ... ## $ screen_porch &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0,... ## $ pool_area &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0,... ## $ pool_qc &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA... ## $ fence &lt;chr&gt; NA, NA, NA, NA, NA, &quot;MnPrv... ## $ misc_feature &lt;chr&gt; NA, NA, NA, NA, NA, &quot;Shed&quot;... ## $ misc_val &lt;dbl&gt; 0, 0, 0, 0, 0, 700, 0, 350... ## $ mo_sold &lt;dbl&gt; 2, 5, 9, 2, 12, 10, 8, 11,... ## $ yr_sold &lt;dbl&gt; 2008, 2007, 2008, 2006, 20... ## $ sale_type &lt;chr&gt; &quot;WD&quot;, &quot;WD&quot;, &quot;WD&quot;, &quot;WD&quot;, &quot;W... ## $ sale_condition &lt;chr&gt; &quot;Normal&quot;, &quot;Normal&quot;, &quot;Norma... ## $ sale_price &lt;dbl&gt; 208500, 181500, 223500, 14... 感谢曾倬同学提供的解释说明文档 explanation &lt;- readxl::read_excel(&quot;./demo_data/ames_houseprice_explanation.xlsx&quot;) explanation %&gt;% knitr::kable() 列名 description 解释 MSSubClass Identifies the type of dwelling involved in the sale. 住宅概况 MSZoning Identifies the general zoning classification of the sale. 建筑性质（农业、商业、高/低密度住宅） LotFrontage Linear feet of street connected to property 建筑离街道的距离 LotArea Lot size in square feet 占地面积 Street Type of road access to property 建筑附近的路面材质 Alley Type of alley access to property 建筑附近小巷的修建材质 LotShape General shape of property 建筑物的形状 LandContour Flatness of the property 地面平坦程度 Utilities Type of utilities available 可用公用设施类型 LotConfig Lot configuration 房屋哪里配置多 LandSlope Slope of property 建筑的斜率 Neighborhood Physical locations within Ames city limits 建筑在Ames城市的位置 Condition1 Proximity to various conditions 建筑附近的交通网络 Condition2 Proximity to various conditions (if more than one is present) 建筑附近的交通网络 BldgType Type of dwelling 住宅类别（联排别墅、独栋别墅…） HouseStyle Style of dwelling 建筑风格 OverallQual Rates the overall material and finish of the house 房屋装饰材质水平 OverallCond Rates the overall condition of the house 房屋整体状况评估 YearBuilt Original construction date 房屋修建日期 YearRemodAdd Remodel date (same as construction date if no remodeling or additions) 房屋改建日期 RoofStyle Type of roof 屋顶类型 RoofMatl Roof material 屋顶材质 Exterior1st Exterior covering on house 建筑外立面材质 Exterior2nd Exterior covering on house (if more than one material) 建筑外立面材质 MasVnrType Masonry veneer type 建筑表层砌体类型 MasVnrArea Masonry veneer area in square feet 每平方英尺的砌体面积 ExterQual Evaluates the quality of the material on the exterior 建筑表层砌体材料质量评估 ExterCond Evaluates the present condition of the material on the exterior 建筑表层砌体材料现状评估 Foundation Type of foundation 建筑基础的类型 BsmtQual Evaluates the height of the basement 地下室高度评估 BsmtCond Evaluates the general condition of the basement 地下室总体状况评估 BsmtExposure Refers to walkout or garden level walls 走廊/花园外墙的评估 BsmtFinType1 Rating of basement finished area 地下室完工区域的等级评价 BsmtFinSF1 Type 1 finished square feet 地下室完工区域的面积 BsmtFinType2 Rating of basement finished area (if multiple types) 其他地下室完工区域的等级评价 BsmtFinSF2 Type 2 finished square feet 其他地下室完工区域的面积 BsmtUnfSF Unfinished square feet of basement area 地下室未完工部分的面积 TotalBsmtSF Total square feet of basement area 地下室总面积 Heating Type of heating 房屋暖气类型（地暖、墙暖….） HeatingQC Heating quality and condition 暖气设施的质量和条件 CentralAir Central air conditioning 是否有中央空调 Electrical Electrical system 电器系统配置标准 1stFlrSF First Floor square feet 一楼面积 2ndFlrSF Second floor square feet 二楼面积 LowQualFinSF Low quality finished square feet (all floors) 所有楼层中低质量施工面积 GrLivArea Above grade (ground) living area square feet 地上居住面积 BsmtFullBath Basement full bathrooms 地下室标准卫生间个数 BsmtHalfBath Basement half bathrooms 地下室简易卫生间个数 FullBath Full bathrooms above grade 地上楼层标准卫生间个数 HalfBath Half baths above grade 地上楼层简易卫生间个数 BedroomAbvGr Bedrooms above grade (does NOT include basement bedrooms) 地上楼层卧室个数 KitchenAbvGr Kitchens above grade 地上楼层厨房个数 KitchenQual Kitchen quality 厨房质量评估 TopRmsAbvGrd Total rooms above grade (does not include bathrooms) 地上楼层房间总数（除去卧室） Functional Home functionality (Assume typical unless deductions are warranted) 房屋功能情况 Fireplaces Number of fireplaces 壁炉个数 FireplaceQu Fireplace quality 壁炉质量 GarageType Garage location 车库位置 GarageYrBlt Year garage was built 车库建成年份 GarageFinish Interior finish of the garage 车库内部装饰情况 GarageCars Size of garage in car capacity 车库容量 GarageArea Size of garage in square feet 车库占地面积 GarageQual Garage quality 车库质量 GarageCond Garage condition 车库条件 PavedDrive Paved driveway 车道施工方式 WoodDeckSF Wood deck area in square feet 木甲板面积 OpenPorchSF Open porch area in square feet 开放式门廊面积 EnclosedPorch Enclosed porch area in square feet 封闭式门廊面积 3SsnPorch Three season porch area in square feet 三季门廊面积 ScreenPorch Screen porch area in square feet 纱窗门廊面积 PoolArea Pool area in square feet 游泳池面积 PoolQC Pool quality 游泳池质量 Fence Fence quality 栅栏质量 MiscFeature Miscellaneous feature not covered in other categories 其他配套设施（网球场、电梯…） MiscVal $Value of miscellaneous feature 其他配套设施的费用 MoSold Month Sold (MM) 销售月份 YrSold Year Sold (YYYY) 销售年份 SaleType Type of sale 支付方式 SaleCondition Condition of sale 房屋出售的情况 47.2 探索设想 读懂数据描述，比如 房屋设施 (bedrooms, garage, fireplace, pool, porch, etc.), 地理位置 (neighborhood), 土地信息 (zoning, shape, size, etc.), 品相等级 出售价格 探索影响房屋价格的因素 必要的预处理（缺失值处理、标准化、对数化等等） 必要的可视化（比如价格分布图等） 必要的统计（比如各地区房屋价格的均值） 合理选取若干预测变量，建立多元线性模型，并对模型结果给出解释 房屋价格与预测变量（房屋大小、在城市的位置、房屋类型、与街道的距离） 47.3 变量选取 d &lt;- ames %&gt;% select(sale_price, lot_frontage, # 建筑离街道的距离 lot_area, # 占地面积 neighborhood, # 建筑在城市的位置 gr_liv_area, # 地上居住面积 bldg_type, # 住宅类别(联排别墅、独栋别墅...) year_built # 房屋修建日期 ) d ## # A tibble: 1,460 x 7 ## sale_price lot_frontage lot_area neighborhood ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 208500 65 8450 CollgCr ## 2 181500 80 9600 Veenker ## 3 223500 68 11250 CollgCr ## 4 140000 60 9550 Crawfor ## 5 250000 84 14260 NoRidge ## 6 143000 85 14115 Mitchel ## 7 307000 75 10084 Somerst ## 8 200000 NA 10382 NWAmes ## 9 129900 51 6120 OldTown ## 10 118000 50 7420 BrkSide ## # ... with 1,450 more rows, and 3 more variables: ## # gr_liv_area &lt;dbl&gt;, bldg_type &lt;chr&gt;, ## # year_built &lt;dbl&gt; 47.4 缺失值处理 d %&gt;% summarise( across(everything(), function(x) sum(is.na(x)) ) ) ## # A tibble: 1 x 7 ## sale_price lot_frontage lot_area neighborhood ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 259 0 0 ## # ... with 3 more variables: gr_liv_area &lt;int&gt;, ## # bldg_type &lt;int&gt;, year_built &lt;int&gt; 找出来看看 d %&gt;% filter_all( any_vars(is.na(.)) ) ## # A tibble: 259 x 7 ## sale_price lot_frontage lot_area neighborhood ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 200000 NA 10382 NWAmes ## 2 144000 NA 12968 Sawyer ## 3 157000 NA 10920 NAmes ## 4 149000 NA 11241 NAmes ## 5 154000 NA 8246 Sawyer ## 6 149350 NA 8544 Sawyer ## 7 144000 NA 9180 SawyerW ## 8 130250 NA 9200 CollgCr ## 9 177000 NA 13869 Gilbert ## 10 219500 NA 9375 CollgCr ## # ... with 249 more rows, and 3 more variables: ## # gr_liv_area &lt;dbl&gt;, bldg_type &lt;chr&gt;, ## # year_built &lt;dbl&gt; library(visdat) d %&gt;% vis_dat() 如果不选择lot_frontage 就不会有缺失值，如何选择，自己抉择 d %&gt;% select(-lot_frontage) %&gt;% visdat::vis_dat() 我个人觉得这个变量很重要，所以还是保留，牺牲一点样本量吧 d &lt;- d %&gt;% drop_na() d %&gt;% visdat::vis_dat() 47.5 预处理 标准化 standard &lt;- function(x) { (x - mean(x)) / sd(x) } d %&gt;% mutate( across(where(is.numeric), standard), across(where(is.character), as.factor) ) ## # A tibble: 1,201 x 7 ## sale_price lot_frontage lot_area neighborhood ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 0.333 -0.208 -0.190 CollgCr ## 2 0.00875 0.410 -0.0444 Veenker ## 3 0.512 -0.0844 0.164 CollgCr ## 4 -0.489 -0.414 -0.0507 Crawfor ## 5 0.830 0.574 0.544 NoRidge ## 6 -0.453 0.616 0.525 Mitchel ## 7 1.51 0.204 0.0167 Somerst ## 8 -0.610 -0.784 -0.484 OldTown ## 9 -0.753 -0.826 -0.319 BrkSide ## 10 -0.615 -0.00206 0.158 Sawyer ## # ... with 1,191 more rows, and 3 more variables: ## # gr_liv_area &lt;dbl&gt;, bldg_type &lt;fct&gt;, ## # year_built &lt;dbl&gt; 对数化 d %&gt;% mutate( log_sale_price = log(sale_price) ) ## # A tibble: 1,201 x 8 ## sale_price lot_frontage lot_area neighborhood ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 208500 65 8450 CollgCr ## 2 181500 80 9600 Veenker ## 3 223500 68 11250 CollgCr ## 4 140000 60 9550 Crawfor ## 5 250000 84 14260 NoRidge ## 6 143000 85 14115 Mitchel ## 7 307000 75 10084 Somerst ## 8 129900 51 6120 OldTown ## 9 118000 50 7420 BrkSide ## 10 129500 70 11200 Sawyer ## # ... with 1,191 more rows, and 4 more variables: ## # gr_liv_area &lt;dbl&gt;, bldg_type &lt;chr&gt;, ## # year_built &lt;dbl&gt;, log_sale_price &lt;dbl&gt; d %&gt;% mutate( across(where(is.numeric), log), across(where(is.character), as.factor) ) ## # A tibble: 1,201 x 7 ## sale_price lot_frontage lot_area neighborhood ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 12.2 4.17 9.04 CollgCr ## 2 12.1 4.38 9.17 Veenker ## 3 12.3 4.22 9.33 CollgCr ## 4 11.8 4.09 9.16 Crawfor ## 5 12.4 4.43 9.57 NoRidge ## 6 11.9 4.44 9.55 Mitchel ## 7 12.6 4.32 9.22 Somerst ## 8 11.8 3.93 8.72 OldTown ## 9 11.7 3.91 8.91 BrkSide ## 10 11.8 4.25 9.32 Sawyer ## # ... with 1,191 more rows, and 3 more variables: ## # gr_liv_area &lt;dbl&gt;, bldg_type &lt;fct&gt;, ## # year_built &lt;dbl&gt; 标准化 vs 对数化 选择哪一种，我们看图说话 d %&gt;% ggplot(aes(x = sale_price)) + geom_density() d %&gt;% ggplot(aes(x = log(sale_price))) + geom_density() 我们选择对数化，并保存结果 d &lt;- d %&gt;% mutate( across(where(is.numeric), .fns = list(log = log), .names = &quot;{.fn}_{.col}&quot; ), across(where(is.character), as.factor) ) 47.6 有趣的探索 47.6.1 各区域的房屋价格均值 d %&gt;% count(neighborhood) ## # A tibble: 25 x 2 ## neighborhood n ## &lt;fct&gt; &lt;int&gt; ## 1 Blmngtn 14 ## 2 Blueste 2 ## 3 BrDale 16 ## 4 BrkSide 51 ## 5 ClearCr 13 ## 6 CollgCr 126 ## 7 Crawfor 41 ## 8 Edwards 92 ## 9 Gilbert 49 ## 10 IDOTRR 34 ## # ... with 15 more rows d %&gt;% group_by(neighborhood) %&gt;% summarise( mean_sale = mean(sale_price) ) %&gt;% ggplot( aes(x = mean_sale, y = fct_reorder(neighborhood, mean_sale)) ) + geom_col(aes(fill = mean_sale &lt; 150000), show.legend = FALSE) + geom_text(aes(label = round(mean_sale, 0)), hjust = 1) + # scale_x_continuous( # expand = c(0, 0), # breaks = c(0, 100000, 200000, 300000), # labels = c(0, &quot;1w&quot;, &quot;2w&quot;, &quot;3w&quot;) # ) + scale_x_continuous( expand = c(0, 0), labels = scales::dollar ) + scale_fill_viridis_d(option = &quot;D&quot;) + theme_classic() + labs(x = NULL, y = NULL) 47.6.2 房屋价格与占地面积 d %&gt;% ggplot(aes(x = log_lot_area, y = log_sale_price)) + geom_point(colour = &quot;blue&quot;) + geom_smooth(method = lm, se = FALSE, formula = &quot;y ~ x&quot;) d %&gt;% ggplot(aes(x = log_lot_area, y = log_sale_price)) + geom_point(aes(colour = neighborhood)) + geom_smooth(method = lm, se = FALSE, formula = &quot;y ~ x&quot;) d %&gt;% ggplot(aes(x = log_lot_area, y = log_sale_price)) + geom_point(colour = &quot;blue&quot;) + geom_smooth(method = lm, se = FALSE, formula = &quot;y ~ x&quot;, fullrange = TRUE) + facet_wrap(~neighborhood) + theme(strip.background = element_blank()) 47.6.3 房屋价格与房屋居住面积 d %&gt;% ggplot(aes(x = log_gr_liv_area, y = log_sale_price)) + geom_point(aes(colour = neighborhood)) + geom_smooth(method = lm, se = FALSE, formula = &quot;y ~ x&quot;) d %&gt;% ggplot(aes(x = log_gr_liv_area, y = log_sale_price)) + geom_point() + geom_smooth(method = lm, se = FALSE, formula = &quot;y ~ x&quot;, fullrange = TRUE) + facet_wrap(~neighborhood) + theme(strip.background = element_blank()) 47.6.4 车库与房屋价格 车库大小是否对销售价格有帮助? ames %&gt;% #select(garage_cars, garage_area, sale_price) %&gt;% ggplot(aes(x = garage_area, y = sale_price)) + geom_point( data = select(ames, -garage_cars), color = &quot;gray50&quot; ) + geom_point(aes(color = as_factor(garage_cars))) + facet_wrap(vars(garage_cars)) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;This is the influence of garage for sale price&quot;) 47.7 建模 lm(log_sale_price ~ 1 + log_gr_liv_area + neighborhood, data = d) %&gt;% broom::tidy() ## # A tibble: 26 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 7.53 0.154 48.7 2.21e-284 ## 2 log_gr_liv_a~ 0.638 0.0200 31.9 3.76e-161 ## 3 neighborhood~ -0.314 0.149 -2.10 3.55e- 2 ## 4 neighborhood~ -0.466 0.0724 -6.43 1.80e- 10 ## 5 neighborhood~ -0.336 0.0597 -5.62 2.44e- 8 ## 6 neighborhood~ -0.103 0.0762 -1.35 1.76e- 1 ## 7 neighborhood~ 0.00332 0.0556 0.0597 9.52e- 1 ## 8 neighborhood~ -0.0870 0.0612 -1.42 1.55e- 1 ## 9 neighborhood~ -0.365 0.0567 -6.44 1.79e- 10 ## 10 neighborhood~ -0.0621 0.0599 -1.04 3.00e- 1 ## # ... with 16 more rows library(lme4) lmer(log_sale_price ~ 1 + log_gr_liv_area + (log_gr_liv_area | neighborhood), data = d) %&gt;% broom.mixed::tidy() ## # A tibble: 6 x 6 ## effect group term estimate std.error statistic ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 fixed &lt;NA&gt; (Interce~ 6.88 0.334 20.6 ## 2 fixed &lt;NA&gt; log_gr_l~ 0.705 0.0493 14.3 ## 3 ran_pa~ neigh~ sd__(Int~ 1.34 NA NA ## 4 ran_pa~ neigh~ cor__(In~ -0.993 NA NA ## 5 ran_pa~ neigh~ sd__log_~ 0.205 NA NA ## 6 ran_pa~ Resid~ sd__Obse~ 0.191 NA NA "],["eda-vaccine.html", "第 48 章 探索性数据分析-新冠疫苗有效率的计算 48.1 引言 48.2 模型 48.3 计算 48.4 结果", " 第 48 章 探索性数据分析-新冠疫苗有效率的计算 48.1 引言 纽约时报报道说， 美国制药公司辉瑞（Pfizer）和德国生物科技公司（BioNTech）11月9日率先宣布 ，根据在数国临床试验初步结果，其研发的新冠疫苗有效率达到90%以上，星期三，完整结果显示，参加疫苗实验的44000个志愿者中，共有170人确诊感染，其中安慰剂组162人，接种疫苗组仅8人，这证明了辉瑞开发的新冠疫苗有效率高达95%。 group volunteers got_covid placebo 22000 162 vaccinated 22000 8 新冠疫苗是有效的，且有效率高达95%。 那么，这个95%是怎么计算出来的呢？它的概率是多少以及不确定性是多少呢？ 回到这个问题，我们首先需要了解，辉瑞公司是如何定义疫苗有效率的 \\[ \\text{VE} = 1 - \\frac{p_{t}}{p_{c}} \\] 其中\\(p_t\\)是疫苗组(vaccinated)的感染率，\\(p_c\\)是安慰剂组(placebo)的感染率。 48.2 模型 library(tidyverse) library(tidybayes) library(rstan) rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) 然后，我们建立如下数学模型： \\[ \\begin{align} y_{c} \\sim \\textsf{binomial}(n_{c},p_{c}) \\\\ y_{t} \\sim \\textsf{binomial}(n_{t},p_{t}) \\\\ p_{c} \\sim \\textsf{beta}(1, 1) \\\\ p_{t} \\sim \\textsf{beta}(1, 1) \\end{align} \\] 通过模型可以直接计算干预效果\\(\\textsf{effect}\\)和疫苗有效性\\(VE\\) \\[ \\begin{align} \\text{effect} = p_{t} - p_{c} \\\\ \\text{VE} = 1 - \\frac{p_{t}}{p_{c}} \\end{align} \\] 48.3 计算 具体Stan代码如下 stan_program &lt;- &quot; data { int&lt;lower=1&gt; event_c; // num events, control int&lt;lower=1&gt; event_t; // num events, treatment int&lt;lower=1&gt; n_c; // num of person trial, control int&lt;lower=1&gt; n_t; // num of person trial, treatment } parameters { real&lt;lower=0,upper=1&gt; p_c; real&lt;lower=0,upper=1&gt; p_t; } model { event_c ~ binomial(n_c, p_c); event_t ~ binomial(n_t, p_t); p_c ~ beta(1, 1); p_t ~ beta(1, 1); } generated quantities { real effect = p_t - p_c; real VE = 1- p_t /p_c; real log_odds = log(p_t / (1- p_t)) - log(p_c / (1- p_c)); } &quot; stan_data &lt;- list( event_c = 162, event_t = 8, n_c = 4.4e4 / 2, n_t = 4.4e4 / 2 ) mod_vaccine &lt;- stan(model_code = stan_program, data = stan_data) 48.4 结果 最后，我们后验概率抽样 draws &lt;- mod_vaccine %&gt;% tidybayes::spread_draws(effect, VE, log_odds) draws %&gt;% head() ## # A tibble: 6 x 6 ## .chain .iteration .draw effect VE log_odds ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1 -0.00915 0.986 -4.30 ## 2 1 2 2 -0.00604 0.959 -3.19 ## 3 1 3 3 -0.00637 0.936 -2.75 ## 4 1 4 4 -0.00761 0.956 -3.14 ## 5 1 5 5 -0.00646 0.947 -2.94 ## 6 1 6 6 -0.00723 0.949 -2.98 48.4.1 干预效果 从结果中看到effect中很多负数。事实上，effect中越多的负值，即被感染的可能性越低，说明疫苗干预效果越好 mean(draws$effect &lt; 0) %&gt;% round(2) ## [1] 1 结果告诉我们，疫苗有明显的干预效果。比如，我们假定10000个人接受了疫苗，那么被感染的人数以及相应的可能性，如下图 draws %&gt;% ggplot(aes(x = effect * 1e4)) + geom_density(fill = &quot;blue&quot;, alpha = .2) + expand_limits(y = 0) + theme_minimal() + xlab(&quot;效应大小&quot;) + ggtitle(&quot;每10000个接种疫苗的人中被感染新冠的数量&quot;) 48.4.2 疫苗有效率 我们再看看疫苗有效率 VE 的结果 draws %&gt;% select(VE) %&gt;% ggdist::median_qi(.width = c(0.90)) ## # A tibble: 1 x 6 ## VE .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.947 0.909 0.972 0.9 median qi 通过数据看出，疫苗的有效性为0.95，在90%的可信赖水平, 中位数区间[0.91, 0.97]. 当然，通过图可能理解的更清晰。 label_txt &lt;- paste(&quot;median =&quot;, round(median(draws$VE), 2)) draws %&gt;% ggplot(aes(x = VE)) + geom_density(fill = &quot;blue&quot;, alpha = .2) + expand_limits(y = 0) + theme_minimal() + geom_vline(xintercept = median(draws$VE), size = 0.2) + annotate(&quot;text&quot;, x = 0.958, y = 10, label = label_txt, size = 3) + xlab(&quot;疫苗有效率&quot;) + ggtitle(&quot;辉瑞公司定义疫苗有效率为 VE = 1 - Pt/Pc&quot;) "],["rvest.html", "第 49 章 网络爬虫 49.1 链家网 49.2 猪肉价格", " 第 49 章 网络爬虫 library(tidyverse) library(rvest) library(sf) 49.1 链家网 urls &lt;- paste0(&quot;https://sh.lianjia.com/ershoufang/pg&quot;, seq_along(1:2)) scrape_house_info &lt;- function(url) { web &lt;- read_html(url) title &lt;- web %&gt;% html_nodes(&#39;.clear .title a&#39;) %&gt;% html_text() houseinfo &lt;- web %&gt;% html_nodes(&#39;.houseInfo&#39;) %&gt;% html_text() price &lt;- web %&gt;% html_nodes(&#39;.totalPrice span&#39;) %&gt;% html_text() price_per &lt;- web %&gt;% html_nodes(&#39;.unitPrice span&#39;) %&gt;% html_text() df &lt;- data.frame(title, houseinfo, price, price_per) return(df) } tb &lt;- urls %&gt;% map_df(scrape_house_info) tb %&gt;% head() ## title ## 1 斜土路板块，超低总价精装两房，配套成熟 ## 2 全明户型格局，低总价两房，满五唯一，采光好诚意出售 ## 3 房型方正，大两房，采光可以，装修保养好 ## 4 颛桥万达旁边招商雍华府二房精装修诚意出售 ## 5 中楼层 售后公房 满五唯一 税费少 ## 6 店长推荐、户型方正、满五唯一、采光好、两房朝南 ## houseinfo ## 1 2室0厅 | 48.66平米 | 北 | 精装 | 高楼层(共6层) | 1985年建 | 板楼 ## 2 2室2厅 | 82.31平米 | 南 | 精装 | 低楼层(共29层) | 2004年建 | 板塔结合 ## 3 2室1厅 | 87.5平米 | 南 北 | 精装 | 中楼层(共13层) | 2010年建 | 板楼 ## 4 2室2厅 | 86.1平米 | 南 北 | 精装 | 6层 | 2010年建 | 板楼 ## 5 2室1厅 | 54.17平米 | 南 北 | 毛坯 | 中楼层(共6层) | 1985年建 | 板楼 ## 6 2室2厅 | 85.03平米 | 南 | 精装 | 中楼层(共16层) | 2013年建 | 板楼 ## price price_per ## 1 355 单价72956元/平米 ## 2 800 单价97194元/平米 ## 3 790 单价90286元/平米 ## 4 545 单价63299元/平米 ## 5 335 单价61843元/平米 ## 6 225 单价26462元/平米 49.2 猪肉价格 df_price &lt;- read_html(&quot;https://hangqing.zhuwang.cc/shengzhu/20190905/407978.html&quot;) %&gt;% html_node(&quot;.tabzj&quot;) %&gt;% html_table(header = T) %&gt;% set_names( c(&quot;region&quot;, &quot;name&quot;, &quot;price_today&quot;, &quot;price_yestoday&quot;, &quot;diff_last_day&quot;, &quot;diff_last_week&quot;) ) %&gt;% mutate_at(vars(name), ~str_remove_all(., &quot; &quot;) ) %&gt;% mutate_at(vars(name), ~if_else( name == &quot;黑龙江&quot;, &quot;黑龙江省&quot;, .)) df_price %&gt;% head() ## region name price_today price_yestoday ## 1 华东 安徽省 28.03 27.79 ## 2 华东 山东省 26.62 26.67 ## 3 华东 浙江省 29.93 29.83 ## 4 华东 江西省 28.93 28.60 ## 5 华东 福建省 29.12 28.89 ## 6 华东 江苏省 28.05 28.43 ## diff_last_day diff_last_week ## 1 0.24 0.37 ## 2 -0.05 0.83 ## 3 0.10 1.84 ## 4 0.33 0.40 ## 5 0.23 0.52 ## 6 -0.38 0.88 china &lt;- st_read(&quot;./demo_data/chinamap_data/bou2_4p.shp&quot;) %&gt;% st_set_crs(4326) %&gt;% group_by(NAME) %&gt;% summarize() ## Reading layer `bou2_4p&#39; from data source `G:\\R_for_Data_Science\\demo_data\\chinamap_data\\bou2_4p.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 925 features and 7 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 73.45 ymin: 6.319 xmax: 135.1 ymax: 53.56 ## CRS: NA china_uni &lt;- china %&gt;% mutate( NAME = iconv(NAME, &quot;GBK&quot;, &quot;UTF-8&quot;) ) %&gt;% mutate_at(vars(NAME), ~str_remove_all(., &quot;自治区|回族|维吾尔|壮族&quot;) ) %&gt;% mutate_at(vars(NAME), ~str_trim(.)) df &lt;- left_join(china_uni, df_price, by = c(&quot;NAME&quot; = &quot;name&quot;)) ggplot(data = df) + geom_sf( aes(fill = price_today &lt; 28), show.legend = FALSE) + geom_sf_text(aes(label = NAME), size = 3 ) + geom_sf_text(aes(label = price_today), size = 3, #nudge_x = c(-0.4, 0.5, 0.7), nudge_y = c(-1, -1, -1) ) + coord_sf(crs = 4326) + ggtitle(&quot;全国猪肉价格地图&quot;) "],["tidygraph.html", "第 50 章 社会网络分析 50.1 图论基本知识 50.2 网络分析 50.3 Network graph manipulation 50.4 Network analysis 50.5 小结 50.6 Network Visualization 50.7 扩展阅读", " 第 50 章 社会网络分析 本章通过tidygraph宏包介绍社会网络分析。社会网络分析涉及的知识比较多，而tidygraph将网络结构规整地比较清晰，降低了学习难度，很适合入门学习。 library(tidyverse) library(tidygraph) library(ggraph) 50.1 图论基本知识 网络图有两个主要特征: nodes and edges， nodes: edges: 当然还包括其它的概念，比如 adjacency matrix: edge list: Node list: Weighted network graph: Directed and undirected network graph: 有向图 无向图 50.2 网络分析 先介绍tidygraph宏包 50.2.1 tidygraph: A tidy API for graph manipulation 50.2.2 Tidy Network Anaylsis 在 tidygraph 框架, 网络数据可以分解成两个tidy数据框: 一个是 node data 一个是 edge data tidygraph 宏包提供了node数据框和edge数据框相互切换的方案，并且可以使用dplyr的语法操控 tidygraph 提供了常用的网络结构的algorithms，比如，计算网络拓扑结构中节点的重要性、中心度等。 50.2.3 Create network objects 创建网络对象主要有两个函数: tbl_graph(). Creates a network object from nodes and edges data as_tbl_graph(). Converts network data and objects to a tbl_graph network. 案例: 欧盟总统之间通话以及次数。 library(&quot;navdata&quot;) # devtools::install_github(&quot;kassambara/navdata&quot;) data(&quot;phone.call2&quot;) node_list &lt;- phone.call2$nodes node_list ## # A tibble: 16 x 2 ## id label ## &lt;int&gt; &lt;chr&gt; ## 1 1 France ## 2 2 Belgium ## 3 3 Germany ## 4 4 Danemark ## 5 5 Croatia ## 6 6 Slovenia ## 7 7 Hungary ## 8 8 Spain ## 9 9 Italy ## 10 10 Netherlands ## 11 11 UK ## 12 12 Austria ## 13 13 Poland ## 14 14 Switzerland ## 15 15 Czech republic ## 16 16 Slovania edge_list &lt;- phone.call2$edges edge_list ## # A tibble: 18 x 3 ## from to weight ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 3 9 ## 2 2 1 4 ## 3 1 8 3 ## 4 1 9 4 ## 5 1 10 2 ## 6 1 11 3 ## 7 3 12 2 ## 8 3 13 2 ## 9 2 3 3 ## 10 3 14 2 ## 11 3 15 2 ## 12 3 10 2 ## 13 4 3 2 ## 14 5 3 2 ## 15 5 16 2 ## 16 5 7 2 ## 17 6 3 2 ## 18 7 16 2.5 50.2.4 Use tbl_graph Create a tbl_graph network object using the phone call data: phone.net &lt;- tbl_graph(nodes = node_list, edges = edge_list, directed = TRUE) Visualize the network graph ggraph(phone.net, layout = &quot;graphopt&quot;) + geom_edge_link(width = 1, colour = &quot;lightgray&quot;) + geom_node_point(size = 4, colour = &quot;red&quot;) + geom_node_text(aes(label = label), repel = TRUE) + theme_graph() 50.2.5 Use as_tbl_graph mtcars data set: R 的内置数据集，记录了32种不同品牌的轿车的的11个属性 1、we create a correlation matrix network graph library(corrr) res.cor &lt;- datasets::mtcars[, c(1, 3:6)] %&gt;% # (1) t() %&gt;% correlate() %&gt;% # (2) shave(upper = TRUE) %&gt;% # (3) stretch(na.rm = TRUE) %&gt;% # (4) filter(r &gt;= 0.998) # (5) res.cor ## # A tibble: 59 x 3 ## x y r ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Mazda RX4 Mazda RX4 Wag 1.00 ## 2 Mazda RX4 Merc 230 1.00 ## 3 Mazda RX4 Merc 280 0.999 ## 4 Mazda RX4 Merc 280C 0.999 ## 5 Mazda RX4 Merc 450SL 0.998 ## 6 Mazda RX4 Wag Merc 230 1.00 ## 7 Mazda RX4 Wag Merc 280 0.999 ## 8 Mazda RX4 Wag Merc 280C 0.999 ## 9 Mazda RX4 Wag Merc 450SL 0.998 ## 10 Datsun 710 Toyota Corona 0.999 ## # ... with 49 more rows 2、Create the correlation network graph: set.seed(1) cor.graph &lt;- as_tbl_graph(res.cor, directed = FALSE) ggraph(cor.graph) + geom_edge_link() + geom_node_point() + geom_node_text( aes(label = name), size = 3, repel = TRUE ) + theme_graph() 50.2.6 Print out a network object cor.graph ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Node Data: 24 x 1 (active) ## name ## &lt;chr&gt; ## 1 Mazda RX4 ## 2 Mazda RX4 Wag ## 3 Datsun 710 ## 4 Hornet 4 Drive ## 5 Hornet Sportabout ## 6 Valiant ## # ... with 18 more rows ## # ## # Edge Data: 59 x 3 ## from to r ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## # ... with 56 more rows 50.2.7 extract the current active data cor.graph %&gt;% activate(edges) %&gt;% arrange(desc(r)) ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Edge Data: 59 x 3 (active) ## from to r ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 10 11 1.00 ## 3 10 12 1.00 ## 4 11 12 1.00 ## 5 8 9 1.00 ## 6 5 18 1.00 ## # ... with 53 more rows ## # ## # Node Data: 24 x 1 ## name ## &lt;chr&gt; ## 1 Mazda RX4 ## 2 Mazda RX4 Wag ## 3 Datsun 710 ## # ... with 21 more rows Note that, to extract the current active data as a tibble, you can use the function as_tibble(cor.graph). 50.3 Network graph manipulation 50.3.1 Car groups info (Number of cylinders) # Car groups info cars.group &lt;- tibble( name = rownames(datasets::mtcars), cyl = as.factor(datasets::mtcars$cyl) ) cars.group ## # A tibble: 32 x 2 ## name cyl ## &lt;chr&gt; &lt;fct&gt; ## 1 Mazda RX4 6 ## 2 Mazda RX4 Wag 6 ## 3 Datsun 710 4 ## 4 Hornet 4 Drive 6 ## 5 Hornet Sportabout 8 ## 6 Valiant 6 ## 7 Duster 360 8 ## 8 Merc 240D 4 ## 9 Merc 230 4 ## 10 Merc 280 6 ## # ... with 22 more rows 50.3.2 Modify the nodes data: # Modify the nodes data cor.graph &lt;- cor.graph %&gt;% activate(nodes) %&gt;% left_join(cars.group, by = &quot;name&quot;) %&gt;% rename(label = name) cor.graph ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Node Data: 24 x 2 (active) ## label cyl ## &lt;chr&gt; &lt;fct&gt; ## 1 Mazda RX4 6 ## 2 Mazda RX4 Wag 6 ## 3 Datsun 710 4 ## 4 Hornet 4 Drive 6 ## 5 Hornet Sportabout 8 ## 6 Valiant 6 ## # ... with 18 more rows ## # ## # Edge Data: 59 x 3 ## from to r ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## # ... with 56 more rows 50.3.3 Modify the edge data. # Modify the edge data. cor.graph &lt;- cor.graph %&gt;% activate(edges) %&gt;% rename(weight = r) cor.graph ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Edge Data: 59 x 3 (active) ## from to weight ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## 4 1 9 0.999 ## 5 1 11 0.998 ## 6 2 20 1.00 ## # ... with 53 more rows ## # ## # Node Data: 24 x 2 ## label cyl ## &lt;chr&gt; &lt;fct&gt; ## 1 Mazda RX4 6 ## 2 Mazda RX4 Wag 6 ## 3 Datsun 710 4 ## # ... with 21 more rows 50.3.4 Display the final modified graphs object: cor.graph ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Edge Data: 59 x 3 (active) ## from to weight ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## 4 1 9 0.999 ## 5 1 11 0.998 ## 6 2 20 1.00 ## # ... with 53 more rows ## # ## # Node Data: 24 x 2 ## label cyl ## &lt;chr&gt; &lt;fct&gt; ## 1 Mazda RX4 6 ## 2 Mazda RX4 Wag 6 ## 3 Datsun 710 4 ## # ... with 21 more rows 50.3.5 Visualize the correlation network set.seed(1) ggraph(cor.graph) + geom_edge_link(aes(width = weight), alpha = 0.2) + scale_edge_width(range = c(0.2, 1)) + geom_node_point(aes(color = cyl), size = 2) + geom_node_text(aes(label = label), size = 3, repel = TRUE) + theme_graph() 50.4 Network analysis 50.4.1 Centrality Centrality is an important concept when analyzing network graph. The tidygraph package contains more than 10 centrality measures, prefixed with the term centrality_ : # centrality_alpha() # centrality_power() # centrality_authority() # centrality_betweenness() # centrality_closeness() # centrality_hub() # centrality_degree() # centrality_pagerank() # centrality_eigen() # centrality_subgraph # centrality_edge_betweenness() example: - use the phone call network graph ( 欧盟总统之间通话以及次数) - compute nodes centrality set.seed(123) phone.net %&gt;% activate(nodes) %&gt;% mutate(centrality = centrality_authority()) ## # A tbl_graph: 16 nodes and 18 edges ## # ## # A directed acyclic simple graph with 1 component ## # ## # Node Data: 16 x 3 (active) ## id label centrality ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 France 1.61e- 1 ## 2 2 Belgium 1.15e-16 ## 3 3 Germany 1.00e+ 0 ## 4 4 Danemark 5.74e-17 ## 5 5 Croatia 1.15e-16 ## 6 6 Slovenia 5.74e-17 ## # ... with 10 more rows ## # ## # Edge Data: 18 x 3 ## from to weight ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 3 9 ## 2 2 1 4 ## 3 1 8 3 ## # ... with 15 more rows set.seed(123) phone.net %&gt;% activate(nodes) %&gt;% mutate(centrality = centrality_authority()) %&gt;% ggraph(layout = &quot;graphopt&quot;) + geom_edge_link(width = 1, colour = &quot;lightgray&quot;) + geom_node_point(aes(size = centrality, colour = centrality)) + geom_node_text(aes(label = label), repel = TRUE) + scale_color_gradient(low = &quot;yellow&quot;, high = &quot;red&quot;) + theme_graph() 50.4.2 Clustering Clustering is a common operation in network analysis and it consists of grouping nodes based on the graph topology. Many clustering algorithms from are available in the tidygraph package and prefixed with the term group_. These include: Infomap community finding. It groups nodes by minimizing the expected description length of a random walker trajectory. R function: group_infomap() Community structure detection based on edge betweenness. It groups densely connected nodes. R function: group_edge_betweenness() example: - use the correlation network graphs (记录了32种不同品牌的轿车的的11个属性) - detect clusters or communities set.seed(123) cluster_mtcars &lt;- cor.graph %&gt;% activate(nodes) %&gt;% mutate(community = as.factor(group_infomap())) cluster_mtcars ## # A tbl_graph: 24 nodes and 59 edges ## # ## # An undirected simple graph with 3 components ## # ## # Node Data: 24 x 3 (active) ## label cyl community ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; ## 1 Mazda RX4 6 1 ## 2 Mazda RX4 Wag 6 1 ## 3 Datsun 710 4 3 ## 4 Hornet 4 Drive 6 2 ## 5 Hornet Sportabout 8 2 ## 6 Valiant 6 2 ## # ... with 18 more rows ## # ## # Edge Data: 59 x 3 ## from to weight ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 2 1.00 ## 2 1 20 1.00 ## 3 1 8 0.999 ## # ... with 56 more rows cluster_mtcars %&gt;% ggraph(layout = &quot;graphopt&quot;) + geom_edge_link(width = 1, colour = &quot;lightgray&quot;) + geom_node_point(aes(colour = community), size = 4) + geom_node_text(aes(label = label), repel = TRUE) + theme_graph() 50.4.3 More Algorithms 50.5 小结 tidybayes很聪明地将复杂的网络结构用两个数据框表征出来，node 数据框负责节点的属性，edge 数据框负责网络连接的属性，调整其中的一个数据框，另一个也会相应的调整，比如node数据框中删除一个节点，edge数据框就会自动地删除该节点的所有连接。 50.6 Network Visualization 这里主要介绍tidygraph配套的ggraph宏包，它们的作者都是同一个人。 50.6.1 ggraph: A grammar of graphics for relational data ggraph 沿袭了ggplot2的语法规则， cluster_mtcars %&gt;% # Layout ggraph(layout = &quot;graphopt&quot;) + # Edges geom_edge_link( width = 1, colour = &quot;lightgray&quot; ) + # Nodes geom_node_point( aes(colour = community), size = 4 ) + geom_node_text( aes(label = label), repel = TRUE ) + theme_graph() 50.7 扩展阅读 https://www.data-imaginist.com/2017/introducing-tidygraph/ https://github.com/thomasp85/tidygraph https://christophergandrud.github.io/networkD3/ "],["tidytext.html", "第 51 章 文本挖掘", " 第 51 章 文本挖掘 library(tidyverse) library(tidytext) "],["tibbletime.html", "第 52 章 时间序列分析", " 第 52 章 时间序列分析 library(tidyverse) library(tibbletime) library(slider) "],["stars.html", "第 53 章 地理数据处理", " 第 53 章 地理数据处理 library(tidyverse) library(sf) library(stars) "],["rowwise.html", "第 54 章 tidyverse中行方向的操作 54.1 问题 54.2 rowwise函数 54.3 Row-wise Summaries 54.4 purrr::map方案 54.5 tidy 的方案 54.6 用slide方案 54.7 rowwise() + c_across() 54.8 用lay方案", " 第 54 章 tidyverse中行方向的操作 dplyr 1.0 推出之后，数据框行方向的操作得到完美解决，因此本章的内容已经过时，大家可以跳出本章，直接阅读第22 章。（留着本章，主要是让自己时常回顾下之前的探索。让自己最难忘的，或许就是曾经的痛点吧） library(tidyverse) tidyverse 喜欢数据框，因为一列就是一个向量，一列一列的处理起来很方便。然而我们有时候也要，完成行方向的操作，所以有必要介绍tidyverse中行方向的处理机制。 54.1 问题 df &lt;- tibble(x = 1:3, y = 4:6) df 对每行的求和、求均值、最小值或者最大值？ 54.2 rowwise函数 dplyr提供了rowwise函数，但大神说不推荐 df %&gt;% rowwise() %&gt;% mutate(i = sum(x, y)) df %&gt;% rowwise() %&gt;% mutate(i = mean(c(x, y))) df %&gt;% rowwise() %&gt;% mutate( min = min(x, y), max = max(x, y) ) df %&gt;% rowwise() %&gt;% do(i = mean(c(.$x, .$y))) %&gt;% unnest(i) 54.3 Row-wise Summaries df %&gt;% mutate(row_sum = rowSums(.[1:2])) df %&gt;% mutate(row_mean = rowMeans(.[1:2])) df %&gt;% mutate(t_sum = rowSums(select_if(., is.numeric))) 固然可解决问题， 然而，却不是一个很好的办法，比如除了求和与计算均值，可能还要计算每行的中位数、方差等等， 因为，不是每种计算都对应的row_函数？ 既然是tidyverse ，还是用tidyverse 的方法解决 54.4 purrr::map方案 按照Jenny Bryan的方案 df %&gt;% mutate(t_sum = pmap_dbl(list(x, y), sum)) df %&gt;% mutate(t_sum = pmap_dbl(select_if(., is.numeric), sum)) 计算均值的时候， 然而报错了 df %&gt;% mutate(t_sum = pmap_dbl(select_if(., is.numeric), mean)) tidyverse 总会想出办法来解决，把mean() 变成 lift_vd(mean) df %&gt;% mutate(data = pmap_dbl(select_if(., is.numeric), lift_vd(mean))) 同理 df %&gt;% mutate(t_median = pmap_dbl(select_if(., is.numeric), lift_vd(median))) df %&gt;% mutate(t_sd = pmap_dbl(select_if(., is.numeric), lift_vd(sd))) 54.5 tidy 的方案 我个人推荐的方法(Gather, group, summarize, left_join) new_df &lt;- df %&gt;% mutate(id = row_number()) s &lt;- new_df %&gt;% gather(&quot;time&quot;, &quot;val&quot;, -id) %&gt;% group_by(id) %&gt;% summarize( t_avg = mean(val), t_sum = sum(val) ) s new_df %&gt;% left_join(s) 有点繁琐，但思路清晰 ss &lt;- new_df %&gt;% group_by(id) %&gt;% summarise(t_avg = mean(c(x, y))) ss new_df %&gt;% left_join(ss) 之所以有这么多的搞法，是因为没有一个很好的搞法 54.6 用slide方案 slide很强大，可以滚动喔 如果第一个参数是数据框，slide把数据框看作a vector of rows， 然后行方向的滚动，事实上， .x是一个个的小数据框（如下） 与purrr::map不同，因为map把数据框看作列方向的向量， 然后迭代 如果第一个参数是原子型向量的话，还是依次迭代逗号分隔的元素，只不过这里是slide比map更强大的是，还可以是滚动 library(slider) df &lt;- tibble(a = 1:3, b = 4:6) slide( select_if(df, is.numeric), ~.x, .before = 1 ) df %&gt;% mutate( r_mean = slide_dbl( select_if(df, is.numeric), ~ mean(unlist(.x)), .before = 1 ) ) 54.7 rowwise() + c_across() df &lt;- tibble(id = 1:6, w = 10:15, x = 20:25, y = 30:35, z = 40:45) df df %&gt;% rowwise(id) %&gt;% summarise(mean = mean(c(w, x, y, z))) df %&gt;% rowwise(id) %&gt;% mutate(mean = mean(c(w, x, y, z))) df %&gt;% rowwise(id) %&gt;% mutate(total = mean(c_across(w:z))) df %&gt;% rowwise(id) %&gt;% mutate(mean = mean(c_across(is.numeric))) # across() df %&gt;% mutate(mean = rowMeans(across(is.numeric &amp; -id))) 54.8 用lay方案 lay包解决方案 library(lay) library(dplyr, warn.conflicts = FALSE) iris &lt;- as_tibble(iris) # apply mean to each &quot;row&quot; iris %&gt;% mutate(sepal = lay(across(starts_with(&quot;Sepal&quot;)), mean)) "],["ggplot2-academic.html", "第 55 章 科研数据可视化 55.1 统计分布图 55.2 说明", " 第 55 章 科研数据可视化 55.1 统计分布图 在学术中，很多情形我们都需要画出统计分布图。比如，围绕天气温度数据(美国内布拉斯加州东部，林肯市， 2016年)，我们想看每个月份里气温的分布情况 lincoln_df &lt;- ggridges::lincoln_weather %&gt;% mutate( month_short = fct_recode( Month, Jan = &quot;January&quot;, Feb = &quot;February&quot;, Mar = &quot;March&quot;, Apr = &quot;April&quot;, May = &quot;May&quot;, Jun = &quot;June&quot;, Jul = &quot;July&quot;, Aug = &quot;August&quot;, Sep = &quot;September&quot;, Oct = &quot;October&quot;, Nov = &quot;November&quot;, Dec = &quot;December&quot; ) ) %&gt;% mutate(month_short = fct_rev(month_short)) %&gt;% select(Month, month_short, `Mean Temperature [F]`) lincoln_df %&gt;% head(5) ## # A tibble: 5 x 3 ## Month month_short `Mean Temperature [F]` ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 January Jan 24 ## 2 January Jan 23 ## 3 January Jan 23 ## 4 January Jan 17 ## 5 January Jan 29 统计分布图的方法很多，我们下面比较各种方法的优劣。 55.1.1 points-errorbars 画分布图的最简单的方法，就是计算每个月的气温均值或者中位数，并在均值或者中位数位置标出误差棒(error bars)，比如图 55.1 。 lincoln_errbar &lt;- lincoln_df %&gt;% ggplot(aes(x = month_short, y = `Mean Temperature [F]`)) + stat_summary( fun.y = mean, fun.ymax = function(x) { mean(x) + 2 * sd(x) }, fun.ymin = function(x) { mean(x) - 2 * sd(x) }, geom = &quot;pointrange&quot;, fatten = 5 ) + xlab(&quot;month&quot;) + ylab(&quot;mean temperature (°F)&quot;) + theme_classic(base_size = 14) + theme( axis.text = element_text(color = &quot;black&quot;, size = 12), plot.margin = margin(3, 7, 3, 1.5) ) lincoln_errbar 图 55.1: 林肯市2016年气温变化图 但这个图有很多问题，或者说是错误的 图中只用了一个点和两个误差棒，丢失了很多分布信息。 读者不能很直观的读出这个点的含义（是均值还是中位数？） 误差棒代表的含义不明确（标准差？标准误？还是其他？） 通过看代码，知道这里用的是，均值加减2倍的标准差，其目的是想表达这个范围涵盖了95%的的数据。 事实上，误差棒一般用于标准误（或者加减2倍的标准误来代表估计均值的95%置信区间），所以这里使用标准差就造成了混淆。 ( 标准误：对样本均值估计的不确定性; 标准差：对偏离均值的分散程度 ) 现实的数据往往是偏态的，但这个图的误差棒几乎是对称，会让人觉得产生怀疑。 55.1.2 箱线图 为了解决以上问题，可以使用箱线图（boxplot），箱线图将数据分成若干段，如图 55.2. 图 55.2: 箱线图示意图 盒子中间的横线是中位数(50th percentile)，底部的横线代表第一分位数(25th percentile)，顶部的横线代表第三分位数(75th percentile) 盒子的范围覆盖了50%的数据，每个小盒子是25%的数据，盒子高度越短， 说明数据越集中，盒子高度越长，数据越分散。 上面的这条竖线的长度 = 从盒子上边缘开始，延伸到1.5倍盒子高度的范围中最远的点 下面的这条竖线的长度 = 从盒子下边缘开始，延伸到1.5倍盒子高度的范围中最远的点 在线条之外的点就是 outlies 那么气温分布用箱线图画出来 (图 55.3)。 我们可以看到12月份数据 偏态（绝大部分时候中等的冷，少部分是极度寒冷），其他月份，比如7月份，数据分布的比较正态 lincoln_box &lt;- lincoln_df %&gt;% ggplot(aes(x = month_short, y = `Mean Temperature [F]`)) + geom_boxplot(fill = &quot;grey90&quot;) + xlab(&quot;month&quot;) + ylab(&quot;mean temperature (°F)&quot;) + theme_classic(base_size = 14) + theme( axis.text = element_text(color = &quot;black&quot;, size = 12), plot.margin = margin(3, 7, 3, 1.5) ) lincoln_box 图 55.3: 林肯市2016年气温分布箱线图 55.1.3 小提琴图 箱线图是1970年代统计学家发明的一种可视化方法，这种图可以很方便地用手工画出，所以当时很流行，现在计算机性能大大提升了，所以大家喜欢用视觉上更直观的小提琴图取代箱线图 图 55.4: 小提琴图示意图 小提琴图相当于密度分布图旋转90度，然后再做个对称的镜像 最宽或者最厚的地方，对应着数据密度最大的地方 箱线图能用的地方小提琴图都能用，而且小提琴图可以很好的展示bimodal data的情况（箱线图做不到） 图 55.5: 图片来源：nature methods, VOL.11, NO.2, FEBRUARY 2014 在图 55.6， 我们使用小提琴图画图气温分布，可以看到，11月份的时候，有两个高密度区间（两个峰，50 degrees 和 35 degrees Fahrenheit），注意，这个信息在前面两个图中是没有的。 lincoln_violin &lt;- lincoln_df %&gt;% ggplot(aes(x = month_short, y = `Mean Temperature [F]`)) + geom_violin(fill = &quot;grey90&quot;) + xlab(&quot;month&quot;) + ylab(&quot;mean temperature (°F)&quot;) + theme_classic(base_size = 14) + theme( axis.text = element_text(color = &quot;black&quot;, size = 12), plot.margin = margin(3, 7, 3, 1.5) ) lincoln_violin 图 55.6: 林肯市2016年气温分布小提琴图 事实上，小提琴图也是不完美的，用的是密度分布图，会造成没有数据点的地方，也会有分布。怎么解决呢？ 55.1.4 sina 图 解决办法就是，把原始数据点打上去， lincoln_points &lt;- lincoln_df %&gt;% ggplot(aes(x = month_short, y = `Mean Temperature [F]`)) + geom_point(size = 0.75) + xlab(&quot;month&quot;) + ylab(&quot;mean temperature (°F)&quot;) + theme_classic(base_size = 14) + theme( axis.text = element_text(color = &quot;black&quot;, size = 12), plot.margin = margin(3, 7, 3, 1.5) ) lincoln_points 图 55.7: 林肯市2016年气温分布散点图 但问题又来了，这样会有大量重叠的点。有时候会采用透明度的办法，即给每个点设置透明度，某个位置颜色越深，说明这个位置重叠的越多。当然，最好的办法是，给每个点增加一个随机的很小的“偏移”，即抖散图。 lincoln_jitter &lt;- lincoln_df %&gt;% ggplot(aes(x = month_short, y = `Mean Temperature [F]`)) + geom_point(position = position_jitter(width = .15, height = 0, seed = 320), size = 0.75) + xlab(&quot;month&quot;) + ylab(&quot;mean temperature (°F)&quot;) + theme_classic(base_size = 14) + theme( axis.text = element_text( color = &quot;black&quot;, size = 12 ), plot.margin = margin(3, 7, 3, 1.5) ) lincoln_jitter 图 55.8: 林肯市2016年气温分布抖散图 于是，（小提琴图 + 抖散图）= sina 图，这样既可以看到原始的点，又可以看到统计分布，见图 55.9. lincoln_sina &lt;- lincoln_df %&gt;% ggplot(aes(x = month_short, y = `Mean Temperature [F]`)) + geom_violin(color = &quot;transparent&quot;, fill = &quot;gray90&quot;) + # dviz.supp::stat_sina(size = 0.85) + geom_jitter(width = 0.25, size = 0.85) + xlab(&quot;month&quot;) + ylab(&quot;mean temperature (°F)&quot;) + theme_classic(base_size = 14) + theme( axis.text = element_text( color = &quot;black&quot;, size = 12 ), plot.margin = margin(3, 7, 3, 1.5) ) lincoln_sina 图 55.9: 林肯市2016年气温分布 sina 图 55.1.5 山峦图 前面的图，分组变量（月份）是顺着x轴，这里介绍的山峦图（重山叠叠的感觉）分组变量是顺着y轴，这种图，在画不同时间的分布图的时候，效果非常不错。 比如图 55.10， 展示气温分布的山峦图。同样，图中很直观地展示了11月份的气温分布有两个峰值。 bandwidth &lt;- 3.4 lincoln_df %&gt;% ggplot(aes(x = `Mean Temperature [F]`, y = `Month`)) + geom_density_ridges( scale = 3, rel_min_height = 0.01, bandwidth = bandwidth, fill = colorspace::lighten(&quot;#56B4E9&quot;, .3), color = &quot;white&quot; ) + scale_x_continuous( name = &quot;mean temperature (°F)&quot;, expand = c(0, 0), breaks = c(0, 25, 50, 75) ) + scale_y_discrete(name = NULL, expand = c(0, .2, 0, 2.6)) + theme_minimal(base_size = 14) + theme( axis.text = element_text(color = &quot;black&quot;, size = 12), axis.text.y = element_text(vjust = 0), plot.margin = margin(3, 7, 3, 1.5) ) 图 55.10: 林肯市2016年气温分布山峦图 但这种图，也有一个问题，y轴是分组变量，x轴是数据的密度分布，缺少了密度分布的标度（即，缺少了密度图的高度，事实上，小提琴图也有这个毛病），所以这种图不适合比较精确的密度分布展示，但在探索性分析中，比较不同分组的密度分布，可以很方便获取直观的认知感受。 55.1.6 有颜色山峦图 我们看到 温度值越高，x轴坐标越靠右； 温度值越高，颜色更亮； 因此，可以将气温变量映射到位置属性和颜色属性，见图 55.11 bandwidth &lt;- 3.4 lincoln_base &lt;- lincoln_weather %&gt;% ggplot(aes(x = `Mean Temperature [F]`, y = `Month`, fill = ..x..)) + geom_density_ridges_gradient( scale = 3, rel_min_height = 0.01, bandwidth = bandwidth, color = &quot;black&quot;, size = 0.25 ) + scale_x_continuous( name = &quot;mean temperature (°F)&quot;, expand = c(0, 0), breaks = c(0, 25, 50, 75), labels = NULL ) + scale_y_discrete(name = NULL, expand = c(0, .2, 0, 2.6)) + colorspace::scale_fill_continuous_sequential( palette = &quot;Heat&quot;, l1 = 20, l2 = 100, c2 = 0, rev = FALSE ) + guides(fill = &quot;none&quot;) + theme_minimal(base_size = 14) + theme( axis.text = element_text(color = &quot;black&quot;, size = 12), axis.text.y = element_text(vjust = 0), plot.margin = margin(3, 7, 3, 1.5) ) # x axis labels temps &lt;- data.frame(temp = c(0, 25, 50, 75)) # calculate corrected color ranges # stat_joy uses the +/- 3*bandwidth calculation internally tmin &lt;- min(lincoln_weather$`Mean Temperature [F]`) - 3 * bandwidth tmax &lt;- max(lincoln_weather$`Mean Temperature [F]`) + 3 * bandwidth xax &lt;- axis_canvas(lincoln_base, axis = &quot;x&quot;, ylim = c(0, 2)) + geom_ridgeline_gradient( data = data.frame(temp = seq(tmin, tmax, length.out = 100)), aes(x = temp, y = 1.1, height = .9, fill = temp), color = &quot;transparent&quot; ) + geom_text( data = temps, aes(x = temp, label = temp), color = &quot;black&quot;, y = 0.9, hjust = 0.5, vjust = 1, size = 14 / .pt ) + colorspace::scale_fill_continuous_sequential( palette = &quot;Heat&quot;, l1 = 20, l2 = 100, c2 = 0, rev = FALSE ) lincoln_final &lt;- cowplot::insert_xaxis_grob(lincoln_base, xax, position = &quot;bottom&quot;, height = unit(0.1, &quot;null&quot;)) ggdraw(lincoln_final) 图 55.11: 林肯市2016年气温分布山峦图（颜色越亮，温度越高） 55.2 说明 本章的数据和代码来源于《Fundamentals of Data Visualization》的第9章和第20章。感谢Claus O. Wilke为大家写了这本非常好的书。 "],["ggplot2-colors.html", "第 56 章 数据可视化中的配色 56.1 配色模板 56.2 使用案例 56.3 color-wheel", " 第 56 章 数据可视化中的配色 library(tidyverse) library(palmerpenguins) 为了让图更好看，需要在画图中使用配色，但如果从颜色的色相、色度、明亮度三个属性（Hue-Chroma-Luminance ）开始学，感觉这样要学的东西太多了 . 事实上，大神们已经为我们准备好了很多好看的模板，我们可以偷懒直接拿来用. 我个人比较喜欢colorspace中的配色，今天我们就讲讲如何使用这个宏包！ library(colorspace) colorspace 宏包提供了三种类型的配色模板: Qualitative: 分类，用于呈现分类信息，比如不同种类用不同的颜色，颜色之间一般对比鲜明。 Sequential: 序列，用于呈现有序/连续的数值信息，比如为了展示某地区黑人比例，比例越高颜色越深，比例越低颜色越浅。 Diverging: 分歧，用于呈现有序/连续的数值信息，这些数值围绕着一个中心值，比中心值越大的方向用一种渐变色，比中心值越小用另一种渐变色。 三种类型对应着三个函数 qualitative_hcl(), sequential_hcl(), 和 diverging_hcl(). 56.1 配色模板 hcl_palettes(plot = TRUE) 56.2 使用案例 ggplot2默认 penguins %&gt;% ggplot(aes(bill_length_mm, fill = species)) + geom_density(alpha = 0.6) 手动修改 penguins %&gt;% ggplot(aes(bill_length_mm, fill = species)) + geom_density(alpha = 0.6) + scale_fill_manual( breaks = c(&quot;Adelie&quot;, &quot;Chinstrap&quot;, &quot;Gentoo&quot;), values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;) ) 模板配色 penguins %&gt;% ggplot(aes(bill_length_mm, fill = species)) + geom_density(alpha = 0.6) + scale_fill_discrete_qualitative(palette = &quot;cold&quot;) 56.3 color-wheel Adobe Color scheme Color "],["ggplot2-gganimate.html", "第 57 章 ggplot2之让你的数据骚动起来 57.1 为什么要使用动图 57.2 gganimate宏包 57.3 The grammar of animation 57.4 希望动画随哪个变量动起来 57.5 希望坐标轴随数据动起来 57.6 希望动画有个记忆 57.7 定义新数据出现和旧数据退去的方式 57.8 控制变化的节奏 57.9 标签 57.10 保存 57.11 案例演示一 57.12 案例演示二 57.13 案例演示三 57.14 课后作业", " 第 57 章 ggplot2之让你的数据骚动起来 这节课，我们讲如何让我们的图动起来。（因为渲染需要花费很长时间，所以文档中的动图代码都没有执行。） 57.1 为什么要使用动图 改进了图形在时间上和空间上的重新定位 传递更多信息 引人注意 57.2 gganimate宏包 动图可以将其理解为多张静态图堆在一起，当然不是随意的堆放，而是按照一定的规则，比如按照时间的顺序，或者类别的顺序。一般而言，动图制作包括两个步骤: 静态图制作及图形组装。静态图制作，前面几章我们讲过主要用ggplot2宏包实现；对于图形组装，需要用到今天我们要讲Thomas Lin Pedersen的gganimate宏包，来自同一工厂的产品，用起来自然是无缝衔接啦。 install.packages(&quot;gganimate&quot;) 57.2.1 先来一张静态图 library(tidyverse) library(covdata) # remotes::install_github(&quot;kjhealy/covdata&quot;) library(gganimate) covdata::covnat %&gt;% dplyr::filter(iso3 == &quot;USA&quot;) %&gt;% dplyr::filter(cu_cases &gt; 0) %&gt;% ggplot(aes(x = date, y = cases)) + geom_path() + labs( title = &quot;美国新冠肺炎累积确诊病例&quot;, subtitle = &quot;数据来源https://kjhealy.github.io/covdata/&quot; ) 让它动起来，我们只需要增加一行代码！ covdata::covnat %&gt;% dplyr::filter(iso3 == &quot;USA&quot;) %&gt;% dplyr::filter(cu_cases &gt; 0) %&gt;% ggplot(aes(x = date, y = cases)) + geom_path() + labs( title = &quot;美国新冠肺炎累积确诊病例 {frame_along}&quot;, subtitle = &quot;数据来源https://kjhealy.github.io/covdata/&quot; ) + transition_reveal(along = date) 57.2.2 相对复杂点的例子 library(datasauRus) ggplot(datasaurus_dozen) + aes(x, y, color = dataset) + geom_point() 用分面展示 ggplot(datasaurus_dozen) + aes(x, y, color = dataset) + geom_point() + facet_wrap(~dataset) 可以用动图展示 ggplot(datasaurus_dozen) + aes(x, y, color = dataset) + geom_point() + transition_states(dataset, 3, 1) + # &lt;&lt; labs(title = &quot;Dataset: {closest_state}&quot;) 是不是很炫酷，下面我们就一个个讲解其中的函数。 57.3 The grammar of animation 使用gganimate做动画，只需要掌握以下五类函数： transition_*(): 定义动画是根据哪个变量进行”动”，以及如何”动” view_*(): 定义坐标轴随数据变化. shadow_*(): 影子（旧数据的历史记忆）?定义点相继出现的方式. enter_*()/exit_*(): 定义新数据出现和旧数据退去的方式. ease_aes(): 美观定义，控制变化的节奏(如何让整个动画看起来更舒适). 下面通过案例依次讲解这些函数功能。 57.4 希望动画随哪个变量动起来 变量如何选择，这需要从变量类型和变量代表的信息来确定。 57.4.1 transition_states transition_states(states = ), 这里的参数states往往带有分组信息，可以等价于静态图中的分面。 diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + facet_wrap(vars(color)) diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_states(states = color, transition_length = 3, state_length = 1) 57.4.2 transition_time transition_time(time = ), 这里的time一般认为是连续的值，相比于transition_states，没有了transtion_length这个选项，是因为transtion_length默认为time. 事实上，transition_time是transition_states的一种特例，但其实也有分组的要求 p &lt;- gapminder::gapminder %&gt;% ggplot(aes(x = gdpPercap, y = lifeExp, size = pop, colour = country)) + geom_point(alpha = 0.7, show.legend = FALSE) + scale_size(range = c(2, 12)) + scale_x_log10() + labs( x = &quot;GDP per capita&quot;, y = &quot;life expectancy&quot; ) p anim &lt;- p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) anim 57.4.3 transition_reveal transition_reveal(along = ), along 这个词可以看出，它是按照某个变量依次显示的意思，比如顺着x轴显示 ggplot(data = economics) + aes(x = date, y = unemploy) + geom_line() ggplot(economics) + aes(x = date, y = unemploy) + geom_line() + transition_reveal(along = date) + labs(title = &quot;now is {frame_along}&quot;) 57.4.4 transition_filter transition_filter( 至少2个筛选条件，transition_length = , filter_length =), 动图将会在这些筛选条件对应的子图之间转换 diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_filter( transition_length = 3, filter_length = 1, cut == &quot;Ideal&quot;, Deep = depth &gt;= 60 ) 57.4.5 transition_layers transition_layers(): 依次显示每个图层 mtcars %&gt;% ggplot(aes(mpg, disp)) + geom_point() + geom_smooth(colour = &quot;grey&quot;, se = FALSE) + geom_smooth(aes(colour = factor(gear))) + transition_layers( layer_length = 1, transition_length = 2, from_blank = FALSE, keep_layers = c(Inf, 0, 0) ) + enter_fade() + exit_fade() 57.4.6 其他 transition_manual() transition_components() transition_events() 57.5 希望坐标轴随数据动起来 动画过程中，绘图窗口怎么变化呢？ 57.5.1 view_follow ggplot(iris, aes(Sepal.Length, Sepal.Width)) + geom_point() + labs(title = &quot;{closest_state}&quot;) + transition_states(Species, transition_length = 4, state_length = 1) + view_follow() 57.5.2 其它 view_step() view_step_manual() view_zoom() view_zoom_manual() 57.6 希望动画有个记忆 shadow_wake(wake_length =, ) 旧数据消退时，制造点小小的尾迹的效果（wake除了叫醒，还有尾迹的意思，合起来就是记忆_尾迹） shadow_trail(distance = 0.05) 旧数据消退时，制造面包屑一样的残留痕迹（记忆_零星残留） shadow_mark(past = TRUE, future = FALSE) 将旧数据和新数据当作背景（记忆_标记） 57.6.1 shadow_wake() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + shadow_wake(wake_length = 0.1, alpha = FALSE) ggplot(iris, aes(Petal.Length, Sepal.Length)) + geom_point(size = 2) + labs(title = &quot;{closest_state}&quot;) + transition_states(Species, transition_length = 4, state_length = 1) + shadow_wake(wake_length = 0.1) 57.6.2 shadow_trail() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + shadow_trail(distance = 0.1) ggplot(iris, aes(Petal.Length, Sepal.Length)) + geom_point(size = 2) + labs(title = &quot;{closest_state}&quot;) + transition_states(Species, transition_length = 4, state_length = 1) + shadow_trail(distance = 0.1) 57.6.3 shadow_mark() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + shadow_mark(alpha = 0.3, size = 0.5) ggplot(airquality, aes(Day, Temp)) + geom_line(color = &quot;red&quot;, size = 1) + transition_time(Month) + shadow_mark(colour = &quot;black&quot;, size = 0.75) 57.7 定义新数据出现和旧数据退去的方式 出现和退去的函数是成对的 57.7.1 enter/exit_fade() 透明度上的变化，我这里用柱状图展示，效果要明显一点。 tibble( x = month.name, y = sample.int(12) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_col() + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) + transition_states(states = month.name) tibble( x = month.name, y = sample.int(12) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_col() + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) + transition_states(states = month.name) + shadow_mark(past = TRUE) + enter_fade() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + enter_fade() 57.7.2 enter_grow()/exit_shrink() 大小上的变化 tibble( x = month.name, y = sample.int(12) ) %&gt;% ggplot(aes(x = x, y = y)) + geom_col() + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) + transition_states(states = month.name) + shadow_mark(past = TRUE) + enter_grow() p + transition_time(time = year) + labs(title = &quot;year: {frame_time}&quot;) + enter_grow() + enter_fade() 57.8 控制变化的节奏 控制数据点变化的快慢 p + ease_aes({aesthetic} = {ease}) p + ease_aes(x = &quot;cubic&quot;) knitr::include_graphics(&quot;images/ease.png&quot;) Source: https://easings.net/ 看下面的案例： diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_states(color, transition_length = 3, state_length = 1) + ease_aes(&quot;cubic-in&quot;) # Change easing of all aesthetics diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_states(color, transition_length = 3, state_length = 1) + ease_aes(x = &quot;elastic-in&quot;) # Only change `x` (others remain “linear”) 57.9 标签 我们可能需要在标题中加入每张动画的信息，常用罗列如下 transition_states(states = ) + labs(title = &quot;previous is {previous_state}, current is {closest_state}, next is {next_state}&quot;) transition_layers() + labs(title = &quot;previous is {previous_layers}, current is {closest_layers}, next is {next_layers}&quot;) transition_time(time = ) + labs(title = &quot;now is {frame_time}&quot;) transition_reveal(along = ) + labs(title = &quot;now is {frame_along}&quot;) 57.10 保存 57.10.1 Renderer options ## # A tibble: 6 x 2 ## Function Description ## &lt;chr&gt; &lt;chr&gt; ## 1 gifski_rende~ Default, super fast gif renderer. ## 2 magick_rende~ Somewhat slower gif renderer. ## 3 ffmpeg_rende~ Uses ffmpeg to create a video from the~ ## 4 av_renderer Uses the av package to create a video ~ ## 5 file_renderer Dumps a list of image frames from the ~ ## 6 sprite_rende~ Creates a spritesheet from frames of t~ 57.10.2 常用方法 一般用anim_save()保存为 gif 格式，方法类似ggsave() animation_to_save &lt;- diamonds %&gt;% ggplot(aes(carat, price)) + geom_point() + transition_states(color, transition_length = 3, state_length = 1) + ease_aes(&quot;cubic-in&quot;) anim_save(&quot;first_saved_animation.gif&quot;, animation = animation_to_save) 57.11 案例演示一 这是网上有段时间比较火的racing_bar图 ranked_by_date &lt;- covdata::covnat %&gt;% group_by(date) %&gt;% arrange(date, desc(cu_cases)) %&gt;% mutate(rank = 1:n()) %&gt;% filter(rank &lt;= 10) %&gt;% ungroup() ranked_by_date %&gt;% filter(date &gt;= &quot;2020-05-01&quot;) %&gt;% ggplot( aes(x = rank, y = cname, group = cname, fill = cname) ) + geom_tile( aes( y = cu_cases / 2, height = cu_cases, width = 0.9 ), alpha = 0.8, show.legend = F ) + geom_text(aes( y = cu_cases, label = cname ), show.legend = FALSE ) + scale_x_reverse( breaks = c(1:10), label = c(1:10) ) + theme_minimal() + coord_flip(clip = &quot;off&quot;, expand = FALSE) + labs( title = &quot;日期: {closest_state}&quot;, x = &quot;&quot;, caption = &quot;Source: github/kjhealy/covdata&quot; ) + transition_states(date, transition_length = 4, state_length = 1, wrap = TRUE ) + ease_aes(&quot;cubic-in-out&quot;) 57.12 案例演示二 bats &lt;- readr::read_csv(&quot;./demo_data/bats-subset.csv&quot;) %&gt;% dplyr::mutate(id = factor(id)) bats %&gt;% ggplot(aes( x = longitude, y = latitude, group = id, color = id )) + geom_point() 57.12.1 常规的方法 bats %&gt;% ggplot(aes( x = longitude, y = latitude, group = id, color = id )) + geom_point() + transition_time(time) + shadow_mark(past = TRUE) geom_path()是按照数据点出现的先后顺序 geom_line()是按照数据点在x轴的顺序 bats %&gt;% ggplot(aes( x = longitude, y = latitude, group = id, color = id )) + geom_path() + transition_time(time) + shadow_mark(past = TRUE) 57.12.2 炫酷点的 bats %&gt;% dplyr::mutate( image = &quot;images/bat-cartoon.png&quot; ) %&gt;% ggplot(aes( x = longitude, y = latitude, group = id, color = id )) + geom_path() + ggimage::geom_image(aes(image = image), size = 0.1) + transition_reveal(time) 57.13 案例演示三 全球R-Ladies组织，会议活动的情况，我们在地图上用动图展示 rladies &lt;- read_csv(&quot;./demo_data/rladies.csv&quot;) rladies 这里需要一个地图，可以这样 ggplot() + ggplot2::borders(&quot;world&quot;, colour = &quot;gray85&quot;, fill = &quot;gray80&quot;) + ggthemes::theme_map() 当然，最好是这样 library(maps) world &lt;- map_data(&quot;world&quot;) world_map &lt;- ggplot() + geom_polygon(data = world, aes(x = long, y = lat, group = group), color = &quot;white&quot;, fill = &quot;gray80&quot; ) + ggthemes::theme_map() world_map 然后把点打上去 world_map + geom_point( data = rladies, aes(x = lon, y = lat, size = followers), colour = &quot;purple&quot;, alpha = .5 ) + scale_size_continuous( range = c(1, 8), breaks = c(250, 500, 750, 1000) ) + labs(size = &quot;Followers&quot;) 用动图展示（这种方法常用在流行病传播的展示上） world_map + geom_point(aes(x = lon, y = lat, size = followers), data = rladies, colour = &quot;purple&quot;, alpha = .5 ) + scale_size_continuous( range = c(1, 8), breaks = c(250, 500, 750, 1000) ) + transition_states(created_at) + shadow_mark(past = TRUE) + labs(title = &quot;Day: {closest_state}&quot;) 57.14 课后作业 57.14.1 作业1 把下图弄成你喜欢的样子 library(gapminder) theme_set(theme_bw()) ggplot(gapminder) + aes( x = gdpPercap, y = lifeExp, size = pop, colour = country ) + geom_point(show.legend = FALSE) + scale_x_log10() + scale_color_viridis_d() + scale_size(range = c(2, 12)) + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy&quot;) + transition_time(year) + labs(title = &quot;Year: {frame_time}&quot;) 57.14.2 作业2 那请说说这以下三个的区别？ bats %&gt;% dplyr::filter(id == 1) %&gt;% ggplot( aes( x = longitude, y = latitude ) ) + geom_point() + transition_reveal(time) # &lt;&lt; bats %&gt;% dplyr::filter(id == 1) %&gt;% ggplot( aes( x = longitude, y = latitude ) ) + geom_point() + transition_states(time) # &lt;&lt; bats %&gt;% dplyr::filter(id == 1) %&gt;% ggplot( aes( x = longitude, y = latitude ) ) + geom_point() + transition_time(time) # &lt;&lt; "],["lazyman.html", "第 58 章 懒人系列 58.1 列名太乱了 58.2 比count()更懂我的心 58.3 比distinct()更知我心 58.4 代码太乱了，谁帮我整理下 58.5 谁帮我敲模型的公式 58.6 模型有了，不知道怎么写论文？ 58.7 模型评估一步到位 58.8 统计表格不用愁 58.9 统计结果写图上 58.10 正则表达式太南了 58.11 颜控怎么配色？ 58.12 画图颜色好看不 58.13 宏包太多 58.14 犹抱琵琶半遮面 58.15 整理Rmarkdown 58.16 如何有效的提问 58.17 程序结束后记得提醒我 58.18 多张图摆放 58.19 缺失值处理 58.20 看看数据什么情况 58.21 管道都不想 58.22 各种插件，任君选取", " 第 58 章 懒人系列 R社区上很多大神，贡献了很多非常优秀的工具，节省了我们的时间，也给我们的生活增添了无限乐趣。我平时逛github的时候时整理一些，现在分享出来供像我一样的懒人用，因此本文档叫“懒人系列”。欢迎大家补充。 58.1 列名太乱了 library(tidyverse) library(janitor) ## install.packages(&quot;janitor&quot;) ## https://github.com/sfirke/janitor fake_raw &lt;- tibble::tribble( ~id, ~`count/num`, ~W.t, ~Case, ~`time--d`, ~`%percent`, 1L, &quot;china&quot;, 3L, &quot;w&quot;, 5L, 25L, 2L, &quot;us&quot;, 4L, &quot;f&quot;, 6L, 34L, 3L, &quot;india&quot;, 5L, &quot;q&quot;, 8L, 78L ) fake_raw ## # A tibble: 3 x 6 ## id `count/num` W.t Case `time--d` `%percent` ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 1 china 3 w 5 25 ## 2 2 us 4 f 6 34 ## 3 3 india 5 q 8 78 fake_raw %&gt;% janitor::clean_names() ## # A tibble: 3 x 6 ## id count_num w_t case time_d percent_percent ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 1 china 3 w 5 25 ## 2 2 us 4 f 6 34 ## 3 3 india 5 q 8 78 58.2 比count()更懂我的心 mtcars %&gt;% dplyr::count(cyl) ## # A tibble: 3 x 2 ## cyl n ## &lt;dbl&gt; &lt;int&gt; ## 1 4 11 ## 2 6 7 ## 3 8 14 mtcars %&gt;% janitor::tabyl(cyl) ## cyl n percent ## 4 11 0.3438 ## 6 7 0.2188 ## 8 14 0.4375 58.3 比distinct()更知我心 df &lt;- tribble( ~id, ~date, ~store_id, ~sales, 1, &quot;2020-03-01&quot;, 1, 100, 2, &quot;2020-03-01&quot;, 2, 100, 3, &quot;2020-03-01&quot;, 3, 150, 4, &quot;2020-03-02&quot;, 1, 110, 5, &quot;2020-03-02&quot;, 3, 101 ) df %&gt;% janitor::get_dupes(store_id) ## # A tibble: 4 x 5 ## store_id dupe_count id date sales ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 2 1 2020-03-01 100 ## 2 1 2 4 2020-03-02 110 ## 3 3 2 3 2020-03-01 150 ## 4 3 2 5 2020-03-02 101 df %&gt;% janitor::get_dupes(date) ## # A tibble: 5 x 5 ## date dupe_count id store_id sales ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-03-01 3 1 1 100 ## 2 2020-03-01 3 2 2 100 ## 3 2020-03-01 3 3 3 150 ## 4 2020-03-02 2 4 1 110 ## 5 2020-03-02 2 5 3 101 58.4 代码太乱了，谁帮我整理下 ## install.packages(&quot;styler&quot;) 安装后，然后这两个地方点两下，就发现你的代码整齐很多了。或者直接输入 styler:::style_active_file() 58.5 谁帮我敲模型的公式 library(equatiomatic) ## https://github.com/datalorax/equatiomatic mod1 &lt;- lm(mpg ~ cyl + disp, mtcars) extract_eq(mod1) \\[ \\operatorname{mpg} = \\alpha + \\beta_{1}(\\operatorname{cyl}) + \\beta_{2}(\\operatorname{disp}) + \\epsilon \\] extract_eq(mod1, use_coefs = TRUE) \\[ \\operatorname{mpg} = 34.66 - 1.59(\\operatorname{cyl}) - 0.02(\\operatorname{disp}) + \\epsilon \\] 58.6 模型有了，不知道怎么写论文？ library(report) ## https://github.com/easystats/report model &lt;- lm(Sepal.Length ~ Species, data = iris) report(model) We fitted a linear model (estimated using OLS) to predict Sepal.Length with Species (formula = Sepal.Length ~ Species). Standardized parameters were obtained by fitting the model on a standardized version of the dataset. Effect sizes were labelled following Cohen’s (1988) recommendations. The model explains a significant and substantial proportion of variance (R2 = 0.62, F(2, 147) = 119.26, p &lt; .001, adj. R2 = 0.61). The model’s intercept, corresponding to Sepal.Length = 0 and Species = setosa, is at 5.01 (SE = 0.07, 95% CI [4.86, 5.15], p &lt; .001). Within this model: The effect of Species [versicolor] is positive and can be considered as large and significant (beta = 0.93, SE = 0.10, 95% CI [0.73, 1.13], std. beta = 1.12, p &lt; .001). The effect of Species [virginica] is positive and can be considered as large and significant (beta = 1.58, SE = 0.10, 95% CI [1.38, 1.79], std. beta = 1.91, p &lt; .001). 58.7 模型评估一步到位 library(performance) model &lt;- lm(mpg ~ wt * cyl + gear, data = mtcars) performance::check_model(model) 58.8 统计表格不用愁 library(gtsummary) ## https://github.com/ddsjoberg/gtsummary gtsummary::trial %&gt;% dplyr::select(trt, age, grade, response) %&gt;% gtsummary::tbl_summary( by = trt, missing = &quot;no&quot; ) %&gt;% gtsummary::add_p() %&gt;% gtsummary::add_overall() %&gt;% gtsummary::add_n() %&gt;% gtsummary::bold_labels() 直接复制到论文即可 t1 &lt;- glm(response ~ trt + age + grade, trial, family = binomial) %&gt;% gtsummary::tbl_regression(exponentiate = TRUE) t2 &lt;- survival::coxph(survival::Surv(ttdeath, death) ~ trt + grade + age, trial) %&gt;% gtsummary::tbl_regression(exponentiate = TRUE) gtsummary::tbl_merge( tbls = list(t1, t2), tab_spanner = c(&quot;**Tumor Response**&quot;, &quot;**Time to Death**&quot;) ) 58.9 统计结果写图上 library(ggplot2) library(statsExpressions) # https://github.com/IndrajeetPatil/statsExpressions ggplot(mtcars, aes(x = mpg, y = wt)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs( title = &quot;Spearman&#39;s rank correlation coefficient&quot;, subtitle = expr_corr_test(mtcars, mpg, wt, type = &quot;nonparametric&quot;) ) 58.10 正则表达式太南了 library(inferregex) ## remotes::install_github(&quot;daranzolin/inferregex&quot;) s &lt;- &quot;abcd-9999-ab9&quot; infer_regex(s)$regex ## [1] &quot;^[a-z]{4}-\\\\d{4}-[a-z]{2}\\\\d$&quot; 有了它，妈妈再也不担心我的正则表达式了 58.11 颜控怎么配色？ library(ggthemr) ## devtools::install_github(&#39;cttobin/ggthemr&#39;) ggthemr(&quot;dust&quot;) mtcars %&gt;% mutate(cyl = factor(cyl)) %&gt;% ggplot(aes(x = mpg, fill = cyl, colour = cyl)) + geom_density(alpha = 0.75) + labs(fill = &quot;Cylinders&quot;, colour = &quot;Cylinders&quot;, x = &quot;MPG&quot;, y = &quot;Density&quot;) + legend_top() 用完别忘了 ggthemr_reset() 58.12 画图颜色好看不 scales也是大神的作品，功能多多 ## https://github.com/r-lib/scales library(scales) show_col(viridis_pal()(10)) 不推荐个人配色，因为我们不专业。直接用专业的配色网站 colorbrewer 先看看颜色，再选择 58.13 宏包太多 library(pacman) ## p_load(lattice, foreign, boot, rpart) 唉，这个library()都要偷懒，真服了你们了 58.14 犹抱琵琶半遮面 ## https://github.com/EmilHvitfeldt/gganonymize library(ggplot2) library(gganonymize) ggg &lt;- ggplot(mtcars, aes(as.factor(cyl))) + geom_bar() + labs( title = &quot;Test title&quot;, subtitle = &quot;Test subtitle, this one have a lot lot lot lot lot more text then the rest&quot;, caption = &quot;Test caption&quot;, tag = 1 ) + facet_wrap(~vs) gganonomize(ggg) 你可以看我的图，但就不想告诉你图什么意思，因为我加密了 58.15 整理Rmarkdown # remotes::install_github(&quot;tjmahr/WrapRmd&quot;) # remotes::install_github(&quot;fkeck/quickview&quot;) # remotes::install_github(&quot;mwip/beautifyR&quot;) 58.16 如何有效的提问 直接看官方网站，这里不举例了 ## install.packages(&quot;reprex&quot;) ## https://reprex.tidyverse.org/ 58.17 程序结束后记得提醒我 ## beepr::beep(sound = &quot;mario&quot;) 你听到了声音吗? 58.18 多张图摆放 library(patchwork) p1 &lt;- ggplot(mtcars) + geom_point(aes(mpg, disp)) p2 &lt;- ggplot(mtcars) + geom_boxplot(aes(gear, disp, group = gear)) p3 &lt;- ggplot(mtcars) + geom_smooth(aes(disp, qsec)) p1 + p2 + p3 58.19 缺失值处理 library(naniar) ## https://github.com/njtierney/naniar airquality %&gt;% group_by(Month) %&gt;% naniar::miss_var_summary() ## # A tibble: 25 x 4 ## # Groups: Month [5] ## Month variable n_miss pct_miss ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 5 Ozone 5 16.1 ## 2 5 Solar.R 4 12.9 ## 3 5 Wind 0 0 ## 4 5 Temp 0 0 ## 5 5 Day 0 0 ## 6 6 Ozone 21 70 ## 7 6 Solar.R 0 0 ## 8 6 Wind 0 0 ## 9 6 Temp 0 0 ## 10 6 Day 0 0 ## # ... with 15 more rows 58.20 看看数据什么情况 library(visdat) vis_dat(airquality) 58.21 管道都不想 管道都不想写， 写代码还有美感？ ## library(nakepipe) 58.22 各种插件，任君选取 ## https://github.com/daattali/addinslist "],["exams.html", "A 期末考试 A.1 方式 A.2 要求 A.3 数据集", " A 期末考试 研究生生涯的主要工作就是学习，而学以致用是最好的学习路径。考虑同学们不同的学科背景，同时也参考国内其它高校的做法，本学期《数据科学中的 R 语言》期末考试安排如下： A.1 方式 结合所在学科，找一篇与自己研究方向相关的文献，用课堂上学到的R统计编程技能，重复文献的数据分析过程。 A.2 要求 在2020年06月15日前，将以下资料打包并提交38552109@qq.com邮箱 所重复的文献（并在文献中高亮你重复的部分） 数据 Rmarkdown源代码 分析结果(生成的pdf或者html文件) 注明学号和姓名 A.3 数据集 仅供参考 https://datahub.io/collections/economic-data https://cnki.net/ https://osf.io/ https://www.kaggle.com/datasets https://toolbox.google.com/datasetsearch https://chfs.swufe.edu.cn/（中国家庭金融调查） http://www.isss.pku.edu.cn/cfps/index.htm（中国家庭追踪调查） http://www.ciejournal.org/ (中国工业经济) http://www.stats.gov.cn/tjsj/ndsj/ (中国统计年鉴) https://www.oecd.org/pisa/ 国际学生评估项目 (PISA) "],["references.html", "参考文献", " 参考文献 Grolemund, Garrett. 2014. Hands-on Programming with r. 1 edition. Houston: O’Reilly Media. https://rstudio-education.github.io/hopr/. Grolemund, Garrett, and Hadley Wickham. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1 edition. Houston: O’Reilly Media. http://r4ds.had.co.nz/. "]]
